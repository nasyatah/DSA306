---
title: "EDAv1.0"
output: html_document
date: "2023-09-21"
---

```{r}
# OPEN CSV FILE HERE
# transactions <- arrow::open_dataset(sources = "transactions.csv", format = "csv")
# SAVE DATASET IN PARQUET FORMAT HERE
# Create AAPL directory
# dir.create("parquet_folder")  
# write parquet file to directory
# arrow::write_dataset(transactions,format = "parquet", path = "parquet_folder",partitioning = NULL)
```

```{r}
#OPEN SAVED PARQUET FILE HERE
transactions_parquet <- arrow::open_dataset(
  sources = "parquet_folder/part-0.parquet",
  format = "parquet")

# Collect the data into a data frame
transaction_df <- transactions_parquet |>
  dplyr::collect()

```

```{r}
library(sparklyr)
library(dplyr)

# Connect to a local instance of Spark
sc <- spark_connect(master = "local", version = "3.4.0")
```

```{r}
# Copy the transactions R data frame to Spark memory and create the R reference transaction_ref
transaction_ref <- copy_to(sc, transaction_df)    
head(transaction_ref, 4)  
```
1. Data Cleaning
1.1 Generating summary statistics for every column - applicable to numerical variables
```{r}
#summary statistics for every column
sdf_describe(transaction_ref, cols = colnames(transaction_ref)) 
```
1.2 Checking for null values in every column
```{r}
#check the number of na values present in every column 
na_values <- transaction_ref |>
  summarise_all(~sum(as.integer(is.na(.))))
na_values
```
```{r}
#check for unique values 
unique_date <- transaction_ref |>
  select(Date) |>
  distinct()

unique_date
```



1.3 Checking for negative values in the Quantity column
```{r}
transaction_ref |> 
  filter(Quantity < 0)
```
1.4 Number of unique customerno
```{r}
unique_customers <- transaction_ref |>
  group_by(CustomerNo, Country) |> #finds out which country is each customer from
  summarise(total_products_bought = n_distinct(ProductNo), 
            total_spent = sum(Price*Quantity),
            total_transactions = n())|>
  collect()

unique_customers

#initial code: changed code to add more columns 
#unique_customers <- transaction_ref |>
#  group_by(CustomerNo) |>
#  summarise(count = n()) |>
#  collect()

row_count <- unique_customers |>
count()

# Extract the count value
total_rows <- row_count$n
total_rows
```

1.5 removing rows with NA CustomerNo, and rows with negative quantity

```{r}
transaction_df <- transaction_ref |>
  filter(!is.na(CustomerNo) & Quantity > 0) |>
  collect()

#USE TRANS DF FOR ALL FUTURE ANALYSIS??
```

1.6 Converting date to date format
```{r}
library(dplyr)

transaction_df <- transaction_ref |>
    mutate(
    month = substring_index(Date, "/", 1),
    day = substring_index(substring_index(Date, "/", -2), "/", 1),
    year = substring_index(Date, "/", -1)
  ) 
# Add leading zeros to month and day
transaction_df <- transaction_ref |>
  mutate(
    month = lpad(month, 2, "0"),
    day = lpad(day, 2, "0")
  )

# Combine the formatted values to create the "MM/dd/yyyy" date
transaction_df <- transaction_ref %>%
  mutate(FormattedDate = concat(year, "-", month, "-", day)) |>
  select(-month, -day, -year, -Date)

#convert to date format from chr
transaction_df <-transaction_ref |>
  mutate(date_parsed = to_date(FormattedDate, "yyyy/mm/dd"))

transaction_df

```


1.7 Create new columns for Recency, Frequency, Monetary values
https://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp 
```{r}
# Calculate Recency, Frequency, and Monetary values 
# edit: added variables to rfm_df
rfm_df <- transaction_ref |>
  group_by(CustomerNo, Country) |>
  summarise(
    Recency = as.numeric(datediff(max(date_parsed), to_date("2019-12-31"))),
    Frequency = n(),
    Monetary = sum(Price * Quantity),
    ConcatenatedProductNames = concat_ws(", ", collect_list(ProductName)),
    total_products_bought = n_distinct(ProductNo), 
    total_spent = sum(Price*Quantity),
    total_transactions = n()
    )

# Show the resulting RFM DataFrame
head(rfm_df)
```

```{r}
#compute the percentile values for the Recency, Frequency and Monetary value columns 

rfm_df <- rfm_df|>
  mutate(r_percentile = percent_rank(Recency),
         f_percentile = percent_rank(Frequency),
         m_percentile = percent_rank(Monetary))

head(rfm_df)
```

```{r}
#countries with the most customers 
library(dbplot)
library(ggplot2)


dbplot_bar(unique_customers, x = Country, Customers = sum(CustomerNo))
```

```{r}
#grouping the data by customer id and transaction date and get the count and then see how many rows have a count >1

sameday_transasctions <- transaction_ref |>
  group_by(CustomerNo, FormattedDate) |>
  summarise(total_products_bought = n_distinct(ProductNo), 
            total_spent = sum(Price*Quantity),
            total_transactions = n())

sameday_transasctions <- sameday_transasctions |>
  filter(total_transactions> 1)
sameday_transasctions

num_customers <- sameday_transasctions |>
  group_by(FormattedDate) |>
  summarise(num_of_customers = n_distinct(CustomerNo))
num_customers

dbplot_bar(num_customers, x = FormattedDate,  y= n_distinct(CustomerNo))
```

```{r}
customer_base <- unique_customers |> 
  group_by(Country) |>
  summarise(Customers = sum(CustomerNo)) |> 
  na.omit(customer_base) |>
  filter(Customers > 150000) |> #tryna cut down the data base, filtering out countries with "too low" customer bases
  collect()

dbplot_bar(customer_base, x = Country, Customers) + labs(title = "Customers per country", subtitle = "Identifying countries with the largest customer base")
```

```{r}
#country by customerbase (number of customers)
#same graph as above, but with map (think this is better cos i didnt omit data)

library(rworldmap)

customer_base1 <- unique_customers |> 
  group_by(Country) |>
  summarise(Customers = sum(CustomerNo)) |> 
  na.omit(customer_base) |>
  collect()

c1 <- joinCountryData2Map(customer_base1, joinCode="NAME", nameJoinColumn="Country")
mapCountryData(c1, nameColumnToPlot="Customers", catMethod="logFixedWidth", colourPalette = "heat", addLegend = TRUE, mapTitle = "Customerbase per country")

#zoom zoom
map_region <- "Europe"
c1_europe <- mapCountryData(c1, nameColumnToPlot="Customers", mapRegion = "Europe", addLegend=FALSE, mapTitle = "Customers in Europe Region")

#from this we can see that idk i think its france/germany that has a high customer data base im bad at geography

```

```{r}
#country by expenditure 

customerbase2 <- unique_customers |> 
  group_by(Country) |> 
  summarise(Expenditure = sum(total_spent)) |> 
  collect()

c2 <- joinCountryData2Map(customerbase2, joinCode="NAME", nameJoinColumn="Country")
mapCountryData(c2, nameColumnToPlot="Expenditure", catMethod="fixedWidth", colourPalette = "heat", addLegend = TRUE, mapTitle = "Expenditure per country")

c2_europe <- mapCountryData(c2, nameColumnToPlot="Expenditure", mapRegion = "Europe", addLegend=FALSE, mapTitle = "Expenditure in Europe Region")

```

```{r}
#product analysis 

popular_product <- transaction_df |> 
  group_by(ProductName, ProductNo) |> 
  summarise(Total_sold = sum(Quantity)) |>
  collect()

popular_product
#there are 3753 products

library(plotly)
plot_ly(data = popular_product, x = ~ProductName, y = ~Total_sold, type = "bar") %>%
  layout(title = "Most Popular Products", xaxis = list(categoryorder = "total descending"))

#most popular item: paper craft little birdie
```

```{r}
#most busy dates (most transactions)

busy_dates <- transaction_df |>
  group_by(Date) |>
  mutate(Date = as.Date(Date, format = "%y/%m/%d")) |>
  summarise(Total_transactions = n()) |>
  collect()

busy_dates[order(busy_dates$Total_transactions, decreasing = TRUE), ]

#busiest months in the year: nov, dec

fig <- plot_ly(busy_dates, type = 'scatter', mode = 'lines')%>%
  add_trace(x = ~Date, y = ~Total_transactions)%>%
  layout(showlegend = F, title='Time Series with Range Slider and Selectors',
         xaxis = list(rangeslider = list(visible = T),
                      rangeselector=list(
                        buttons=list(
                          list(count=1, label="1m", step="month", stepmode="backward"),
                          list(count=6, label="6m", step="month", stepmode="backward"),
                          list(count=1, label="YTD", step="year", stepmode="todate"),
                          list(count=1, label="1y", step="year", stepmode="backward"),
                          list(step="all")
                        ))))
fig <- fig %>%
  layout(
         xaxis = list(zerolinecolor = '#ffff',
                      zerolinewidth = 2,
                      gridcolor = 'ffff'),
         yaxis = list(zerolinecolor = '#ffff',
                      zerolinewidth = 2,
                      gridcolor = 'ffff'),
         plot_bgcolor='#e5ecf6', margin = 0.1, width = 900)
fig
```


```{r}
#grouping the data by customer id and transaction date and get the count and then see how many rows have a count >1

sameday_transasctions <- transaction_ref |>
  group_by(CustomerNo, FormattedDate) |>
  summarise(total_products_bought = n_distinct(ProductNo), 
            total_spent = sum(Price*Quantity),
            total_transactions = n())

sameday_transasctions <- sameday_transasctions |>
  filter(total_transactions> 1)
sameday_transasctions

num_customers <- sameday_transasctions |>
  group_by(FormattedDate) |>
  summarise(num_of_customers = n_distinct(CustomerNo))
num_customers



dbplot_bar(num_customers, x = FormattedDate,  y= num_of_customers)
```


```{r}
#hello
#hello from erica
```

