---
title: "EDAv1.0"
output: html_document
date: "2023-09-21"
---

```{r}
# # OPEN CSV FILE HERE
# transactions <- arrow::open_dataset(sources = "transactions.csv", format = "csv")
# # SAVE DATASET IN PARQUET FORMAT HERE
# # Create AAPL directory
# dir.create("parquet_folder")  
# #write parquet file to directory
#arrow::write_dataset(transactions,format = "parquet", path = "parquet_folder",partitioning = NULL)
```

```{r}
#OPEN SAVED PARQUET FILE HERE
transactions_parquet <- arrow::open_dataset(
  sources = "parquet_folder/part-0.parquet",
  format = "parquet")

# Collect the data into a data frame
transaction_df <- transactions_parquet |>
  dplyr::collect()

```

```{r}
library(sparklyr)
library(dplyr)

# Connect to a local instance of Spark
sc <- spark_connect(master = "local", version = "3.4.0")
```

```{r}
# Copy the transactions R data frame to Spark memory and create the R reference transaction_ref
transaction_ref <- copy_to(sc, transaction_df)    
head(transaction_ref, 4)  
```
1. Data Cleaning
1.1 Generating summary statistics for every column - applicable to numerical variables
```{r}
#summary statistics for every column
sdf_describe(transaction_ref, cols = colnames(transaction_ref)) 
```
1.2 Checking for null values in every column
```{r}
#check the number of na values present in every column 
na_values <- transaction_ref |>
  summarise_all(~sum(as.integer(is.na(.))))
na_values
```
```{r}
#check for unique values 
unique_date <- transaction_ref |>
  select(Date) |>
  distinct() |>
  collect()

unique_date
```



1.3 Checking for negative values in the Quantity column
```{r}
transaction_ref |> 
  filter(Quantity < 0)
  #collect()
```
1.4 Number of unique customerno
```{r}
unique_customers <- transaction_ref |>
  group_by(CustomerNo) |>
  summarise(count = n()) |>
  collect()

row_count <- unique_customers |>
count()

# Extract the count value
total_rows <- row_count$n
total_rows
```

1.5 removing rows with NA CustomerNo, and rows with negative quantity

```{r}
transaction_ref <- transaction_ref |>
  filter(!is.na(CustomerNo) & Quantity > 0)
```

1.6 Converting date to date format
```{r}
transaction_ref <- transaction_ref |>
    mutate(
    month = substring_index(Date, "/", 1),
    day = substring_index(substring_index(Date, "/", -2), "/", 1),
    year = substring_index(Date, "/", -1)
  )
# Add leading zeros to month and day
transaction_ref <- transaction_ref |>
  mutate(
    month = lpad(month, 2, "0"),
    day = lpad(day, 2, "0")
  )

# Combine the formatted values to create the "MM/dd/yyyy" date
transaction_ref <- transaction_ref %>%
  mutate(FormattedDate = concat(month, "/", day, "/", year)) |>
  select(-month, -day, -year, -Date)

#convert to date format from chr
transaction_ref <-transaction_ref |>
  mutate(date_parsed = to_date(FormattedDate, "MM/dd/yyyy"))

transaction_ref

```


1.7 Create new columns for Recency, Frequency, Monetary values
https://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp 
```{r}
# Calculate Recency, Frequency, and Monetary values
rfm_df <- transaction_ref |>
  group_by(CustomerNo) |>
  summarise(
    Recency = as.numeric(datediff(max(date_parsed), to_date("2019-12-31"))),
    Frequency = n(),
    Monetary = sum(Price * Quantity),
    ConcatenatedProductNames = concat_ws(", ", collect_list(ProductName))
  )
# Show the resulting RFM DataFrame
head(rfm_df)
```

```{r}
#compute the percentile values for the Recency, Frequency and Monetary value columns 

rfm_df <- rfm_df|>
  mutate(r_percentile = percent_rank(Recency),
         f_percentile = percent_rank(Frequency),
         m_percentile = percent_rank(Monetary))

head(rfm_df)
```

```{r}
#compute the r,f,m score 


```



