23/10/18 18:17:09.122 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/conf/hive-site.xml
23/10/18 18:17:09.453 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.0
23/10/18 18:17:09.478 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/10/18 18:17:09.585 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/10/18 18:17:09.616 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/10/18 18:17:09.616 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/10/18 18:17:09.616 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/10/18 18:17:09.616 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/10/18 18:17:09.650 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/10/18 18:17:09.659 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/10/18 18:17:09.659 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/10/18 18:17:09.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: priya
23/10/18 18:17:09.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: priya
23/10/18 18:17:09.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/10/18 18:17:09.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/10/18 18:17:09.733 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: priya; groups with view permissions: EMPTY; users with modify permissions: priya; groups with modify permissions: EMPTY
23/10/18 18:17:09.885 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 64091.
23/10/18 18:17:09.941 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/10/18 18:17:10.033 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/10/18 18:17:10.083 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/10/18 18:17:10.084 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/10/18 18:17:10.092 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/10/18 18:17:10.140 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\blockmgr-34211c98-36f9-4dbc-8596-a4cd6c85a103
23/10/18 18:17:10.183 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
23/10/18 18:17:10.225 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/10/18 18:17:10.233 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/local]. Please check your configured local directories.
23/10/18 18:17:10.558 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
23/10/18 18:17:10.690 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/10/18 18:17:10.766 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/priya/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:64091/jars/sparklyr-master-2.12.jar with timestamp 1697624229437
23/10/18 18:17:10.867 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/10/18 18:17:10.883 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/10/18 18:17:10.900 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:64091/jars/sparklyr-master-2.12.jar with timestamp 1697624229437
23/10/18 18:17:10.978 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64091 after 27 ms (0 ms spent in bootstraps)
23/10/18 18:17:10.985 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:64091/jars/sparklyr-master-2.12.jar to C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0\fetchFileTemp12710910467095801955.tmp
23/10/18 18:17:11.209 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/local/spark-04df42eb-dab9-4ffe-8628-449cb7680a9e/userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0/sparklyr-master-2.12.jar to class loader
23/10/18 18:17:11.259 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64093.
23/10/18 18:17:11.267 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:64093
23/10/18 18:17:11.267 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/10/18 18:17:11.283 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 18:17:11.290 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64093 with 1048.8 MiB RAM, BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 18:17:11.299 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 18:17:11.299 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 18:17:11.907 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
23/10/18 18:17:11.923 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive'.
23/10/18 18:17:18.023 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/10/18 18:17:18.359 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive
23/10/18 18:17:18.693 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/10/18 18:17:18.693 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/10/18 18:17:18.693 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/10/18 18:17:18.758 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/10/18 18:17:18.975 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/10/18 18:17:18.975 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/10/18 18:17:20.613 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/10/18 18:17:22.285 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/10/18 18:17:22.308 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/10/18 18:17:22.385 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/10/18 18:17:22.385 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.72
23/10/18 18:17:22.411 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/10/18 18:17:22.559 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/10/18 18:17:22.567 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/10/18 18:17:22.617 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/10/18 18:17:22.733 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:22.741 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:22.764 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/10/18 18:17:22.765 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/10/18 18:17:22.766 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/10/18 18:17:22.768 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:22.769 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:22.771 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:22.772 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:22.775 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/18 18:17:22.775 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/18 18:17:23.269 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:23.269 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:23.269 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:23.269 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:23.277 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/18 18:17:23.277 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/18 18:17:24.161 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 252.4313 ms
23/10/18 18:17:24.307 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:17:24.318 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.008586 s
23/10/18 18:17:34.096 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.9575 ms
23/10/18 18:17:34.120 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:17:34.133 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:17:34.133 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
23/10/18 18:17:34.133 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:17:34.137 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:17:34.140 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
23/10/18 18:17:34.214 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.4 KiB, free 1048.8 MiB)
23/10/18 18:17:34.266 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1048.8 MiB)
23/10/18 18:17:34.271 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64093 (size: 3.7 KiB, free: 1048.8 MiB)
23/10/18 18:17:34.273 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
23/10/18 18:17:34.292 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:17:34.292 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/10/18 18:17:34.373 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/18 18:17:34.388 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/10/18 18:17:34.524 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
23/10/18 18:17:34.537 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 187 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:17:34.539 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/10/18 18:17:34.544 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.385 s
23/10/18 18:17:34.548 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:17:34.548 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/10/18 18:17:34.549 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.428675 s
23/10/18 18:17:34.598 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.2883 ms
23/10/18 18:17:34.901 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:17:34.901 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:17:34.901 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
23/10/18 18:17:34.901 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:17:34.901 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:17:34.909 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
23/10/18 18:17:34.912 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.4 KiB, free 1048.8 MiB)
23/10/18 18:17:34.917 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1048.8 MiB)
23/10/18 18:17:34.917 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64093 (size: 3.7 KiB, free: 1048.8 MiB)
23/10/18 18:17:34.917 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
23/10/18 18:17:34.917 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:17:34.917 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/10/18 18:17:34.925 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/18 18:17:34.925 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/10/18 18:17:34.935 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
23/10/18 18:17:34.935 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:17:34.935 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/10/18 18:17:34.935 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.024 s
23/10/18 18:17:34.935 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:17:34.935 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/10/18 18:17:34.935 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.032037 s
23/10/18 18:17:35.050 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:35.058 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:35.064 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/18 18:17:35.065 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/18 18:17:35.067 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/18 18:17:35.067 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/18 18:17:35.218 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 65.8188 ms
23/10/18 18:17:35.283 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.4311 ms
23/10/18 18:17:35.325 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.8242 ms
23/10/18 18:17:35.554 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.2756 ms
23/10/18 18:17:35.566 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:64093 in memory (size: 3.7 KiB, free: 1048.8 MiB)
23/10/18 18:17:35.624 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:17:35.626 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:17:35.626 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
23/10/18 18:17:35.626 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:17:35.626 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:17:35.630 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
23/10/18 18:17:35.639 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.0 KiB, free 1048.8 MiB)
23/10/18 18:17:35.647 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 1048.8 MiB)
23/10/18 18:17:35.649 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64093 (size: 6.7 KiB, free: 1048.8 MiB)
23/10/18 18:17:35.650 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
23/10/18 18:17:35.650 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:17:35.650 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/10/18 18:17:36.001 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64093 in memory (size: 3.7 KiB, free: 1048.8 MiB)
23/10/18 18:17:36.173 dispatcher-event-loop-2 WARN TaskSetManager: Stage 2 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:17:36.182 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/18 18:17:36.184 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/10/18 18:17:38.103 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 11.7 MiB, free 1037.1 MiB)
23/10/18 18:17:38.131 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:64093 (size: 11.7 MiB, free: 1037.1 MiB)
23/10/18 18:17:38.150 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 8.1063 ms
23/10/18 18:17:38.206 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 43.03 ms
23/10/18 18:17:38.233 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_11_0]
23/10/18 18:17:38.241 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1972 bytes result sent to driver
23/10/18 18:17:38.241 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2591 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:17:38.241 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/10/18 18:17:38.241 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 2.611 s
23/10/18 18:17:38.241 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:17:38.241 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/10/18 18:17:38.241 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 2.620591 s
23/10/18 18:17:38.267 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.4179 ms
23/10/18 18:18:12.183 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.4858 ms
23/10/18 18:18:12.198 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:18:12.199 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:12.199 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
23/10/18 18:18:12.199 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:18:12.199 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:12.200 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:12.202 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/18 18:18:12.204 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/18 18:18:12.204 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64093 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/18 18:18:12.204 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:12.204 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:12.204 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/10/18 18:18:12.204 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/18 18:18:12.204 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/10/18 18:18:12.212 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1370 bytes result sent to driver
23/10/18 18:18:12.216 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:12.216 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/10/18 18:18:12.216 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.015 s
23/10/18 18:18:12.216 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:18:12.216 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/10/18 18:18:12.218 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.019514 s
23/10/18 18:18:12.233 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.5409 ms
23/10/18 18:18:12.612 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
23/10/18 18:18:12.723 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:26) as input to shuffle 0
23/10/18 18:18:12.731 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 5 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:12.731 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 4 (collect at utils.scala:26)
23/10/18 18:18:12.731 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:18:12.731 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:12.739 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[22] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:12.810 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 54.8 KiB, free 1037.1 MiB)
23/10/18 18:18:12.820 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 1037.0 MiB)
23/10/18 18:18:12.820 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64093 (size: 20.2 KiB, free: 1037.1 MiB)
23/10/18 18:18:12.820 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:12.820 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[22] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:12.828 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/10/18 18:18:13.125 dispatcher-event-loop-3 WARN TaskSetManager: Stage 4 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:18:13.125 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:18:13.125 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/10/18 18:18:13.222 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64093 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/18 18:18:13.335 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO BlockManager: Found block rdd_11_0 locally
23/10/18 18:18:13.441 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 44.149 ms
23/10/18 18:18:13.665 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 99.7695 ms
23/10/18 18:18:13.673 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 4.2695 ms
23/10/18 18:18:13.700 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 16.9204 ms
23/10/18 18:18:14.153 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:64093 in memory (size: 6.7 KiB, free: 1037.1 MiB)
23/10/18 18:18:18.433 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2068 bytes result sent to driver
23/10/18 18:18:18.433 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5601 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:18.433 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/10/18 18:18:18.442 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 4 (collect at utils.scala:26) finished in 5.703 s
23/10/18 18:18:18.442 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:18:18.442 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:18:18.442 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:18:18.442 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:18:18.551 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 32.7593 ms
23/10/18 18:18:18.606 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:18:18.615 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:18.615 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
23/10/18 18:18:18.615 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
23/10/18 18:18:18.616 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:18.616 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:18.640 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 117.1 KiB, free 1037.0 MiB)
23/10/18 18:18:18.648 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1036.9 MiB)
23/10/18 18:18:18.648 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64093 (size: 35.0 KiB, free: 1037.1 MiB)
23/10/18 18:18:18.648 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:18.648 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:18.648 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/10/18 18:18:18.648 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:18:18.648 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
23/10/18 18:18:18.682 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:18:18.690 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
23/10/18 18:18:18.799 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 44.8792 ms
23/10/18 18:18:18.849 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 23.247 ms
23/10/18 18:18:18.899 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 40.7686 ms
23/10/18 18:18:18.956 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 4973 bytes result sent to driver
23/10/18 18:18:18.956 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 308 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:18.956 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/10/18 18:18:18.956 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.340 s
23/10/18 18:18:18.956 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:18:18.956 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/10/18 18:18:18.956 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.349623 s
23/10/18 18:18:18.973 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.1562 ms
23/10/18 18:18:21.807 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.8206 ms
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:26) as input to shuffle 1
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 7 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 7 (collect at utils.scala:26)
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 22.5 KiB, free 1036.9 MiB)
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 1036.9 MiB)
23/10/18 18:18:21.815 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64093 (size: 8.6 KiB, free: 1037.1 MiB)
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:21.815 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/10/18 18:18:22.123 dispatcher-event-loop-2 WARN TaskSetManager: Stage 7 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:18:22.123 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:18:22.123 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
23/10/18 18:18:22.346 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 1839 bytes result sent to driver
23/10/18 18:18:22.348 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 525 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:22.348 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/10/18 18:18:22.349 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:26) finished in 0.534 s
23/10/18 18:18:22.349 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:18:22.349 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:18:22.350 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:18:22.350 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:18:22.381 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.7766 ms
23/10/18 18:18:22.388 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:18:22.396 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:22.396 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
23/10/18 18:18:22.396 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
23/10/18 18:18:22.396 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:22.396 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:22.399 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.2 KiB, free 1036.9 MiB)
23/10/18 18:18:22.400 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 1036.9 MiB)
23/10/18 18:18:22.400 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64093 (size: 8.9 KiB, free: 1037.1 MiB)
23/10/18 18:18:22.400 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:22.400 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:22.400 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/10/18 18:18:22.400 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:18:22.400 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO Executor: Running task 0.0 in stage 9.0 (TID 7)
23/10/18 18:18:22.400 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:18:22.400 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:18:22.408 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 3950 bytes result sent to driver
23/10/18 18:18:22.408 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 8 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:22.408 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/10/18 18:18:22.415 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.019 s
23/10/18 18:18:22.415 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:18:22.415 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/10/18 18:18:22.416 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.021322 s
23/10/18 18:18:22.424 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.0987 ms
23/10/18 18:18:23.323 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 23.1978 ms
23/10/18 18:18:23.348 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 34 (collect at utils.scala:26) as input to shuffle 2
23/10/18 18:18:23.356 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 9 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:23.357 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at utils.scala:26)
23/10/18 18:18:23.357 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:18:23.357 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:23.357 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:23.365 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 23.1 KiB, free 1036.8 MiB)
23/10/18 18:18:23.367 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 1036.8 MiB)
23/10/18 18:18:23.367 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64093 (size: 11.0 KiB, free: 1037.1 MiB)
23/10/18 18:18:23.367 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:23.367 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:23.367 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/10/18 18:18:23.433 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64093 in memory (size: 35.0 KiB, free: 1037.1 MiB)
23/10/18 18:18:23.437 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:64093 in memory (size: 8.9 KiB, free: 1037.1 MiB)
23/10/18 18:18:23.559 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64093 in memory (size: 20.2 KiB, free: 1037.1 MiB)
23/10/18 18:18:23.562 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64093 in memory (size: 8.6 KiB, free: 1037.1 MiB)
23/10/18 18:18:23.723 dispatcher-event-loop-6 WARN TaskSetManager: Stage 10 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:18:23.723 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:18:23.723 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO Executor: Running task 0.0 in stage 10.0 (TID 8)
23/10/18 18:18:23.879 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 9.5773 ms
23/10/18 18:18:23.923 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.2249 ms
23/10/18 18:18:24.532 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 5.0522 ms
23/10/18 18:18:24.541 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 5.6115 ms
23/10/18 18:18:24.548 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.6525 ms
23/10/18 18:18:24.555 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 4.3407 ms
23/10/18 18:18:24.566 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 10.0156 ms
23/10/18 18:18:24.834 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO Executor: Finished task 0.0 in stage 10.0 (TID 8). 2014 bytes result sent to driver
23/10/18 18:18:24.834 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 1467 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:24.834 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/10/18 18:18:24.834 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:26) finished in 1.477 s
23/10/18 18:18:24.834 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:18:24.840 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:18:24.840 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:18:24.840 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:18:24.850 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:18:24.890 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.1455 ms
23/10/18 18:18:24.916 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:18:24.924 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:24.924 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
23/10/18 18:18:24.924 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
23/10/18 18:18:24.924 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:24.924 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:24.966 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.3 KiB, free 1037.1 MiB)
23/10/18 18:18:24.966 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 1037.1 MiB)
23/10/18 18:18:24.966 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64093 (size: 13.5 KiB, free: 1037.1 MiB)
23/10/18 18:18:24.966 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:24.966 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:24.966 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/10/18 18:18:24.966 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:18:24.966 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO Executor: Running task 0.0 in stage 12.0 (TID 9)
23/10/18 18:18:24.975 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO ShuffleBlockFetcherIterator: Getting 1 (136.8 KiB) non-empty blocks including 1 (136.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:18:24.975 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:18:24.993 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 4.5914 ms
23/10/18 18:18:24.998 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 3.7728 ms
23/10/18 18:18:25.007 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 4.7858 ms
23/10/18 18:18:25.016 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO Executor: Finished task 0.0 in stage 12.0 (TID 9). 82166 bytes result sent to driver
23/10/18 18:18:25.023 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 57 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:25.024 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/10/18 18:18:25.025 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.061 s
23/10/18 18:18:25.025 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:18:25.025 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/10/18 18:18:25.025 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.101928 s
23/10/18 18:18:25.034 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.7153 ms
23/10/18 18:18:34.998 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.2602 ms
23/10/18 18:18:35.005 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:18:35.006 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:18:35.006 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
23/10/18 18:18:35.006 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:18:35.006 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:18:35.007 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26), which has no missing parents
23/10/18 18:18:35.009 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 9.1 KiB, free 1037.1 MiB)
23/10/18 18:18:35.009 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1037.1 MiB)
23/10/18 18:18:35.009 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64093 (size: 4.3 KiB, free: 1037.1 MiB)
23/10/18 18:18:35.009 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
23/10/18 18:18:35.009 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:18:35.012 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/10/18 18:18:35.234 dispatcher-event-loop-1 WARN TaskSetManager: Stage 13 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:18:35.234 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/18 18:18:35.236 Executor task launch worker for task 0.0 in stage 13.0 (TID 10) INFO Executor: Running task 0.0 in stage 13.0 (TID 10)
23/10/18 18:18:35.254 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64093 in memory (size: 13.5 KiB, free: 1037.1 MiB)
23/10/18 18:18:35.369 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:64093 in memory (size: 11.0 KiB, free: 1037.1 MiB)
23/10/18 18:18:35.398 Executor task launch worker for task 0.0 in stage 13.0 (TID 10) INFO Executor: Finished task 0.0 in stage 13.0 (TID 10). 47679 bytes result sent to driver
23/10/18 18:18:35.399 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 386 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:18:35.399 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/10/18 18:18:35.400 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0.392 s
23/10/18 18:18:35.400 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:18:35.401 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/10/18 18:18:35.401 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.395350 s
23/10/18 18:38:29.782 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.3595 ms
23/10/18 18:38:29.796 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:38:29.796 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:38:29.796 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
23/10/18 18:38:29.796 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:38:29.796 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:38:29.796 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26), which has no missing parents
23/10/18 18:38:29.804 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.7 KiB, free 1037.1 MiB)
23/10/18 18:38:29.804 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 1037.1 MiB)
23/10/18 18:38:29.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64093 (size: 5.1 KiB, free: 1037.1 MiB)
23/10/18 18:38:29.804 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
23/10/18 18:38:29.804 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:38:29.804 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
23/10/18 18:38:30.060 dispatcher-event-loop-1 WARN TaskSetManager: Stage 14 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:38:30.060 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/18 18:38:30.068 Executor task launch worker for task 0.0 in stage 14.0 (TID 11) INFO Executor: Running task 0.0 in stage 14.0 (TID 11)
23/10/18 18:38:30.254 Executor task launch worker for task 0.0 in stage 14.0 (TID 11) INFO Executor: Finished task 0.0 in stage 14.0 (TID 11). 41075 bytes result sent to driver
23/10/18 18:38:30.262 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 458 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:38:30.263 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
23/10/18 18:38:30.264 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.467 s
23/10/18 18:38:30.264 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:38:30.264 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
23/10/18 18:38:30.264 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.464931 s
23/10/18 18:38:30.287 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.2533 ms
23/10/18 18:38:30.333 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:64093 in memory (size: 4.3 KiB, free: 1037.1 MiB)
23/10/18 18:40:01.468 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.9959 ms
23/10/18 18:40:01.477 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:26) as input to shuffle 3
23/10/18 18:40:01.477 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 13 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:01.477 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at utils.scala:26)
23/10/18 18:40:01.477 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:40:01.477 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:01.477 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[45] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:01.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 32.0 KiB, free 1037.1 MiB)
23/10/18 18:40:01.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 1037.1 MiB)
23/10/18 18:40:01.502 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64093 (size: 14.3 KiB, free: 1037.1 MiB)
23/10/18 18:40:01.502 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:01.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[45] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:01.510 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/10/18 18:40:01.801 dispatcher-event-loop-3 WARN TaskSetManager: Stage 15 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:40:01.801 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:40:01.801 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
23/10/18 18:40:02.027 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 6.6748 ms
23/10/18 18:40:02.045 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 9.408 ms
23/10/18 18:40:02.061 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 11.923 ms
23/10/18 18:40:02.080 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 12.3957 ms
23/10/18 18:40:02.094 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 8.2854 ms
23/10/18 18:40:02.186 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:02.227 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 6.8608 ms
23/10/18 18:40:02.250 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 11.7106 ms
23/10/18 18:40:02.271 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 8.6911 ms
23/10/18 18:40:02.286 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 8.3452 ms
23/10/18 18:40:02.521 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:64093 in memory (size: 5.1 KiB, free: 1037.1 MiB)
23/10/18 18:40:03.295 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 11.863 ms
23/10/18 18:40:03.799 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 2147 bytes result sent to driver
23/10/18 18:40:03.799 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 2288 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:03.799 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/10/18 18:40:03.799 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:26) finished in 2.322 s
23/10/18 18:40:03.799 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:03.799 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:03.799 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:03.799 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:03.811 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/18 18:40:03.820 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 49 (collect at utils.scala:26) as input to shuffle 4
23/10/18 18:40:03.820 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 14 (collect at utils.scala:26) with 8 output partitions
23/10/18 18:40:03.820 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 17 (collect at utils.scala:26)
23/10/18 18:40:03.820 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
23/10/18 18:40:03.820 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:03.820 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[49] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:03.829 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 36.7 KiB, free 1037.1 MiB)
23/10/18 18:40:03.829 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 1037.0 MiB)
23/10/18 18:40:03.835 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64093 (size: 16.7 KiB, free: 1037.1 MiB)
23/10/18 18:40:03.835 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:03.835 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[49] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/18 18:40:03.835 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 8 tasks resource profile 0
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 14) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 15) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 16) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 17) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 18) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 17.0 (TID 19) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 17.0 (TID 20) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:03.835 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO Executor: Running task 0.0 in stage 17.0 (TID 13)
23/10/18 18:40:03.835 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO Executor: Running task 1.0 in stage 17.0 (TID 14)
23/10/18 18:40:03.835 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO Executor: Running task 2.0 in stage 17.0 (TID 15)
23/10/18 18:40:03.844 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO Executor: Running task 7.0 in stage 17.0 (TID 20)
23/10/18 18:40:03.844 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.844 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:40:03.844 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO Executor: Running task 3.0 in stage 17.0 (TID 16)
23/10/18 18:40:03.844 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO Executor: Running task 6.0 in stage 17.0 (TID 19)
23/10/18 18:40:03.852 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.852 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.852 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.852 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.852 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO Executor: Running task 4.0 in stage 17.0 (TID 17)
23/10/18 18:40:03.852 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.852 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.858 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.858 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.860 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.860 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.862 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO Executor: Running task 5.0 in stage 17.0 (TID 18)
23/10/18 18:40:03.863 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.863 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.863 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 6.7977 ms
23/10/18 18:40:03.867 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:03.867 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:03.877 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 9.3391 ms
23/10/18 18:40:03.889 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.889 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.889 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.917 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.917 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.928 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO CodeGenerator: Code generated in 11.0981 ms
23/10/18 18:40:03.944 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.945 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 6.8548 ms
23/10/18 18:40:03.957 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 11.4802 ms
23/10/18 18:40:03.967 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 5.2343 ms
23/10/18 18:40:03.977 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 6.3295 ms
23/10/18 18:40:03.979 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.985 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.985 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.985 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.985 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.987 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 4.7505 ms
23/10/18 18:40:03.987 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.992 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:03.998 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 5.1704 ms
23/10/18 18:40:04.047 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:04.061 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO CodeGenerator: Code generated in 8.1951 ms
23/10/18 18:40:04.067 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:04.094 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:04.205 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO Executor: Finished task 7.0 in stage 17.0 (TID 20). 4942 bytes result sent to driver
23/10/18 18:40:04.205 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 17.0 (TID 20) in 370 ms on 127.0.0.1 (executor driver) (1/8)
23/10/18 18:40:04.218 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO Executor: Finished task 0.0 in stage 17.0 (TID 13). 4942 bytes result sent to driver
23/10/18 18:40:04.220 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 385 ms on 127.0.0.1 (executor driver) (2/8)
23/10/18 18:40:04.227 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO Executor: Finished task 6.0 in stage 17.0 (TID 19). 4942 bytes result sent to driver
23/10/18 18:40:04.229 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 17.0 (TID 19) in 394 ms on 127.0.0.1 (executor driver) (3/8)
23/10/18 18:40:04.233 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO Executor: Finished task 3.0 in stage 17.0 (TID 16). 4985 bytes result sent to driver
23/10/18 18:40:04.234 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 16) in 399 ms on 127.0.0.1 (executor driver) (4/8)
23/10/18 18:40:04.246 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO Executor: Finished task 4.0 in stage 17.0 (TID 17). 4985 bytes result sent to driver
23/10/18 18:40:04.246 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 17) in 411 ms on 127.0.0.1 (executor driver) (5/8)
23/10/18 18:40:04.249 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO Executor: Finished task 2.0 in stage 17.0 (TID 15). 4942 bytes result sent to driver
23/10/18 18:40:04.249 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 15) in 414 ms on 127.0.0.1 (executor driver) (6/8)
23/10/18 18:40:04.252 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO Executor: Finished task 1.0 in stage 17.0 (TID 14). 4942 bytes result sent to driver
23/10/18 18:40:04.253 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 14) in 418 ms on 127.0.0.1 (executor driver) (7/8)
23/10/18 18:40:04.255 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO Executor: Finished task 5.0 in stage 17.0 (TID 18). 4942 bytes result sent to driver
23/10/18 18:40:04.255 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 18) in 420 ms on 127.0.0.1 (executor driver) (8/8)
23/10/18 18:40:04.255 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/10/18 18:40:04.255 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:26) finished in 0.435 s
23/10/18 18:40:04.255 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:04.255 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:04.255 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:04.255 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:04.262 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1427525, minimum partition size: 1048576
23/10/18 18:40:04.263 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:40:04.271 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:04.271 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:26)
23/10/18 18:40:04.271 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
23/10/18 18:40:04.271 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:04.271 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:04.277 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 42.8 KiB, free 1037.0 MiB)
23/10/18 18:40:04.278 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 1037.0 MiB)
23/10/18 18:40:04.278 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64093 (size: 18.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:04.278 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:04.278 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:04.278 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
23/10/18 18:40:04.278 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 21) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:40:04.278 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO Executor: Running task 0.0 in stage 20.0 (TID 21)
23/10/18 18:40:04.286 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ShuffleBlockFetcherIterator: Getting 8 (1368.0 KiB) non-empty blocks including 8 (1368.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:04.286 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:04.294 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.6014 ms
23/10/18 18:40:04.302 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 3.4503 ms
23/10/18 18:40:04.311 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.1019 ms
23/10/18 18:40:04.320 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:04.363 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO Executor: Finished task 0.0 in stage 20.0 (TID 21). 790566 bytes result sent to driver
23/10/18 18:40:04.363 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 21) in 85 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:04.363 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
23/10/18 18:40:04.363 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collect at utils.scala:26) finished in 0.092 s
23/10/18 18:40:04.363 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:40:04.363 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
23/10/18 18:40:04.363 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.096836 s
23/10/18 18:40:04.371 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:40:04.371 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 2 output partitions
23/10/18 18:40:04.371 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
23/10/18 18:40:04.371 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
23/10/18 18:40:04.371 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:04.371 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:04.378 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 42.8 KiB, free 1036.9 MiB)
23/10/18 18:40:04.378 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 1036.9 MiB)
23/10/18 18:40:04.378 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64093 (size: 18.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:04.378 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:04.378 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/18 18:40:04.378 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks resource profile 0
23/10/18 18:40:04.378 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/18 18:40:04.378 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 23) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/18 18:40:04.387 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO Executor: Running task 0.0 in stage 23.0 (TID 22)
23/10/18 18:40:04.388 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO Executor: Running task 1.0 in stage 23.0 (TID 23)
23/10/18 18:40:04.393 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ShuffleBlockFetcherIterator: Getting 8 (1275.8 KiB) non-empty blocks including 8 (1275.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:04.394 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:40:04.394 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ShuffleBlockFetcherIterator: Getting 8 (1262.6 KiB) non-empty blocks including 8 (1262.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:04.394 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/18 18:40:04.410 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:04.410 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/18 18:40:04.438 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:64093 in memory (size: 16.7 KiB, free: 1037.1 MiB)
23/10/18 18:40:04.444 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:64093 in memory (size: 14.3 KiB, free: 1037.1 MiB)
23/10/18 18:40:04.452 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO Executor: Finished task 0.0 in stage 23.0 (TID 22). 754601 bytes result sent to driver
23/10/18 18:40:04.452 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 74 ms on 127.0.0.1 (executor driver) (1/2)
23/10/18 18:40:04.452 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO Executor: Finished task 1.0 in stage 23.0 (TID 23). 751524 bytes result sent to driver
23/10/18 18:40:04.452 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 23) in 74 ms on 127.0.0.1 (executor driver) (2/2)
23/10/18 18:40:04.452 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
23/10/18 18:40:04.452 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0.074 s
23/10/18 18:40:04.452 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:40:04.452 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
23/10/18 18:40:04.452 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.083407 s
23/10/18 18:40:04.470 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.5917 ms
23/10/18 18:40:14.208 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:14.271 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 48.7591 ms
23/10/18 18:40:14.277 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 54 (collect at utils.scala:26) as input to shuffle 5
23/10/18 18:40:14.277 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 17 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:14.277 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at utils.scala:26)
23/10/18 18:40:14.277 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:40:14.277 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:14.277 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:14.285 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 37.1 KiB, free 1037.0 MiB)
23/10/18 18:40:14.285 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 1037.0 MiB)
23/10/18 18:40:14.285 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64093 (size: 16.8 KiB, free: 1037.1 MiB)
23/10/18 18:40:14.285 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:14.285 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:14.285 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/10/18 18:40:14.535 dispatcher-event-loop-2 WARN TaskSetManager: Stage 24 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:40:14.535 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:40:14.535 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
23/10/18 18:40:14.661 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO CodeGenerator: Code generated in 2.9749 ms
23/10/18 18:40:14.669 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO CodeGenerator: Code generated in 3.3059 ms
23/10/18 18:40:14.678 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO CodeGenerator: Code generated in 3.8764 ms
23/10/18 18:40:15.141 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:64093 in memory (size: 18.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:15.144 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:64093 in memory (size: 18.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:15.361 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2250 bytes result sent to driver
23/10/18 18:40:15.369 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 1084 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:15.369 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/10/18 18:40:15.369 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 24 (collect at utils.scala:26) finished in 1.092 s
23/10/18 18:40:15.369 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:15.369 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:15.369 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:15.369 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:15.369 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:40:15.394 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:15.495 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 89.5725 ms
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 57 (collect at utils.scala:26) as input to shuffle 6
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 18 (collect at utils.scala:26) with 4 output partitions
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 26 (collect at utils.scala:26)
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[57] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:15.503 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 58.8 KiB, free 1037.0 MiB)
23/10/18 18:40:15.512 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 1037.0 MiB)
23/10/18 18:40:15.512 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64093 (size: 23.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:15.512 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:15.512 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[57] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
23/10/18 18:40:15.512 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks resource profile 0
23/10/18 18:40:15.512 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:15.512 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 26) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:15.512 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 27) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:15.512 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 28) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:15.512 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO Executor: Running task 3.0 in stage 26.0 (TID 28)
23/10/18 18:40:15.512 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO Executor: Running task 2.0 in stage 26.0 (TID 27)
23/10/18 18:40:15.512 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
23/10/18 18:40:15.512 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO Executor: Running task 1.0 in stage 26.0 (TID 26)
23/10/18 18:40:15.533 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:15.533 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:15.534 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:15.534 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:15.534 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:15.534 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:15.534 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:15.534 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:15.543 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO CodeGenerator: Code generated in 3.9098 ms
23/10/18 18:40:15.549 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO CodeGenerator: Code generated in 3.8092 ms
23/10/18 18:40:15.710 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:64093 in memory (size: 16.8 KiB, free: 1037.1 MiB)
23/10/18 18:40:15.920 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO Executor: Finished task 3.0 in stage 26.0 (TID 28). 5411 bytes result sent to driver
23/10/18 18:40:15.922 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 28) in 410 ms on 127.0.0.1 (executor driver) (1/4)
23/10/18 18:40:15.924 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 5368 bytes result sent to driver
23/10/18 18:40:15.925 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 413 ms on 127.0.0.1 (executor driver) (2/4)
23/10/18 18:40:15.929 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO Executor: Finished task 2.0 in stage 26.0 (TID 27). 5411 bytes result sent to driver
23/10/18 18:40:15.930 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 27) in 418 ms on 127.0.0.1 (executor driver) (3/4)
23/10/18 18:40:15.932 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO Executor: Finished task 1.0 in stage 26.0 (TID 26). 5368 bytes result sent to driver
23/10/18 18:40:15.932 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 26) in 420 ms on 127.0.0.1 (executor driver) (4/4)
23/10/18 18:40:15.932 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/10/18 18:40:15.932 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:26) finished in 0.429 s
23/10/18 18:40:15.932 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:15.932 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:15.932 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:15.932 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:15.932 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:40:15.941 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:15.952 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.1032 ms
23/10/18 18:40:15.962 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:26)
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[60] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 51.2 KiB, free 1037.0 MiB)
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 1037.0 MiB)
23/10/18 18:40:15.970 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64093 (size: 21.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[60] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:15.970 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
23/10/18 18:40:15.977 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:40:15.977 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
23/10/18 18:40:15.977 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO ShuffleBlockFetcherIterator: Getting 4 (373.0 KiB) non-empty blocks including 4 (373.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:15.977 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:16.002 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 110827 bytes result sent to driver
23/10/18 18:40:16.002 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 25 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:16.002 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/10/18 18:40:16.010 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at utils.scala:26) finished in 0.040 s
23/10/18 18:40:16.011 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:40:16.011 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/10/18 18:40:16.011 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0.041751 s
23/10/18 18:40:16.012 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.8819 ms
23/10/18 18:40:32.661 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:32.677 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.3201 ms
23/10/18 18:40:32.677 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 62 (collect at utils.scala:26) as input to shuffle 7
23/10/18 18:40:32.677 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:32.677 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 30 (collect at utils.scala:26)
23/10/18 18:40:32.677 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:40:32.677 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:32.677 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[62] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:32.685 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 41.2 KiB, free 1036.9 MiB)
23/10/18 18:40:32.685 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 1036.9 MiB)
23/10/18 18:40:32.685 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:64093 (size: 18.3 KiB, free: 1037.1 MiB)
23/10/18 18:40:32.685 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:32.685 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[62] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:32.685 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
23/10/18 18:40:32.910 dispatcher-event-loop-2 WARN TaskSetManager: Stage 30 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:40:32.910 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:40:32.911 Executor task launch worker for task 0.0 in stage 30.0 (TID 30) INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
23/10/18 18:40:33.034 Executor task launch worker for task 0.0 in stage 30.0 (TID 30) INFO CodeGenerator: Code generated in 5.4164 ms
23/10/18 18:40:33.043 Executor task launch worker for task 0.0 in stage 30.0 (TID 30) INFO CodeGenerator: Code generated in 4.3352 ms
23/10/18 18:40:33.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:64093 in memory (size: 23.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:33.294 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:64093 in memory (size: 21.5 KiB, free: 1037.1 MiB)
23/10/18 18:40:33.898 Executor task launch worker for task 0.0 in stage 30.0 (TID 30) INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 2250 bytes result sent to driver
23/10/18 18:40:33.898 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 1213 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:33.898 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
23/10/18 18:40:33.898 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 30 (collect at utils.scala:26) finished in 1.221 s
23/10/18 18:40:33.898 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:33.901 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:33.901 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:33.901 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:33.903 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1118735, minimum partition size: 1048576
23/10/18 18:40:33.909 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:33.934 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.4259 ms
23/10/18 18:40:33.939 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 65 (collect at utils.scala:26) as input to shuffle 8
23/10/18 18:40:33.939 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 21 (collect at utils.scala:26) with 8 output partitions
23/10/18 18:40:33.939 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at utils.scala:26)
23/10/18 18:40:33.939 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
23/10/18 18:40:33.939 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:33.939 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[65] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:33.944 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 60.1 KiB, free 1037.0 MiB)
23/10/18 18:40:33.946 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 1037.0 MiB)
23/10/18 18:40:33.946 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:64093 (size: 24.0 KiB, free: 1037.1 MiB)
23/10/18 18:40:33.946 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:33.946 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[65] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/18 18:40:33.946 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 8 tasks resource profile 0
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 31) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 32) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 33) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 34) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 32.0 (TID 35) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 32.0 (TID 36) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 32.0 (TID 37) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.951 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 32.0 (TID 38) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:33.951 Executor task launch worker for task 2.0 in stage 32.0 (TID 33) INFO Executor: Running task 2.0 in stage 32.0 (TID 33)
23/10/18 18:40:33.951 Executor task launch worker for task 3.0 in stage 32.0 (TID 34) INFO Executor: Running task 3.0 in stage 32.0 (TID 34)
23/10/18 18:40:33.951 Executor task launch worker for task 5.0 in stage 32.0 (TID 36) INFO Executor: Running task 5.0 in stage 32.0 (TID 36)
23/10/18 18:40:33.951 Executor task launch worker for task 7.0 in stage 32.0 (TID 38) INFO Executor: Running task 7.0 in stage 32.0 (TID 38)
23/10/18 18:40:33.951 Executor task launch worker for task 1.0 in stage 32.0 (TID 32) INFO Executor: Running task 1.0 in stage 32.0 (TID 32)
23/10/18 18:40:33.951 Executor task launch worker for task 0.0 in stage 32.0 (TID 31) INFO Executor: Running task 0.0 in stage 32.0 (TID 31)
23/10/18 18:40:33.951 Executor task launch worker for task 6.0 in stage 32.0 (TID 37) INFO Executor: Running task 6.0 in stage 32.0 (TID 37)
23/10/18 18:40:33.951 Executor task launch worker for task 4.0 in stage 32.0 (TID 35) INFO Executor: Running task 4.0 in stage 32.0 (TID 35)
23/10/18 18:40:33.957 Executor task launch worker for task 4.0 in stage 32.0 (TID 35) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.957 Executor task launch worker for task 0.0 in stage 32.0 (TID 31) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.957 Executor task launch worker for task 6.0 in stage 32.0 (TID 37) INFO ShuffleBlockFetcherIterator: Getting 1 (1186.9 KiB) non-empty blocks including 1 (1186.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.957 Executor task launch worker for task 0.0 in stage 32.0 (TID 31) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:33.957 Executor task launch worker for task 2.0 in stage 32.0 (TID 33) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.958 Executor task launch worker for task 7.0 in stage 32.0 (TID 38) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.958 Executor task launch worker for task 1.0 in stage 32.0 (TID 32) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.958 Executor task launch worker for task 7.0 in stage 32.0 (TID 38) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:33.958 Executor task launch worker for task 4.0 in stage 32.0 (TID 35) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:40:33.958 Executor task launch worker for task 2.0 in stage 32.0 (TID 33) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:40:33.959 Executor task launch worker for task 6.0 in stage 32.0 (TID 37) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/18 18:40:33.959 Executor task launch worker for task 1.0 in stage 32.0 (TID 32) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:40:33.961 Executor task launch worker for task 3.0 in stage 32.0 (TID 34) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.961 Executor task launch worker for task 3.0 in stage 32.0 (TID 34) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:33.962 Executor task launch worker for task 5.0 in stage 32.0 (TID 36) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:33.962 Executor task launch worker for task 5.0 in stage 32.0 (TID 36) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:33.970 Executor task launch worker for task 0.0 in stage 32.0 (TID 31) INFO CodeGenerator: Code generated in 10.0536 ms
23/10/18 18:40:33.993 Executor task launch worker for task 3.0 in stage 32.0 (TID 34) INFO CodeGenerator: Code generated in 5.9886 ms
23/10/18 18:40:34.279 Executor task launch worker for task 0.0 in stage 32.0 (TID 31) INFO Executor: Finished task 0.0 in stage 32.0 (TID 31). 5368 bytes result sent to driver
23/10/18 18:40:34.279 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 31) in 333 ms on 127.0.0.1 (executor driver) (1/8)
23/10/18 18:40:34.284 Executor task launch worker for task 7.0 in stage 32.0 (TID 38) INFO Executor: Finished task 7.0 in stage 32.0 (TID 38). 5368 bytes result sent to driver
23/10/18 18:40:34.287 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 32.0 (TID 38) in 336 ms on 127.0.0.1 (executor driver) (2/8)
23/10/18 18:40:34.297 Executor task launch worker for task 2.0 in stage 32.0 (TID 33) INFO Executor: Finished task 2.0 in stage 32.0 (TID 33). 5368 bytes result sent to driver
23/10/18 18:40:34.298 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 33) in 351 ms on 127.0.0.1 (executor driver) (3/8)
23/10/18 18:40:34.300 Executor task launch worker for task 4.0 in stage 32.0 (TID 35) INFO Executor: Finished task 4.0 in stage 32.0 (TID 35). 5368 bytes result sent to driver
23/10/18 18:40:34.300 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 32.0 (TID 35) in 354 ms on 127.0.0.1 (executor driver) (4/8)
23/10/18 18:40:34.304 Executor task launch worker for task 5.0 in stage 32.0 (TID 36) INFO Executor: Finished task 5.0 in stage 32.0 (TID 36). 5368 bytes result sent to driver
23/10/18 18:40:34.305 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 32.0 (TID 36) in 359 ms on 127.0.0.1 (executor driver) (5/8)
23/10/18 18:40:34.305 Executor task launch worker for task 6.0 in stage 32.0 (TID 37) INFO Executor: Finished task 6.0 in stage 32.0 (TID 37). 5368 bytes result sent to driver
23/10/18 18:40:34.305 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 32.0 (TID 37) in 359 ms on 127.0.0.1 (executor driver) (6/8)
23/10/18 18:40:34.313 Executor task launch worker for task 3.0 in stage 32.0 (TID 34) INFO Executor: Finished task 3.0 in stage 32.0 (TID 34). 5368 bytes result sent to driver
23/10/18 18:40:34.313 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 34) in 367 ms on 127.0.0.1 (executor driver) (7/8)
23/10/18 18:40:34.315 Executor task launch worker for task 1.0 in stage 32.0 (TID 32) INFO Executor: Finished task 1.0 in stage 32.0 (TID 32). 5368 bytes result sent to driver
23/10/18 18:40:34.315 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 32) in 369 ms on 127.0.0.1 (executor driver) (8/8)
23/10/18 18:40:34.315 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
23/10/18 18:40:34.315 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:26) finished in 0.373 s
23/10/18 18:40:34.315 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:34.315 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:34.315 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:34.315 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:34.323 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:40:34.328 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:34.344 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.9938 ms
23/10/18 18:40:34.352 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[68] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 53.7 KiB, free 1036.9 MiB)
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 1036.9 MiB)
23/10/18 18:40:34.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:64093 (size: 22.6 KiB, free: 1037.1 MiB)
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[68] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:34.352 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
23/10/18 18:40:34.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 39) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:40:34.361 Executor task launch worker for task 0.0 in stage 35.0 (TID 39) INFO Executor: Running task 0.0 in stage 35.0 (TID 39)
23/10/18 18:40:34.361 Executor task launch worker for task 0.0 in stage 35.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 8 (1987.5 KiB) non-empty blocks including 8 (1987.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:34.361 Executor task launch worker for task 0.0 in stage 35.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:34.442 Executor task launch worker for task 0.0 in stage 35.0 (TID 39) INFO Executor: Finished task 0.0 in stage 35.0 (TID 39). 27646 bytes result sent to driver
23/10/18 18:40:34.450 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 39) in 90 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:34.450 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
23/10/18 18:40:34.450 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 0.098 s
23/10/18 18:40:34.450 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:40:34.450 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
23/10/18 18:40:34.450 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: collect at utils.scala:26, took 0.099323 s
23/10/18 18:40:34.461 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.8857 ms
23/10/18 18:40:36.123 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.1141 ms
23/10/18 18:40:36.123 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 70 (collect at utils.scala:26) as input to shuffle 9
23/10/18 18:40:36.123 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 23 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:36.123 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 36 (collect at utils.scala:26)
23/10/18 18:40:36.123 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:40:36.123 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:36.123 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[70] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:36.132 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 37.6 KiB, free 1036.9 MiB)
23/10/18 18:40:36.132 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1036.9 MiB)
23/10/18 18:40:36.132 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:64093 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/18 18:40:36.132 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:36.132 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[70] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:36.132 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
23/10/18 18:40:36.176 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:64093 in memory (size: 24.0 KiB, free: 1037.1 MiB)
23/10/18 18:40:36.184 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:64093 in memory (size: 22.6 KiB, free: 1037.1 MiB)
23/10/18 18:40:36.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:64093 in memory (size: 18.3 KiB, free: 1037.1 MiB)
23/10/18 18:40:36.402 dispatcher-event-loop-2 WARN TaskSetManager: Stage 36 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:40:36.402 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 40) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:40:36.402 Executor task launch worker for task 0.0 in stage 36.0 (TID 40) INFO Executor: Running task 0.0 in stage 36.0 (TID 40)
23/10/18 18:40:36.527 Executor task launch worker for task 0.0 in stage 36.0 (TID 40) INFO CodeGenerator: Code generated in 3.6994 ms
23/10/18 18:40:36.585 Executor task launch worker for task 0.0 in stage 36.0 (TID 40) INFO CodeGenerator: Code generated in 7.6865 ms
23/10/18 18:40:37.102 Executor task launch worker for task 0.0 in stage 36.0 (TID 40) INFO Executor: Finished task 0.0 in stage 36.0 (TID 40). 2250 bytes result sent to driver
23/10/18 18:40:37.102 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 40) in 970 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:37.102 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
23/10/18 18:40:37.102 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 36 (collect at utils.scala:26) finished in 0.979 s
23/10/18 18:40:37.102 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:37.102 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:37.102 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:37.102 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:37.109 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:40:37.118 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:37.118 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:37.141 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.9569 ms
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 73 (collect at utils.scala:26) as input to shuffle 10
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 24 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 38 (collect at utils.scala:26)
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[73] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 45.9 KiB, free 1037.0 MiB)
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 1037.0 MiB)
23/10/18 18:40:37.144 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:64093 (size: 19.6 KiB, free: 1037.1 MiB)
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[73] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:37.144 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
23/10/18 18:40:37.144 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 41) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:37.144 Executor task launch worker for task 0.0 in stage 38.0 (TID 41) INFO Executor: Running task 0.0 in stage 38.0 (TID 41)
23/10/18 18:40:37.181 Executor task launch worker for task 0.0 in stage 38.0 (TID 41) INFO ShuffleBlockFetcherIterator: Getting 1 (245.2 KiB) non-empty blocks including 1 (245.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:37.181 Executor task launch worker for task 0.0 in stage 38.0 (TID 41) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
23/10/18 18:40:37.193 Executor task launch worker for task 0.0 in stage 38.0 (TID 41) INFO CodeGenerator: Code generated in 8.0604 ms
23/10/18 18:40:37.194 Executor task launch worker for task 0.0 in stage 38.0 (TID 41) INFO CodeGenerator: Code generated in 3.3171 ms
23/10/18 18:40:37.267 Executor task launch worker for task 0.0 in stage 38.0 (TID 41) INFO Executor: Finished task 0.0 in stage 38.0 (TID 41). 5381 bytes result sent to driver
23/10/18 18:40:37.267 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 41) in 123 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:37.267 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
23/10/18 18:40:37.267 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:26) finished in 0.123 s
23/10/18 18:40:37.267 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:37.271 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:37.271 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:37.271 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:37.272 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:40:37.276 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:37.293 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.3336 ms
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 76 (collect at utils.scala:26) as input to shuffle 11
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 25 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at utils.scala:26)
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[76] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 54.2 KiB, free 1037.0 MiB)
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 1036.9 MiB)
23/10/18 18:40:37.302 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:64093 (size: 22.8 KiB, free: 1037.1 MiB)
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[76] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:37.302 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
23/10/18 18:40:37.302 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 42) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:40:37.302 Executor task launch worker for task 0.0 in stage 41.0 (TID 42) INFO Executor: Running task 0.0 in stage 41.0 (TID 42)
23/10/18 18:40:37.310 Executor task launch worker for task 0.0 in stage 41.0 (TID 42) INFO ShuffleBlockFetcherIterator: Getting 1 (188.6 KiB) non-empty blocks including 1 (188.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:37.310 Executor task launch worker for task 0.0 in stage 41.0 (TID 42) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:37.318 Executor task launch worker for task 0.0 in stage 41.0 (TID 42) INFO CodeGenerator: Code generated in 4.7732 ms
23/10/18 18:40:37.327 Executor task launch worker for task 0.0 in stage 41.0 (TID 42) INFO CodeGenerator: Code generated in 4.5454 ms
23/10/18 18:40:37.372 Executor task launch worker for task 0.0 in stage 41.0 (TID 42) INFO Executor: Finished task 0.0 in stage 41.0 (TID 42). 7384 bytes result sent to driver
23/10/18 18:40:37.373 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 42) in 71 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:37.373 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
23/10/18 18:40:37.373 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:26) finished in 0.071 s
23/10/18 18:40:37.373 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:40:37.373 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:40:37.374 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:40:37.374 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:40:37.377 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:40:37.381 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:40:37.382 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.0509 ms
23/10/18 18:40:37.394 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:40:37.394 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:40:37.394 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:26)
23/10/18 18:40:37.394 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
23/10/18 18:40:37.394 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:40:37.394 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[79] at collect at utils.scala:26), which has no missing parents
23/10/18 18:40:37.402 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 48.5 KiB, free 1036.9 MiB)
23/10/18 18:40:37.402 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 20.9 KiB, free 1036.9 MiB)
23/10/18 18:40:37.402 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:64093 (size: 20.9 KiB, free: 1037.1 MiB)
23/10/18 18:40:37.402 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535
23/10/18 18:40:37.402 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[79] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:40:37.402 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
23/10/18 18:40:37.402 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 43) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:40:37.402 Executor task launch worker for task 0.0 in stage 45.0 (TID 43) INFO Executor: Running task 0.0 in stage 45.0 (TID 43)
23/10/18 18:40:37.409 Executor task launch worker for task 0.0 in stage 45.0 (TID 43) INFO ShuffleBlockFetcherIterator: Getting 1 (4.4 KiB) non-empty blocks including 1 (4.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:40:37.409 Executor task launch worker for task 0.0 in stage 45.0 (TID 43) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:40:37.409 Executor task launch worker for task 0.0 in stage 45.0 (TID 43) INFO Executor: Finished task 0.0 in stage 45.0 (TID 43). 11807 bytes result sent to driver
23/10/18 18:40:37.409 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 43) in 7 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:40:37.409 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
23/10/18 18:40:37.418 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 45 (collect at utils.scala:26) finished in 0.024 s
23/10/18 18:40:37.418 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:40:37.418 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
23/10/18 18:40:37.419 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0.019131 s
23/10/18 18:40:37.426 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.4902 ms
23/10/18 18:41:59.934 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:41:59.942 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.2706 ms
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 81 (collect at utils.scala:26) as input to shuffle 12
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 27 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 46 (collect at utils.scala:26)
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[81] at collect at utils.scala:26), which has no missing parents
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 28.2 KiB, free 1036.9 MiB)
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 12.9 KiB, free 1036.8 MiB)
23/10/18 18:41:59.951 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:64093 (size: 12.9 KiB, free: 1037.1 MiB)
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[81] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:41:59.951 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
23/10/18 18:42:00.195 dispatcher-event-loop-0 WARN TaskSetManager: Stage 46 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:42:00.195 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 44) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:42:00.195 Executor task launch worker for task 0.0 in stage 46.0 (TID 44) INFO Executor: Running task 0.0 in stage 46.0 (TID 44)
23/10/18 18:42:00.272 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:64093 in memory (size: 20.9 KiB, free: 1037.1 MiB)
23/10/18 18:42:00.275 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:64093 in memory (size: 19.6 KiB, free: 1037.1 MiB)
23/10/18 18:42:00.275 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:64093 in memory (size: 22.8 KiB, free: 1037.1 MiB)
23/10/18 18:42:00.340 Executor task launch worker for task 0.0 in stage 46.0 (TID 44) INFO CodeGenerator: Code generated in 5.3388 ms
23/10/18 18:42:00.348 Executor task launch worker for task 0.0 in stage 46.0 (TID 44) INFO CodeGenerator: Code generated in 3.5456 ms
23/10/18 18:42:00.528 Executor task launch worker for task 0.0 in stage 46.0 (TID 44) INFO Executor: Finished task 0.0 in stage 46.0 (TID 44). 2250 bytes result sent to driver
23/10/18 18:42:00.528 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 44) in 577 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:42:00.528 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
23/10/18 18:42:00.536 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 46 (collect at utils.scala:26) finished in 0.577 s
23/10/18 18:42:00.536 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:42:00.536 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:42:00.536 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:42:00.536 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:42:00.536 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:42:00.543 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:42:00.561 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.3593 ms
23/10/18 18:42:00.561 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 84 (collect at utils.scala:26) as input to shuffle 13
23/10/18 18:42:00.561 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 28 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:42:00.561 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 48 (collect at utils.scala:26)
23/10/18 18:42:00.561 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
23/10/18 18:42:00.561 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:42:00.561 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[84] at collect at utils.scala:26), which has no missing parents
23/10/18 18:42:00.569 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 45.2 KiB, free 1037.0 MiB)
23/10/18 18:42:00.569 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 1037.0 MiB)
23/10/18 18:42:00.569 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:64093 (size: 19.5 KiB, free: 1037.1 MiB)
23/10/18 18:42:00.569 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
23/10/18 18:42:00.569 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[84] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:42:00.569 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
23/10/18 18:42:00.569 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 45) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:42:00.569 Executor task launch worker for task 0.0 in stage 48.0 (TID 45) INFO Executor: Running task 0.0 in stage 48.0 (TID 45)
23/10/18 18:42:00.575 Executor task launch worker for task 0.0 in stage 48.0 (TID 45) INFO ShuffleBlockFetcherIterator: Getting 1 (33.5 KiB) non-empty blocks including 1 (33.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:00.575 Executor task launch worker for task 0.0 in stage 48.0 (TID 45) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:00.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:64093 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/18 18:42:00.623 Executor task launch worker for task 0.0 in stage 48.0 (TID 45) INFO Executor: Finished task 0.0 in stage 48.0 (TID 45). 5325 bytes result sent to driver
23/10/18 18:42:00.625 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 45) in 56 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:42:00.625 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
23/10/18 18:42:00.625 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 48 (collect at utils.scala:26) finished in 0.064 s
23/10/18 18:42:00.626 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:42:00.626 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:42:00.626 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:42:00.626 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:42:00.626 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:42:00.626 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:42:00.636 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.0834 ms
23/10/18 18:42:00.647 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:42:00.647 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:42:00.647 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:26)
23/10/18 18:42:00.647 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
23/10/18 18:42:00.647 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:42:00.647 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[87] at collect at utils.scala:26), which has no missing parents
23/10/18 18:42:00.651 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 39.2 KiB, free 1037.0 MiB)
23/10/18 18:42:00.651 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 1037.0 MiB)
23/10/18 18:42:00.651 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:64093 (size: 17.7 KiB, free: 1037.1 MiB)
23/10/18 18:42:00.651 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1535
23/10/18 18:42:00.651 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[87] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:42:00.651 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
23/10/18 18:42:00.651 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:42:00.651 Executor task launch worker for task 0.0 in stage 51.0 (TID 46) INFO Executor: Running task 0.0 in stage 51.0 (TID 46)
23/10/18 18:42:00.658 Executor task launch worker for task 0.0 in stage 51.0 (TID 46) INFO ShuffleBlockFetcherIterator: Getting 1 (1391.0 B) non-empty blocks including 1 (1391.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:00.658 Executor task launch worker for task 0.0 in stage 51.0 (TID 46) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:00.663 Executor task launch worker for task 0.0 in stage 51.0 (TID 46) INFO Executor: Finished task 0.0 in stage 51.0 (TID 46). 7602 bytes result sent to driver
23/10/18 18:42:00.667 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 16 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:42:00.667 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
23/10/18 18:42:00.667 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collect at utils.scala:26) finished in 0.016 s
23/10/18 18:42:00.667 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:42:00.667 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
23/10/18 18:42:00.667 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: collect at utils.scala:26, took 0.018684 s
23/10/18 18:42:00.671 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.4057 ms
23/10/18 18:42:17.868 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 89 (collect at utils.scala:26) as input to shuffle 14
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 30 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 52 (collect at utils.scala:26)
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[89] at collect at utils.scala:26), which has no missing parents
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 37.1 KiB, free 1036.9 MiB)
23/10/18 18:42:17.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 1036.9 MiB)
23/10/18 18:42:17.875 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:64093 (size: 16.8 KiB, free: 1037.1 MiB)
23/10/18 18:42:17.883 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535
23/10/18 18:42:17.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[89] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:42:17.883 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
23/10/18 18:42:18.086 dispatcher-event-loop-1 WARN TaskSetManager: Stage 52 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:42:18.086 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 47) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:42:18.086 Executor task launch worker for task 0.0 in stage 52.0 (TID 47) INFO Executor: Running task 0.0 in stage 52.0 (TID 47)
23/10/18 18:42:18.121 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:64093 in memory (size: 19.5 KiB, free: 1037.1 MiB)
23/10/18 18:42:18.121 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:64093 in memory (size: 17.7 KiB, free: 1037.1 MiB)
23/10/18 18:42:18.446 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:64093 in memory (size: 12.9 KiB, free: 1037.1 MiB)
23/10/18 18:42:18.860 Executor task launch worker for task 0.0 in stage 52.0 (TID 47) INFO Executor: Finished task 0.0 in stage 52.0 (TID 47). 2250 bytes result sent to driver
23/10/18 18:42:18.860 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 47) in 977 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:42:18.860 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
23/10/18 18:42:18.860 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 52 (collect at utils.scala:26) finished in 0.985 s
23/10/18 18:42:18.860 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:42:18.860 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:42:18.860 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:42:18.860 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:42:18.868 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:42:18.874 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:42:18.888 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 92 (collect at utils.scala:26) as input to shuffle 15
23/10/18 18:42:18.888 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 31 (collect at utils.scala:26) with 4 output partitions
23/10/18 18:42:18.888 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 54 (collect at utils.scala:26)
23/10/18 18:42:18.888 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
23/10/18 18:42:18.888 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:42:18.888 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[92] at collect at utils.scala:26), which has no missing parents
23/10/18 18:42:18.891 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 58.8 KiB, free 1037.0 MiB)
23/10/18 18:42:18.891 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 1037.0 MiB)
23/10/18 18:42:18.891 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:64093 (size: 23.5 KiB, free: 1037.1 MiB)
23/10/18 18:42:18.891 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
23/10/18 18:42:18.891 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[92] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
23/10/18 18:42:18.891 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks resource profile 0
23/10/18 18:42:18.891 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 48) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:42:18.891 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 49) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/18 18:42:18.891 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 50) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/18 18:42:18.891 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 51) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/18 18:42:18.900 Executor task launch worker for task 0.0 in stage 54.0 (TID 48) INFO Executor: Running task 0.0 in stage 54.0 (TID 48)
23/10/18 18:42:18.900 Executor task launch worker for task 1.0 in stage 54.0 (TID 49) INFO Executor: Running task 1.0 in stage 54.0 (TID 49)
23/10/18 18:42:18.900 Executor task launch worker for task 2.0 in stage 54.0 (TID 50) INFO Executor: Running task 2.0 in stage 54.0 (TID 50)
23/10/18 18:42:18.900 Executor task launch worker for task 3.0 in stage 54.0 (TID 51) INFO Executor: Running task 3.0 in stage 54.0 (TID 51)
23/10/18 18:42:18.905 Executor task launch worker for task 1.0 in stage 54.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:18.905 Executor task launch worker for task 3.0 in stage 54.0 (TID 51) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:18.905 Executor task launch worker for task 2.0 in stage 54.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:18.905 Executor task launch worker for task 0.0 in stage 54.0 (TID 48) INFO ShuffleBlockFetcherIterator: Getting 1 (1783.5 KiB) non-empty blocks including 1 (1783.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:18.906 Executor task launch worker for task 1.0 in stage 54.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:18.906 Executor task launch worker for task 2.0 in stage 54.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:18.906 Executor task launch worker for task 3.0 in stage 54.0 (TID 51) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:18.906 Executor task launch worker for task 0.0 in stage 54.0 (TID 48) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:19.154 Executor task launch worker for task 1.0 in stage 54.0 (TID 49) INFO Executor: Finished task 1.0 in stage 54.0 (TID 49). 5411 bytes result sent to driver
23/10/18 18:42:19.155 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 49) in 264 ms on 127.0.0.1 (executor driver) (1/4)
23/10/18 18:42:19.160 Executor task launch worker for task 3.0 in stage 54.0 (TID 51) INFO Executor: Finished task 3.0 in stage 54.0 (TID 51). 5411 bytes result sent to driver
23/10/18 18:42:19.161 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 51) in 270 ms on 127.0.0.1 (executor driver) (2/4)
23/10/18 18:42:19.163 Executor task launch worker for task 2.0 in stage 54.0 (TID 50) INFO Executor: Finished task 2.0 in stage 54.0 (TID 50). 5368 bytes result sent to driver
23/10/18 18:42:19.163 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 50) in 272 ms on 127.0.0.1 (executor driver) (3/4)
23/10/18 18:42:19.165 Executor task launch worker for task 0.0 in stage 54.0 (TID 48) INFO Executor: Finished task 0.0 in stage 54.0 (TID 48). 5411 bytes result sent to driver
23/10/18 18:42:19.165 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 48) in 274 ms on 127.0.0.1 (executor driver) (4/4)
23/10/18 18:42:19.165 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
23/10/18 18:42:19.167 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 54 (collect at utils.scala:26) finished in 0.276 s
23/10/18 18:42:19.167 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:42:19.167 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:42:19.167 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:42:19.167 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:42:19.169 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:42:19.176 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:42:19.185 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:26)
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[95] at collect at utils.scala:26), which has no missing parents
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 51.1 KiB, free 1037.0 MiB)
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 1036.9 MiB)
23/10/18 18:42:19.185 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:64093 (size: 21.5 KiB, free: 1037.1 MiB)
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[95] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:42:19.185 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
23/10/18 18:42:19.192 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 52) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:42:19.193 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO Executor: Running task 0.0 in stage 57.0 (TID 52)
23/10/18 18:42:19.193 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO ShuffleBlockFetcherIterator: Getting 4 (373.0 KiB) non-empty blocks including 4 (373.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:42:19.193 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:42:19.216 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO Executor: Finished task 0.0 in stage 57.0 (TID 52). 29208 bytes result sent to driver
23/10/18 18:42:19.216 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 52) in 24 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:42:19.216 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
23/10/18 18:42:19.216 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collect at utils.scala:26) finished in 0.031 s
23/10/18 18:42:19.216 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:42:19.216 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
23/10/18 18:42:19.216 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: collect at utils.scala:26, took 0.034923 s
23/10/18 18:43:38.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:64093 in memory (size: 23.5 KiB, free: 1037.1 MiB)
23/10/18 18:43:38.334 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:64093 in memory (size: 21.5 KiB, free: 1037.1 MiB)
23/10/18 18:43:38.398 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:38.407 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 97 (collect at utils.scala:26) as input to shuffle 16
23/10/18 18:43:38.407 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 33 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:43:38.407 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 58 (collect at utils.scala:26)
23/10/18 18:43:38.407 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:43:38.407 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:38.407 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[97] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:38.416 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 41.2 KiB, free 1037.0 MiB)
23/10/18 18:43:38.416 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 1037.0 MiB)
23/10/18 18:43:38.416 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:64093 (size: 18.3 KiB, free: 1037.1 MiB)
23/10/18 18:43:38.416 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:38.416 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[97] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:43:38.416 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
23/10/18 18:43:38.557 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:64093 in memory (size: 16.8 KiB, free: 1037.1 MiB)
23/10/18 18:43:38.761 dispatcher-event-loop-6 WARN TaskSetManager: Stage 58 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:43:38.761 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 53) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:43:38.761 Executor task launch worker for task 0.0 in stage 58.0 (TID 53) INFO Executor: Running task 0.0 in stage 58.0 (TID 53)
23/10/18 18:43:39.717 Executor task launch worker for task 0.0 in stage 58.0 (TID 53) INFO Executor: Finished task 0.0 in stage 58.0 (TID 53). 2293 bytes result sent to driver
23/10/18 18:43:39.717 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 53) in 1293 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:43:39.718 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
23/10/18 18:43:39.719 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 58 (collect at utils.scala:26) finished in 1.311 s
23/10/18 18:43:39.743 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:43:39.743 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:43:39.743 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:43:39.743 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:43:39.751 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1118735, minimum partition size: 1048576
23/10/18 18:43:39.756 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:39.773 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 100 (collect at utils.scala:26) as input to shuffle 17
23/10/18 18:43:39.773 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 34 (collect at utils.scala:26) with 8 output partitions
23/10/18 18:43:39.773 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at utils.scala:26)
23/10/18 18:43:39.773 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
23/10/18 18:43:39.773 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:39.773 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[100] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:39.781 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 60.1 KiB, free 1037.0 MiB)
23/10/18 18:43:39.781 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 1037.0 MiB)
23/10/18 18:43:39.781 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:64093 (size: 24.0 KiB, free: 1037.1 MiB)
23/10/18 18:43:39.781 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:39.781 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[100] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/18 18:43:39.781 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 8 tasks resource profile 0
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 54) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 55) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 56) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 57) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 58) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 59) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 60) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 61) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:39.781 Executor task launch worker for task 0.0 in stage 60.0 (TID 54) INFO Executor: Running task 0.0 in stage 60.0 (TID 54)
23/10/18 18:43:39.781 Executor task launch worker for task 1.0 in stage 60.0 (TID 55) INFO Executor: Running task 1.0 in stage 60.0 (TID 55)
23/10/18 18:43:39.781 Executor task launch worker for task 2.0 in stage 60.0 (TID 56) INFO Executor: Running task 2.0 in stage 60.0 (TID 56)
23/10/18 18:43:39.781 Executor task launch worker for task 3.0 in stage 60.0 (TID 57) INFO Executor: Running task 3.0 in stage 60.0 (TID 57)
23/10/18 18:43:39.791 Executor task launch worker for task 4.0 in stage 60.0 (TID 58) INFO Executor: Running task 4.0 in stage 60.0 (TID 58)
23/10/18 18:43:39.793 Executor task launch worker for task 2.0 in stage 60.0 (TID 56) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.793 Executor task launch worker for task 0.0 in stage 60.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.793 Executor task launch worker for task 3.0 in stage 60.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.794 Executor task launch worker for task 0.0 in stage 60.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.794 Executor task launch worker for task 2.0 in stage 60.0 (TID 56) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.794 Executor task launch worker for task 3.0 in stage 60.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.794 Executor task launch worker for task 6.0 in stage 60.0 (TID 60) INFO Executor: Running task 6.0 in stage 60.0 (TID 60)
23/10/18 18:43:39.795 Executor task launch worker for task 7.0 in stage 60.0 (TID 61) INFO Executor: Running task 7.0 in stage 60.0 (TID 61)
23/10/18 18:43:39.795 Executor task launch worker for task 4.0 in stage 60.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.795 Executor task launch worker for task 1.0 in stage 60.0 (TID 55) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.795 Executor task launch worker for task 4.0 in stage 60.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.796 Executor task launch worker for task 1.0 in stage 60.0 (TID 55) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.796 Executor task launch worker for task 6.0 in stage 60.0 (TID 60) INFO ShuffleBlockFetcherIterator: Getting 1 (1186.9 KiB) non-empty blocks including 1 (1186.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.796 Executor task launch worker for task 6.0 in stage 60.0 (TID 60) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.796 Executor task launch worker for task 7.0 in stage 60.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.796 Executor task launch worker for task 7.0 in stage 60.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.796 Executor task launch worker for task 5.0 in stage 60.0 (TID 59) INFO Executor: Running task 5.0 in stage 60.0 (TID 59)
23/10/18 18:43:39.796 Executor task launch worker for task 5.0 in stage 60.0 (TID 59) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:39.796 Executor task launch worker for task 5.0 in stage 60.0 (TID 59) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:39.922 Executor task launch worker for task 3.0 in stage 60.0 (TID 57) INFO Executor: Finished task 3.0 in stage 60.0 (TID 57). 5325 bytes result sent to driver
23/10/18 18:43:39.925 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 57) in 143 ms on 127.0.0.1 (executor driver) (1/8)
23/10/18 18:43:39.946 Executor task launch worker for task 0.0 in stage 60.0 (TID 54) INFO Executor: Finished task 0.0 in stage 60.0 (TID 54). 5325 bytes result sent to driver
23/10/18 18:43:39.946 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 54) in 165 ms on 127.0.0.1 (executor driver) (2/8)
23/10/18 18:43:39.956 Executor task launch worker for task 7.0 in stage 60.0 (TID 61) INFO Executor: Finished task 7.0 in stage 60.0 (TID 61). 5325 bytes result sent to driver
23/10/18 18:43:39.958 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 61) in 177 ms on 127.0.0.1 (executor driver) (3/8)
23/10/18 18:43:39.966 Executor task launch worker for task 4.0 in stage 60.0 (TID 58) INFO Executor: Finished task 4.0 in stage 60.0 (TID 58). 5368 bytes result sent to driver
23/10/18 18:43:39.966 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 58) in 185 ms on 127.0.0.1 (executor driver) (4/8)
23/10/18 18:43:39.970 Executor task launch worker for task 1.0 in stage 60.0 (TID 55) INFO Executor: Finished task 1.0 in stage 60.0 (TID 55). 5368 bytes result sent to driver
23/10/18 18:43:39.970 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 55) in 189 ms on 127.0.0.1 (executor driver) (5/8)
23/10/18 18:43:39.972 Executor task launch worker for task 5.0 in stage 60.0 (TID 59) INFO Executor: Finished task 5.0 in stage 60.0 (TID 59). 5325 bytes result sent to driver
23/10/18 18:43:39.972 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 59) in 191 ms on 127.0.0.1 (executor driver) (6/8)
23/10/18 18:43:39.973 Executor task launch worker for task 6.0 in stage 60.0 (TID 60) INFO Executor: Finished task 6.0 in stage 60.0 (TID 60). 5325 bytes result sent to driver
23/10/18 18:43:39.973 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 60) in 192 ms on 127.0.0.1 (executor driver) (7/8)
23/10/18 18:43:39.973 Executor task launch worker for task 2.0 in stage 60.0 (TID 56) INFO Executor: Finished task 2.0 in stage 60.0 (TID 56). 5325 bytes result sent to driver
23/10/18 18:43:39.973 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 56) in 192 ms on 127.0.0.1 (executor driver) (8/8)
23/10/18 18:43:39.973 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
23/10/18 18:43:39.973 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 60 (collect at utils.scala:26) finished in 0.200 s
23/10/18 18:43:39.973 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:43:39.973 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:43:39.973 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:43:39.973 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:43:39.981 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:43:39.981 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:39.990 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:43:39.990 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:43:39.990 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:26)
23/10/18 18:43:39.990 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
23/10/18 18:43:39.990 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:39.990 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[103] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:40.000 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 53.7 KiB, free 1036.9 MiB)
23/10/18 18:43:40.000 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 1036.9 MiB)
23/10/18 18:43:40.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:64093 (size: 22.6 KiB, free: 1037.1 MiB)
23/10/18 18:43:40.000 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:40.000 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[103] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:43:40.000 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
23/10/18 18:43:40.000 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 62) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:43:40.000 Executor task launch worker for task 0.0 in stage 63.0 (TID 62) INFO Executor: Running task 0.0 in stage 63.0 (TID 62)
23/10/18 18:43:40.007 Executor task launch worker for task 0.0 in stage 63.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 8 (1987.5 KiB) non-empty blocks including 8 (1987.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:40.007 Executor task launch worker for task 0.0 in stage 63.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:40.058 Executor task launch worker for task 0.0 in stage 63.0 (TID 62) INFO Executor: Finished task 0.0 in stage 63.0 (TID 62). 27646 bytes result sent to driver
23/10/18 18:43:40.058 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 62) in 58 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:43:40.058 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
23/10/18 18:43:40.058 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 63 (collect at utils.scala:26) finished in 0.068 s
23/10/18 18:43:40.058 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:43:40.058 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
23/10/18 18:43:40.058 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 35 finished: collect at utils.scala:26, took 0.063675 s
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:26) as input to shuffle 18
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 36 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 64 (collect at utils.scala:26)
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[105] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 37.6 KiB, free 1036.9 MiB)
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1036.9 MiB)
23/10/18 18:43:41.542 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:64093 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[105] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:43:41.542 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
23/10/18 18:43:41.749 dispatcher-event-loop-5 WARN TaskSetManager: Stage 64 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:43:41.749 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 63) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:43:41.749 Executor task launch worker for task 0.0 in stage 64.0 (TID 63) INFO Executor: Running task 0.0 in stage 64.0 (TID 63)
23/10/18 18:43:41.974 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:64093 in memory (size: 24.0 KiB, free: 1037.1 MiB)
23/10/18 18:43:41.974 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:64093 in memory (size: 22.6 KiB, free: 1037.1 MiB)
23/10/18 18:43:42.180 Executor task launch worker for task 0.0 in stage 64.0 (TID 63) INFO Executor: Finished task 0.0 in stage 64.0 (TID 63). 2293 bytes result sent to driver
23/10/18 18:43:42.180 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 63) in 638 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:43:42.180 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
23/10/18 18:43:42.180 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 64 (collect at utils.scala:26) finished in 0.638 s
23/10/18 18:43:42.180 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:43:42.180 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:43:42.180 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:43:42.180 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:43:42.198 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:43:42.208 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:42.208 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:42.223 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 108 (collect at utils.scala:26) as input to shuffle 19
23/10/18 18:43:42.223 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 37 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:43:42.223 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 66 (collect at utils.scala:26)
23/10/18 18:43:42.223 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
23/10/18 18:43:42.223 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:42.228 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[108] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:42.228 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 45.9 KiB, free 1037.0 MiB)
23/10/18 18:43:42.228 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 1037.0 MiB)
23/10/18 18:43:42.228 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:64093 (size: 19.6 KiB, free: 1037.1 MiB)
23/10/18 18:43:42.228 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:42.228 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[108] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:43:42.228 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
23/10/18 18:43:42.238 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 64) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:42.238 Executor task launch worker for task 0.0 in stage 66.0 (TID 64) INFO Executor: Running task 0.0 in stage 66.0 (TID 64)
23/10/18 18:43:42.241 Executor task launch worker for task 0.0 in stage 66.0 (TID 64) INFO ShuffleBlockFetcherIterator: Getting 1 (245.2 KiB) non-empty blocks including 1 (245.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:42.241 Executor task launch worker for task 0.0 in stage 66.0 (TID 64) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/18 18:43:42.341 Executor task launch worker for task 0.0 in stage 66.0 (TID 64) INFO Executor: Finished task 0.0 in stage 66.0 (TID 64). 5381 bytes result sent to driver
23/10/18 18:43:42.341 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 64) in 103 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:43:42.341 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
23/10/18 18:43:42.341 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 66 (collect at utils.scala:26) finished in 0.113 s
23/10/18 18:43:42.341 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:43:42.341 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:43:42.341 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:43:42.341 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:43:42.349 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:43:42.349 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 111 (collect at utils.scala:26) as input to shuffle 20
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 38 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 69 (collect at utils.scala:26)
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[111] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 54.2 KiB, free 1036.9 MiB)
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 1036.9 MiB)
23/10/18 18:43:42.365 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:64093 (size: 22.8 KiB, free: 1037.1 MiB)
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[111] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:43:42.365 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
23/10/18 18:43:42.365 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 65) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:43:42.365 Executor task launch worker for task 0.0 in stage 69.0 (TID 65) INFO Executor: Running task 0.0 in stage 69.0 (TID 65)
23/10/18 18:43:42.377 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:64093 in memory (size: 18.3 KiB, free: 1037.1 MiB)
23/10/18 18:43:42.377 Executor task launch worker for task 0.0 in stage 69.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 1 (188.6 KiB) non-empty blocks including 1 (188.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:42.377 Executor task launch worker for task 0.0 in stage 69.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:42.418 Executor task launch worker for task 0.0 in stage 69.0 (TID 65) INFO Executor: Finished task 0.0 in stage 69.0 (TID 65). 7341 bytes result sent to driver
23/10/18 18:43:42.418 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 65) in 53 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:43:42.418 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
23/10/18 18:43:42.418 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 69 (collect at utils.scala:26) finished in 0.053 s
23/10/18 18:43:42.418 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:43:42.418 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:43:42.418 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:43:42.418 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:43:42.423 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:43:42.423 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:43:42.440 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:43:42.441 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:43:42.442 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:26)
23/10/18 18:43:42.442 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
23/10/18 18:43:42.442 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:43:42.442 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[114] at collect at utils.scala:26), which has no missing parents
23/10/18 18:43:42.444 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 48.5 KiB, free 1036.9 MiB)
23/10/18 18:43:42.445 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 1036.9 MiB)
23/10/18 18:43:42.446 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:64093 (size: 21.0 KiB, free: 1037.1 MiB)
23/10/18 18:43:42.446 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
23/10/18 18:43:42.446 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[114] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:43:42.447 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
23/10/18 18:43:42.448 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 66) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:43:42.448 Executor task launch worker for task 0.0 in stage 73.0 (TID 66) INFO Executor: Running task 0.0 in stage 73.0 (TID 66)
23/10/18 18:43:42.451 Executor task launch worker for task 0.0 in stage 73.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 1 (4.4 KiB) non-empty blocks including 1 (4.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:43:42.451 Executor task launch worker for task 0.0 in stage 73.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:43:42.457 Executor task launch worker for task 0.0 in stage 73.0 (TID 66) INFO Executor: Finished task 0.0 in stage 73.0 (TID 66). 11850 bytes result sent to driver
23/10/18 18:43:42.457 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 66) in 10 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:43:42.457 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
23/10/18 18:43:42.457 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 73 (collect at utils.scala:26) finished in 0.014 s
23/10/18 18:43:42.457 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:43:42.457 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
23/10/18 18:43:42.457 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: collect at utils.scala:26, took 0.018969 s
23/10/18 18:44:38.680 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:26) as input to shuffle 21
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 40 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 74 (collect at utils.scala:26)
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[116] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 41.2 KiB, free 1036.8 MiB)
23/10/18 18:44:38.691 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 1036.8 MiB)
23/10/18 18:44:38.699 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:64093 (size: 18.3 KiB, free: 1037.0 MiB)
23/10/18 18:44:38.699 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:38.699 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[116] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:44:38.699 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
23/10/18 18:44:38.917 dispatcher-event-loop-1 WARN TaskSetManager: Stage 74 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:44:38.917 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 67) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:44:38.917 Executor task launch worker for task 0.0 in stage 74.0 (TID 67) INFO Executor: Running task 0.0 in stage 74.0 (TID 67)
23/10/18 18:44:39.135 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:64093 in memory (size: 19.6 KiB, free: 1037.1 MiB)
23/10/18 18:44:39.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:64093 in memory (size: 22.8 KiB, free: 1037.1 MiB)
23/10/18 18:44:39.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:64093 in memory (size: 21.0 KiB, free: 1037.1 MiB)
23/10/18 18:44:39.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:64093 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/18 18:44:39.670 Executor task launch worker for task 0.0 in stage 74.0 (TID 67) INFO Executor: Finished task 0.0 in stage 74.0 (TID 67). 2250 bytes result sent to driver
23/10/18 18:44:39.670 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 67) in 971 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:44:39.672 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
23/10/18 18:44:39.672 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 74 (collect at utils.scala:26) finished in 0.981 s
23/10/18 18:44:39.672 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:44:39.672 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:44:39.672 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:44:39.672 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:44:39.673 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1118735, minimum partition size: 1048576
23/10/18 18:44:39.681 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:39.701 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 119 (collect at utils.scala:26) as input to shuffle 22
23/10/18 18:44:39.701 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 41 (collect at utils.scala:26) with 8 output partitions
23/10/18 18:44:39.701 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 76 (collect at utils.scala:26)
23/10/18 18:44:39.701 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
23/10/18 18:44:39.701 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:39.702 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[119] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:39.704 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 60.1 KiB, free 1037.0 MiB)
23/10/18 18:44:39.706 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 1037.0 MiB)
23/10/18 18:44:39.706 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:64093 (size: 24.0 KiB, free: 1037.1 MiB)
23/10/18 18:44:39.707 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:39.707 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[119] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/18 18:44:39.707 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 76.0 with 8 tasks resource profile 0
23/10/18 18:44:39.708 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 68) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.708 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 69) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.708 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 70) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.709 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 71) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.709 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 76.0 (TID 72) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.709 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 76.0 (TID 73) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.710 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 76.0 (TID 74) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.710 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 76.0 (TID 75) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:39.710 Executor task launch worker for task 0.0 in stage 76.0 (TID 68) INFO Executor: Running task 0.0 in stage 76.0 (TID 68)
23/10/18 18:44:39.710 Executor task launch worker for task 1.0 in stage 76.0 (TID 69) INFO Executor: Running task 1.0 in stage 76.0 (TID 69)
23/10/18 18:44:39.711 Executor task launch worker for task 3.0 in stage 76.0 (TID 71) INFO Executor: Running task 3.0 in stage 76.0 (TID 71)
23/10/18 18:44:39.711 Executor task launch worker for task 2.0 in stage 76.0 (TID 70) INFO Executor: Running task 2.0 in stage 76.0 (TID 70)
23/10/18 18:44:39.711 Executor task launch worker for task 4.0 in stage 76.0 (TID 72) INFO Executor: Running task 4.0 in stage 76.0 (TID 72)
23/10/18 18:44:39.711 Executor task launch worker for task 6.0 in stage 76.0 (TID 74) INFO Executor: Running task 6.0 in stage 76.0 (TID 74)
23/10/18 18:44:39.711 Executor task launch worker for task 7.0 in stage 76.0 (TID 75) INFO Executor: Running task 7.0 in stage 76.0 (TID 75)
23/10/18 18:44:39.711 Executor task launch worker for task 5.0 in stage 76.0 (TID 73) INFO Executor: Running task 5.0 in stage 76.0 (TID 73)
23/10/18 18:44:39.715 Executor task launch worker for task 7.0 in stage 76.0 (TID 75) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.715 Executor task launch worker for task 4.0 in stage 76.0 (TID 72) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.715 Executor task launch worker for task 1.0 in stage 76.0 (TID 69) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.715 Executor task launch worker for task 5.0 in stage 76.0 (TID 73) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.716 Executor task launch worker for task 1.0 in stage 76.0 (TID 69) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.716 Executor task launch worker for task 5.0 in stage 76.0 (TID 73) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.715 Executor task launch worker for task 6.0 in stage 76.0 (TID 74) INFO ShuffleBlockFetcherIterator: Getting 1 (1186.9 KiB) non-empty blocks including 1 (1186.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.716 Executor task launch worker for task 7.0 in stage 76.0 (TID 75) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.715 Executor task launch worker for task 0.0 in stage 76.0 (TID 68) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.716 Executor task launch worker for task 0.0 in stage 76.0 (TID 68) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.716 Executor task launch worker for task 6.0 in stage 76.0 (TID 74) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.716 Executor task launch worker for task 4.0 in stage 76.0 (TID 72) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.717 Executor task launch worker for task 3.0 in stage 76.0 (TID 71) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.717 Executor task launch worker for task 3.0 in stage 76.0 (TID 71) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.717 Executor task launch worker for task 2.0 in stage 76.0 (TID 70) INFO ShuffleBlockFetcherIterator: Getting 1 (1079.0 KiB) non-empty blocks including 1 (1079.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.717 Executor task launch worker for task 2.0 in stage 76.0 (TID 70) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.827 Executor task launch worker for task 7.0 in stage 76.0 (TID 75) INFO Executor: Finished task 7.0 in stage 76.0 (TID 75). 5325 bytes result sent to driver
23/10/18 18:44:39.828 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 76.0 (TID 75) in 118 ms on 127.0.0.1 (executor driver) (1/8)
23/10/18 18:44:39.831 Executor task launch worker for task 2.0 in stage 76.0 (TID 70) INFO Executor: Finished task 2.0 in stage 76.0 (TID 70). 5368 bytes result sent to driver
23/10/18 18:44:39.832 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 70) in 124 ms on 127.0.0.1 (executor driver) (2/8)
23/10/18 18:44:39.835 Executor task launch worker for task 1.0 in stage 76.0 (TID 69) INFO Executor: Finished task 1.0 in stage 76.0 (TID 69). 5325 bytes result sent to driver
23/10/18 18:44:39.836 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 69) in 127 ms on 127.0.0.1 (executor driver) (3/8)
23/10/18 18:44:39.839 Executor task launch worker for task 6.0 in stage 76.0 (TID 74) INFO Executor: Finished task 6.0 in stage 76.0 (TID 74). 5325 bytes result sent to driver
23/10/18 18:44:39.840 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 76.0 (TID 74) in 131 ms on 127.0.0.1 (executor driver) (4/8)
23/10/18 18:44:39.844 Executor task launch worker for task 4.0 in stage 76.0 (TID 72) INFO Executor: Finished task 4.0 in stage 76.0 (TID 72). 5325 bytes result sent to driver
23/10/18 18:44:39.844 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 76.0 (TID 72) in 135 ms on 127.0.0.1 (executor driver) (5/8)
23/10/18 18:44:39.844 Executor task launch worker for task 3.0 in stage 76.0 (TID 71) INFO Executor: Finished task 3.0 in stage 76.0 (TID 71). 5368 bytes result sent to driver
23/10/18 18:44:39.844 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 71) in 135 ms on 127.0.0.1 (executor driver) (6/8)
23/10/18 18:44:39.844 Executor task launch worker for task 5.0 in stage 76.0 (TID 73) INFO Executor: Finished task 5.0 in stage 76.0 (TID 73). 5325 bytes result sent to driver
23/10/18 18:44:39.844 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 76.0 (TID 73) in 135 ms on 127.0.0.1 (executor driver) (7/8)
23/10/18 18:44:39.852 Executor task launch worker for task 0.0 in stage 76.0 (TID 68) INFO Executor: Finished task 0.0 in stage 76.0 (TID 68). 5325 bytes result sent to driver
23/10/18 18:44:39.852 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 68) in 144 ms on 127.0.0.1 (executor driver) (8/8)
23/10/18 18:44:39.852 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
23/10/18 18:44:39.852 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 76 (collect at utils.scala:26) finished in 0.149 s
23/10/18 18:44:39.852 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:44:39.852 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:44:39.852 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:44:39.852 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:44:39.857 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:44:39.857 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:39.865 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:44:39.865 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:44:39.865 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:26)
23/10/18 18:44:39.865 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
23/10/18 18:44:39.865 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:39.865 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[122] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:39.874 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 53.7 KiB, free 1036.9 MiB)
23/10/18 18:44:39.874 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 1036.9 MiB)
23/10/18 18:44:39.874 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:64093 (size: 22.6 KiB, free: 1037.1 MiB)
23/10/18 18:44:39.874 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:39.874 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[122] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:44:39.874 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
23/10/18 18:44:39.874 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 76) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:44:39.874 Executor task launch worker for task 0.0 in stage 79.0 (TID 76) INFO Executor: Running task 0.0 in stage 79.0 (TID 76)
23/10/18 18:44:39.874 Executor task launch worker for task 0.0 in stage 79.0 (TID 76) INFO ShuffleBlockFetcherIterator: Getting 8 (1987.5 KiB) non-empty blocks including 8 (1987.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:39.874 Executor task launch worker for task 0.0 in stage 79.0 (TID 76) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:39.939 Executor task launch worker for task 0.0 in stage 79.0 (TID 76) INFO Executor: Finished task 0.0 in stage 79.0 (TID 76). 27646 bytes result sent to driver
23/10/18 18:44:39.939 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 76) in 65 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:44:39.939 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
23/10/18 18:44:39.939 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 79 (collect at utils.scala:26) finished in 0.067 s
23/10/18 18:44:39.939 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:44:39.939 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
23/10/18 18:44:39.939 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0.072299 s
23/10/18 18:44:42.006 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 124 (collect at utils.scala:26) as input to shuffle 23
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 43 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 80 (collect at utils.scala:26)
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[124] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 37.6 KiB, free 1036.9 MiB)
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1036.9 MiB)
23/10/18 18:44:42.012 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:64093 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[124] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:44:42.012 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
23/10/18 18:44:42.264 dispatcher-event-loop-6 WARN TaskSetManager: Stage 80 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 18:44:42.264 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 77) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/18 18:44:42.264 Executor task launch worker for task 0.0 in stage 80.0 (TID 77) INFO Executor: Running task 0.0 in stage 80.0 (TID 77)
23/10/18 18:44:42.351 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:64093 in memory (size: 22.6 KiB, free: 1037.1 MiB)
23/10/18 18:44:42.356 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:64093 in memory (size: 24.0 KiB, free: 1037.1 MiB)
23/10/18 18:44:42.573 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:64093 in memory (size: 18.3 KiB, free: 1037.1 MiB)
23/10/18 18:44:42.735 Executor task launch worker for task 0.0 in stage 80.0 (TID 77) INFO Executor: Finished task 0.0 in stage 80.0 (TID 77). 2250 bytes result sent to driver
23/10/18 18:44:42.735 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 77) in 723 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:44:42.735 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
23/10/18 18:44:42.735 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 80 (collect at utils.scala:26) finished in 0.723 s
23/10/18 18:44:42.735 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:44:42.735 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:44:42.735 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:44:42.735 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:44:42.739 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:44:42.747 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:42.747 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 127 (collect at utils.scala:26) as input to shuffle 24
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 44 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 82 (collect at utils.scala:26)
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[127] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 45.9 KiB, free 1037.0 MiB)
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 1037.0 MiB)
23/10/18 18:44:42.756 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:64093 (size: 19.6 KiB, free: 1037.1 MiB)
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[127] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:44:42.756 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
23/10/18 18:44:42.756 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 78) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:42.756 Executor task launch worker for task 0.0 in stage 82.0 (TID 78) INFO Executor: Running task 0.0 in stage 82.0 (TID 78)
23/10/18 18:44:42.764 Executor task launch worker for task 0.0 in stage 82.0 (TID 78) INFO ShuffleBlockFetcherIterator: Getting 1 (245.2 KiB) non-empty blocks including 1 (245.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:42.764 Executor task launch worker for task 0.0 in stage 82.0 (TID 78) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:42.888 Executor task launch worker for task 0.0 in stage 82.0 (TID 78) INFO Executor: Finished task 0.0 in stage 82.0 (TID 78). 5424 bytes result sent to driver
23/10/18 18:44:42.888 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 78) in 132 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:44:42.888 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
23/10/18 18:44:42.894 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 82 (collect at utils.scala:26) finished in 0.137 s
23/10/18 18:44:42.894 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:44:42.894 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:44:42.894 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:44:42.894 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:44:42.894 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:44:42.905 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 130 (collect at utils.scala:26) as input to shuffle 25
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 45 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 85 (collect at utils.scala:26)
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[130] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:42.914 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 54.2 KiB, free 1037.0 MiB)
23/10/18 18:44:42.922 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 1036.9 MiB)
23/10/18 18:44:42.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:64093 (size: 22.9 KiB, free: 1037.1 MiB)
23/10/18 18:44:42.923 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:42.923 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[130] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:44:42.923 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
23/10/18 18:44:42.926 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 79) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/18 18:44:42.926 Executor task launch worker for task 0.0 in stage 85.0 (TID 79) INFO Executor: Running task 0.0 in stage 85.0 (TID 79)
23/10/18 18:44:42.930 Executor task launch worker for task 0.0 in stage 85.0 (TID 79) INFO ShuffleBlockFetcherIterator: Getting 1 (188.6 KiB) non-empty blocks including 1 (188.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:42.930 Executor task launch worker for task 0.0 in stage 85.0 (TID 79) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:42.980 Executor task launch worker for task 0.0 in stage 85.0 (TID 79) INFO Executor: Finished task 0.0 in stage 85.0 (TID 79). 7341 bytes result sent to driver
23/10/18 18:44:42.980 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 79) in 54 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:44:42.980 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
23/10/18 18:44:42.980 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 85 (collect at utils.scala:26) finished in 0.066 s
23/10/18 18:44:42.980 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/18 18:44:42.980 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/18 18:44:42.980 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/18 18:44:42.980 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/18 18:44:42.980 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/18 18:44:42.989 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/18 18:44:42.998 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:44:42.998 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:44:42.998 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:26)
23/10/18 18:44:42.998 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
23/10/18 18:44:43.005 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:44:43.005 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[133] at collect at utils.scala:26), which has no missing parents
23/10/18 18:44:43.007 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 48.5 KiB, free 1036.9 MiB)
23/10/18 18:44:43.010 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 1036.9 MiB)
23/10/18 18:44:43.010 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:64093 (size: 21.0 KiB, free: 1037.1 MiB)
23/10/18 18:44:43.010 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
23/10/18 18:44:43.010 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[133] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:44:43.010 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
23/10/18 18:44:43.010 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 80) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/18 18:44:43.010 Executor task launch worker for task 0.0 in stage 89.0 (TID 80) INFO Executor: Running task 0.0 in stage 89.0 (TID 80)
23/10/18 18:44:43.010 Executor task launch worker for task 0.0 in stage 89.0 (TID 80) INFO ShuffleBlockFetcherIterator: Getting 1 (4.4 KiB) non-empty blocks including 1 (4.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/18 18:44:43.010 Executor task launch worker for task 0.0 in stage 89.0 (TID 80) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/18 18:44:43.018 Executor task launch worker for task 0.0 in stage 89.0 (TID 80) INFO Executor: Finished task 0.0 in stage 89.0 (TID 80). 11850 bytes result sent to driver
23/10/18 18:44:43.022 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 80) in 12 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 18:44:43.022 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
23/10/18 18:44:43.022 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 89 (collect at utils.scala:26) finished in 0.015 s
23/10/18 18:44:43.022 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 18:44:43.022 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
23/10/18 18:44:43.022 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: collect at utils.scala:26, took 0.019359 s
23/10/18 18:50:17.633 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:64093 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/18 18:50:17.639 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:64093 in memory (size: 19.6 KiB, free: 1037.1 MiB)
23/10/18 18:50:17.639 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:64093 in memory (size: 22.9 KiB, free: 1037.1 MiB)
23/10/18 18:50:17.639 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:64093 in memory (size: 21.0 KiB, free: 1037.1 MiB)
23/10/18 18:59:59.773 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (collect at utils.scala:26) with 1 output partitions
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:26)
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[135] at collect at utils.scala:26), which has no missing parents
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 11.7 KiB, free 1037.1 MiB)
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 1037.1 MiB)
23/10/18 18:59:59.781 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:64093 (size: 5.1 KiB, free: 1037.1 MiB)
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[135] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/18 18:59:59.781 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
23/10/18 19:00:00.116 dispatcher-event-loop-6 WARN TaskSetManager: Stage 90 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/18 19:00:00.116 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 81) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/18 19:00:00.116 Executor task launch worker for task 0.0 in stage 90.0 (TID 81) INFO Executor: Running task 0.0 in stage 90.0 (TID 81)
23/10/18 19:00:00.404 Executor task launch worker for task 0.0 in stage 90.0 (TID 81) INFO Executor: Finished task 0.0 in stage 90.0 (TID 81). 41032 bytes result sent to driver
23/10/18 19:00:00.405 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 81) in 614 ms on 127.0.0.1 (executor driver) (1/1)
23/10/18 19:00:00.405 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
23/10/18 19:00:00.405 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 90 (collect at utils.scala:26) finished in 0.624 s
23/10/18 19:00:00.406 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/18 19:00:00.406 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
23/10/18 19:00:00.406 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: collect at utils.scala:26, took 0.624159 s
23/10/18 19:17:11.752 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:64093 in memory (size: 5.1 KiB, free: 1037.1 MiB)
23/10/18 21:05:15.705 dispatcher-HeartbeatReceiver WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 3018386 ms exceeds timeout 120000 ms
23/10/18 21:05:15.714 kill-executor-thread WARN SparkContext: Killing executors is not supported by current scheduler.
23/10/18 21:05:18.349 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.350 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.350 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.364 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.363 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.365 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.366 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.366 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.366 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.367 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.368 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.368 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.368 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.369 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.369 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.370 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.370 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.370 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.371 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.371 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.372 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.372 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.372 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.372 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.372 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.374 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.374 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.374 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.374 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.375 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.375 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.376 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.376 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.376 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.377 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.377 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.377 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.377 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.378 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.378 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.379 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.379 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.379 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.379 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.379 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.381 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.381 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.382 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.382 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.382 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.383 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.384 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.384 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.386 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.386 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.389 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.389 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.389 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.390 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.390 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.391 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.391 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.391 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.391 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.392 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.392 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.392 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.393 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.394 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.394 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.395 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.395 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.395 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.396 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.396 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.397 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.397 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.397 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.398 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.398 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.399 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.399 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.399 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.400 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.400 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.401 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.401 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.401 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.401 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.401 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.402 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.402 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.402 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.403 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.403 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.404 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.404 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.404 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.404 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.404 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.405 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.405 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.405 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.407 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.407 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.408 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.408 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.408 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.409 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.409 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.409 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.409 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.409 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.410 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.410 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.411 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.411 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.411 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.412 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.412 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.412 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.413 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.413 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.413 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.413 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.414 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.414 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.414 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.414 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.414 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.415 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.415 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.415 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.417 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.417 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.418 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.418 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.418 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.418 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.418 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.419 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.419 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.419 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.420 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.420 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.421 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.421 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.421 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.429 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.429 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.438 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.439 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.439 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.440 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.440 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.441 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.441 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.441 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.447 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.447 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.448 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.448 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.448 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.449 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.449 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.450 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.450 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.450 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.451 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.451 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.452 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.452 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.452 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.453 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.453 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.454 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.454 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.454 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.455 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.455 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.457 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.457 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.457 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.457 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.457 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.458 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.458 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.458 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.459 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.459 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.460 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.460 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.460 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.461 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.461 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.462 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.462 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.462 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.464 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.464 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.465 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.465 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.465 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.466 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.466 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.467 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.467 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.467 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.468 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.468 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.469 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.469 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.469 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.470 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.470 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.471 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.471 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.471 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.471 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.471 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.472 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.472 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.472 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.473 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.473 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.473 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.473 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.473 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.476 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.476 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.476 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.477 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.477 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.477 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.477 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.478 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.478 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.478 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.479 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.479 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.480 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.480 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.480 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.480 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.480 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.481 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.481 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.481 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.482 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.482 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.483 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.483 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.483 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.484 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.484 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.486 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.486 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.486 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.487 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.488 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.489 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.489 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.489 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.489 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.489 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.490 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.490 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.490 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.491 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.491 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
23/10/18 21:05:18.492 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.492 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.492 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.493 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.493 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.494 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.494 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.494 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.494 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.494 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.495 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.495 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.495 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.496 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.496 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.496 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.496 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.496 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.497 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.497 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.497 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.497 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.497 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.500 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.500 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.501 executor-heartbeater INFO Executor: Told to re-register on heartbeat
23/10/18 21:05:18.501 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None) re-registering with master
23/10/18 21:05:18.501 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64093, None)
23/10/18 21:05:18.501 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.501 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@127.0.0.1:64091
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
23/10/18 21:05:18.502 executor-heartbeater ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times
23/10/18 21:05:28.529 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
23/10/18 21:05:28.529 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/10/18 21:05:28.546 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/10/18 21:05:28.559 dispatcher-event-loop-7 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/10/18 21:05:28.638 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
23/10/18 21:05:28.638 shutdown-hook-0 INFO BlockManager: BlockManager stopped
23/10/18 21:05:28.642 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
23/10/18 21:05:28.645 dispatcher-event-loop-5 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/10/18 21:05:28.650 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0
java.io.IOException: Failed to delete: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0\sparklyr-master-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
23/10/18 21:05:28.651 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
23/10/18 21:05:28.651 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
23/10/18 21:05:28.652 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\priya\AppData\Local\Temp\spark-60a664ca-50bc-45f1-b605-ca80e9e2dc0f
23/10/18 21:05:28.653 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0
23/10/18 21:05:28.654 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0
java.io.IOException: Failed to delete: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0\sparklyr-master-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
23/10/18 21:05:28.654 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e
23/10/18 21:05:28.656 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e
java.io.IOException: Failed to delete: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-04df42eb-dab9-4ffe-8628-449cb7680a9e\userFiles-9d1aa5d3-bd6f-46f2-b9da-94c31ce0acd0\sparklyr-master-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
23/10/22 13:35:37.117 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/conf/hive-site.xml
23/10/22 13:35:37.383 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.0
23/10/22 13:35:37.507 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/10/22 13:35:37.550 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/10/22 13:35:37.550 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/10/22 13:35:37.550 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/10/22 13:35:37.550 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/10/22 13:35:37.601 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/10/22 13:35:37.616 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/10/22 13:35:37.616 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/10/22 13:35:37.683 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: priya
23/10/22 13:35:37.683 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: priya
23/10/22 13:35:37.683 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/10/22 13:35:37.683 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/10/22 13:35:37.683 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: priya; groups with view permissions: EMPTY; users with modify permissions: priya; groups with modify permissions: EMPTY
23/10/22 13:35:37.820 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 57168.
23/10/22 13:35:37.859 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/10/22 13:35:37.899 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/10/22 13:35:37.920 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/10/22 13:35:37.928 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/10/22 13:35:37.928 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/10/22 13:35:37.967 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\blockmgr-647dafb3-a6a2-46c5-bc59-00f04941f3f3
23/10/22 13:35:37.992 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
23/10/22 13:35:38.001 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/10/22 13:35:38.017 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/local]. Please check your configured local directories.
23/10/22 13:35:38.224 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
23/10/22 13:35:38.326 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/10/22 13:35:38.374 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/priya/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:57168/jars/sparklyr-master-2.12.jar with timestamp 1697952937374
23/10/22 13:35:38.458 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/10/22 13:35:38.466 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/10/22 13:35:38.474 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:57168/jars/sparklyr-master-2.12.jar with timestamp 1697952937374
23/10/22 13:35:38.518 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57168 after 16 ms (0 ms spent in bootstraps)
23/10/22 13:35:38.524 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:57168/jars/sparklyr-master-2.12.jar to C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0\fetchFileTemp2028965066983367694.tmp
23/10/22 13:35:38.624 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/local/spark-b91f7b0c-5116-49d6-ac6a-11f71741d377/userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0/sparklyr-master-2.12.jar to class loader
23/10/22 13:35:38.641 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57170.
23/10/22 13:35:38.649 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:57170
23/10/22 13:35:38.649 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/10/22 13:35:38.657 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57170, None)
23/10/22 13:35:38.661 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57170 with 1048.8 MiB RAM, BlockManagerId(driver, 127.0.0.1, 57170, None)
23/10/22 13:35:38.661 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57170, None)
23/10/22 13:35:38.667 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57170, None)
23/10/22 13:35:39.001 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
23/10/22 13:35:39.026 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive'.
23/10/22 13:35:43.624 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/10/22 13:35:43.985 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive
23/10/22 13:35:44.191 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/10/22 13:35:44.191 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/10/22 13:35:44.191 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/10/22 13:35:44.259 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/10/22 13:35:44.459 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/10/22 13:35:44.459 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/10/22 13:35:45.846 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/10/22 13:35:47.301 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/10/22 13:35:47.301 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/10/22 13:35:47.374 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/10/22 13:35:47.374 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.72
23/10/22 13:35:47.406 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/10/22 13:35:47.558 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/10/22 13:35:47.558 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/10/22 13:35:47.607 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/10/22 13:35:47.733 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:35:47.733 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:35:47.749 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/22 13:35:47.757 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/22 13:35:48.748 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 261.6755 ms
23/10/22 13:35:48.890 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:35:48.890 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.006113 s
23/10/22 13:36:00.258 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.7793 ms
23/10/22 13:36:00.268 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:00.282 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:00.290 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
23/10/22 13:36:00.290 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:00.290 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:00.290 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:00.350 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.4 KiB, free 1048.8 MiB)
23/10/22 13:36:00.402 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1048.8 MiB)
23/10/22 13:36:00.402 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 13:36:00.410 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:00.426 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:00.435 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/10/22 13:36:00.509 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 13:36:00.530 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/10/22 13:36:00.626 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1499 bytes result sent to driver
23/10/22 13:36:00.634 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 141 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:00.642 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/10/22 13:36:00.642 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.342 s
23/10/22 13:36:00.650 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:00.650 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/10/22 13:36:00.650 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.375619 s
23/10/22 13:36:00.722 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 53.0923 ms
23/10/22 13:36:00.744 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 13:36:01.100 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:01.100 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:01.100 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
23/10/22 13:36:01.100 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:01.100 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:01.100 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:01.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.4 KiB, free 1048.8 MiB)
23/10/22 13:36:01.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1048.8 MiB)
23/10/22 13:36:01.114 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 13:36:01.114 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:01.114 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:01.114 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/10/22 13:36:01.114 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 13:36:01.114 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/10/22 13:36:01.125 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1370 bytes result sent to driver
23/10/22 13:36:01.135 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 21 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:01.135 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/10/22 13:36:01.135 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.027 s
23/10/22 13:36:01.135 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:01.135 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/10/22 13:36:01.135 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.034962 s
23/10/22 13:36:01.295 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:36:01.296 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:36:01.299 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:36:01.299 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:36:01.304 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/22 13:36:01.304 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/22 13:36:01.445 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 76.3717 ms
23/10/22 13:36:01.496 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.1852 ms
23/10/22 13:36:01.520 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.885 ms
23/10/22 13:36:01.559 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:36:01.559 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:36:01.559 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 13:36:01.559 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 13:36:01.559 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/22 13:36:01.559 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/22 13:36:01.848 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.0043 ms
23/10/22 13:36:01.961 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:01.961 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:01.961 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
23/10/22 13:36:01.961 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:01.969 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:01.970 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:01.998 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 13:36:02.009 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.0 KiB, free 1048.8 MiB)
23/10/22 13:36:02.036 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 1048.8 MiB)
23/10/22 13:36:02.038 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57170 (size: 6.7 KiB, free: 1048.8 MiB)
23/10/22 13:36:02.039 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:02.039 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:02.039 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/10/22 13:36:02.552 dispatcher-event-loop-2 WARN TaskSetManager: Stage 2 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:36:02.552 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/22 13:36:02.552 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/10/22 13:36:05.157 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 11.7 MiB, free 1037.1 MiB)
23/10/22 13:36:05.196 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:57170 (size: 11.7 MiB, free: 1037.1 MiB)
23/10/22 13:36:05.217 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 7.0348 ms
23/10/22 13:36:05.265 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 43.0829 ms
23/10/22 13:36:05.299 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_11_0]
23/10/22 13:36:05.299 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2015 bytes result sent to driver
23/10/22 13:36:05.307 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 3264 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:05.307 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/10/22 13:36:05.307 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 3.337 s
23/10/22 13:36:05.307 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:05.307 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/10/22 13:36:05.307 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 3.345957 s
23/10/22 13:36:05.349 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 28.4502 ms
23/10/22 13:36:05.890 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.3184 ms
23/10/22 13:36:05.910 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:05.910 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:05.910 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
23/10/22 13:36:05.910 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:05.910 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:05.913 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:05.914 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 13:36:05.917 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 13:36:05.918 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 13:36:05.919 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:05.919 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:05.919 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/10/22 13:36:05.919 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 13:36:05.919 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/10/22 13:36:05.927 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1413 bytes result sent to driver
23/10/22 13:36:05.927 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 8 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:05.927 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/10/22 13:36:05.927 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.014 s
23/10/22 13:36:05.927 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:05.927 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/10/22 13:36:05.935 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.024202 s
23/10/22 13:36:05.951 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.0831 ms
23/10/22 13:36:06.432 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
23/10/22 13:36:06.535 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:26) as input to shuffle 0
23/10/22 13:36:06.547 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 5 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:06.547 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 4 (collect at utils.scala:26)
23/10/22 13:36:06.547 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:06.555 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:06.555 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[22] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:06.601 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 54.8 KiB, free 1037.1 MiB)
23/10/22 13:36:06.617 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 1037.0 MiB)
23/10/22 13:36:06.620 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57170 (size: 20.2 KiB, free: 1037.1 MiB)
23/10/22 13:36:06.620 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:06.620 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[22] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:06.620 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/10/22 13:36:06.968 dispatcher-event-loop-7 WARN TaskSetManager: Stage 4 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:36:06.968 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 13:36:06.976 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/10/22 13:36:07.283 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO BlockManager: Found block rdd_11_0 locally
23/10/22 13:36:07.382 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 41.1365 ms
23/10/22 13:36:07.632 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 124.0062 ms
23/10/22 13:36:07.641 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 5.2268 ms
23/10/22 13:36:07.666 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 17.5581 ms
23/10/22 13:36:08.122 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 13:36:12.400 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57170 in memory (size: 6.7 KiB, free: 1037.1 MiB)
23/10/22 13:36:13.567 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2068 bytes result sent to driver
23/10/22 13:36:13.567 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6947 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:13.567 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/10/22 13:36:13.575 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 4 (collect at utils.scala:26) finished in 7.020 s
23/10/22 13:36:13.575 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:36:13.575 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:36:13.575 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:36:13.575 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:36:13.636 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.9494 ms
23/10/22 13:36:13.652 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:13.652 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:13.652 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
23/10/22 13:36:13.652 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
23/10/22 13:36:13.652 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:13.652 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:13.684 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 117.1 KiB, free 1037.0 MiB)
23/10/22 13:36:13.684 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1036.9 MiB)
23/10/22 13:36:13.692 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57170 (size: 35.0 KiB, free: 1037.1 MiB)
23/10/22 13:36:13.692 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:13.692 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:13.692 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/10/22 13:36:13.692 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 13:36:13.692 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
23/10/22 13:36:13.732 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:36:13.732 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
23/10/22 13:36:13.852 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 42.7047 ms
23/10/22 13:36:13.940 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 30.4313 ms
23/10/22 13:36:13.998 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 40.6792 ms
23/10/22 13:36:14.066 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 4930 bytes result sent to driver
23/10/22 13:36:14.066 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 374 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:14.066 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/10/22 13:36:14.066 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.406 s
23/10/22 13:36:14.066 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:14.066 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/10/22 13:36:14.066 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.417910 s
23/10/22 13:36:14.082 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.8233 ms
23/10/22 13:36:16.914 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.8456 ms
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:26) as input to shuffle 1
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 7 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 7 (collect at utils.scala:26)
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:16.914 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 22.5 KiB, free 1036.9 MiB)
23/10/22 13:36:16.922 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 1036.9 MiB)
23/10/22 13:36:16.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57170 (size: 8.6 KiB, free: 1037.1 MiB)
23/10/22 13:36:16.922 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:16.922 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:16.922 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/10/22 13:36:17.161 dispatcher-event-loop-6 WARN TaskSetManager: Stage 7 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:36:17.161 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 13:36:17.161 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
23/10/22 13:36:17.384 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 1839 bytes result sent to driver
23/10/22 13:36:17.384 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 462 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:17.384 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/10/22 13:36:17.384 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:26) finished in 0.470 s
23/10/22 13:36:17.384 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:36:17.384 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:36:17.384 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:36:17.384 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:36:17.423 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.8272 ms
23/10/22 13:36:17.439 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:17.439 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:17.439 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
23/10/22 13:36:17.439 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
23/10/22 13:36:17.439 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:17.439 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:17.439 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.2 KiB, free 1036.9 MiB)
23/10/22 13:36:17.447 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 1036.9 MiB)
23/10/22 13:36:17.447 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57170 (size: 8.9 KiB, free: 1037.1 MiB)
23/10/22 13:36:17.447 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:17.447 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:17.447 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/10/22 13:36:17.447 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 13:36:17.447 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO Executor: Running task 0.0 in stage 9.0 (TID 7)
23/10/22 13:36:17.455 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:36:17.455 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:36:17.455 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 3907 bytes result sent to driver
23/10/22 13:36:17.455 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 8 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:17.455 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/10/22 13:36:17.455 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.016 s
23/10/22 13:36:17.455 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:17.455 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/10/22 13:36:17.463 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.020930 s
23/10/22 13:36:17.475 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.2144 ms
23/10/22 13:36:18.518 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.188 ms
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 34 (collect at utils.scala:26) as input to shuffle 2
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 9 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at utils.scala:26)
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:18.538 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 23.1 KiB, free 1036.8 MiB)
23/10/22 13:36:18.547 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 1036.8 MiB)
23/10/22 13:36:18.547 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57170 (size: 11.0 KiB, free: 1037.1 MiB)
23/10/22 13:36:18.547 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:18.547 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:18.547 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/10/22 13:36:18.894 dispatcher-event-loop-5 WARN TaskSetManager: Stage 10 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:36:18.894 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 13:36:18.894 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO Executor: Running task 0.0 in stage 10.0 (TID 8)
23/10/22 13:36:18.984 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:57170 in memory (size: 8.9 KiB, free: 1037.1 MiB)
23/10/22 13:36:18.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57170 in memory (size: 35.0 KiB, free: 1037.1 MiB)
23/10/22 13:36:19.072 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 12.9471 ms
23/10/22 13:36:19.091 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 7.0516 ms
23/10/22 13:36:19.836 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 3.7927 ms
23/10/22 13:36:19.846 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.5045 ms
23/10/22 13:36:19.848 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.5129 ms
23/10/22 13:36:19.856 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.2818 ms
23/10/22 13:36:19.880 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 9.9168 ms
23/10/22 13:36:20.241 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO Executor: Finished task 0.0 in stage 10.0 (TID 8). 2057 bytes result sent to driver
23/10/22 13:36:20.241 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 1694 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:20.241 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/10/22 13:36:20.241 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:26) finished in 1.703 s
23/10/22 13:36:20.241 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:36:20.241 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:36:20.241 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:36:20.241 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:36:20.249 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 13:36:20.274 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.4012 ms
23/10/22 13:36:20.282 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:20.282 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:20.282 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
23/10/22 13:36:20.282 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
23/10/22 13:36:20.282 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:20.282 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:20.290 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.3 KiB, free 1037.0 MiB)
23/10/22 13:36:20.290 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 1037.0 MiB)
23/10/22 13:36:20.295 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57170 (size: 13.5 KiB, free: 1037.1 MiB)
23/10/22 13:36:20.295 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:20.295 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:20.295 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/10/22 13:36:20.295 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 13:36:20.295 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO Executor: Running task 0.0 in stage 12.0 (TID 9)
23/10/22 13:36:20.303 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO ShuffleBlockFetcherIterator: Getting 1 (136.8 KiB) non-empty blocks including 1 (136.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:36:20.303 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
23/10/22 13:36:20.327 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 6.8837 ms
23/10/22 13:36:20.335 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 4.5882 ms
23/10/22 13:36:20.343 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 4.0282 ms
23/10/22 13:36:20.351 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO Executor: Finished task 0.0 in stage 12.0 (TID 9). 82209 bytes result sent to driver
23/10/22 13:36:20.359 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 64 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:20.359 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/10/22 13:36:20.359 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.069 s
23/10/22 13:36:20.359 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:20.359 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/10/22 13:36:20.359 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.073762 s
23/10/22 13:36:20.368 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.9492 ms
23/10/22 13:36:20.764 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.6583 ms
23/10/22 13:36:20.772 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 9.1 KiB, free 1037.0 MiB)
23/10/22 13:36:20.772 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1036.9 MiB)
23/10/22 13:36:20.772 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57170 (size: 4.3 KiB, free: 1037.1 MiB)
23/10/22 13:36:20.780 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:20.780 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:20.780 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/10/22 13:36:20.858 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:57170 in memory (size: 13.5 KiB, free: 1037.1 MiB)
23/10/22 13:36:20.970 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57170 in memory (size: 20.2 KiB, free: 1037.1 MiB)
23/10/22 13:36:21.155 dispatcher-event-loop-3 WARN TaskSetManager: Stage 13 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:36:21.155 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/22 13:36:21.155 Executor task launch worker for task 0.0 in stage 13.0 (TID 10) INFO Executor: Running task 0.0 in stage 13.0 (TID 10)
23/10/22 13:36:21.284 Executor task launch worker for task 0.0 in stage 13.0 (TID 10) INFO Executor: Finished task 0.0 in stage 13.0 (TID 10). 47636 bytes result sent to driver
23/10/22 13:36:21.286 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 506 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:21.286 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/10/22 13:36:21.287 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0.514 s
23/10/22 13:36:21.287 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:21.287 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/10/22 13:36:21.287 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.512868 s
23/10/22 13:36:24.106 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 40.2242 ms
23/10/22 13:36:24.123 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:36:24.124 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:36:24.124 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
23/10/22 13:36:24.124 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:36:24.124 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:36:24.124 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26), which has no missing parents
23/10/22 13:36:24.124 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.2 KiB, free 1037.1 MiB)
23/10/22 13:36:24.135 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 1037.0 MiB)
23/10/22 13:36:24.138 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57170 (size: 5.2 KiB, free: 1037.1 MiB)
23/10/22 13:36:24.138 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
23/10/22 13:36:24.138 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:36:24.138 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
23/10/22 13:36:24.453 dispatcher-event-loop-6 WARN TaskSetManager: Stage 14 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:36:24.453 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/22 13:36:24.453 Executor task launch worker for task 0.0 in stage 14.0 (TID 11) INFO Executor: Running task 0.0 in stage 14.0 (TID 11)
23/10/22 13:36:24.705 Executor task launch worker for task 0.0 in stage 14.0 (TID 11) INFO Executor: Finished task 0.0 in stage 14.0 (TID 11). 41131 bytes result sent to driver
23/10/22 13:36:24.705 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 562 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:36:24.705 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
23/10/22 13:36:24.705 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.581 s
23/10/22 13:36:24.707 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:36:24.707 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
23/10/22 13:36:24.707 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.584113 s
23/10/22 13:36:24.711 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.884 ms
23/10/22 13:39:17.546 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.032 ms
23/10/22 13:39:17.547 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:26) as input to shuffle 3
23/10/22 13:39:17.547 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 13 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:39:17.547 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at utils.scala:26)
23/10/22 13:39:17.547 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:39:17.547 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:17.547 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[45] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:17.562 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 13:39:17.563 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 13:39:17.563 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 13:39:17.563 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:17.563 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[45] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:39:17.563 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/10/22 13:39:17.697 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57170 in memory (size: 8.6 KiB, free: 1037.1 MiB)
23/10/22 13:39:17.697 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:57170 in memory (size: 5.2 KiB, free: 1037.1 MiB)
23/10/22 13:39:17.703 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:57170 in memory (size: 4.3 KiB, free: 1037.1 MiB)
23/10/22 13:39:17.703 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57170 in memory (size: 11.0 KiB, free: 1037.1 MiB)
23/10/22 13:39:17.850 dispatcher-event-loop-7 WARN TaskSetManager: Stage 15 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:39:17.850 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 13:39:17.850 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
23/10/22 13:39:17.979 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 3.6119 ms
23/10/22 13:39:17.996 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 5.3153 ms
23/10/22 13:39:18.013 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 8.6353 ms
23/10/22 13:39:18.029 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 7.8724 ms
23/10/22 13:39:18.033 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 5.6611 ms
23/10/22 13:39:18.080 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:18.080 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 4.7565 ms
23/10/22 13:39:18.097 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 5.6394 ms
23/10/22 13:39:18.113 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 4.2476 ms
23/10/22 13:39:18.113 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 3.223 ms
23/10/22 13:39:18.963 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 6.7533 ms
23/10/22 13:39:19.447 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 2104 bytes result sent to driver
23/10/22 13:39:19.447 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 1884 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:39:19.447 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/10/22 13:39:19.447 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:26) finished in 1.900 s
23/10/22 13:39:19.447 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:39:19.447 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:39:19.462 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:39:19.463 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:39:19.465 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 13:39:19.480 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 49 (collect at utils.scala:26) as input to shuffle 4
23/10/22 13:39:19.480 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 14 (collect at utils.scala:26) with 8 output partitions
23/10/22 13:39:19.480 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 17 (collect at utils.scala:26)
23/10/22 13:39:19.480 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
23/10/22 13:39:19.480 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:19.480 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[49] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:19.497 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 13:39:19.497 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 13:39:19.497 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 13:39:19.497 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:19.497 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[49] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 13:39:19.497 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 8 tasks resource profile 0
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 14) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 15) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 16) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 17) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 18) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 17.0 (TID 19) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.497 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 17.0 (TID 20) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:19.512 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO Executor: Running task 0.0 in stage 17.0 (TID 13)
23/10/22 13:39:19.512 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO Executor: Running task 1.0 in stage 17.0 (TID 14)
23/10/22 13:39:19.514 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO Executor: Running task 4.0 in stage 17.0 (TID 17)
23/10/22 13:39:19.514 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO Executor: Running task 5.0 in stage 17.0 (TID 18)
23/10/22 13:39:19.514 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO Executor: Running task 3.0 in stage 17.0 (TID 16)
23/10/22 13:39:19.514 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO Executor: Running task 2.0 in stage 17.0 (TID 15)
23/10/22 13:39:19.519 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.519 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.525 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.525 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.526 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.526 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.532 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.532 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.539 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.540 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.541 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO Executor: Running task 7.0 in stage 17.0 (TID 20)
23/10/22 13:39:19.540 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO Executor: Running task 6.0 in stage 17.0 (TID 19)
23/10/22 13:39:19.543 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO CodeGenerator: Code generated in 10.8831 ms
23/10/22 13:39:19.549 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.549 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.549 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.549 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.549 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:19.549 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:19.549 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO CodeGenerator: Code generated in 10.746 ms
23/10/22 13:39:19.568 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.568 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.568 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.581 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.583 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.583 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.583 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.602 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO CodeGenerator: Code generated in 5.5004 ms
23/10/22 13:39:19.609 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.614 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO CodeGenerator: Code generated in 6.2531 ms
23/10/22 13:39:19.629 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO CodeGenerator: Code generated in 4.6042 ms
23/10/22 13:39:19.636 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO CodeGenerator: Code generated in 5.6474 ms
23/10/22 13:39:19.646 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO CodeGenerator: Code generated in 5.4869 ms
23/10/22 13:39:19.654 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.654 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.654 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.654 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.664 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.666 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.666 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO CodeGenerator: Code generated in 6.7072 ms
23/10/22 13:39:19.668 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.671 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:19.674 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO CodeGenerator: Code generated in 4.916 ms
23/10/22 13:39:19.737 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO CodeGenerator: Code generated in 14.6352 ms
23/10/22 13:39:19.879 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO Executor: Finished task 1.0 in stage 17.0 (TID 14). 4985 bytes result sent to driver
23/10/22 13:39:19.881 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO Executor: Finished task 5.0 in stage 17.0 (TID 18). 4985 bytes result sent to driver
23/10/22 13:39:19.882 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 14) in 385 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 13:39:19.882 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 18) in 385 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 13:39:19.892 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO Executor: Finished task 4.0 in stage 17.0 (TID 17). 4985 bytes result sent to driver
23/10/22 13:39:19.894 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 17) in 397 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 13:39:19.947 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO Executor: Finished task 6.0 in stage 17.0 (TID 19). 4942 bytes result sent to driver
23/10/22 13:39:19.949 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 17.0 (TID 19) in 452 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 13:39:19.958 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO Executor: Finished task 7.0 in stage 17.0 (TID 20). 4942 bytes result sent to driver
23/10/22 13:39:19.958 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 17.0 (TID 20) in 461 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 13:39:19.966 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO Executor: Finished task 0.0 in stage 17.0 (TID 13). 4985 bytes result sent to driver
23/10/22 13:39:19.968 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO Executor: Finished task 3.0 in stage 17.0 (TID 16). 4985 bytes result sent to driver
23/10/22 13:39:19.968 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 471 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 13:39:19.968 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 16) in 471 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 13:39:19.976 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO Executor: Finished task 2.0 in stage 17.0 (TID 15). 4942 bytes result sent to driver
23/10/22 13:39:19.976 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 15) in 479 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 13:39:19.976 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/10/22 13:39:19.978 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:26) finished in 0.498 s
23/10/22 13:39:19.978 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:39:19.978 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:39:19.978 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:39:19.978 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:39:19.983 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 13:39:19.988 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:39:19.996 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:39:19.996 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:26)
23/10/22 13:39:19.996 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
23/10/22 13:39:19.996 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:19.996 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:20.006 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 13:39:20.007 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 13:39:20.007 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1037.0 MiB)
23/10/22 13:39:20.007 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57170 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 13:39:20.007 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:20.007 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:39:20.007 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
23/10/22 13:39:20.007 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 21) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:20.007 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO Executor: Running task 0.0 in stage 20.0 (TID 21)
23/10/22 13:39:20.017 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:20.017 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:20.030 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.6958 ms
23/10/22 13:39:20.039 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.0344 ms
23/10/22 13:39:20.049 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 6.963 ms
23/10/22 13:39:20.057 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:20.090 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO Executor: Finished task 0.0 in stage 20.0 (TID 21). 778681 bytes result sent to driver
23/10/22 13:39:20.096 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 21) in 89 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:39:20.096 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
23/10/22 13:39:20.096 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collect at utils.scala:26) finished in 0.093 s
23/10/22 13:39:20.096 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:39:20.096 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
23/10/22 13:39:20.098 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.102674 s
23/10/22 13:39:20.098 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:39:20.098 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 2 output partitions
23/10/22 13:39:20.098 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
23/10/22 13:39:20.098 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
23/10/22 13:39:20.098 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:20.098 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:20.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 13:39:20.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1037.0 MiB)
23/10/22 13:39:20.108 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57170 (size: 18.9 KiB, free: 1037.1 MiB)
23/10/22 13:39:20.108 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:20.108 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 13:39:20.108 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks resource profile 0
23/10/22 13:39:20.108 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:20.112 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 23) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:20.112 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO Executor: Running task 1.0 in stage 23.0 (TID 23)
23/10/22 13:39:20.112 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO Executor: Running task 0.0 in stage 23.0 (TID 22)
23/10/22 13:39:20.113 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:20.113 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:20.119 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:20.119 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:20.130 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:20.130 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:20.162 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO Executor: Finished task 1.0 in stage 23.0 (TID 23). 745943 bytes result sent to driver
23/10/22 13:39:20.164 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 23) in 52 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 13:39:20.166 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO Executor: Finished task 0.0 in stage 23.0 (TID 22). 747491 bytes result sent to driver
23/10/22 13:39:20.166 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 58 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 13:39:20.166 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
23/10/22 13:39:20.166 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0.068 s
23/10/22 13:39:20.166 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:39:20.166 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
23/10/22 13:39:20.166 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.066804 s
23/10/22 13:39:20.180 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.9024 ms
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 55 (collect at utils.scala:26) as input to shuffle 5
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 17 (collect at utils.scala:26) with 1 output partitions
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at utils.scala:26)
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[55] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:28.738 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.7 KiB, free 1036.9 MiB)
23/10/22 13:39:28.745 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.9 MiB)
23/10/22 13:39:28.745 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 13:39:28.745 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:28.745 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[55] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 13:39:28.745 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/10/22 13:39:29.008 dispatcher-event-loop-0 WARN TaskSetManager: Stage 24 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 13:39:29.008 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 13:39:29.008 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
23/10/22 13:39:29.215 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:29.567 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:57170 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 13:39:29.567 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:57170 in memory (size: 18.9 KiB, free: 1037.1 MiB)
23/10/22 13:39:30.303 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2147 bytes result sent to driver
23/10/22 13:39:30.303 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 1558 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 13:39:30.303 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/10/22 13:39:30.303 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 24 (collect at utils.scala:26) finished in 1.565 s
23/10/22 13:39:30.303 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:39:30.303 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:39:30.303 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:39:30.303 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:39:30.303 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 59 (collect at utils.scala:26) as input to shuffle 6
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 18 (collect at utils.scala:26) with 8 output partitions
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 26 (collect at utils.scala:26)
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[59] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 13:39:30.313 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 13:39:30.319 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 13:39:30.320 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:30.320 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[59] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 13:39:30.320 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 8 tasks resource profile 0
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 26) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 27) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 28) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 29) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 30) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 31) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 26.0 (TID 32) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 13:39:30.320 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO Executor: Running task 1.0 in stage 26.0 (TID 26)
23/10/22 13:39:30.320 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
23/10/22 13:39:30.324 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO Executor: Running task 2.0 in stage 26.0 (TID 27)
23/10/22 13:39:30.324 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO Executor: Running task 3.0 in stage 26.0 (TID 28)
23/10/22 13:39:30.324 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO Executor: Running task 4.0 in stage 26.0 (TID 29)
23/10/22 13:39:30.324 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO Executor: Running task 5.0 in stage 26.0 (TID 30)
23/10/22 13:39:30.325 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO Executor: Running task 6.0 in stage 26.0 (TID 31)
23/10/22 13:39:30.325 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO Executor: Running task 7.0 in stage 26.0 (TID 32)
23/10/22 13:39:30.325 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.325 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.330 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.331 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.331 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.331 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.331 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.330 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.331 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.335 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 13:39:30.335 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.335 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.335 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.336 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.336 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.336 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.345 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.346 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.348 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.352 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.345 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.368 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.368 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.380 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.388 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.388 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.396 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.404 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.433 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.439 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.440 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.488 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 13:39:30.508 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.573 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO Executor: Finished task 3.0 in stage 26.0 (TID 28). 4899 bytes result sent to driver
23/10/22 13:39:30.575 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 28) in 255 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 13:39:30.578 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO Executor: Finished task 7.0 in stage 26.0 (TID 32). 4899 bytes result sent to driver
23/10/22 13:39:30.580 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 26.0 (TID 32) in 260 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 13:39:30.587 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO Executor: Finished task 6.0 in stage 26.0 (TID 31). 4899 bytes result sent to driver
23/10/22 13:39:30.588 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 31) in 268 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 13:39:30.596 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO Executor: Finished task 5.0 in stage 26.0 (TID 30). 4899 bytes result sent to driver
23/10/22 13:39:30.598 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 30) in 278 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 13:39:30.601 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO Executor: Finished task 4.0 in stage 26.0 (TID 29). 4899 bytes result sent to driver
23/10/22 13:39:30.602 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 29) in 282 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 13:39:30.605 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO Executor: Finished task 2.0 in stage 26.0 (TID 27). 4899 bytes result sent to driver
23/10/22 13:39:30.605 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 27) in 285 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 13:39:30.607 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO Executor: Finished task 1.0 in stage 26.0 (TID 26). 4942 bytes result sent to driver
23/10/22 13:39:30.609 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 26) in 289 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 13:39:30.612 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 4899 bytes result sent to driver
23/10/22 13:39:30.612 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 292 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 13:39:30.612 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/10/22 13:39:30.612 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:26) finished in 0.299 s
23/10/22 13:39:30.612 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 13:39:30.612 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 13:39:30.612 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 13:39:30.612 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 13:39:30.612 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 13:39:30.622 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 13:39:30.629 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 8 output partitions
23/10/22 13:39:30.629 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:26)
23/10/22 13:39:30.629 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/10/22 13:39:30.629 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 13:39:30.630 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[62] at collect at utils.scala:26), which has no missing parents
23/10/22 13:39:30.631 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 44.0 KiB, free 1037.0 MiB)
23/10/22 13:39:30.631 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1037.0 MiB)
23/10/22 13:39:30.631 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:57170 (size: 18.9 KiB, free: 1037.1 MiB)
23/10/22 13:39:30.631 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535
23/10/22 13:39:30.631 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 29 (MapPartitionsRDD[62] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 13:39:30.631 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 8 tasks resource profile 0
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 33) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 34) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 35) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 36) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 37) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 38) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 39) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 40) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7363 bytes) 
23/10/22 13:39:30.631 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO Executor: Running task 0.0 in stage 29.0 (TID 33)
23/10/22 13:39:30.631 Executor task launch worker for task 2.0 in stage 29.0 (TID 35) INFO Executor: Running task 2.0 in stage 29.0 (TID 35)
23/10/22 13:39:30.639 Executor task launch worker for task 4.0 in stage 29.0 (TID 37) INFO Executor: Running task 4.0 in stage 29.0 (TID 37)
23/10/22 13:39:30.639 Executor task launch worker for task 3.0 in stage 29.0 (TID 36) INFO Executor: Running task 3.0 in stage 29.0 (TID 36)
23/10/22 13:39:30.639 Executor task launch worker for task 7.0 in stage 29.0 (TID 40) INFO Executor: Running task 7.0 in stage 29.0 (TID 40)
23/10/22 13:39:30.639 Executor task launch worker for task 5.0 in stage 29.0 (TID 38) INFO Executor: Running task 5.0 in stage 29.0 (TID 38)
23/10/22 13:39:30.639 Executor task launch worker for task 6.0 in stage 29.0 (TID 39) INFO Executor: Running task 6.0 in stage 29.0 (TID 39)
23/10/22 13:39:30.631 Executor task launch worker for task 1.0 in stage 29.0 (TID 34) INFO Executor: Running task 1.0 in stage 29.0 (TID 34)
23/10/22 13:39:30.643 Executor task launch worker for task 3.0 in stage 29.0 (TID 36) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.643 Executor task launch worker for task 6.0 in stage 29.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.644 Executor task launch worker for task 1.0 in stage 29.0 (TID 34) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.644 Executor task launch worker for task 5.0 in stage 29.0 (TID 38) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.644 Executor task launch worker for task 1.0 in stage 29.0 (TID 34) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.645 Executor task launch worker for task 6.0 in stage 29.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:30.645 Executor task launch worker for task 7.0 in stage 29.0 (TID 40) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.645 Executor task launch worker for task 7.0 in stage 29.0 (TID 40) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.644 Executor task launch worker for task 3.0 in stage 29.0 (TID 36) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.647 Executor task launch worker for task 5.0 in stage 29.0 (TID 38) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 13:39:30.648 Executor task launch worker for task 4.0 in stage 29.0 (TID 37) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.648 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.649 Executor task launch worker for task 4.0 in stage 29.0 (TID 37) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.649 Executor task launch worker for task 2.0 in stage 29.0 (TID 35) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 13:39:30.649 Executor task launch worker for task 2.0 in stage 29.0 (TID 35) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 13:39:30.649 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 13:39:30.662 Executor task launch worker for task 4.0 in stage 29.0 (TID 37) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.662 Executor task launch worker for task 2.0 in stage 29.0 (TID 35) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.663 Executor task launch worker for task 7.0 in stage 29.0 (TID 40) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.664 Executor task launch worker for task 1.0 in stage 29.0 (TID 34) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.669 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.682 Executor task launch worker for task 6.0 in stage 29.0 (TID 39) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.682 Executor task launch worker for task 5.0 in stage 29.0 (TID 38) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.708 Executor task launch worker for task 2.0 in stage 29.0 (TID 35) INFO Executor: Finished task 2.0 in stage 29.0 (TID 35). 745936 bytes result sent to driver
23/10/22 13:39:30.711 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 35) in 80 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 13:39:30.729 Executor task launch worker for task 5.0 in stage 29.0 (TID 38) INFO Executor: Finished task 5.0 in stage 29.0 (TID 38). 649391 bytes result sent to driver
23/10/22 13:39:30.736 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO Executor: Finished task 0.0 in stage 29.0 (TID 33). 778760 bytes result sent to driver
23/10/22 13:39:30.738 Executor task launch worker for task 1.0 in stage 29.0 (TID 34) INFO Executor: Finished task 1.0 in stage 29.0 (TID 34). 747527 bytes result sent to driver
23/10/22 13:39:30.738 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 38) in 107 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 13:39:30.740 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 33) in 109 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 13:39:30.741 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 34) in 110 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 13:39:30.744 Executor task launch worker for task 4.0 in stage 29.0 (TID 37) INFO Executor: Finished task 4.0 in stage 29.0 (TID 37). 873716 bytes result sent to driver
23/10/22 13:39:30.745 Executor task launch worker for task 7.0 in stage 29.0 (TID 40) INFO MemoryStore: Block taskresult_40 stored as bytes in memory (estimated size 1052.5 KiB, free 1019.8 MiB)
23/10/22 13:39:30.746 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 37) in 115 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 13:39:30.746 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added taskresult_40 in memory on 127.0.0.1:57170 (size: 1052.5 KiB, free: 1036.1 MiB)
23/10/22 13:39:30.748 Executor task launch worker for task 7.0 in stage 29.0 (TID 40) INFO Executor: Finished task 7.0 in stage 29.0 (TID 40). 1077780 bytes result sent via BlockManager)
23/10/22 13:39:30.753 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1036.1 MiB)
23/10/22 13:39:30.753 Executor task launch worker for task 3.0 in stage 29.0 (TID 36) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 13:39:30.766 Executor task launch worker for task 6.0 in stage 29.0 (TID 39) INFO Executor: Finished task 6.0 in stage 29.0 (TID 39). 816010 bytes result sent to driver
23/10/22 13:39:30.768 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 39) in 137 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 13:39:30.781 Executor task launch worker for task 3.0 in stage 29.0 (TID 36) INFO Executor: Finished task 3.0 in stage 29.0 (TID 36). 819214 bytes result sent to driver
23/10/22 13:39:30.781 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 36) in 150 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 13:39:30.789 task-result-getter-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57170 after 1 ms (0 ms spent in bootstraps)
23/10/22 13:39:30.813 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 40) in 182 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 13:39:30.813 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/10/22 13:39:30.813 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at utils.scala:26) finished in 0.182 s
23/10/22 13:39:30.813 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 13:39:30.813 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/10/22 13:39:30.813 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0.198098 s
23/10/22 13:39:30.813 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed taskresult_40 on 127.0.0.1:57170 in memory (size: 1052.5 KiB, free: 1037.1 MiB)
23/10/22 13:39:30.839 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:57170 in memory (size: 18.9 KiB, free: 1037.1 MiB)
23/10/22 13:39:31.014 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 13:53:57.361 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 13:54:07.375 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 13:54:17.391 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 13:54:27.399 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 13:54:32.249 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 13:54:32.249 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 13:54:32.249 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 13:54:32.249 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 14:21:14.878 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 14:21:24.894 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 14:21:34.910 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 14:21:44.927 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 14:21:49.811 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 14:21:49.811 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 14:21:49.811 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 14:21:49.811 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 14:44:41.830 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 65 (collect at utils.scala:26) as input to shuffle 7
23/10/22 14:44:41.830 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:44:41.830 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 30 (collect at utils.scala:26)
23/10/22 14:44:41.830 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:44:41.831 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:44:41.831 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[65] at collect at utils.scala:26), which has no missing parents
23/10/22 14:44:41.892 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 14:44:41.898 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.1 MiB)
23/10/22 14:44:41.898 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:44:41.898 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535
23/10/22 14:44:41.905 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[65] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:44:41.905 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
23/10/22 14:44:42.203 dispatcher-event-loop-7 WARN TaskSetManager: Stage 30 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:44:42.203 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 41) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:44:42.203 Executor task launch worker for task 0.0 in stage 30.0 (TID 41) INFO Executor: Running task 0.0 in stage 30.0 (TID 41)
23/10/22 14:44:42.376 Executor task launch worker for task 0.0 in stage 30.0 (TID 41) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.121 Executor task launch worker for task 0.0 in stage 30.0 (TID 41) INFO Executor: Finished task 0.0 in stage 30.0 (TID 41). 2147 bytes result sent to driver
23/10/22 14:44:43.121 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 41) in 1215 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:44:43.121 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 30 (collect at utils.scala:26) finished in 1.290 s
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:44:43.121 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:26) as input to shuffle 8
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 21 (collect at utils.scala:26) with 8 output partitions
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at utils.scala:26)
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:44:43.121 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[69] at collect at utils.scala:26), which has no missing parents
23/10/22 14:44:43.137 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:44:43.137 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:44:43.137 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:44:43.137 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
23/10/22 14:44:43.137 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[69] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:44:43.137 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 8 tasks resource profile 0
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 42) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 43) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 44) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 45) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 32.0 (TID 46) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 32.0 (TID 47) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 32.0 (TID 48) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 32.0 (TID 49) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:44:43.137 Executor task launch worker for task 0.0 in stage 32.0 (TID 42) INFO Executor: Running task 0.0 in stage 32.0 (TID 42)
23/10/22 14:44:43.137 Executor task launch worker for task 1.0 in stage 32.0 (TID 43) INFO Executor: Running task 1.0 in stage 32.0 (TID 43)
23/10/22 14:44:43.137 Executor task launch worker for task 2.0 in stage 32.0 (TID 44) INFO Executor: Running task 2.0 in stage 32.0 (TID 44)
23/10/22 14:44:43.137 Executor task launch worker for task 3.0 in stage 32.0 (TID 45) INFO Executor: Running task 3.0 in stage 32.0 (TID 45)
23/10/22 14:44:43.137 Executor task launch worker for task 4.0 in stage 32.0 (TID 46) INFO Executor: Running task 4.0 in stage 32.0 (TID 46)
23/10/22 14:44:43.146 Executor task launch worker for task 1.0 in stage 32.0 (TID 43) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.146 Executor task launch worker for task 3.0 in stage 32.0 (TID 45) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.146 Executor task launch worker for task 0.0 in stage 32.0 (TID 42) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.146 Executor task launch worker for task 4.0 in stage 32.0 (TID 46) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.146 Executor task launch worker for task 1.0 in stage 32.0 (TID 43) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.146 Executor task launch worker for task 3.0 in stage 32.0 (TID 45) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.146 Executor task launch worker for task 4.0 in stage 32.0 (TID 46) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.146 Executor task launch worker for task 0.0 in stage 32.0 (TID 42) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.146 Executor task launch worker for task 5.0 in stage 32.0 (TID 47) INFO Executor: Running task 5.0 in stage 32.0 (TID 47)
23/10/22 14:44:43.146 Executor task launch worker for task 6.0 in stage 32.0 (TID 48) INFO Executor: Running task 6.0 in stage 32.0 (TID 48)
23/10/22 14:44:43.148 Executor task launch worker for task 2.0 in stage 32.0 (TID 44) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.148 Executor task launch worker for task 2.0 in stage 32.0 (TID 44) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.149 Executor task launch worker for task 7.0 in stage 32.0 (TID 49) INFO Executor: Running task 7.0 in stage 32.0 (TID 49)
23/10/22 14:44:43.149 Executor task launch worker for task 5.0 in stage 32.0 (TID 47) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.149 Executor task launch worker for task 5.0 in stage 32.0 (TID 47) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.149 Executor task launch worker for task 6.0 in stage 32.0 (TID 48) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.149 Executor task launch worker for task 6.0 in stage 32.0 (TID 48) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.153 Executor task launch worker for task 7.0 in stage 32.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.153 Executor task launch worker for task 7.0 in stage 32.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.154 Executor task launch worker for task 1.0 in stage 32.0 (TID 43) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.156 Executor task launch worker for task 6.0 in stage 32.0 (TID 48) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.161 Executor task launch worker for task 3.0 in stage 32.0 (TID 45) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.172 Executor task launch worker for task 0.0 in stage 32.0 (TID 42) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.175 Executor task launch worker for task 7.0 in stage 32.0 (TID 49) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.176 Executor task launch worker for task 6.0 in stage 32.0 (TID 48) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.180 Executor task launch worker for task 3.0 in stage 32.0 (TID 45) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.189 Executor task launch worker for task 1.0 in stage 32.0 (TID 43) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.189 Executor task launch worker for task 0.0 in stage 32.0 (TID 42) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.195 Executor task launch worker for task 7.0 in stage 32.0 (TID 49) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.204 Executor task launch worker for task 5.0 in stage 32.0 (TID 47) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.207 Executor task launch worker for task 2.0 in stage 32.0 (TID 44) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.211 Executor task launch worker for task 4.0 in stage 32.0 (TID 46) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.239 Executor task launch worker for task 4.0 in stage 32.0 (TID 46) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.261 Executor task launch worker for task 2.0 in stage 32.0 (TID 44) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.277 Executor task launch worker for task 5.0 in stage 32.0 (TID 47) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.332 Executor task launch worker for task 3.0 in stage 32.0 (TID 45) INFO Executor: Finished task 3.0 in stage 32.0 (TID 45). 4942 bytes result sent to driver
23/10/22 14:44:43.333 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 45) in 196 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:44:43.357 Executor task launch worker for task 7.0 in stage 32.0 (TID 49) INFO Executor: Finished task 7.0 in stage 32.0 (TID 49). 4899 bytes result sent to driver
23/10/22 14:44:43.358 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 32.0 (TID 49) in 221 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:44:43.368 Executor task launch worker for task 4.0 in stage 32.0 (TID 46) INFO Executor: Finished task 4.0 in stage 32.0 (TID 46). 4899 bytes result sent to driver
23/10/22 14:44:43.369 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 32.0 (TID 46) in 232 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:44:43.375 Executor task launch worker for task 6.0 in stage 32.0 (TID 48) INFO Executor: Finished task 6.0 in stage 32.0 (TID 48). 4899 bytes result sent to driver
23/10/22 14:44:43.376 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 32.0 (TID 48) in 239 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:44:43.380 Executor task launch worker for task 0.0 in stage 32.0 (TID 42) INFO Executor: Finished task 0.0 in stage 32.0 (TID 42). 4899 bytes result sent to driver
23/10/22 14:44:43.381 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 42) in 244 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:44:43.383 Executor task launch worker for task 2.0 in stage 32.0 (TID 44) INFO Executor: Finished task 2.0 in stage 32.0 (TID 44). 4942 bytes result sent to driver
23/10/22 14:44:43.383 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 44) in 246 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:44:43.387 Executor task launch worker for task 5.0 in stage 32.0 (TID 47) INFO Executor: Finished task 5.0 in stage 32.0 (TID 47). 4899 bytes result sent to driver
23/10/22 14:44:43.387 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 32.0 (TID 47) in 250 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:44:43.393 Executor task launch worker for task 1.0 in stage 32.0 (TID 43) INFO Executor: Finished task 1.0 in stage 32.0 (TID 43). 4899 bytes result sent to driver
23/10/22 14:44:43.393 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 43) in 256 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:44:43.393 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
23/10/22 14:44:43.393 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:26) finished in 0.272 s
23/10/22 14:44:43.393 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:44:43.393 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:44:43.393 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:44:43.393 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:44:43.396 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:44:43.404 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:44:43.404 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:44:43.404 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
23/10/22 14:44:43.404 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
23/10/22 14:44:43.404 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:44:43.404 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[72] at collect at utils.scala:26), which has no missing parents
23/10/22 14:44:43.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 14:44:43.415 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1037.0 MiB)
23/10/22 14:44:43.415 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:57170 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 14:44:43.415 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535
23/10/22 14:44:43.415 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[72] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:44:43.415 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
23/10/22 14:44:43.415 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 50) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 14:44:43.415 Executor task launch worker for task 0.0 in stage 35.0 (TID 50) INFO Executor: Running task 0.0 in stage 35.0 (TID 50)
23/10/22 14:44:43.420 Executor task launch worker for task 0.0 in stage 35.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.420 Executor task launch worker for task 0.0 in stage 35.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.420 Executor task launch worker for task 0.0 in stage 35.0 (TID 50) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.455 Executor task launch worker for task 0.0 in stage 35.0 (TID 50) INFO Executor: Finished task 0.0 in stage 35.0 (TID 50). 778724 bytes result sent to driver
23/10/22 14:44:43.455 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 50) in 40 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:44:43.455 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
23/10/22 14:44:43.455 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 0.051 s
23/10/22 14:44:43.455 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:44:43.455 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
23/10/22 14:44:43.455 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: collect at utils.scala:26, took 0.061164 s
23/10/22 14:44:43.471 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (collect at utils.scala:26) with 2 output partitions
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:26)
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[72] at collect at utils.scala:26), which has no missing parents
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 43.9 KiB, free 1036.9 MiB)
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1036.9 MiB)
23/10/22 14:44:43.471 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:57170 (size: 18.9 KiB, free: 1037.1 MiB)
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[72] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 14:44:43.471 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks resource profile 0
23/10/22 14:44:43.471 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 51) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 14:44:43.471 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 52) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 14:44:43.471 Executor task launch worker for task 0.0 in stage 38.0 (TID 51) INFO Executor: Running task 0.0 in stage 38.0 (TID 51)
23/10/22 14:44:43.471 Executor task launch worker for task 1.0 in stage 38.0 (TID 52) INFO Executor: Running task 1.0 in stage 38.0 (TID 52)
23/10/22 14:44:43.488 Executor task launch worker for task 1.0 in stage 38.0 (TID 52) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.488 Executor task launch worker for task 0.0 in stage 38.0 (TID 51) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:44:43.488 Executor task launch worker for task 0.0 in stage 38.0 (TID 51) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.488 Executor task launch worker for task 1.0 in stage 38.0 (TID 52) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:44:43.493 Executor task launch worker for task 0.0 in stage 38.0 (TID 51) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.493 Executor task launch worker for task 1.0 in stage 38.0 (TID 52) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:44:43.522 Executor task launch worker for task 1.0 in stage 38.0 (TID 52) INFO Executor: Finished task 1.0 in stage 38.0 (TID 52). 745943 bytes result sent to driver
23/10/22 14:44:43.522 Executor task launch worker for task 0.0 in stage 38.0 (TID 51) INFO Executor: Finished task 0.0 in stage 38.0 (TID 51). 747491 bytes result sent to driver
23/10/22 14:44:43.531 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 52) in 60 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:44:43.532 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 51) in 61 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:44:43.532 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
23/10/22 14:44:43.532 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (collect at utils.scala:26) finished in 0.061 s
23/10/22 14:44:43.532 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:44:43.532 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
23/10/22 14:44:43.532 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: collect at utils.scala:26, took 0.056342 s
23/10/22 14:44:51.648 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:57170 in memory (size: 18.9 KiB, free: 1037.1 MiB)
23/10/22 14:44:51.650 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:57170 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 14:44:51.652 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:46:20.918 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 75 (collect at utils.scala:26) as input to shuffle 9
23/10/22 14:46:20.919 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 24 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:46:20.919 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 39 (collect at utils.scala:26)
23/10/22 14:46:20.919 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:46:20.919 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:20.919 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:20.921 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 14:46:20.922 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 14:46:20.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:20.923 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:20.923 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:46:20.923 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
23/10/22 14:46:21.109 dispatcher-event-loop-0 WARN TaskSetManager: Stage 39 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:46:21.109 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 53) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:46:21.109 Executor task launch worker for task 0.0 in stage 39.0 (TID 53) INFO Executor: Running task 0.0 in stage 39.0 (TID 53)
23/10/22 14:46:21.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:21.239 Executor task launch worker for task 0.0 in stage 39.0 (TID 53) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:21.928 Executor task launch worker for task 0.0 in stage 39.0 (TID 53) INFO Executor: Finished task 0.0 in stage 39.0 (TID 53). 2147 bytes result sent to driver
23/10/22 14:46:21.929 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 53) in 1006 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:46:21.929 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
23/10/22 14:46:21.929 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 39 (collect at utils.scala:26) finished in 1.009 s
23/10/22 14:46:21.930 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:46:21.930 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:46:21.930 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:46:21.930 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:46:21.934 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:46:21.939 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 79 (collect at utils.scala:26) as input to shuffle 10
23/10/22 14:46:21.940 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 25 (collect at utils.scala:26) with 8 output partitions
23/10/22 14:46:21.940 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at utils.scala:26)
23/10/22 14:46:21.940 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
23/10/22 14:46:21.940 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:21.940 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[79] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:21.943 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:46:21.943 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 14:46:21.943 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:57170 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 14:46:21.943 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:21.943 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[79] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:46:21.943 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 8 tasks resource profile 0
23/10/22 14:46:21.943 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 54) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 55) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 56) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 57) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 41.0 (TID 58) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 41.0 (TID 59) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 41.0 (TID 60) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 41.0 (TID 61) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:21.947 Executor task launch worker for task 0.0 in stage 41.0 (TID 54) INFO Executor: Running task 0.0 in stage 41.0 (TID 54)
23/10/22 14:46:21.947 Executor task launch worker for task 1.0 in stage 41.0 (TID 55) INFO Executor: Running task 1.0 in stage 41.0 (TID 55)
23/10/22 14:46:21.947 Executor task launch worker for task 2.0 in stage 41.0 (TID 56) INFO Executor: Running task 2.0 in stage 41.0 (TID 56)
23/10/22 14:46:21.947 Executor task launch worker for task 3.0 in stage 41.0 (TID 57) INFO Executor: Running task 3.0 in stage 41.0 (TID 57)
23/10/22 14:46:21.950 Executor task launch worker for task 5.0 in stage 41.0 (TID 59) INFO Executor: Running task 5.0 in stage 41.0 (TID 59)
23/10/22 14:46:21.950 Executor task launch worker for task 6.0 in stage 41.0 (TID 60) INFO Executor: Running task 6.0 in stage 41.0 (TID 60)
23/10/22 14:46:21.954 Executor task launch worker for task 3.0 in stage 41.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.955 Executor task launch worker for task 3.0 in stage 41.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:21.955 Executor task launch worker for task 1.0 in stage 41.0 (TID 55) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.955 Executor task launch worker for task 1.0 in stage 41.0 (TID 55) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:46:21.956 Executor task launch worker for task 5.0 in stage 41.0 (TID 59) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.956 Executor task launch worker for task 2.0 in stage 41.0 (TID 56) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.956 Executor task launch worker for task 5.0 in stage 41.0 (TID 59) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:21.956 Executor task launch worker for task 2.0 in stage 41.0 (TID 56) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:21.956 Executor task launch worker for task 4.0 in stage 41.0 (TID 58) INFO Executor: Running task 4.0 in stage 41.0 (TID 58)
23/10/22 14:46:21.956 Executor task launch worker for task 7.0 in stage 41.0 (TID 61) INFO Executor: Running task 7.0 in stage 41.0 (TID 61)
23/10/22 14:46:21.957 Executor task launch worker for task 6.0 in stage 41.0 (TID 60) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.958 Executor task launch worker for task 6.0 in stage 41.0 (TID 60) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:21.962 Executor task launch worker for task 4.0 in stage 41.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.963 Executor task launch worker for task 4.0 in stage 41.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:21.964 Executor task launch worker for task 2.0 in stage 41.0 (TID 56) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:21.964 Executor task launch worker for task 5.0 in stage 41.0 (TID 59) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:21.971 Executor task launch worker for task 7.0 in stage 41.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.971 Executor task launch worker for task 7.0 in stage 41.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:21.976 Executor task launch worker for task 0.0 in stage 41.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:21.982 Executor task launch worker for task 5.0 in stage 41.0 (TID 59) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:21.982 Executor task launch worker for task 3.0 in stage 41.0 (TID 57) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:21.982 Executor task launch worker for task 2.0 in stage 41.0 (TID 56) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:21.988 Executor task launch worker for task 0.0 in stage 41.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
23/10/22 14:46:21.996 Executor task launch worker for task 6.0 in stage 41.0 (TID 60) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.010 Executor task launch worker for task 3.0 in stage 41.0 (TID 57) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.014 Executor task launch worker for task 6.0 in stage 41.0 (TID 60) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.026 Executor task launch worker for task 1.0 in stage 41.0 (TID 55) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.046 Executor task launch worker for task 1.0 in stage 41.0 (TID 55) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.077 Executor task launch worker for task 7.0 in stage 41.0 (TID 61) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.077 Executor task launch worker for task 4.0 in stage 41.0 (TID 58) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.080 Executor task launch worker for task 5.0 in stage 41.0 (TID 59) INFO Executor: Finished task 5.0 in stage 41.0 (TID 59). 4899 bytes result sent to driver
23/10/22 14:46:22.088 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 41.0 (TID 59) in 141 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:46:22.093 Executor task launch worker for task 0.0 in stage 41.0 (TID 54) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.097 Executor task launch worker for task 4.0 in stage 41.0 (TID 58) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.104 Executor task launch worker for task 7.0 in stage 41.0 (TID 61) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.112 Executor task launch worker for task 0.0 in stage 41.0 (TID 54) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.142 Executor task launch worker for task 2.0 in stage 41.0 (TID 56) INFO Executor: Finished task 2.0 in stage 41.0 (TID 56). 4899 bytes result sent to driver
23/10/22 14:46:22.143 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 56) in 196 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:46:22.147 Executor task launch worker for task 1.0 in stage 41.0 (TID 55) INFO Executor: Finished task 1.0 in stage 41.0 (TID 55). 4899 bytes result sent to driver
23/10/22 14:46:22.148 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 55) in 205 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:46:22.151 Executor task launch worker for task 6.0 in stage 41.0 (TID 60) INFO Executor: Finished task 6.0 in stage 41.0 (TID 60). 4942 bytes result sent to driver
23/10/22 14:46:22.152 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 41.0 (TID 60) in 205 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:46:22.165 Executor task launch worker for task 3.0 in stage 41.0 (TID 57) INFO Executor: Finished task 3.0 in stage 41.0 (TID 57). 4899 bytes result sent to driver
23/10/22 14:46:22.165 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 57) in 218 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:46:22.170 Executor task launch worker for task 7.0 in stage 41.0 (TID 61) INFO Executor: Finished task 7.0 in stage 41.0 (TID 61). 4942 bytes result sent to driver
23/10/22 14:46:22.171 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 41.0 (TID 61) in 224 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:46:22.173 Executor task launch worker for task 4.0 in stage 41.0 (TID 58) INFO Executor: Finished task 4.0 in stage 41.0 (TID 58). 4942 bytes result sent to driver
23/10/22 14:46:22.174 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 41.0 (TID 58) in 227 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:46:22.177 Executor task launch worker for task 0.0 in stage 41.0 (TID 54) INFO Executor: Finished task 0.0 in stage 41.0 (TID 54). 4899 bytes result sent to driver
23/10/22 14:46:22.177 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 54) in 234 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:46:22.177 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
23/10/22 14:46:22.178 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:26) finished in 0.236 s
23/10/22 14:46:22.178 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:46:22.178 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:46:22.178 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:46:22.178 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:46:22.180 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:46:22.187 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:46:22.188 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:46:22.188 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:26)
23/10/22 14:46:22.188 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
23/10/22 14:46:22.188 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:22.188 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[82] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:22.190 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 14:46:22.190 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1037.0 MiB)
23/10/22 14:46:22.191 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:57170 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:22.191 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:22.191 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[82] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:46:22.191 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
23/10/22 14:46:22.192 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 62) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 14:46:22.192 Executor task launch worker for task 0.0 in stage 44.0 (TID 62) INFO Executor: Running task 0.0 in stage 44.0 (TID 62)
23/10/22 14:46:22.195 Executor task launch worker for task 0.0 in stage 44.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:22.195 Executor task launch worker for task 0.0 in stage 44.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:22.203 Executor task launch worker for task 0.0 in stage 44.0 (TID 62) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.220 Executor task launch worker for task 0.0 in stage 44.0 (TID 62) INFO Executor: Finished task 0.0 in stage 44.0 (TID 62). 778681 bytes result sent to driver
23/10/22 14:46:22.221 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 62) in 29 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:46:22.221 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
23/10/22 14:46:22.221 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 44 (collect at utils.scala:26) finished in 0.033 s
23/10/22 14:46:22.221 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:46:22.221 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
23/10/22 14:46:22.221 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0.034272 s
23/10/22 14:46:22.226 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:46:22.226 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 2 output partitions
23/10/22 14:46:22.226 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:26)
23/10/22 14:46:22.226 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
23/10/22 14:46:22.226 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:22.227 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[82] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:22.228 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 43.9 KiB, free 1036.9 MiB)
23/10/22 14:46:22.229 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1036.9 MiB)
23/10/22 14:46:22.229 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:57170 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:22.229 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:22.229 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[82] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 14:46:22.229 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks resource profile 0
23/10/22 14:46:22.230 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 63) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 14:46:22.230 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 64) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 14:46:22.231 Executor task launch worker for task 0.0 in stage 47.0 (TID 63) INFO Executor: Running task 0.0 in stage 47.0 (TID 63)
23/10/22 14:46:22.231 Executor task launch worker for task 1.0 in stage 47.0 (TID 64) INFO Executor: Running task 1.0 in stage 47.0 (TID 64)
23/10/22 14:46:22.233 Executor task launch worker for task 0.0 in stage 47.0 (TID 63) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:22.233 Executor task launch worker for task 0.0 in stage 47.0 (TID 63) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:22.234 Executor task launch worker for task 1.0 in stage 47.0 (TID 64) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:22.234 Executor task launch worker for task 1.0 in stage 47.0 (TID 64) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:22.241 Executor task launch worker for task 1.0 in stage 47.0 (TID 64) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.243 Executor task launch worker for task 0.0 in stage 47.0 (TID 63) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:46:22.255 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:57170 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 14:46:22.257 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:57170 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:22.262 Executor task launch worker for task 1.0 in stage 47.0 (TID 64) INFO Executor: Finished task 1.0 in stage 47.0 (TID 64). 745943 bytes result sent to driver
23/10/22 14:46:22.263 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 64) in 33 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:46:22.264 Executor task launch worker for task 0.0 in stage 47.0 (TID 63) INFO Executor: Finished task 0.0 in stage 47.0 (TID 63). 747491 bytes result sent to driver
23/10/22 14:46:22.265 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 63) in 35 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:46:22.265 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
23/10/22 14:46:22.265 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 47 (collect at utils.scala:26) finished in 0.038 s
23/10/22 14:46:22.265 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:46:22.265 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
23/10/22 14:46:22.266 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 0.039594 s
23/10/22 14:46:30.439 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:46:30.521 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 68.5836 ms
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 84 (collect at utils.scala:26) as input to shuffle 11
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 28 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 48 (collect at utils.scala:26)
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[84] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:30.523 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 14:46:30.535 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1037.0 MiB)
23/10/22 14:46:30.535 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:57170 (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 14:46:30.535 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:30.536 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[84] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:46:30.536 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
23/10/22 14:46:30.721 dispatcher-event-loop-4 WARN TaskSetManager: Stage 48 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:46:30.721 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 65) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:46:30.721 Executor task launch worker for task 0.0 in stage 48.0 (TID 65) INFO Executor: Running task 0.0 in stage 48.0 (TID 65)
23/10/22 14:46:30.734 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:57170 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:30.821 Executor task launch worker for task 0.0 in stage 48.0 (TID 65) INFO CodeGenerator: Code generated in 4.2055 ms
23/10/22 14:46:30.837 Executor task launch worker for task 0.0 in stage 48.0 (TID 65) INFO CodeGenerator: Code generated in 11.9415 ms
23/10/22 14:46:30.837 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:30.837 Executor task launch worker for task 0.0 in stage 48.0 (TID 65) INFO CodeGenerator: Code generated in 4.1441 ms
23/10/22 14:46:31.352 Executor task launch worker for task 0.0 in stage 48.0 (TID 65) INFO Executor: Finished task 0.0 in stage 48.0 (TID 65). 2306 bytes result sent to driver
23/10/22 14:46:31.352 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 65) in 815 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:46:31.352 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
23/10/22 14:46:31.352 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 48 (collect at utils.scala:26) finished in 0.829 s
23/10/22 14:46:31.352 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:46:31.352 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:46:31.352 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:46:31.352 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:46:31.352 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 14:46:31.368 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:46:31.435 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 68.955 ms
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:26) as input to shuffle 12
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 29 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 50 (collect at utils.scala:26)
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[87] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:31.435 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 65.0 KiB, free 1037.0 MiB)
23/10/22 14:46:31.451 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1037.0 MiB)
23/10/22 14:46:31.452 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:57170 (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:31.452 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:31.452 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[87] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:46:31.452 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
23/10/22 14:46:31.452 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 66) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:31.452 Executor task launch worker for task 0.0 in stage 50.0 (TID 66) INFO Executor: Running task 0.0 in stage 50.0 (TID 66)
23/10/22 14:46:31.452 Executor task launch worker for task 0.0 in stage 50.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 1 (483.5 KiB) non-empty blocks including 1 (483.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:31.452 Executor task launch worker for task 0.0 in stage 50.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:31.452 Executor task launch worker for task 0.0 in stage 50.0 (TID 66) INFO CodeGenerator: Code generated in 2.8998 ms
23/10/22 14:46:31.468 Executor task launch worker for task 0.0 in stage 50.0 (TID 66) INFO CodeGenerator: Code generated in 3.2378 ms
23/10/22 14:46:31.535 Executor task launch worker for task 0.0 in stage 50.0 (TID 66) INFO Executor: Finished task 0.0 in stage 50.0 (TID 66). 5424 bytes result sent to driver
23/10/22 14:46:31.535 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 66) in 83 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:46:31.535 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
23/10/22 14:46:31.535 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:26) finished in 0.100 s
23/10/22 14:46:31.535 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:46:31.535 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:46:31.535 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:46:31.535 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:46:31.535 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 14:46:31.535 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:46:31.582 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 20.4544 ms
23/10/22 14:46:31.592 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 90 (collect at utils.scala:26) as input to shuffle 13
23/10/22 14:46:31.592 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 30 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:46:31.592 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 53 (collect at utils.scala:26)
23/10/22 14:46:31.592 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
23/10/22 14:46:31.592 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:31.592 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[90] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:31.594 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 103.1 KiB, free 1036.9 MiB)
23/10/22 14:46:31.595 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 38.1 KiB, free 1036.9 MiB)
23/10/22 14:46:31.595 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:57170 (size: 38.1 KiB, free: 1037.1 MiB)
23/10/22 14:46:31.596 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:31.596 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[90] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:46:31.596 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
23/10/22 14:46:31.597 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 67) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:46:31.597 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO Executor: Running task 0.0 in stage 53.0 (TID 67)
23/10/22 14:46:31.601 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO ShuffleBlockFetcherIterator: Getting 1 (96.8 KiB) non-empty blocks including 1 (96.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:31.602 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:31.602 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO CodeGenerator: Code generated in 6.1799 ms
23/10/22 14:46:31.602 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO CodeGenerator: Code generated in 3.44 ms
23/10/22 14:46:31.622 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO CodeGenerator: Code generated in 4.7054 ms
23/10/22 14:46:31.622 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO CodeGenerator: Code generated in 2.7349 ms
23/10/22 14:46:31.672 Executor task launch worker for task 0.0 in stage 53.0 (TID 67) INFO Executor: Finished task 0.0 in stage 53.0 (TID 67). 7341 bytes result sent to driver
23/10/22 14:46:31.672 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 67) in 75 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:46:31.672 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
23/10/22 14:46:31.672 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:26) finished in 0.079 s
23/10/22 14:46:31.672 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:46:31.672 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:46:31.672 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:46:31.672 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:46:31.672 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 14:46:31.672 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:46:31.709 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.5814 ms
23/10/22 14:46:31.752 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:46:31.752 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:46:31.752 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:26)
23/10/22 14:46:31.752 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
23/10/22 14:46:31.752 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:46:31.752 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[93] at collect at utils.scala:26), which has no missing parents
23/10/22 14:46:31.767 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 106.0 KiB, free 1036.7 MiB)
23/10/22 14:46:31.768 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 1036.7 MiB)
23/10/22 14:46:31.768 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:57170 (size: 37.8 KiB, free: 1037.0 MiB)
23/10/22 14:46:31.768 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
23/10/22 14:46:31.768 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[93] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:46:31.768 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
23/10/22 14:46:31.768 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 68) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 14:46:31.768 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Running task 0.0 in stage 57.0 (TID 68)
23/10/22 14:46:31.768 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO ShuffleBlockFetcherIterator: Getting 1 (182.3 KiB) non-empty blocks including 1 (182.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:46:31.768 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:46:31.785 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Finished task 0.0 in stage 57.0 (TID 68). 107013 bytes result sent to driver
23/10/22 14:46:31.785 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 68) in 17 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:46:31.785 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
23/10/22 14:46:31.785 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collect at utils.scala:26) finished in 0.033 s
23/10/22 14:46:31.800 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:46:31.800 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
23/10/22 14:46:31.800 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0.036313 s
23/10/22 14:46:31.802 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.1672 ms
23/10/22 14:46:31.802 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:57170 in memory (size: 37.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:31.817 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:57170 in memory (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 14:46:31.818 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:57170 in memory (size: 38.1 KiB, free: 1037.1 MiB)
23/10/22 14:46:32.694 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:57170 in memory (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 14:56:06.747 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:26) as input to shuffle 14
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 32 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 58 (collect at utils.scala:26)
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[95] at collect at utils.scala:26), which has no missing parents
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 43.9 KiB, free 1037.1 MiB)
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1037.1 MiB)
23/10/22 14:56:06.751 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:57170 (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[95] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:56:06.751 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
23/10/22 14:56:06.932 dispatcher-event-loop-5 WARN TaskSetManager: Stage 58 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:56:06.932 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 69) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:56:06.932 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Running task 0.0 in stage 58.0 (TID 69)
23/10/22 14:56:07.505 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Finished task 0.0 in stage 58.0 (TID 69). 2306 bytes result sent to driver
23/10/22 14:56:07.505 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 69) in 754 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:56:07.505 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
23/10/22 14:56:07.506 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 58 (collect at utils.scala:26) finished in 0.755 s
23/10/22 14:56:07.507 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:56:07.507 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:56:07.507 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:56:07.507 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:56:07.511 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 14:56:07.515 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 98 (collect at utils.scala:26) as input to shuffle 15
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 33 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at utils.scala:26)
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[98] at collect at utils.scala:26), which has no missing parents
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 65.0 KiB, free 1037.0 MiB)
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 1037.0 MiB)
23/10/22 14:56:07.531 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:57170 (size: 25.7 KiB, free: 1037.1 MiB)
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[98] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:56:07.531 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
23/10/22 14:56:07.531 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 70) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:56:07.531 Executor task launch worker for task 0.0 in stage 60.0 (TID 70) INFO Executor: Running task 0.0 in stage 60.0 (TID 70)
23/10/22 14:56:07.548 Executor task launch worker for task 0.0 in stage 60.0 (TID 70) INFO ShuffleBlockFetcherIterator: Getting 1 (483.5 KiB) non-empty blocks including 1 (483.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:56:07.548 Executor task launch worker for task 0.0 in stage 60.0 (TID 70) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:56:07.598 Executor task launch worker for task 0.0 in stage 60.0 (TID 70) INFO Executor: Finished task 0.0 in stage 60.0 (TID 70). 5424 bytes result sent to driver
23/10/22 14:56:07.598 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 70) in 67 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:56:07.598 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
23/10/22 14:56:07.598 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 60 (collect at utils.scala:26) finished in 0.067 s
23/10/22 14:56:07.598 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:56:07.598 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:56:07.598 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:56:07.598 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:56:07.611 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 14:56:07.614 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 101 (collect at utils.scala:26) as input to shuffle 16
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 34 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 63 (collect at utils.scala:26)
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[101] at collect at utils.scala:26), which has no missing parents
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 103.1 KiB, free 1036.9 MiB)
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 38.1 KiB, free 1036.9 MiB)
23/10/22 14:56:07.648 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:57170 (size: 38.1 KiB, free: 1037.1 MiB)
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[101] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:56:07.648 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
23/10/22 14:56:07.648 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 71) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:56:07.648 Executor task launch worker for task 0.0 in stage 63.0 (TID 71) INFO Executor: Running task 0.0 in stage 63.0 (TID 71)
23/10/22 14:56:07.664 Executor task launch worker for task 0.0 in stage 63.0 (TID 71) INFO ShuffleBlockFetcherIterator: Getting 1 (96.8 KiB) non-empty blocks including 1 (96.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:56:07.664 Executor task launch worker for task 0.0 in stage 63.0 (TID 71) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:56:07.698 Executor task launch worker for task 0.0 in stage 63.0 (TID 71) INFO Executor: Finished task 0.0 in stage 63.0 (TID 71). 7341 bytes result sent to driver
23/10/22 14:56:07.698 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 71) in 50 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:56:07.698 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
23/10/22 14:56:07.698 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 63 (collect at utils.scala:26) finished in 0.050 s
23/10/22 14:56:07.698 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:56:07.698 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:56:07.698 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:56:07.698 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:56:07.698 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 14:56:07.698 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 14:56:07.715 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:56:07.715 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:56:07.715 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:26)
23/10/22 14:56:07.715 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
23/10/22 14:56:07.715 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:56:07.715 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[104] at collect at utils.scala:26), which has no missing parents
23/10/22 14:56:07.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 106.0 KiB, free 1036.7 MiB)
23/10/22 14:56:07.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 1036.7 MiB)
23/10/22 14:56:07.731 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:57170 (size: 37.8 KiB, free: 1037.0 MiB)
23/10/22 14:56:07.731 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
23/10/22 14:56:07.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[104] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:56:07.731 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
23/10/22 14:56:07.731 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 72) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 14:56:07.731 Executor task launch worker for task 0.0 in stage 67.0 (TID 72) INFO Executor: Running task 0.0 in stage 67.0 (TID 72)
23/10/22 14:56:07.731 Executor task launch worker for task 0.0 in stage 67.0 (TID 72) INFO ShuffleBlockFetcherIterator: Getting 1 (182.3 KiB) non-empty blocks including 1 (182.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:56:07.731 Executor task launch worker for task 0.0 in stage 67.0 (TID 72) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:56:07.748 Executor task launch worker for task 0.0 in stage 67.0 (TID 72) INFO Executor: Finished task 0.0 in stage 67.0 (TID 72). 107013 bytes result sent to driver
23/10/22 14:56:07.748 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 72) in 17 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:56:07.748 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
23/10/22 14:56:07.748 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 67 (collect at utils.scala:26) finished in 0.033 s
23/10/22 14:56:07.748 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:56:07.748 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
23/10/22 14:56:07.748 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 35 finished: collect at utils.scala:26, took 0.034197 s
23/10/22 14:56:08.582 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:57170 in memory (size: 37.8 KiB, free: 1037.1 MiB)
23/10/22 14:56:08.582 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:57170 in memory (size: 38.1 KiB, free: 1037.1 MiB)
23/10/22 14:56:08.582 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:57170 in memory (size: 25.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:11.469 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.8712 ms
23/10/22 14:57:11.481 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:11.483 dag-scheduler-event-loop INFO DAGScheduler: Got job 36 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:11.483 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:26)
23/10/22 14:57:11.483 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:11.483 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:11.483 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[106] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:11.484 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.3 KiB, free 1037.1 MiB)
23/10/22 14:57:11.485 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 14:57:11.486 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:11.486 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:11.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[106] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:11.486 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
23/10/22 14:57:11.488 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 73) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:11.489 Executor task launch worker for task 0.0 in stage 68.0 (TID 73) INFO Executor: Running task 0.0 in stage 68.0 (TID 73)
23/10/22 14:57:11.491 Executor task launch worker for task 0.0 in stage 68.0 (TID 73) INFO Executor: Finished task 0.0 in stage 68.0 (TID 73). 1327 bytes result sent to driver
23/10/22 14:57:11.491 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 73) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:11.492 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
23/10/22 14:57:11.492 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 68 (collect at utils.scala:26) finished in 0.008 s
23/10/22 14:57:11.492 dag-scheduler-event-loop INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:11.492 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
23/10/22 14:57:11.492 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 36 finished: collect at utils.scala:26, took 0.010438 s
23/10/22 14:57:11.499 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.0762 ms
23/10/22 14:57:11.604 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:26)
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[108] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.3 KiB, free 1037.1 MiB)
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 14:57:11.604 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[108] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
23/10/22 14:57:11.604 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 74) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:11.604 Executor task launch worker for task 0.0 in stage 69.0 (TID 74) INFO Executor: Running task 0.0 in stage 69.0 (TID 74)
23/10/22 14:57:11.604 Executor task launch worker for task 0.0 in stage 69.0 (TID 74) INFO Executor: Finished task 0.0 in stage 69.0 (TID 74). 1284 bytes result sent to driver
23/10/22 14:57:11.604 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 74) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:11.604 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 69 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:11.604 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
23/10/22 14:57:11.604 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: collect at utils.scala:26, took 0.006863 s
23/10/22 14:57:12.511 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:12.515 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:12.575 nioEventLoopGroup-2-2 INFO Instrumentation: [b9d13ae0] training finished
23/10/22 14:57:12.715 nioEventLoopGroup-2-2 INFO Instrumentation: [efb7afdd] training finished
23/10/22 14:57:12.715 nioEventLoopGroup-2-2 INFO Instrumentation: [652698f6] Stage class: LinearRegression
23/10/22 14:57:12.715 nioEventLoopGroup-2-2 INFO Instrumentation: [652698f6] Stage uid: linear_regression__dcd983da_2f00_4366_b94c_494db9f282db
23/10/22 14:57:12.782 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 111 (rdd at Instrumentation.scala:62) as input to shuffle 17
23/10/22 14:57:12.797 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 38 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 14:57:12.797 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at Instrumentation.scala:62)
23/10/22 14:57:12.797 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:12.798 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:12.798 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[111] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:12.800 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 14:57:12.805 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 14:57:12.806 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:12.807 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:12.807 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[111] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:12.807 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
23/10/22 14:57:12.936 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:57170 in memory (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:13.047 dispatcher-event-loop-1 WARN TaskSetManager: Stage 70 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:13.047 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 75) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:13.047 Executor task launch worker for task 0.0 in stage 70.0 (TID 75) INFO Executor: Running task 0.0 in stage 70.0 (TID 75)
23/10/22 14:57:13.130 Executor task launch worker for task 0.0 in stage 70.0 (TID 75) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.947 Executor task launch worker for task 0.0 in stage 70.0 (TID 75) INFO Executor: Finished task 0.0 in stage 70.0 (TID 75). 2104 bytes result sent to driver
23/10/22 14:57:13.947 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 75) in 1140 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:13.947 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
23/10/22 14:57:13.947 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 70 (rdd at Instrumentation.scala:62) finished in 1.148 s
23/10/22 14:57:13.947 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:13.947 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:13.947 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:13.947 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:13.947 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:13.963 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 115 (rdd at Instrumentation.scala:62) as input to shuffle 18
23/10/22 14:57:13.963 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 39 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 14:57:13.963 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 72 (rdd at Instrumentation.scala:62)
23/10/22 14:57:13.963 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
23/10/22 14:57:13.963 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:13.963 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[115] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:13.965 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:13.966 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:13.966 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:13.966 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:13.967 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[115] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:13.967 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 72.0 with 8 tasks resource profile 0
23/10/22 14:57:13.967 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 76) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.967 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 77) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.967 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 78) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.968 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 79) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.968 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 80) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.968 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 72.0 (TID 81) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.968 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 72.0 (TID 82) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.968 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 72.0 (TID 83) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:13.968 Executor task launch worker for task 0.0 in stage 72.0 (TID 76) INFO Executor: Running task 0.0 in stage 72.0 (TID 76)
23/10/22 14:57:13.969 Executor task launch worker for task 1.0 in stage 72.0 (TID 77) INFO Executor: Running task 1.0 in stage 72.0 (TID 77)
23/10/22 14:57:13.969 Executor task launch worker for task 2.0 in stage 72.0 (TID 78) INFO Executor: Running task 2.0 in stage 72.0 (TID 78)
23/10/22 14:57:13.969 Executor task launch worker for task 3.0 in stage 72.0 (TID 79) INFO Executor: Running task 3.0 in stage 72.0 (TID 79)
23/10/22 14:57:13.969 Executor task launch worker for task 4.0 in stage 72.0 (TID 80) INFO Executor: Running task 4.0 in stage 72.0 (TID 80)
23/10/22 14:57:13.969 Executor task launch worker for task 5.0 in stage 72.0 (TID 81) INFO Executor: Running task 5.0 in stage 72.0 (TID 81)
23/10/22 14:57:13.970 Executor task launch worker for task 6.0 in stage 72.0 (TID 82) INFO Executor: Running task 6.0 in stage 72.0 (TID 82)
23/10/22 14:57:13.972 Executor task launch worker for task 0.0 in stage 72.0 (TID 76) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.972 Executor task launch worker for task 3.0 in stage 72.0 (TID 79) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.973 Executor task launch worker for task 0.0 in stage 72.0 (TID 76) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.973 Executor task launch worker for task 7.0 in stage 72.0 (TID 83) INFO Executor: Running task 7.0 in stage 72.0 (TID 83)
23/10/22 14:57:13.973 Executor task launch worker for task 1.0 in stage 72.0 (TID 77) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.973 Executor task launch worker for task 4.0 in stage 72.0 (TID 80) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.973 Executor task launch worker for task 3.0 in stage 72.0 (TID 79) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.973 Executor task launch worker for task 5.0 in stage 72.0 (TID 81) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.973 Executor task launch worker for task 1.0 in stage 72.0 (TID 77) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.973 Executor task launch worker for task 4.0 in stage 72.0 (TID 80) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.973 Executor task launch worker for task 5.0 in stage 72.0 (TID 81) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.973 Executor task launch worker for task 2.0 in stage 72.0 (TID 78) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.973 Executor task launch worker for task 2.0 in stage 72.0 (TID 78) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.976 Executor task launch worker for task 7.0 in stage 72.0 (TID 83) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.976 Executor task launch worker for task 7.0 in stage 72.0 (TID 83) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:13.983 Executor task launch worker for task 1.0 in stage 72.0 (TID 77) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.983 Executor task launch worker for task 4.0 in stage 72.0 (TID 80) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.983 Executor task launch worker for task 3.0 in stage 72.0 (TID 79) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.983 Executor task launch worker for task 0.0 in stage 72.0 (TID 76) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.983 Executor task launch worker for task 5.0 in stage 72.0 (TID 81) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.986 Executor task launch worker for task 7.0 in stage 72.0 (TID 83) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.995 Executor task launch worker for task 2.0 in stage 72.0 (TID 78) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:13.995 Executor task launch worker for task 6.0 in stage 72.0 (TID 82) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:13.996 Executor task launch worker for task 6.0 in stage 72.0 (TID 82) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
23/10/22 14:57:14.002 Executor task launch worker for task 4.0 in stage 72.0 (TID 80) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.002 Executor task launch worker for task 3.0 in stage 72.0 (TID 79) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.002 Executor task launch worker for task 6.0 in stage 72.0 (TID 82) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.002 Executor task launch worker for task 7.0 in stage 72.0 (TID 83) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.002 Executor task launch worker for task 0.0 in stage 72.0 (TID 76) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.002 Executor task launch worker for task 5.0 in stage 72.0 (TID 81) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.031 Executor task launch worker for task 1.0 in stage 72.0 (TID 77) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.044 Executor task launch worker for task 6.0 in stage 72.0 (TID 82) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.048 Executor task launch worker for task 2.0 in stage 72.0 (TID 78) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:14.124 Executor task launch worker for task 3.0 in stage 72.0 (TID 79) INFO Executor: Finished task 3.0 in stage 72.0 (TID 79). 4985 bytes result sent to driver
23/10/22 14:57:14.129 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 79) in 161 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:14.142 Executor task launch worker for task 7.0 in stage 72.0 (TID 83) INFO Executor: Finished task 7.0 in stage 72.0 (TID 83). 4985 bytes result sent to driver
23/10/22 14:57:14.146 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 72.0 (TID 83) in 178 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:14.154 Executor task launch worker for task 5.0 in stage 72.0 (TID 81) INFO Executor: Finished task 5.0 in stage 72.0 (TID 81). 4942 bytes result sent to driver
23/10/22 14:57:14.155 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 72.0 (TID 81) in 187 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:14.161 Executor task launch worker for task 4.0 in stage 72.0 (TID 80) INFO Executor: Finished task 4.0 in stage 72.0 (TID 80). 4942 bytes result sent to driver
23/10/22 14:57:14.161 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 72.0 (TID 80) in 193 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:14.166 Executor task launch worker for task 1.0 in stage 72.0 (TID 77) INFO Executor: Finished task 1.0 in stage 72.0 (TID 77). 4942 bytes result sent to driver
23/10/22 14:57:14.166 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 77) in 199 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:14.169 Executor task launch worker for task 2.0 in stage 72.0 (TID 78) INFO Executor: Finished task 2.0 in stage 72.0 (TID 78). 4942 bytes result sent to driver
23/10/22 14:57:14.169 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 78) in 202 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:14.169 Executor task launch worker for task 6.0 in stage 72.0 (TID 82) INFO Executor: Finished task 6.0 in stage 72.0 (TID 82). 4985 bytes result sent to driver
23/10/22 14:57:14.169 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 72.0 (TID 82) in 201 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:14.180 Executor task launch worker for task 0.0 in stage 72.0 (TID 76) INFO Executor: Finished task 0.0 in stage 72.0 (TID 76). 4942 bytes result sent to driver
23/10/22 14:57:14.180 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 76) in 213 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:14.180 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
23/10/22 14:57:14.181 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 72 (rdd at Instrumentation.scala:62) finished in 0.217 s
23/10/22 14:57:14.181 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:14.181 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:14.181 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:14.181 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:14.182 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:14.243 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:14.264 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.4262 ms
23/10/22 14:57:14.330 nioEventLoopGroup-2-2 INFO Instrumentation: [652698f6] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 14:57:14.347 nioEventLoopGroup-2-2 INFO Instrumentation: [652698f6] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 14:57:14.347 nioEventLoopGroup-2-2 INFO Instrumentation: [652698f6] {"numFeatures":1}
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 124 (rdd at LinearRegression.scala:348) as input to shuffle 19
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 40 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 73 (rdd at LinearRegression.scala:348)
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[124] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 14:57:14.480 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[124] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:14.480 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
23/10/22 14:57:14.660 dispatcher-event-loop-0 WARN TaskSetManager: Stage 73 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:14.660 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 84) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:14.660 Executor task launch worker for task 0.0 in stage 73.0 (TID 84) INFO Executor: Running task 0.0 in stage 73.0 (TID 84)
23/10/22 14:57:14.750 Executor task launch worker for task 0.0 in stage 73.0 (TID 84) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.113 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:15.481 Executor task launch worker for task 0.0 in stage 73.0 (TID 84) INFO Executor: Finished task 0.0 in stage 73.0 (TID 84). 2104 bytes result sent to driver
23/10/22 14:57:15.481 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 84) in 1001 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:15.481 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
23/10/22 14:57:15.481 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 73 (rdd at LinearRegression.scala:348) finished in 1.001 s
23/10/22 14:57:15.481 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:15.481 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:15.481 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:15.481 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:15.486 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 128 (rdd at LinearRegression.scala:348) as input to shuffle 20
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 41 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 75 (rdd at LinearRegression.scala:348)
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[128] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:15.486 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[128] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:15.486 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 75.0 with 8 tasks resource profile 0
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 85) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 86) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 87) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 88) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 89) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 90) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 75.0 (TID 91) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 75.0 (TID 92) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.486 Executor task launch worker for task 3.0 in stage 75.0 (TID 88) INFO Executor: Running task 3.0 in stage 75.0 (TID 88)
23/10/22 14:57:15.486 Executor task launch worker for task 6.0 in stage 75.0 (TID 91) INFO Executor: Running task 6.0 in stage 75.0 (TID 91)
23/10/22 14:57:15.486 Executor task launch worker for task 1.0 in stage 75.0 (TID 86) INFO Executor: Running task 1.0 in stage 75.0 (TID 86)
23/10/22 14:57:15.486 Executor task launch worker for task 5.0 in stage 75.0 (TID 90) INFO Executor: Running task 5.0 in stage 75.0 (TID 90)
23/10/22 14:57:15.486 Executor task launch worker for task 2.0 in stage 75.0 (TID 87) INFO Executor: Running task 2.0 in stage 75.0 (TID 87)
23/10/22 14:57:15.486 Executor task launch worker for task 0.0 in stage 75.0 (TID 85) INFO Executor: Running task 0.0 in stage 75.0 (TID 85)
23/10/22 14:57:15.486 Executor task launch worker for task 4.0 in stage 75.0 (TID 89) INFO Executor: Running task 4.0 in stage 75.0 (TID 89)
23/10/22 14:57:15.496 Executor task launch worker for task 7.0 in stage 75.0 (TID 92) INFO Executor: Running task 7.0 in stage 75.0 (TID 92)
23/10/22 14:57:15.500 Executor task launch worker for task 7.0 in stage 75.0 (TID 92) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.500 Executor task launch worker for task 4.0 in stage 75.0 (TID 89) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.501 Executor task launch worker for task 4.0 in stage 75.0 (TID 89) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.500 Executor task launch worker for task 6.0 in stage 75.0 (TID 91) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.501 Executor task launch worker for task 1.0 in stage 75.0 (TID 86) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.500 Executor task launch worker for task 2.0 in stage 75.0 (TID 87) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.501 Executor task launch worker for task 1.0 in stage 75.0 (TID 86) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.501 Executor task launch worker for task 3.0 in stage 75.0 (TID 88) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.501 Executor task launch worker for task 2.0 in stage 75.0 (TID 87) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:15.501 Executor task launch worker for task 3.0 in stage 75.0 (TID 88) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.501 Executor task launch worker for task 6.0 in stage 75.0 (TID 91) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.501 Executor task launch worker for task 7.0 in stage 75.0 (TID 92) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.501 Executor task launch worker for task 0.0 in stage 75.0 (TID 85) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.502 Executor task launch worker for task 0.0 in stage 75.0 (TID 85) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.503 Executor task launch worker for task 5.0 in stage 75.0 (TID 90) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.503 Executor task launch worker for task 5.0 in stage 75.0 (TID 90) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.513 Executor task launch worker for task 2.0 in stage 75.0 (TID 87) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.513 Executor task launch worker for task 0.0 in stage 75.0 (TID 85) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.513 Executor task launch worker for task 6.0 in stage 75.0 (TID 91) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.513 Executor task launch worker for task 7.0 in stage 75.0 (TID 92) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.514 Executor task launch worker for task 4.0 in stage 75.0 (TID 89) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.514 Executor task launch worker for task 3.0 in stage 75.0 (TID 88) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.519 Executor task launch worker for task 5.0 in stage 75.0 (TID 90) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.530 Executor task launch worker for task 1.0 in stage 75.0 (TID 86) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.530 Executor task launch worker for task 6.0 in stage 75.0 (TID 91) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.530 Executor task launch worker for task 7.0 in stage 75.0 (TID 92) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.547 Executor task launch worker for task 4.0 in stage 75.0 (TID 89) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.547 Executor task launch worker for task 3.0 in stage 75.0 (TID 88) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.563 Executor task launch worker for task 2.0 in stage 75.0 (TID 87) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.565 Executor task launch worker for task 5.0 in stage 75.0 (TID 90) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.590 Executor task launch worker for task 0.0 in stage 75.0 (TID 85) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.604 Executor task launch worker for task 1.0 in stage 75.0 (TID 86) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.650 Executor task launch worker for task 6.0 in stage 75.0 (TID 91) INFO Executor: Finished task 6.0 in stage 75.0 (TID 91). 4899 bytes result sent to driver
23/10/22 14:57:15.651 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 75.0 (TID 91) in 165 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:15.684 Executor task launch worker for task 7.0 in stage 75.0 (TID 92) INFO Executor: Finished task 7.0 in stage 75.0 (TID 92). 4899 bytes result sent to driver
23/10/22 14:57:15.685 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 75.0 (TID 92) in 199 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:15.693 Executor task launch worker for task 0.0 in stage 75.0 (TID 85) INFO Executor: Finished task 0.0 in stage 75.0 (TID 85). 4899 bytes result sent to driver
23/10/22 14:57:15.695 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 85) in 209 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:15.697 Executor task launch worker for task 5.0 in stage 75.0 (TID 90) INFO Executor: Finished task 5.0 in stage 75.0 (TID 90). 4899 bytes result sent to driver
23/10/22 14:57:15.697 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 90) in 211 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:15.697 Executor task launch worker for task 1.0 in stage 75.0 (TID 86) INFO Executor: Finished task 1.0 in stage 75.0 (TID 86). 4899 bytes result sent to driver
23/10/22 14:57:15.697 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 86) in 211 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:15.697 Executor task launch worker for task 3.0 in stage 75.0 (TID 88) INFO Executor: Finished task 3.0 in stage 75.0 (TID 88). 4942 bytes result sent to driver
23/10/22 14:57:15.697 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 88) in 211 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:15.697 Executor task launch worker for task 4.0 in stage 75.0 (TID 89) INFO Executor: Finished task 4.0 in stage 75.0 (TID 89). 4942 bytes result sent to driver
23/10/22 14:57:15.697 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 89) in 211 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:15.697 Executor task launch worker for task 2.0 in stage 75.0 (TID 87) INFO Executor: Finished task 2.0 in stage 75.0 (TID 87). 4899 bytes result sent to driver
23/10/22 14:57:15.697 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 87) in 211 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:15.697 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
23/10/22 14:57:15.697 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 75 (rdd at LinearRegression.scala:348) finished in 0.211 s
23/10/22 14:57:15.697 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:15.697 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:15.697 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:15.697 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:15.713 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:15.730 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:15.747 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.146 ms
23/10/22 14:57:15.780 nioEventLoopGroup-2-2 WARN Instrumentation: [652698f6] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 14:57:15.858 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 14:57:15.858 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 137 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 21
23/10/22 14:57:15.858 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 14:57:15.858 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 79 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 14:57:15.858 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
23/10/22 14:57:15.858 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
23/10/22 14:57:15.858 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[137] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:15.864 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 92.1 KiB, free 1037.0 MiB)
23/10/22 14:57:15.864 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 1037.0 MiB)
23/10/22 14:57:15.864 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:57170 (size: 36.4 KiB, free: 1037.1 MiB)
23/10/22 14:57:15.864 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:15.864 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[137] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:15.864 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 78.0 with 8 tasks resource profile 0
23/10/22 14:57:15.864 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 93) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.864 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 94) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.864 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 95) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.864 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 96) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.864 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 97) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.864 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 98) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.879 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 99) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.880 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 100) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:15.880 Executor task launch worker for task 1.0 in stage 78.0 (TID 94) INFO Executor: Running task 1.0 in stage 78.0 (TID 94)
23/10/22 14:57:15.880 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) INFO Executor: Running task 0.0 in stage 78.0 (TID 93)
23/10/22 14:57:15.880 Executor task launch worker for task 6.0 in stage 78.0 (TID 99) INFO Executor: Running task 6.0 in stage 78.0 (TID 99)
23/10/22 14:57:15.880 Executor task launch worker for task 2.0 in stage 78.0 (TID 95) INFO Executor: Running task 2.0 in stage 78.0 (TID 95)
23/10/22 14:57:15.880 Executor task launch worker for task 5.0 in stage 78.0 (TID 98) INFO Executor: Running task 5.0 in stage 78.0 (TID 98)
23/10/22 14:57:15.880 Executor task launch worker for task 4.0 in stage 78.0 (TID 97) INFO Executor: Running task 4.0 in stage 78.0 (TID 97)
23/10/22 14:57:15.880 Executor task launch worker for task 3.0 in stage 78.0 (TID 96) INFO Executor: Running task 3.0 in stage 78.0 (TID 96)
23/10/22 14:57:15.880 Executor task launch worker for task 7.0 in stage 78.0 (TID 100) INFO Executor: Running task 7.0 in stage 78.0 (TID 100)
23/10/22 14:57:15.981 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 6.0 in stage 78.0 (TID 99) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 3.0 in stage 78.0 (TID 96) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 4.0 in stage 78.0 (TID 97) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 6.0 in stage 78.0 (TID 99) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.981 Executor task launch worker for task 3.0 in stage 78.0 (TID 96) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.981 Executor task launch worker for task 4.0 in stage 78.0 (TID 97) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.981 Executor task launch worker for task 5.0 in stage 78.0 (TID 98) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 5.0 in stage 78.0 (TID 98) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.981 Executor task launch worker for task 1.0 in stage 78.0 (TID 94) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 7.0 in stage 78.0 (TID 100) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 2.0 in stage 78.0 (TID 95) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:15.981 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.981 Executor task launch worker for task 1.0 in stage 78.0 (TID 94) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.981 Executor task launch worker for task 7.0 in stage 78.0 (TID 100) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:15.982 Executor task launch worker for task 2.0 in stage 78.0 (TID 95) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:15.997 Executor task launch worker for task 4.0 in stage 78.0 (TID 97) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.998 Executor task launch worker for task 1.0 in stage 78.0 (TID 94) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:15.998 Executor task launch worker for task 2.0 in stage 78.0 (TID 95) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:16.007 Executor task launch worker for task 5.0 in stage 78.0 (TID 98) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:16.012 Executor task launch worker for task 6.0 in stage 78.0 (TID 99) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:16.013 Executor task launch worker for task 3.0 in stage 78.0 (TID 96) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:16.020 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:16.026 Executor task launch worker for task 7.0 in stage 78.0 (TID 100) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:16.031 Executor task launch worker for task 4.0 in stage 78.0 (TID 97) INFO CodeGenerator: Code generated in 12.5513 ms
23/10/22 14:57:16.065 Executor task launch worker for task 7.0 in stage 78.0 (TID 100) INFO CodeGenerator: Code generated in 7.1174 ms
23/10/22 14:57:16.136 Executor task launch worker for task 1.0 in stage 78.0 (TID 94) INFO CodeGenerator: Code generated in 20.3519 ms
23/10/22 14:57:16.147 Executor task launch worker for task 6.0 in stage 78.0 (TID 99) INFO CodeGenerator: Code generated in 5.5635 ms
23/10/22 14:57:16.166 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS
23/10/22 14:57:16.180 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS
23/10/22 14:57:16.316 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:16.373 Executor task launch worker for task 7.0 in stage 78.0 (TID 100) INFO Executor: Finished task 7.0 in stage 78.0 (TID 100). 6648 bytes result sent to driver
23/10/22 14:57:16.375 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 100) in 495 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:16.378 Executor task launch worker for task 3.0 in stage 78.0 (TID 96) INFO Executor: Finished task 3.0 in stage 78.0 (TID 96). 6605 bytes result sent to driver
23/10/22 14:57:16.378 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 96) in 514 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:16.384 Executor task launch worker for task 2.0 in stage 78.0 (TID 95) INFO Executor: Finished task 2.0 in stage 78.0 (TID 95). 6648 bytes result sent to driver
23/10/22 14:57:16.384 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 95) in 520 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:16.390 Executor task launch worker for task 4.0 in stage 78.0 (TID 97) INFO Executor: Finished task 4.0 in stage 78.0 (TID 97). 6648 bytes result sent to driver
23/10/22 14:57:16.390 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 97) in 526 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:16.395 Executor task launch worker for task 1.0 in stage 78.0 (TID 94) INFO Executor: Finished task 1.0 in stage 78.0 (TID 94). 6648 bytes result sent to driver
23/10/22 14:57:16.396 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 94) in 532 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:16.401 Executor task launch worker for task 5.0 in stage 78.0 (TID 98) INFO Executor: Finished task 5.0 in stage 78.0 (TID 98). 6648 bytes result sent to driver
23/10/22 14:57:16.401 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 98) in 537 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:16.401 Executor task launch worker for task 0.0 in stage 78.0 (TID 93) INFO Executor: Finished task 0.0 in stage 78.0 (TID 93). 6648 bytes result sent to driver
23/10/22 14:57:16.401 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 93) in 537 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:16.413 Executor task launch worker for task 6.0 in stage 78.0 (TID 99) INFO Executor: Finished task 6.0 in stage 78.0 (TID 99). 6648 bytes result sent to driver
23/10/22 14:57:16.413 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 99) in 549 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:16.413 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 78 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.549 s
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 79)
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[139] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 93.2 KiB, free 1036.9 MiB)
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 1036.9 MiB)
23/10/22 14:57:16.413 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:57170 (size: 37.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[139] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:16.413 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0
23/10/22 14:57:16.413 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 101) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:16.413 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 102) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:16.413 Executor task launch worker for task 0.0 in stage 79.0 (TID 101) INFO Executor: Running task 0.0 in stage 79.0 (TID 101)
23/10/22 14:57:16.413 Executor task launch worker for task 1.0 in stage 79.0 (TID 102) INFO Executor: Running task 1.0 in stage 79.0 (TID 102)
23/10/22 14:57:16.428 Executor task launch worker for task 0.0 in stage 79.0 (TID 101) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:16.428 Executor task launch worker for task 0.0 in stage 79.0 (TID 101) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:16.428 Executor task launch worker for task 1.0 in stage 79.0 (TID 102) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:16.428 Executor task launch worker for task 1.0 in stage 79.0 (TID 102) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:16.447 Executor task launch worker for task 1.0 in stage 79.0 (TID 102) INFO Executor: Finished task 1.0 in stage 79.0 (TID 102). 6785 bytes result sent to driver
23/10/22 14:57:16.447 Executor task launch worker for task 0.0 in stage 79.0 (TID 101) INFO Executor: Finished task 0.0 in stage 79.0 (TID 101). 6785 bytes result sent to driver
23/10/22 14:57:16.447 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 102) in 34 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:16.447 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 101) in 34 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:16.447 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
23/10/22 14:57:16.447 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 79 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.034 s
23/10/22 14:57:16.447 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:16.447 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
23/10/22 14:57:16.447 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.591301 s
23/10/22 14:57:16.447 nioEventLoopGroup-2-2 INFO Instrumentation: [652698f6] Number of instances: 3785.
23/10/22 14:57:16.546 nioEventLoopGroup-2-2 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 142 (rdd at LinearRegression.scala:921) as input to shuffle 22
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 43 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 80 (rdd at LinearRegression.scala:921)
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[142] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 32.7 KiB, free 1036.9 MiB)
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 14:57:16.680 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[142] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:16.680 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
23/10/22 14:57:16.830 dispatcher-event-loop-5 WARN TaskSetManager: Stage 80 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:16.830 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 103) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:16.830 Executor task launch worker for task 0.0 in stage 80.0 (TID 103) INFO Executor: Running task 0.0 in stage 80.0 (TID 103)
23/10/22 14:57:16.930 Executor task launch worker for task 0.0 in stage 80.0 (TID 103) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.201 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:57170 in memory (size: 36.4 KiB, free: 1037.1 MiB)
23/10/22 14:57:17.201 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:57170 in memory (size: 37.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:17.666 Executor task launch worker for task 0.0 in stage 80.0 (TID 103) INFO Executor: Finished task 0.0 in stage 80.0 (TID 103). 2147 bytes result sent to driver
23/10/22 14:57:17.666 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 103) in 986 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:17.666 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
23/10/22 14:57:17.667 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 80 (rdd at LinearRegression.scala:921) finished in 0.987 s
23/10/22 14:57:17.667 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:17.667 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:17.667 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:17.667 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:17.671 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:17.674 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 146 (rdd at LinearRegression.scala:921) as input to shuffle 23
23/10/22 14:57:17.675 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 44 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 14:57:17.675 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 82 (rdd at LinearRegression.scala:921)
23/10/22 14:57:17.675 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
23/10/22 14:57:17.675 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:17.675 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[146] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:17.677 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:17.678 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:17.678 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:17.678 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:17.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[146] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:17.679 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 82.0 with 8 tasks resource profile 0
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 104) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 105) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 106) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 107) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 82.0 (TID 108) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 82.0 (TID 109) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 82.0 (TID 110) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 82.0 (TID 111) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:17.680 Executor task launch worker for task 2.0 in stage 82.0 (TID 106) INFO Executor: Running task 2.0 in stage 82.0 (TID 106)
23/10/22 14:57:17.682 Executor task launch worker for task 4.0 in stage 82.0 (TID 108) INFO Executor: Running task 4.0 in stage 82.0 (TID 108)
23/10/22 14:57:17.682 Executor task launch worker for task 5.0 in stage 82.0 (TID 109) INFO Executor: Running task 5.0 in stage 82.0 (TID 109)
23/10/22 14:57:17.682 Executor task launch worker for task 3.0 in stage 82.0 (TID 107) INFO Executor: Running task 3.0 in stage 82.0 (TID 107)
23/10/22 14:57:17.682 Executor task launch worker for task 7.0 in stage 82.0 (TID 111) INFO Executor: Running task 7.0 in stage 82.0 (TID 111)
23/10/22 14:57:17.687 Executor task launch worker for task 2.0 in stage 82.0 (TID 106) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.687 Executor task launch worker for task 2.0 in stage 82.0 (TID 106) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.687 Executor task launch worker for task 7.0 in stage 82.0 (TID 111) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.687 Executor task launch worker for task 7.0 in stage 82.0 (TID 111) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.680 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO Executor: Running task 0.0 in stage 82.0 (TID 104)
23/10/22 14:57:17.687 Executor task launch worker for task 4.0 in stage 82.0 (TID 108) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.687 Executor task launch worker for task 4.0 in stage 82.0 (TID 108) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.688 Executor task launch worker for task 3.0 in stage 82.0 (TID 107) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.688 Executor task launch worker for task 3.0 in stage 82.0 (TID 107) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:17.680 Executor task launch worker for task 1.0 in stage 82.0 (TID 105) INFO Executor: Running task 1.0 in stage 82.0 (TID 105)
23/10/22 14:57:17.682 Executor task launch worker for task 6.0 in stage 82.0 (TID 110) INFO Executor: Running task 6.0 in stage 82.0 (TID 110)
23/10/22 14:57:17.688 Executor task launch worker for task 5.0 in stage 82.0 (TID 109) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.688 Executor task launch worker for task 5.0 in stage 82.0 (TID 109) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.690 Executor task launch worker for task 1.0 in stage 82.0 (TID 105) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.690 Executor task launch worker for task 1.0 in stage 82.0 (TID 105) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.690 Executor task launch worker for task 6.0 in stage 82.0 (TID 110) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.690 Executor task launch worker for task 6.0 in stage 82.0 (TID 110) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.699 Executor task launch worker for task 2.0 in stage 82.0 (TID 106) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.700 Executor task launch worker for task 4.0 in stage 82.0 (TID 108) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.703 Executor task launch worker for task 5.0 in stage 82.0 (TID 109) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.713 Executor task launch worker for task 6.0 in stage 82.0 (TID 110) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.713 Executor task launch worker for task 1.0 in stage 82.0 (TID 105) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.720 Executor task launch worker for task 7.0 in stage 82.0 (TID 111) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.720 Executor task launch worker for task 3.0 in stage 82.0 (TID 107) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.735 Executor task launch worker for task 6.0 in stage 82.0 (TID 110) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.747 Executor task launch worker for task 7.0 in stage 82.0 (TID 111) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.751 Executor task launch worker for task 3.0 in stage 82.0 (TID 107) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.751 Executor task launch worker for task 4.0 in stage 82.0 (TID 108) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.751 Executor task launch worker for task 5.0 in stage 82.0 (TID 109) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.781 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:17.781 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:17.781 Executor task launch worker for task 2.0 in stage 82.0 (TID 106) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.797 Executor task launch worker for task 1.0 in stage 82.0 (TID 105) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.839 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.887 Executor task launch worker for task 6.0 in stage 82.0 (TID 110) INFO Executor: Finished task 6.0 in stage 82.0 (TID 110). 4899 bytes result sent to driver
23/10/22 14:57:17.893 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 82.0 (TID 110) in 213 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:17.914 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:17.917 Executor task launch worker for task 5.0 in stage 82.0 (TID 109) INFO Executor: Finished task 5.0 in stage 82.0 (TID 109). 4899 bytes result sent to driver
23/10/22 14:57:17.918 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 82.0 (TID 109) in 238 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:17.922 Executor task launch worker for task 3.0 in stage 82.0 (TID 107) INFO Executor: Finished task 3.0 in stage 82.0 (TID 107). 4899 bytes result sent to driver
23/10/22 14:57:17.922 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 107) in 242 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:17.928 Executor task launch worker for task 4.0 in stage 82.0 (TID 108) INFO Executor: Finished task 4.0 in stage 82.0 (TID 108). 4899 bytes result sent to driver
23/10/22 14:57:17.929 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 82.0 (TID 108) in 249 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:17.934 Executor task launch worker for task 7.0 in stage 82.0 (TID 111) INFO Executor: Finished task 7.0 in stage 82.0 (TID 111). 4899 bytes result sent to driver
23/10/22 14:57:17.934 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 82.0 (TID 111) in 254 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:17.940 Executor task launch worker for task 2.0 in stage 82.0 (TID 106) INFO Executor: Finished task 2.0 in stage 82.0 (TID 106). 4899 bytes result sent to driver
23/10/22 14:57:17.941 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 106) in 261 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:17.946 Executor task launch worker for task 1.0 in stage 82.0 (TID 105) INFO Executor: Finished task 1.0 in stage 82.0 (TID 105). 4899 bytes result sent to driver
23/10/22 14:57:17.946 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 105) in 266 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:17.965 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO Executor: Finished task 0.0 in stage 82.0 (TID 104). 4899 bytes result sent to driver
23/10/22 14:57:17.965 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 104) in 285 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:17.965 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
23/10/22 14:57:17.965 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 82 (rdd at LinearRegression.scala:921) finished in 0.289 s
23/10/22 14:57:17.965 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:17.965 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:17.965 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:17.965 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:17.965 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:17.992 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.6245 ms
23/10/22 14:57:18.030 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 14:57:18.030 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 156 (treeAggregate at Statistics.scala:58) as input to shuffle 24
23/10/22 14:57:18.030 dag-scheduler-event-loop INFO DAGScheduler: Got job 45 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 14:57:18.030 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 86 (treeAggregate at Statistics.scala:58)
23/10/22 14:57:18.030 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
23/10/22 14:57:18.030 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 85)
23/10/22 14:57:18.046 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[156] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:18.047 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 82.5 KiB, free 1037.0 MiB)
23/10/22 14:57:18.047 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1036.9 MiB)
23/10/22 14:57:18.047 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:57170 (size: 35.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.047 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:18.047 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[156] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:18.047 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 85.0 with 8 tasks resource profile 0
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 112) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 113) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 85.0 (TID 114) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 85.0 (TID 115) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 85.0 (TID 116) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 85.0 (TID 117) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 85.0 (TID 118) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 85.0 (TID 119) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:18.047 Executor task launch worker for task 3.0 in stage 85.0 (TID 115) INFO Executor: Running task 3.0 in stage 85.0 (TID 115)
23/10/22 14:57:18.047 Executor task launch worker for task 5.0 in stage 85.0 (TID 117) INFO Executor: Running task 5.0 in stage 85.0 (TID 117)
23/10/22 14:57:18.054 Executor task launch worker for task 6.0 in stage 85.0 (TID 118) INFO Executor: Running task 6.0 in stage 85.0 (TID 118)
23/10/22 14:57:18.054 Executor task launch worker for task 4.0 in stage 85.0 (TID 116) INFO Executor: Running task 4.0 in stage 85.0 (TID 116)
23/10/22 14:57:18.047 Executor task launch worker for task 1.0 in stage 85.0 (TID 113) INFO Executor: Running task 1.0 in stage 85.0 (TID 113)
23/10/22 14:57:18.047 Executor task launch worker for task 0.0 in stage 85.0 (TID 112) INFO Executor: Running task 0.0 in stage 85.0 (TID 112)
23/10/22 14:57:18.054 Executor task launch worker for task 7.0 in stage 85.0 (TID 119) INFO Executor: Running task 7.0 in stage 85.0 (TID 119)
23/10/22 14:57:18.047 Executor task launch worker for task 2.0 in stage 85.0 (TID 114) INFO Executor: Running task 2.0 in stage 85.0 (TID 114)
23/10/22 14:57:18.081 Executor task launch worker for task 6.0 in stage 85.0 (TID 118) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.081 Executor task launch worker for task 7.0 in stage 85.0 (TID 119) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.082 Executor task launch worker for task 6.0 in stage 85.0 (TID 118) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.082 Executor task launch worker for task 1.0 in stage 85.0 (TID 113) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.081 Executor task launch worker for task 3.0 in stage 85.0 (TID 115) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.082 Executor task launch worker for task 3.0 in stage 85.0 (TID 115) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:18.082 Executor task launch worker for task 5.0 in stage 85.0 (TID 117) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.082 Executor task launch worker for task 4.0 in stage 85.0 (TID 116) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.082 Executor task launch worker for task 5.0 in stage 85.0 (TID 117) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.083 Executor task launch worker for task 4.0 in stage 85.0 (TID 116) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.081 Executor task launch worker for task 0.0 in stage 85.0 (TID 112) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.083 Executor task launch worker for task 0.0 in stage 85.0 (TID 112) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:18.083 Executor task launch worker for task 2.0 in stage 85.0 (TID 114) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.082 Executor task launch worker for task 1.0 in stage 85.0 (TID 113) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.083 Executor task launch worker for task 2.0 in stage 85.0 (TID 114) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.083 Executor task launch worker for task 7.0 in stage 85.0 (TID 119) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:18.096 Executor task launch worker for task 6.0 in stage 85.0 (TID 118) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.096 Executor task launch worker for task 3.0 in stage 85.0 (TID 115) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.097 Executor task launch worker for task 0.0 in stage 85.0 (TID 112) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.098 Executor task launch worker for task 7.0 in stage 85.0 (TID 119) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.102 Executor task launch worker for task 2.0 in stage 85.0 (TID 114) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.113 Executor task launch worker for task 5.0 in stage 85.0 (TID 117) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.114 Executor task launch worker for task 4.0 in stage 85.0 (TID 116) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.119 Executor task launch worker for task 1.0 in stage 85.0 (TID 113) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:18.132 Executor task launch worker for task 3.0 in stage 85.0 (TID 115) INFO CodeGenerator: Code generated in 8.2415 ms
23/10/22 14:57:18.154 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.203 Executor task launch worker for task 5.0 in stage 85.0 (TID 117) INFO Executor: Finished task 5.0 in stage 85.0 (TID 117). 6648 bytes result sent to driver
23/10/22 14:57:18.218 Executor task launch worker for task 3.0 in stage 85.0 (TID 115) INFO Executor: Finished task 3.0 in stage 85.0 (TID 115). 6648 bytes result sent to driver
23/10/22 14:57:18.221 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 85.0 (TID 117) in 174 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:18.226 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 85.0 (TID 115) in 179 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:18.229 Executor task launch worker for task 4.0 in stage 85.0 (TID 116) INFO Executor: Finished task 4.0 in stage 85.0 (TID 116). 6605 bytes result sent to driver
23/10/22 14:57:18.232 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 85.0 (TID 116) in 185 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:18.236 Executor task launch worker for task 0.0 in stage 85.0 (TID 112) INFO Executor: Finished task 0.0 in stage 85.0 (TID 112). 6648 bytes result sent to driver
23/10/22 14:57:18.236 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 112) in 189 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:18.242 Executor task launch worker for task 7.0 in stage 85.0 (TID 119) INFO Executor: Finished task 7.0 in stage 85.0 (TID 119). 6605 bytes result sent to driver
23/10/22 14:57:18.242 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 85.0 (TID 119) in 195 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:18.249 Executor task launch worker for task 6.0 in stage 85.0 (TID 118) INFO Executor: Finished task 6.0 in stage 85.0 (TID 118). 6648 bytes result sent to driver
23/10/22 14:57:18.249 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 85.0 (TID 118) in 202 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:18.254 Executor task launch worker for task 1.0 in stage 85.0 (TID 113) INFO Executor: Finished task 1.0 in stage 85.0 (TID 113). 6648 bytes result sent to driver
23/10/22 14:57:18.254 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 113) in 207 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:18.256 Executor task launch worker for task 2.0 in stage 85.0 (TID 114) INFO Executor: Finished task 2.0 in stage 85.0 (TID 114). 6648 bytes result sent to driver
23/10/22 14:57:18.256 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 85.0 (TID 114) in 209 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:18.256 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
23/10/22 14:57:18.256 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 85 (treeAggregate at Statistics.scala:58) finished in 0.209 s
23/10/22 14:57:18.256 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:18.256 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:18.256 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 86)
23/10/22 14:57:18.256 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:18.256 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[158] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:18.263 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 83.6 KiB, free 1036.9 MiB)
23/10/22 14:57:18.263 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 1036.9 MiB)
23/10/22 14:57:18.263 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:57170 (size: 35.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.263 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:18.263 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 86 (MapPartitionsRDD[158] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:18.263 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks resource profile 0
23/10/22 14:57:18.263 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 120) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:18.263 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 121) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:18.263 Executor task launch worker for task 1.0 in stage 86.0 (TID 121) INFO Executor: Running task 1.0 in stage 86.0 (TID 121)
23/10/22 14:57:18.263 Executor task launch worker for task 0.0 in stage 86.0 (TID 120) INFO Executor: Running task 0.0 in stage 86.0 (TID 120)
23/10/22 14:57:18.272 Executor task launch worker for task 1.0 in stage 86.0 (TID 121) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.272 Executor task launch worker for task 0.0 in stage 86.0 (TID 120) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:18.275 Executor task launch worker for task 0.0 in stage 86.0 (TID 120) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.275 Executor task launch worker for task 1.0 in stage 86.0 (TID 121) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:18.280 Executor task launch worker for task 0.0 in stage 86.0 (TID 120) INFO Executor: Finished task 0.0 in stage 86.0 (TID 120). 7630 bytes result sent to driver
23/10/22 14:57:18.280 Executor task launch worker for task 1.0 in stage 86.0 (TID 121) INFO Executor: Finished task 1.0 in stage 86.0 (TID 121). 7630 bytes result sent to driver
23/10/22 14:57:18.281 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 120) in 18 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:18.281 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 121) in 18 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:18.281 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
23/10/22 14:57:18.281 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 86 (treeAggregate at Statistics.scala:58) finished in 0.025 s
23/10/22 14:57:18.281 dag-scheduler-event-loop INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:18.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
23/10/22 14:57:18.281 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 45 finished: treeAggregate at Statistics.scala:58, took 0.237968 s
23/10/22 14:57:18.281 nioEventLoopGroup-2-2 INFO Instrumentation: [19fa8338] training finished
23/10/22 14:57:18.530 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:26)
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[160] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 14:57:18.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[160] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
23/10/22 14:57:18.530 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 122) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:18.530 Executor task launch worker for task 0.0 in stage 87.0 (TID 122) INFO Executor: Running task 0.0 in stage 87.0 (TID 122)
23/10/22 14:57:18.530 Executor task launch worker for task 0.0 in stage 87.0 (TID 122) INFO Executor: Finished task 0.0 in stage 87.0 (TID 122). 1284 bytes result sent to driver
23/10/22 14:57:18.530 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 122) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:18.530 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
23/10/22 14:57:18.530 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 87 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:18.546 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:18.546 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
23/10/22 14:57:18.546 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: collect at utils.scala:26, took 0.006759 s
23/10/22 14:57:18.731 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.734 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:57170 in memory (size: 35.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.736 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:57170 in memory (size: 35.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.750 nioEventLoopGroup-2-2 INFO Instrumentation: [7027d8a2] training finished
23/10/22 14:57:18.830 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:18.830 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:18.830 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:26)
23/10/22 14:57:18.830 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:18.830 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:18.830 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[162] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:18.830 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 14:57:18.848 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[162] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
23/10/22 14:57:18.848 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 123) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:18.848 Executor task launch worker for task 0.0 in stage 88.0 (TID 123) INFO Executor: Running task 0.0 in stage 88.0 (TID 123)
23/10/22 14:57:18.848 Executor task launch worker for task 0.0 in stage 88.0 (TID 123) INFO Executor: Finished task 0.0 in stage 88.0 (TID 123). 1327 bytes result sent to driver
23/10/22 14:57:18.848 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 123) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:18.848 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 88 (collect at utils.scala:26) finished in 0.018 s
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:18.848 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
23/10/22 14:57:18.848 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: collect at utils.scala:26, took 0.012927 s
23/10/22 14:57:18.848 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.0534 ms
23/10/22 14:57:18.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:19.263 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:19.279 dag-scheduler-event-loop INFO DAGScheduler: Got job 48 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:19.279 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:26)
23/10/22 14:57:19.279 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:19.279 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:19.280 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[164] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 14:57:19.281 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[164] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
23/10/22 14:57:19.281 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 124) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:19.281 Executor task launch worker for task 0.0 in stage 89.0 (TID 124) INFO Executor: Running task 0.0 in stage 89.0 (TID 124)
23/10/22 14:57:19.281 Executor task launch worker for task 0.0 in stage 89.0 (TID 124) INFO Executor: Finished task 0.0 in stage 89.0 (TID 124). 1284 bytes result sent to driver
23/10/22 14:57:19.281 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 124) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:19.281 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 89 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:19.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
23/10/22 14:57:19.281 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 48 finished: collect at utils.scala:26, took 0.007438 s
23/10/22 14:57:19.763 nioEventLoopGroup-2-2 INFO Instrumentation: [8e9aaec3] training finished
23/10/22 14:57:19.797 nioEventLoopGroup-2-2 INFO Instrumentation: [3b66cef8] training finished
23/10/22 14:57:19.797 nioEventLoopGroup-2-2 INFO Instrumentation: [f066039c] Stage class: LinearRegression
23/10/22 14:57:19.797 nioEventLoopGroup-2-2 INFO Instrumentation: [f066039c] Stage uid: linear_regression__7ff94102_776d_48d7_b646_37d3ed3b9be5
23/10/22 14:57:19.839 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 167 (rdd at Instrumentation.scala:62) as input to shuffle 25
23/10/22 14:57:19.839 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 49 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 14:57:19.839 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 90 (rdd at Instrumentation.scala:62)
23/10/22 14:57:19.839 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:19.839 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:19.839 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[167] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:19.840 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 14:57:19.841 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.1 MiB)
23/10/22 14:57:19.841 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:19.841 dag-scheduler-event-loop INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:19.842 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[167] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:19.842 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
23/10/22 14:57:19.997 dispatcher-event-loop-4 WARN TaskSetManager: Stage 90 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:20.013 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 125) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:20.014 Executor task launch worker for task 0.0 in stage 90.0 (TID 125) INFO Executor: Running task 0.0 in stage 90.0 (TID 125)
23/10/22 14:57:20.097 Executor task launch worker for task 0.0 in stage 90.0 (TID 125) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.704 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:20.704 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:20.762 Executor task launch worker for task 0.0 in stage 90.0 (TID 125) INFO Executor: Finished task 0.0 in stage 90.0 (TID 125). 2147 bytes result sent to driver
23/10/22 14:57:20.762 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 125) in 920 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:20.763 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 90 (rdd at Instrumentation.scala:62) finished in 0.924 s
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:20.763 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 171 (rdd at Instrumentation.scala:62) as input to shuffle 26
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 50 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 92 (rdd at Instrumentation.scala:62)
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[171] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:20.763 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[171] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:20.763 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 92.0 with 8 tasks resource profile 0
23/10/22 14:57:20.779 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 126) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.779 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 127) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.779 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 128) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.780 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 129) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.780 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 130) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.780 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 131) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.780 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 132) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.780 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 133) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:20.780 Executor task launch worker for task 0.0 in stage 92.0 (TID 126) INFO Executor: Running task 0.0 in stage 92.0 (TID 126)
23/10/22 14:57:20.780 Executor task launch worker for task 1.0 in stage 92.0 (TID 127) INFO Executor: Running task 1.0 in stage 92.0 (TID 127)
23/10/22 14:57:20.780 Executor task launch worker for task 4.0 in stage 92.0 (TID 130) INFO Executor: Running task 4.0 in stage 92.0 (TID 130)
23/10/22 14:57:20.782 Executor task launch worker for task 3.0 in stage 92.0 (TID 129) INFO Executor: Running task 3.0 in stage 92.0 (TID 129)
23/10/22 14:57:20.782 Executor task launch worker for task 5.0 in stage 92.0 (TID 131) INFO Executor: Running task 5.0 in stage 92.0 (TID 131)
23/10/22 14:57:20.780 Executor task launch worker for task 6.0 in stage 92.0 (TID 132) INFO Executor: Running task 6.0 in stage 92.0 (TID 132)
23/10/22 14:57:20.782 Executor task launch worker for task 7.0 in stage 92.0 (TID 133) INFO Executor: Running task 7.0 in stage 92.0 (TID 133)
23/10/22 14:57:20.783 Executor task launch worker for task 2.0 in stage 92.0 (TID 128) INFO Executor: Running task 2.0 in stage 92.0 (TID 128)
23/10/22 14:57:20.786 Executor task launch worker for task 4.0 in stage 92.0 (TID 130) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.786 Executor task launch worker for task 4.0 in stage 92.0 (TID 130) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:20.786 Executor task launch worker for task 7.0 in stage 92.0 (TID 133) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.786 Executor task launch worker for task 7.0 in stage 92.0 (TID 133) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:20.788 Executor task launch worker for task 5.0 in stage 92.0 (TID 131) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.788 Executor task launch worker for task 5.0 in stage 92.0 (TID 131) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:20.788 Executor task launch worker for task 1.0 in stage 92.0 (TID 127) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.788 Executor task launch worker for task 1.0 in stage 92.0 (TID 127) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:20.788 Executor task launch worker for task 2.0 in stage 92.0 (TID 128) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.788 Executor task launch worker for task 2.0 in stage 92.0 (TID 128) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:20.797 Executor task launch worker for task 0.0 in stage 92.0 (TID 126) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.797 Executor task launch worker for task 0.0 in stage 92.0 (TID 126) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:20.797 Executor task launch worker for task 4.0 in stage 92.0 (TID 130) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.797 Executor task launch worker for task 6.0 in stage 92.0 (TID 132) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.798 Executor task launch worker for task 6.0 in stage 92.0 (TID 132) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:20.802 Executor task launch worker for task 5.0 in stage 92.0 (TID 131) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.805 Executor task launch worker for task 6.0 in stage 92.0 (TID 132) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.821 Executor task launch worker for task 7.0 in stage 92.0 (TID 133) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.821 Executor task launch worker for task 0.0 in stage 92.0 (TID 126) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.821 Executor task launch worker for task 3.0 in stage 92.0 (TID 129) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:20.821 Executor task launch worker for task 3.0 in stage 92.0 (TID 129) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 29 ms
23/10/22 14:57:20.833 Executor task launch worker for task 6.0 in stage 92.0 (TID 132) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.835 Executor task launch worker for task 4.0 in stage 92.0 (TID 130) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.847 Executor task launch worker for task 1.0 in stage 92.0 (TID 127) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.864 Executor task launch worker for task 2.0 in stage 92.0 (TID 128) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.882 Executor task launch worker for task 7.0 in stage 92.0 (TID 133) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.897 Executor task launch worker for task 3.0 in stage 92.0 (TID 129) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.942 Executor task launch worker for task 1.0 in stage 92.0 (TID 127) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.950 Executor task launch worker for task 2.0 in stage 92.0 (TID 128) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.984 Executor task launch worker for task 6.0 in stage 92.0 (TID 132) INFO Executor: Finished task 6.0 in stage 92.0 (TID 132). 4899 bytes result sent to driver
23/10/22 14:57:20.987 Executor task launch worker for task 0.0 in stage 92.0 (TID 126) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.988 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 132) in 208 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:20.990 Executor task launch worker for task 5.0 in stage 92.0 (TID 131) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:20.990 Executor task launch worker for task 3.0 in stage 92.0 (TID 129) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:21.058 Executor task launch worker for task 7.0 in stage 92.0 (TID 133) INFO Executor: Finished task 7.0 in stage 92.0 (TID 133). 4942 bytes result sent to driver
23/10/22 14:57:21.064 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 133) in 284 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:21.067 Executor task launch worker for task 4.0 in stage 92.0 (TID 130) INFO Executor: Finished task 4.0 in stage 92.0 (TID 130). 4899 bytes result sent to driver
23/10/22 14:57:21.068 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 130) in 288 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:21.109 Executor task launch worker for task 3.0 in stage 92.0 (TID 129) INFO Executor: Finished task 3.0 in stage 92.0 (TID 129). 4899 bytes result sent to driver
23/10/22 14:57:21.110 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 129) in 331 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:21.115 Executor task launch worker for task 1.0 in stage 92.0 (TID 127) INFO Executor: Finished task 1.0 in stage 92.0 (TID 127). 4899 bytes result sent to driver
23/10/22 14:57:21.116 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 127) in 337 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:21.122 Executor task launch worker for task 5.0 in stage 92.0 (TID 131) INFO Executor: Finished task 5.0 in stage 92.0 (TID 131). 4942 bytes result sent to driver
23/10/22 14:57:21.123 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 131) in 343 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:21.125 Executor task launch worker for task 2.0 in stage 92.0 (TID 128) INFO Executor: Finished task 2.0 in stage 92.0 (TID 128). 4942 bytes result sent to driver
23/10/22 14:57:21.129 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 128) in 350 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:21.132 Executor task launch worker for task 0.0 in stage 92.0 (TID 126) INFO Executor: Finished task 0.0 in stage 92.0 (TID 126). 4899 bytes result sent to driver
23/10/22 14:57:21.132 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 126) in 353 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:21.132 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
23/10/22 14:57:21.132 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 92 (rdd at Instrumentation.scala:62) finished in 0.369 s
23/10/22 14:57:21.132 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:21.132 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:21.132 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:21.132 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:21.146 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:21.165 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.9571 ms
23/10/22 14:57:21.173 nioEventLoopGroup-2-2 INFO Instrumentation: [f066039c] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 14:57:21.173 nioEventLoopGroup-2-2 INFO Instrumentation: [f066039c] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 14:57:21.173 nioEventLoopGroup-2-2 INFO Instrumentation: [f066039c] {"numFeatures":1}
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 180 (rdd at LinearRegression.scala:348) as input to shuffle 27
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 51 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 93 (rdd at LinearRegression.scala:348)
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[180] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 14:57:21.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[180] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:21.230 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
23/10/22 14:57:21.397 dispatcher-event-loop-6 WARN TaskSetManager: Stage 93 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:21.397 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 134) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:21.397 Executor task launch worker for task 0.0 in stage 93.0 (TID 134) INFO Executor: Running task 0.0 in stage 93.0 (TID 134)
23/10/22 14:57:21.483 Executor task launch worker for task 0.0 in stage 93.0 (TID 134) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:21.594 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:21.767 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:22.213 Executor task launch worker for task 0.0 in stage 93.0 (TID 134) INFO Executor: Finished task 0.0 in stage 93.0 (TID 134). 2104 bytes result sent to driver
23/10/22 14:57:22.213 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 134) in 983 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:22.213 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 93 (rdd at LinearRegression.scala:348) finished in 0.983 s
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:22.213 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 184 (rdd at LinearRegression.scala:348) as input to shuffle 28
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 52 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 95 (rdd at LinearRegression.scala:348)
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:22.213 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[184] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:22.229 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:22.229 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:22.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:22.230 dag-scheduler-event-loop INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:22.230 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[184] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:22.230 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 95.0 with 8 tasks resource profile 0
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 135) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 136) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 137) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 138) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 95.0 (TID 139) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 95.0 (TID 140) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 95.0 (TID 141) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 95.0 (TID 142) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.230 Executor task launch worker for task 1.0 in stage 95.0 (TID 136) INFO Executor: Running task 1.0 in stage 95.0 (TID 136)
23/10/22 14:57:22.230 Executor task launch worker for task 2.0 in stage 95.0 (TID 137) INFO Executor: Running task 2.0 in stage 95.0 (TID 137)
23/10/22 14:57:22.233 Executor task launch worker for task 6.0 in stage 95.0 (TID 141) INFO Executor: Running task 6.0 in stage 95.0 (TID 141)
23/10/22 14:57:22.230 Executor task launch worker for task 4.0 in stage 95.0 (TID 139) INFO Executor: Running task 4.0 in stage 95.0 (TID 139)
23/10/22 14:57:22.230 Executor task launch worker for task 5.0 in stage 95.0 (TID 140) INFO Executor: Running task 5.0 in stage 95.0 (TID 140)
23/10/22 14:57:22.230 Executor task launch worker for task 0.0 in stage 95.0 (TID 135) INFO Executor: Running task 0.0 in stage 95.0 (TID 135)
23/10/22 14:57:22.230 Executor task launch worker for task 3.0 in stage 95.0 (TID 138) INFO Executor: Running task 3.0 in stage 95.0 (TID 138)
23/10/22 14:57:22.233 Executor task launch worker for task 7.0 in stage 95.0 (TID 142) INFO Executor: Running task 7.0 in stage 95.0 (TID 142)
23/10/22 14:57:22.237 Executor task launch worker for task 5.0 in stage 95.0 (TID 140) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.237 Executor task launch worker for task 4.0 in stage 95.0 (TID 139) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.237 Executor task launch worker for task 0.0 in stage 95.0 (TID 135) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.237 Executor task launch worker for task 5.0 in stage 95.0 (TID 140) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.238 Executor task launch worker for task 4.0 in stage 95.0 (TID 139) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.238 Executor task launch worker for task 1.0 in stage 95.0 (TID 136) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.237 Executor task launch worker for task 3.0 in stage 95.0 (TID 138) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.238 Executor task launch worker for task 6.0 in stage 95.0 (TID 141) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.238 Executor task launch worker for task 0.0 in stage 95.0 (TID 135) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.238 Executor task launch worker for task 1.0 in stage 95.0 (TID 136) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.238 Executor task launch worker for task 7.0 in stage 95.0 (TID 142) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.238 Executor task launch worker for task 3.0 in stage 95.0 (TID 138) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:22.238 Executor task launch worker for task 6.0 in stage 95.0 (TID 141) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.238 Executor task launch worker for task 7.0 in stage 95.0 (TID 142) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.239 Executor task launch worker for task 2.0 in stage 95.0 (TID 137) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.239 Executor task launch worker for task 2.0 in stage 95.0 (TID 137) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.247 Executor task launch worker for task 0.0 in stage 95.0 (TID 135) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.247 Executor task launch worker for task 6.0 in stage 95.0 (TID 141) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.248 Executor task launch worker for task 5.0 in stage 95.0 (TID 140) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.248 Executor task launch worker for task 3.0 in stage 95.0 (TID 138) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.248 Executor task launch worker for task 1.0 in stage 95.0 (TID 136) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.252 Executor task launch worker for task 4.0 in stage 95.0 (TID 139) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.263 Executor task launch worker for task 7.0 in stage 95.0 (TID 142) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.263 Executor task launch worker for task 5.0 in stage 95.0 (TID 140) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.263 Executor task launch worker for task 2.0 in stage 95.0 (TID 137) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.279 Executor task launch worker for task 1.0 in stage 95.0 (TID 136) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.279 Executor task launch worker for task 6.0 in stage 95.0 (TID 141) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.284 Executor task launch worker for task 0.0 in stage 95.0 (TID 135) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.298 Executor task launch worker for task 3.0 in stage 95.0 (TID 138) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.300 Executor task launch worker for task 4.0 in stage 95.0 (TID 139) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.307 Executor task launch worker for task 2.0 in stage 95.0 (TID 137) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.308 Executor task launch worker for task 7.0 in stage 95.0 (TID 142) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.393 Executor task launch worker for task 1.0 in stage 95.0 (TID 136) INFO Executor: Finished task 1.0 in stage 95.0 (TID 136). 4985 bytes result sent to driver
23/10/22 14:57:22.396 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 136) in 166 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:22.407 Executor task launch worker for task 6.0 in stage 95.0 (TID 141) INFO Executor: Finished task 6.0 in stage 95.0 (TID 141). 4942 bytes result sent to driver
23/10/22 14:57:22.410 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 95.0 (TID 141) in 180 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:22.415 Executor task launch worker for task 3.0 in stage 95.0 (TID 138) INFO Executor: Finished task 3.0 in stage 95.0 (TID 138). 4942 bytes result sent to driver
23/10/22 14:57:22.416 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 138) in 186 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:22.422 Executor task launch worker for task 4.0 in stage 95.0 (TID 139) INFO Executor: Finished task 4.0 in stage 95.0 (TID 139). 4942 bytes result sent to driver
23/10/22 14:57:22.424 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 95.0 (TID 139) in 194 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:22.428 Executor task launch worker for task 2.0 in stage 95.0 (TID 137) INFO Executor: Finished task 2.0 in stage 95.0 (TID 137). 4942 bytes result sent to driver
23/10/22 14:57:22.429 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 137) in 199 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:22.433 Executor task launch worker for task 0.0 in stage 95.0 (TID 135) INFO Executor: Finished task 0.0 in stage 95.0 (TID 135). 4942 bytes result sent to driver
23/10/22 14:57:22.434 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 135) in 204 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:22.440 Executor task launch worker for task 7.0 in stage 95.0 (TID 142) INFO Executor: Finished task 7.0 in stage 95.0 (TID 142). 4942 bytes result sent to driver
23/10/22 14:57:22.440 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 95.0 (TID 142) in 210 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:22.446 Executor task launch worker for task 5.0 in stage 95.0 (TID 140) INFO Executor: Finished task 5.0 in stage 95.0 (TID 140). 4942 bytes result sent to driver
23/10/22 14:57:22.447 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 95.0 (TID 140) in 217 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:22.447 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
23/10/22 14:57:22.447 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 95 (rdd at LinearRegression.scala:348) finished in 0.234 s
23/10/22 14:57:22.447 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:22.447 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:22.447 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:22.447 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:22.447 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:22.484 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 26.0616 ms
23/10/22 14:57:22.497 nioEventLoopGroup-2-2 WARN Instrumentation: [f066039c] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 14:57:22.513 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 193 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 29
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO DAGScheduler: Got job 53 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 99 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 98)
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[193] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 92.6 KiB, free 1037.0 MiB)
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 36.7 KiB, free 1036.9 MiB)
23/10/22 14:57:22.513 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:57170 (size: 36.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:22.513 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:22.529 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[193] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:22.529 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 98.0 with 8 tasks resource profile 0
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 143) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 144) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 145) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 146) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 98.0 (TID 147) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 98.0 (TID 148) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 98.0 (TID 149) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 98.0 (TID 150) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:22.530 Executor task launch worker for task 0.0 in stage 98.0 (TID 143) INFO Executor: Running task 0.0 in stage 98.0 (TID 143)
23/10/22 14:57:22.530 Executor task launch worker for task 1.0 in stage 98.0 (TID 144) INFO Executor: Running task 1.0 in stage 98.0 (TID 144)
23/10/22 14:57:22.533 Executor task launch worker for task 3.0 in stage 98.0 (TID 146) INFO Executor: Running task 3.0 in stage 98.0 (TID 146)
23/10/22 14:57:22.533 Executor task launch worker for task 6.0 in stage 98.0 (TID 149) INFO Executor: Running task 6.0 in stage 98.0 (TID 149)
23/10/22 14:57:22.530 Executor task launch worker for task 2.0 in stage 98.0 (TID 145) INFO Executor: Running task 2.0 in stage 98.0 (TID 145)
23/10/22 14:57:22.533 Executor task launch worker for task 4.0 in stage 98.0 (TID 147) INFO Executor: Running task 4.0 in stage 98.0 (TID 147)
23/10/22 14:57:22.534 Executor task launch worker for task 7.0 in stage 98.0 (TID 150) INFO Executor: Running task 7.0 in stage 98.0 (TID 150)
23/10/22 14:57:22.533 Executor task launch worker for task 5.0 in stage 98.0 (TID 148) INFO Executor: Running task 5.0 in stage 98.0 (TID 148)
23/10/22 14:57:22.539 Executor task launch worker for task 1.0 in stage 98.0 (TID 144) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.539 Executor task launch worker for task 1.0 in stage 98.0 (TID 144) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.546 Executor task launch worker for task 2.0 in stage 98.0 (TID 145) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.546 Executor task launch worker for task 2.0 in stage 98.0 (TID 145) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.548 Executor task launch worker for task 6.0 in stage 98.0 (TID 149) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.548 Executor task launch worker for task 6.0 in stage 98.0 (TID 149) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.549 Executor task launch worker for task 7.0 in stage 98.0 (TID 150) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.550 Executor task launch worker for task 7.0 in stage 98.0 (TID 150) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.550 Executor task launch worker for task 0.0 in stage 98.0 (TID 143) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.550 Executor task launch worker for task 0.0 in stage 98.0 (TID 143) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.548 Executor task launch worker for task 3.0 in stage 98.0 (TID 146) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.551 Executor task launch worker for task 3.0 in stage 98.0 (TID 146) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 14:57:22.552 Executor task launch worker for task 5.0 in stage 98.0 (TID 148) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.552 Executor task launch worker for task 5.0 in stage 98.0 (TID 148) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.552 Executor task launch worker for task 4.0 in stage 98.0 (TID 147) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.552 Executor task launch worker for task 4.0 in stage 98.0 (TID 147) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.570 Executor task launch worker for task 1.0 in stage 98.0 (TID 144) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.570 Executor task launch worker for task 4.0 in stage 98.0 (TID 147) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.570 Executor task launch worker for task 6.0 in stage 98.0 (TID 149) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.580 Executor task launch worker for task 7.0 in stage 98.0 (TID 150) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.585 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:22.597 Executor task launch worker for task 3.0 in stage 98.0 (TID 146) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.621 Executor task launch worker for task 2.0 in stage 98.0 (TID 145) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.622 Executor task launch worker for task 5.0 in stage 98.0 (TID 148) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.633 Executor task launch worker for task 0.0 in stage 98.0 (TID 143) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:22.656 Executor task launch worker for task 6.0 in stage 98.0 (TID 149) INFO Executor: Finished task 6.0 in stage 98.0 (TID 149). 6605 bytes result sent to driver
23/10/22 14:57:22.665 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 98.0 (TID 149) in 135 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:22.684 Executor task launch worker for task 3.0 in stage 98.0 (TID 146) INFO Executor: Finished task 3.0 in stage 98.0 (TID 146). 6562 bytes result sent to driver
23/10/22 14:57:22.688 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 146) in 158 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:22.690 Executor task launch worker for task 7.0 in stage 98.0 (TID 150) INFO Executor: Finished task 7.0 in stage 98.0 (TID 150). 6562 bytes result sent to driver
23/10/22 14:57:22.693 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 98.0 (TID 150) in 163 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:22.698 Executor task launch worker for task 4.0 in stage 98.0 (TID 147) INFO Executor: Finished task 4.0 in stage 98.0 (TID 147). 6605 bytes result sent to driver
23/10/22 14:57:22.701 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 98.0 (TID 147) in 171 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:22.715 Executor task launch worker for task 1.0 in stage 98.0 (TID 144) INFO Executor: Finished task 1.0 in stage 98.0 (TID 144). 6605 bytes result sent to driver
23/10/22 14:57:22.717 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 144) in 187 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:22.731 Executor task launch worker for task 5.0 in stage 98.0 (TID 148) INFO Executor: Finished task 5.0 in stage 98.0 (TID 148). 6605 bytes result sent to driver
23/10/22 14:57:22.732 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 98.0 (TID 148) in 202 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:22.738 Executor task launch worker for task 0.0 in stage 98.0 (TID 143) INFO Executor: Finished task 0.0 in stage 98.0 (TID 143). 6605 bytes result sent to driver
23/10/22 14:57:22.739 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 143) in 209 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:22.744 Executor task launch worker for task 2.0 in stage 98.0 (TID 145) INFO Executor: Finished task 2.0 in stage 98.0 (TID 145). 6562 bytes result sent to driver
23/10/22 14:57:22.745 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 145) in 215 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:22.745 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
23/10/22 14:57:22.746 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 98 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.233 s
23/10/22 14:57:22.746 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:22.746 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:22.746 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 99)
23/10/22 14:57:22.746 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:22.746 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[195] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:22.749 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 93.6 KiB, free 1036.9 MiB)
23/10/22 14:57:22.749 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 1036.8 MiB)
23/10/22 14:57:22.749 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:57170 (size: 37.3 KiB, free: 1037.1 MiB)
23/10/22 14:57:22.749 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:22.749 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 99 (MapPartitionsRDD[195] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:22.749 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 99.0 with 2 tasks resource profile 0
23/10/22 14:57:22.749 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 151) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:22.749 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 152) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:22.749 Executor task launch worker for task 0.0 in stage 99.0 (TID 151) INFO Executor: Running task 0.0 in stage 99.0 (TID 151)
23/10/22 14:57:22.749 Executor task launch worker for task 1.0 in stage 99.0 (TID 152) INFO Executor: Running task 1.0 in stage 99.0 (TID 152)
23/10/22 14:57:22.754 Executor task launch worker for task 0.0 in stage 99.0 (TID 151) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.754 Executor task launch worker for task 1.0 in stage 99.0 (TID 152) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:22.762 Executor task launch worker for task 0.0 in stage 99.0 (TID 151) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.762 Executor task launch worker for task 1.0 in stage 99.0 (TID 152) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:22.764 Executor task launch worker for task 1.0 in stage 99.0 (TID 152) INFO Executor: Finished task 1.0 in stage 99.0 (TID 152). 6742 bytes result sent to driver
23/10/22 14:57:22.764 Executor task launch worker for task 0.0 in stage 99.0 (TID 151) INFO Executor: Finished task 0.0 in stage 99.0 (TID 151). 6742 bytes result sent to driver
23/10/22 14:57:22.764 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 152) in 15 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:22.772 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 151) in 23 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:22.772 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
23/10/22 14:57:22.772 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 99 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.025 s
23/10/22 14:57:22.773 dag-scheduler-event-loop INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:22.773 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
23/10/22 14:57:22.773 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 53 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.251852 s
23/10/22 14:57:22.773 nioEventLoopGroup-2-2 INFO Instrumentation: [f066039c] Number of instances: 3785.
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 198 (rdd at LinearRegression.scala:921) as input to shuffle 30
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 54 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 100 (rdd at LinearRegression.scala:921)
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[198] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 14:57:22.865 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[198] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:22.865 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
23/10/22 14:57:23.081 dispatcher-event-loop-1 WARN TaskSetManager: Stage 100 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:23.081 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 153) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:23.081 Executor task launch worker for task 0.0 in stage 100.0 (TID 153) INFO Executor: Running task 0.0 in stage 100.0 (TID 153)
23/10/22 14:57:23.163 Executor task launch worker for task 0.0 in stage 100.0 (TID 153) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.452 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:57170 in memory (size: 37.3 KiB, free: 1037.1 MiB)
23/10/22 14:57:23.463 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:57170 in memory (size: 36.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:23.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:23.824 Executor task launch worker for task 0.0 in stage 100.0 (TID 153) INFO Executor: Finished task 0.0 in stage 100.0 (TID 153). 2147 bytes result sent to driver
23/10/22 14:57:23.824 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 153) in 959 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:23.824 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
23/10/22 14:57:23.824 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 100 (rdd at LinearRegression.scala:921) finished in 0.959 s
23/10/22 14:57:23.824 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:23.824 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:23.824 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:23.824 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:23.830 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:23.830 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 202 (rdd at LinearRegression.scala:921) as input to shuffle 31
23/10/22 14:57:23.836 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 55 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 14:57:23.836 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 102 (rdd at LinearRegression.scala:921)
23/10/22 14:57:23.836 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
23/10/22 14:57:23.836 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:23.836 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 102 (MapPartitionsRDD[202] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:23.838 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:23.839 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:23.839 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:23.840 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:23.840 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[202] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:23.840 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 102.0 with 8 tasks resource profile 0
23/10/22 14:57:23.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 154) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 155) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 156) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 157) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 102.0 (TID 158) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 102.0 (TID 159) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.842 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 102.0 (TID 160) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.842 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 102.0 (TID 161) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:23.842 Executor task launch worker for task 2.0 in stage 102.0 (TID 156) INFO Executor: Running task 2.0 in stage 102.0 (TID 156)
23/10/22 14:57:23.842 Executor task launch worker for task 4.0 in stage 102.0 (TID 158) INFO Executor: Running task 4.0 in stage 102.0 (TID 158)
23/10/22 14:57:23.843 Executor task launch worker for task 7.0 in stage 102.0 (TID 161) INFO Executor: Running task 7.0 in stage 102.0 (TID 161)
23/10/22 14:57:23.842 Executor task launch worker for task 3.0 in stage 102.0 (TID 157) INFO Executor: Running task 3.0 in stage 102.0 (TID 157)
23/10/22 14:57:23.842 Executor task launch worker for task 0.0 in stage 102.0 (TID 154) INFO Executor: Running task 0.0 in stage 102.0 (TID 154)
23/10/22 14:57:23.842 Executor task launch worker for task 1.0 in stage 102.0 (TID 155) INFO Executor: Running task 1.0 in stage 102.0 (TID 155)
23/10/22 14:57:23.843 Executor task launch worker for task 5.0 in stage 102.0 (TID 159) INFO Executor: Running task 5.0 in stage 102.0 (TID 159)
23/10/22 14:57:23.843 Executor task launch worker for task 6.0 in stage 102.0 (TID 160) INFO Executor: Running task 6.0 in stage 102.0 (TID 160)
23/10/22 14:57:23.847 Executor task launch worker for task 4.0 in stage 102.0 (TID 158) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.847 Executor task launch worker for task 6.0 in stage 102.0 (TID 160) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.847 Executor task launch worker for task 4.0 in stage 102.0 (TID 158) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:23.847 Executor task launch worker for task 1.0 in stage 102.0 (TID 155) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.847 Executor task launch worker for task 0.0 in stage 102.0 (TID 154) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.847 Executor task launch worker for task 0.0 in stage 102.0 (TID 154) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:23.848 Executor task launch worker for task 2.0 in stage 102.0 (TID 156) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.848 Executor task launch worker for task 2.0 in stage 102.0 (TID 156) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:23.849 Executor task launch worker for task 6.0 in stage 102.0 (TID 160) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 14:57:23.850 Executor task launch worker for task 3.0 in stage 102.0 (TID 157) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.850 Executor task launch worker for task 3.0 in stage 102.0 (TID 157) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:23.847 Executor task launch worker for task 1.0 in stage 102.0 (TID 155) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:23.849 Executor task launch worker for task 7.0 in stage 102.0 (TID 161) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.850 Executor task launch worker for task 7.0 in stage 102.0 (TID 161) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:23.850 Executor task launch worker for task 5.0 in stage 102.0 (TID 159) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:23.850 Executor task launch worker for task 5.0 in stage 102.0 (TID 159) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:23.852 Executor task launch worker for task 4.0 in stage 102.0 (TID 158) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.852 Executor task launch worker for task 3.0 in stage 102.0 (TID 157) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.852 Executor task launch worker for task 6.0 in stage 102.0 (TID 160) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.864 Executor task launch worker for task 5.0 in stage 102.0 (TID 159) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.867 Executor task launch worker for task 2.0 in stage 102.0 (TID 156) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.884 Executor task launch worker for task 7.0 in stage 102.0 (TID 161) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.884 Executor task launch worker for task 6.0 in stage 102.0 (TID 160) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.884 Executor task launch worker for task 3.0 in stage 102.0 (TID 157) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.899 Executor task launch worker for task 5.0 in stage 102.0 (TID 159) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.908 Executor task launch worker for task 2.0 in stage 102.0 (TID 156) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.916 Executor task launch worker for task 1.0 in stage 102.0 (TID 155) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.918 Executor task launch worker for task 4.0 in stage 102.0 (TID 158) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.956 Executor task launch worker for task 7.0 in stage 102.0 (TID 161) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.968 Executor task launch worker for task 1.0 in stage 102.0 (TID 155) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:23.985 Executor task launch worker for task 0.0 in stage 102.0 (TID 154) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.034 Executor task launch worker for task 2.0 in stage 102.0 (TID 156) INFO Executor: Finished task 2.0 in stage 102.0 (TID 156). 4899 bytes result sent to driver
23/10/22 14:57:24.034 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 156) in 193 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:24.038 Executor task launch worker for task 0.0 in stage 102.0 (TID 154) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.044 Executor task launch worker for task 6.0 in stage 102.0 (TID 160) INFO Executor: Finished task 6.0 in stage 102.0 (TID 160). 4899 bytes result sent to driver
23/10/22 14:57:24.046 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 102.0 (TID 160) in 205 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:24.057 Executor task launch worker for task 5.0 in stage 102.0 (TID 159) INFO Executor: Finished task 5.0 in stage 102.0 (TID 159). 4942 bytes result sent to driver
23/10/22 14:57:24.057 Executor task launch worker for task 4.0 in stage 102.0 (TID 158) INFO Executor: Finished task 4.0 in stage 102.0 (TID 158). 4899 bytes result sent to driver
23/10/22 14:57:24.058 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 102.0 (TID 159) in 217 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:24.058 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 102.0 (TID 158) in 217 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:24.101 Executor task launch worker for task 3.0 in stage 102.0 (TID 157) INFO Executor: Finished task 3.0 in stage 102.0 (TID 157). 4942 bytes result sent to driver
23/10/22 14:57:24.101 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 157) in 260 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:24.134 Executor task launch worker for task 7.0 in stage 102.0 (TID 161) INFO Executor: Finished task 7.0 in stage 102.0 (TID 161). 4899 bytes result sent to driver
23/10/22 14:57:24.135 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 102.0 (TID 161) in 292 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:24.140 Executor task launch worker for task 1.0 in stage 102.0 (TID 155) INFO Executor: Finished task 1.0 in stage 102.0 (TID 155). 4899 bytes result sent to driver
23/10/22 14:57:24.141 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 155) in 300 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:24.152 Executor task launch worker for task 0.0 in stage 102.0 (TID 154) INFO Executor: Finished task 0.0 in stage 102.0 (TID 154). 4899 bytes result sent to driver
23/10/22 14:57:24.153 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 154) in 312 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:24.153 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
23/10/22 14:57:24.153 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 102 (rdd at LinearRegression.scala:921) finished in 0.317 s
23/10/22 14:57:24.153 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:24.154 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:24.154 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:24.154 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:24.159 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:24.175 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.5981 ms
23/10/22 14:57:24.201 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 14:57:24.202 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 212 (treeAggregate at Statistics.scala:58) as input to shuffle 32
23/10/22 14:57:24.202 dag-scheduler-event-loop INFO DAGScheduler: Got job 56 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 14:57:24.203 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 106 (treeAggregate at Statistics.scala:58)
23/10/22 14:57:24.203 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
23/10/22 14:57:24.203 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 105)
23/10/22 14:57:24.203 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[212] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:24.206 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 83.1 KiB, free 1037.0 MiB)
23/10/22 14:57:24.206 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1036.9 MiB)
23/10/22 14:57:24.207 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:57170 (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 14:57:24.207 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:24.207 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[212] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:24.208 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 105.0 with 8 tasks resource profile 0
23/10/22 14:57:24.208 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 162) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.208 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 163) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.209 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 164) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.209 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 165) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.209 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 166) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.209 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 167) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.209 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 168) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.209 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 169) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:24.210 Executor task launch worker for task 0.0 in stage 105.0 (TID 162) INFO Executor: Running task 0.0 in stage 105.0 (TID 162)
23/10/22 14:57:24.210 Executor task launch worker for task 1.0 in stage 105.0 (TID 163) INFO Executor: Running task 1.0 in stage 105.0 (TID 163)
23/10/22 14:57:24.210 Executor task launch worker for task 3.0 in stage 105.0 (TID 165) INFO Executor: Running task 3.0 in stage 105.0 (TID 165)
23/10/22 14:57:24.210 Executor task launch worker for task 4.0 in stage 105.0 (TID 166) INFO Executor: Running task 4.0 in stage 105.0 (TID 166)
23/10/22 14:57:24.210 Executor task launch worker for task 2.0 in stage 105.0 (TID 164) INFO Executor: Running task 2.0 in stage 105.0 (TID 164)
23/10/22 14:57:24.210 Executor task launch worker for task 5.0 in stage 105.0 (TID 167) INFO Executor: Running task 5.0 in stage 105.0 (TID 167)
23/10/22 14:57:24.210 Executor task launch worker for task 6.0 in stage 105.0 (TID 168) INFO Executor: Running task 6.0 in stage 105.0 (TID 168)
23/10/22 14:57:24.210 Executor task launch worker for task 7.0 in stage 105.0 (TID 169) INFO Executor: Running task 7.0 in stage 105.0 (TID 169)
23/10/22 14:57:24.217 Executor task launch worker for task 0.0 in stage 105.0 (TID 162) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.217 Executor task launch worker for task 5.0 in stage 105.0 (TID 167) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.217 Executor task launch worker for task 0.0 in stage 105.0 (TID 162) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.218 Executor task launch worker for task 1.0 in stage 105.0 (TID 163) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.218 Executor task launch worker for task 1.0 in stage 105.0 (TID 163) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.218 Executor task launch worker for task 7.0 in stage 105.0 (TID 169) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.218 Executor task launch worker for task 7.0 in stage 105.0 (TID 169) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.219 Executor task launch worker for task 3.0 in stage 105.0 (TID 165) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.219 Executor task launch worker for task 3.0 in stage 105.0 (TID 165) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.219 Executor task launch worker for task 5.0 in stage 105.0 (TID 167) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 14:57:24.219 Executor task launch worker for task 6.0 in stage 105.0 (TID 168) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.220 Executor task launch worker for task 6.0 in stage 105.0 (TID 168) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.223 Executor task launch worker for task 2.0 in stage 105.0 (TID 164) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.223 Executor task launch worker for task 2.0 in stage 105.0 (TID 164) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.224 Executor task launch worker for task 4.0 in stage 105.0 (TID 166) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.225 Executor task launch worker for task 4.0 in stage 105.0 (TID 166) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:24.235 Executor task launch worker for task 0.0 in stage 105.0 (TID 162) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.236 Executor task launch worker for task 3.0 in stage 105.0 (TID 165) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.238 Executor task launch worker for task 6.0 in stage 105.0 (TID 168) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.239 Executor task launch worker for task 1.0 in stage 105.0 (TID 163) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.243 Executor task launch worker for task 2.0 in stage 105.0 (TID 164) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.251 Executor task launch worker for task 4.0 in stage 105.0 (TID 166) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.255 Executor task launch worker for task 5.0 in stage 105.0 (TID 167) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.264 Executor task launch worker for task 7.0 in stage 105.0 (TID 169) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:24.310 Executor task launch worker for task 6.0 in stage 105.0 (TID 168) INFO Executor: Finished task 6.0 in stage 105.0 (TID 168). 6562 bytes result sent to driver
23/10/22 14:57:24.311 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 168) in 102 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:24.318 Executor task launch worker for task 0.0 in stage 105.0 (TID 162) INFO Executor: Finished task 0.0 in stage 105.0 (TID 162). 6562 bytes result sent to driver
23/10/22 14:57:24.319 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 162) in 111 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:24.325 Executor task launch worker for task 2.0 in stage 105.0 (TID 164) INFO Executor: Finished task 2.0 in stage 105.0 (TID 164). 6562 bytes result sent to driver
23/10/22 14:57:24.326 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 164) in 117 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:24.332 Executor task launch worker for task 4.0 in stage 105.0 (TID 166) INFO Executor: Finished task 4.0 in stage 105.0 (TID 166). 6562 bytes result sent to driver
23/10/22 14:57:24.333 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 166) in 124 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:24.339 Executor task launch worker for task 3.0 in stage 105.0 (TID 165) INFO Executor: Finished task 3.0 in stage 105.0 (TID 165). 6562 bytes result sent to driver
23/10/22 14:57:24.340 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 165) in 131 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:24.345 Executor task launch worker for task 1.0 in stage 105.0 (TID 163) INFO Executor: Finished task 1.0 in stage 105.0 (TID 163). 6562 bytes result sent to driver
23/10/22 14:57:24.346 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 163) in 138 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:24.351 Executor task launch worker for task 7.0 in stage 105.0 (TID 169) INFO Executor: Finished task 7.0 in stage 105.0 (TID 169). 6562 bytes result sent to driver
23/10/22 14:57:24.352 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 169) in 143 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:24.356 Executor task launch worker for task 5.0 in stage 105.0 (TID 167) INFO Executor: Finished task 5.0 in stage 105.0 (TID 167). 6562 bytes result sent to driver
23/10/22 14:57:24.356 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 167) in 147 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:24.356 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
23/10/22 14:57:24.357 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 105 (treeAggregate at Statistics.scala:58) finished in 0.153 s
23/10/22 14:57:24.357 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:24.357 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:24.357 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 106)
23/10/22 14:57:24.357 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:24.357 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[214] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:24.360 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 84.2 KiB, free 1036.8 MiB)
23/10/22 14:57:24.361 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 1036.8 MiB)
23/10/22 14:57:24.361 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:57170 (size: 35.9 KiB, free: 1037.0 MiB)
23/10/22 14:57:24.362 dag-scheduler-event-loop INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:24.362 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 106 (MapPartitionsRDD[214] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:24.362 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 106.0 with 2 tasks resource profile 0
23/10/22 14:57:24.363 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 170) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:24.363 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 171) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:24.363 Executor task launch worker for task 0.0 in stage 106.0 (TID 170) INFO Executor: Running task 0.0 in stage 106.0 (TID 170)
23/10/22 14:57:24.363 Executor task launch worker for task 1.0 in stage 106.0 (TID 171) INFO Executor: Running task 1.0 in stage 106.0 (TID 171)
23/10/22 14:57:24.369 Executor task launch worker for task 0.0 in stage 106.0 (TID 170) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.369 Executor task launch worker for task 0.0 in stage 106.0 (TID 170) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.370 Executor task launch worker for task 1.0 in stage 106.0 (TID 171) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:24.370 Executor task launch worker for task 1.0 in stage 106.0 (TID 171) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:24.375 Executor task launch worker for task 0.0 in stage 106.0 (TID 170) INFO Executor: Finished task 0.0 in stage 106.0 (TID 170). 7630 bytes result sent to driver
23/10/22 14:57:24.375 Executor task launch worker for task 1.0 in stage 106.0 (TID 171) INFO Executor: Finished task 1.0 in stage 106.0 (TID 171). 7630 bytes result sent to driver
23/10/22 14:57:24.375 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 170) in 12 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:24.376 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 171) in 13 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:24.376 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
23/10/22 14:57:24.376 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 106 (treeAggregate at Statistics.scala:58) finished in 0.018 s
23/10/22 14:57:24.377 dag-scheduler-event-loop INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:24.377 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
23/10/22 14:57:24.377 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 56 finished: treeAggregate at Statistics.scala:58, took 0.175318 s
23/10/22 14:57:24.378 nioEventLoopGroup-2-2 INFO Instrumentation: [631b2630] training finished
23/10/22 14:57:24.740 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:24.741 dag-scheduler-event-loop INFO DAGScheduler: Got job 57 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:24.741 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 107 (collect at utils.scala:26)
23/10/22 14:57:24.741 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:24.741 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:24.741 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[216] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:24.742 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:24.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:24.743 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:24.743 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:24.744 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[216] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:24.744 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0
23/10/22 14:57:24.746 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 172) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:24.747 Executor task launch worker for task 0.0 in stage 107.0 (TID 172) INFO Executor: Running task 0.0 in stage 107.0 (TID 172)
23/10/22 14:57:24.749 Executor task launch worker for task 0.0 in stage 107.0 (TID 172) INFO Executor: Finished task 0.0 in stage 107.0 (TID 172). 1327 bytes result sent to driver
23/10/22 14:57:24.750 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 172) in 5 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:24.750 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
23/10/22 14:57:24.750 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 107 (collect at utils.scala:26) finished in 0.008 s
23/10/22 14:57:24.750 dag-scheduler-event-loop INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:24.750 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished
23/10/22 14:57:24.750 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 57 finished: collect at utils.scala:26, took 0.010068 s
23/10/22 14:57:24.930 nioEventLoopGroup-2-2 INFO Instrumentation: [db015451] training finished
23/10/22 14:57:25.012 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:25.012 dag-scheduler-event-loop INFO DAGScheduler: Got job 58 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:25.012 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:26)
23/10/22 14:57:25.012 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:25.012 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[218] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:25.013 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[218] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0
23/10/22 14:57:25.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 173) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:25.013 Executor task launch worker for task 0.0 in stage 108.0 (TID 173) INFO Executor: Running task 0.0 in stage 108.0 (TID 173)
23/10/22 14:57:25.013 Executor task launch worker for task 0.0 in stage 108.0 (TID 173) INFO Executor: Finished task 0.0 in stage 108.0 (TID 173). 1284 bytes result sent to driver
23/10/22 14:57:25.013 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 173) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:25.013 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 108 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:25.013 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished
23/10/22 14:57:25.013 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 58 finished: collect at utils.scala:26, took 0.006114 s
23/10/22 14:57:25.354 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:25.354 dag-scheduler-event-loop INFO DAGScheduler: Got job 59 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:25.354 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:26)
23/10/22 14:57:25.354 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:25.354 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:25.354 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[220] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:25.355 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:25.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:25.356 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:25.356 dag-scheduler-event-loop INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:25.356 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[220] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:25.356 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0
23/10/22 14:57:25.357 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 174) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:25.357 Executor task launch worker for task 0.0 in stage 109.0 (TID 174) INFO Executor: Running task 0.0 in stage 109.0 (TID 174)
23/10/22 14:57:25.359 Executor task launch worker for task 0.0 in stage 109.0 (TID 174) INFO Executor: Finished task 0.0 in stage 109.0 (TID 174). 1284 bytes result sent to driver
23/10/22 14:57:25.360 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 174) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:25.360 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
23/10/22 14:57:25.360 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 109 (collect at utils.scala:26) finished in 0.005 s
23/10/22 14:57:25.360 dag-scheduler-event-loop INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:25.360 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished
23/10/22 14:57:25.360 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 59 finished: collect at utils.scala:26, took 0.006392 s
23/10/22 14:57:25.913 nioEventLoopGroup-2-2 INFO Instrumentation: [faa457f9] training finished
23/10/22 14:57:25.913 nioEventLoopGroup-2-2 INFO Instrumentation: [97ea8a48] training finished
23/10/22 14:57:25.930 nioEventLoopGroup-2-2 INFO Instrumentation: [4eca27bf] Stage class: LinearRegression
23/10/22 14:57:25.930 nioEventLoopGroup-2-2 INFO Instrumentation: [4eca27bf] Stage uid: linear_regression__fe5a0f59_ad22_4418_bf32_82504124f50c
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 223 (rdd at Instrumentation.scala:62) as input to shuffle 33
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 60 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 110 (rdd at Instrumentation.scala:62)
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[223] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 32.7 KiB, free 1036.7 MiB)
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 14:57:25.964 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[223] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:25.964 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
23/10/22 14:57:26.180 dispatcher-event-loop-3 WARN TaskSetManager: Stage 110 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:26.180 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 175) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:26.180 Executor task launch worker for task 0.0 in stage 110.0 (TID 175) INFO Executor: Running task 0.0 in stage 110.0 (TID 175)
23/10/22 14:57:26.201 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:57170 in memory (size: 35.4 KiB, free: 1037.0 MiB)
23/10/22 14:57:26.201 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:57170 in memory (size: 35.9 KiB, free: 1037.1 MiB)
23/10/22 14:57:26.207 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:26.207 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:26.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:26.213 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:26.369 Executor task launch worker for task 0.0 in stage 110.0 (TID 175) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:26.448 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:27.462 Executor task launch worker for task 0.0 in stage 110.0 (TID 175) INFO Executor: Finished task 0.0 in stage 110.0 (TID 175). 2147 bytes result sent to driver
23/10/22 14:57:27.463 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 175) in 1499 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:27.463 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
23/10/22 14:57:27.463 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 110 (rdd at Instrumentation.scala:62) finished in 1.499 s
23/10/22 14:57:27.464 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:27.464 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:27.464 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:27.464 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:27.471 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:27.474 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 227 (rdd at Instrumentation.scala:62) as input to shuffle 34
23/10/22 14:57:27.475 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 61 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 14:57:27.475 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 112 (rdd at Instrumentation.scala:62)
23/10/22 14:57:27.475 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)
23/10/22 14:57:27.475 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:27.475 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[227] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:27.477 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:27.478 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:27.478 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:27.479 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:27.479 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[227] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:27.479 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 112.0 with 8 tasks resource profile 0
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 176) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 177) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 112.0 (TID 178) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 112.0 (TID 179) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 112.0 (TID 180) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 112.0 (TID 181) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 112.0 (TID 182) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 112.0 (TID 183) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:27.480 Executor task launch worker for task 3.0 in stage 112.0 (TID 179) INFO Executor: Running task 3.0 in stage 112.0 (TID 179)
23/10/22 14:57:27.480 Executor task launch worker for task 5.0 in stage 112.0 (TID 181) INFO Executor: Running task 5.0 in stage 112.0 (TID 181)
23/10/22 14:57:27.482 Executor task launch worker for task 4.0 in stage 112.0 (TID 180) INFO Executor: Running task 4.0 in stage 112.0 (TID 180)
23/10/22 14:57:27.480 Executor task launch worker for task 0.0 in stage 112.0 (TID 176) INFO Executor: Running task 0.0 in stage 112.0 (TID 176)
23/10/22 14:57:27.480 Executor task launch worker for task 2.0 in stage 112.0 (TID 178) INFO Executor: Running task 2.0 in stage 112.0 (TID 178)
23/10/22 14:57:27.480 Executor task launch worker for task 1.0 in stage 112.0 (TID 177) INFO Executor: Running task 1.0 in stage 112.0 (TID 177)
23/10/22 14:57:27.482 Executor task launch worker for task 6.0 in stage 112.0 (TID 182) INFO Executor: Running task 6.0 in stage 112.0 (TID 182)
23/10/22 14:57:27.482 Executor task launch worker for task 7.0 in stage 112.0 (TID 183) INFO Executor: Running task 7.0 in stage 112.0 (TID 183)
23/10/22 14:57:27.486 Executor task launch worker for task 5.0 in stage 112.0 (TID 181) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.486 Executor task launch worker for task 2.0 in stage 112.0 (TID 178) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.486 Executor task launch worker for task 5.0 in stage 112.0 (TID 181) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.486 Executor task launch worker for task 2.0 in stage 112.0 (TID 178) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.487 Executor task launch worker for task 0.0 in stage 112.0 (TID 176) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.487 Executor task launch worker for task 0.0 in stage 112.0 (TID 176) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:27.487 Executor task launch worker for task 7.0 in stage 112.0 (TID 183) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.487 Executor task launch worker for task 7.0 in stage 112.0 (TID 183) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.488 Executor task launch worker for task 1.0 in stage 112.0 (TID 177) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.489 Executor task launch worker for task 3.0 in stage 112.0 (TID 179) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.488 Executor task launch worker for task 6.0 in stage 112.0 (TID 182) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.489 Executor task launch worker for task 6.0 in stage 112.0 (TID 182) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.489 Executor task launch worker for task 3.0 in stage 112.0 (TID 179) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.489 Executor task launch worker for task 1.0 in stage 112.0 (TID 177) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.489 Executor task launch worker for task 4.0 in stage 112.0 (TID 180) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:27.489 Executor task launch worker for task 4.0 in stage 112.0 (TID 180) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:27.498 Executor task launch worker for task 2.0 in stage 112.0 (TID 178) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.498 Executor task launch worker for task 5.0 in stage 112.0 (TID 181) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.498 Executor task launch worker for task 0.0 in stage 112.0 (TID 176) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.498 Executor task launch worker for task 7.0 in stage 112.0 (TID 183) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.498 Executor task launch worker for task 1.0 in stage 112.0 (TID 177) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.514 Executor task launch worker for task 3.0 in stage 112.0 (TID 179) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.514 Executor task launch worker for task 4.0 in stage 112.0 (TID 180) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.514 Executor task launch worker for task 2.0 in stage 112.0 (TID 178) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.514 Executor task launch worker for task 6.0 in stage 112.0 (TID 182) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.529 Executor task launch worker for task 5.0 in stage 112.0 (TID 181) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.531 Executor task launch worker for task 3.0 in stage 112.0 (TID 179) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.547 Executor task launch worker for task 7.0 in stage 112.0 (TID 183) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.564 Executor task launch worker for task 1.0 in stage 112.0 (TID 177) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.564 Executor task launch worker for task 0.0 in stage 112.0 (TID 176) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.594 Executor task launch worker for task 4.0 in stage 112.0 (TID 180) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.623 Executor task launch worker for task 6.0 in stage 112.0 (TID 182) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:27.681 Executor task launch worker for task 5.0 in stage 112.0 (TID 181) INFO Executor: Finished task 5.0 in stage 112.0 (TID 181). 4899 bytes result sent to driver
23/10/22 14:57:27.686 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 112.0 (TID 181) in 206 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:27.699 Executor task launch worker for task 3.0 in stage 112.0 (TID 179) INFO Executor: Finished task 3.0 in stage 112.0 (TID 179). 4899 bytes result sent to driver
23/10/22 14:57:27.699 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 112.0 (TID 179) in 219 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:27.699 Executor task launch worker for task 2.0 in stage 112.0 (TID 178) INFO Executor: Finished task 2.0 in stage 112.0 (TID 178). 4899 bytes result sent to driver
23/10/22 14:57:27.699 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 112.0 (TID 178) in 219 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:27.775 Executor task launch worker for task 6.0 in stage 112.0 (TID 182) INFO Executor: Finished task 6.0 in stage 112.0 (TID 182). 4899 bytes result sent to driver
23/10/22 14:57:27.776 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 112.0 (TID 182) in 296 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:27.788 Executor task launch worker for task 7.0 in stage 112.0 (TID 183) INFO Executor: Finished task 7.0 in stage 112.0 (TID 183). 4899 bytes result sent to driver
23/10/22 14:57:27.789 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 112.0 (TID 183) in 309 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:27.797 Executor task launch worker for task 1.0 in stage 112.0 (TID 177) INFO Executor: Finished task 1.0 in stage 112.0 (TID 177). 4899 bytes result sent to driver
23/10/22 14:57:27.797 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 177) in 317 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:27.803 Executor task launch worker for task 0.0 in stage 112.0 (TID 176) INFO Executor: Finished task 0.0 in stage 112.0 (TID 176). 4899 bytes result sent to driver
23/10/22 14:57:27.803 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 176) in 323 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:27.815 Executor task launch worker for task 4.0 in stage 112.0 (TID 180) INFO Executor: Finished task 4.0 in stage 112.0 (TID 180). 4942 bytes result sent to driver
23/10/22 14:57:27.815 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 112.0 (TID 180) in 335 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:27.815 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
23/10/22 14:57:27.816 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 112 (rdd at Instrumentation.scala:62) finished in 0.340 s
23/10/22 14:57:27.816 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:27.816 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:27.816 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:27.816 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:27.823 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:27.847 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.6818 ms
23/10/22 14:57:27.847 nioEventLoopGroup-2-2 INFO Instrumentation: [4eca27bf] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 14:57:27.847 nioEventLoopGroup-2-2 INFO Instrumentation: [4eca27bf] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 14:57:27.847 nioEventLoopGroup-2-2 INFO Instrumentation: [4eca27bf] {"numFeatures":2}
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 236 (rdd at LinearRegression.scala:348) as input to shuffle 35
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 62 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 113 (rdd at LinearRegression.scala:348)
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[236] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 14:57:27.947 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 14:57:27.947 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:27.963 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:27.963 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[236] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:27.964 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0
23/10/22 14:57:28.326 dispatcher-event-loop-7 WARN TaskSetManager: Stage 113 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:28.331 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 184) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:28.331 Executor task launch worker for task 0.0 in stage 113.0 (TID 184) INFO Executor: Running task 0.0 in stage 113.0 (TID 184)
23/10/22 14:57:28.514 Executor task launch worker for task 0.0 in stage 113.0 (TID 184) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:28.674 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:28.965 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:29.780 Executor task launch worker for task 0.0 in stage 113.0 (TID 184) INFO Executor: Finished task 0.0 in stage 113.0 (TID 184). 2104 bytes result sent to driver
23/10/22 14:57:29.780 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 184) in 1816 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:29.780 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
23/10/22 14:57:29.780 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 113 (rdd at LinearRegression.scala:348) finished in 1.833 s
23/10/22 14:57:29.780 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:29.780 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:29.780 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:29.780 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:29.797 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 240 (rdd at LinearRegression.scala:348) as input to shuffle 36
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 63 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 115 (rdd at LinearRegression.scala:348)
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 114)
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[240] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:29.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[240] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:29.797 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 115.0 with 8 tasks resource profile 0
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 185) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 186) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 187) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 188) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 189) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 190) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 191) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 192) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:29.797 Executor task launch worker for task 3.0 in stage 115.0 (TID 188) INFO Executor: Running task 3.0 in stage 115.0 (TID 188)
23/10/22 14:57:29.797 Executor task launch worker for task 1.0 in stage 115.0 (TID 186) INFO Executor: Running task 1.0 in stage 115.0 (TID 186)
23/10/22 14:57:29.808 Executor task launch worker for task 6.0 in stage 115.0 (TID 191) INFO Executor: Running task 6.0 in stage 115.0 (TID 191)
23/10/22 14:57:29.808 Executor task launch worker for task 7.0 in stage 115.0 (TID 192) INFO Executor: Running task 7.0 in stage 115.0 (TID 192)
23/10/22 14:57:29.797 Executor task launch worker for task 5.0 in stage 115.0 (TID 190) INFO Executor: Running task 5.0 in stage 115.0 (TID 190)
23/10/22 14:57:29.797 Executor task launch worker for task 4.0 in stage 115.0 (TID 189) INFO Executor: Running task 4.0 in stage 115.0 (TID 189)
23/10/22 14:57:29.797 Executor task launch worker for task 0.0 in stage 115.0 (TID 185) INFO Executor: Running task 0.0 in stage 115.0 (TID 185)
23/10/22 14:57:29.797 Executor task launch worker for task 2.0 in stage 115.0 (TID 187) INFO Executor: Running task 2.0 in stage 115.0 (TID 187)
23/10/22 14:57:29.812 Executor task launch worker for task 2.0 in stage 115.0 (TID 187) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.812 Executor task launch worker for task 5.0 in stage 115.0 (TID 190) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.812 Executor task launch worker for task 6.0 in stage 115.0 (TID 191) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.813 Executor task launch worker for task 2.0 in stage 115.0 (TID 187) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.813 Executor task launch worker for task 6.0 in stage 115.0 (TID 191) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.813 Executor task launch worker for task 5.0 in stage 115.0 (TID 190) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.814 Executor task launch worker for task 0.0 in stage 115.0 (TID 185) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.814 Executor task launch worker for task 0.0 in stage 115.0 (TID 185) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.814 Executor task launch worker for task 7.0 in stage 115.0 (TID 192) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.814 Executor task launch worker for task 7.0 in stage 115.0 (TID 192) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.814 Executor task launch worker for task 1.0 in stage 115.0 (TID 186) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.814 Executor task launch worker for task 1.0 in stage 115.0 (TID 186) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.815 Executor task launch worker for task 3.0 in stage 115.0 (TID 188) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.815 Executor task launch worker for task 4.0 in stage 115.0 (TID 189) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:29.816 Executor task launch worker for task 3.0 in stage 115.0 (TID 188) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.816 Executor task launch worker for task 4.0 in stage 115.0 (TID 189) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:29.816 Executor task launch worker for task 7.0 in stage 115.0 (TID 192) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.816 Executor task launch worker for task 1.0 in stage 115.0 (TID 186) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.816 Executor task launch worker for task 5.0 in stage 115.0 (TID 190) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.816 Executor task launch worker for task 0.0 in stage 115.0 (TID 185) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.816 Executor task launch worker for task 6.0 in stage 115.0 (TID 191) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.833 Executor task launch worker for task 4.0 in stage 115.0 (TID 189) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.837 Executor task launch worker for task 3.0 in stage 115.0 (TID 188) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.854 Executor task launch worker for task 7.0 in stage 115.0 (TID 192) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.854 Executor task launch worker for task 5.0 in stage 115.0 (TID 190) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.856 Executor task launch worker for task 2.0 in stage 115.0 (TID 187) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.858 Executor task launch worker for task 6.0 in stage 115.0 (TID 191) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.864 Executor task launch worker for task 0.0 in stage 115.0 (TID 185) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.871 Executor task launch worker for task 1.0 in stage 115.0 (TID 186) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.880 Executor task launch worker for task 2.0 in stage 115.0 (TID 187) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.880 Executor task launch worker for task 4.0 in stage 115.0 (TID 189) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.880 Executor task launch worker for task 3.0 in stage 115.0 (TID 188) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:29.965 Executor task launch worker for task 7.0 in stage 115.0 (TID 192) INFO Executor: Finished task 7.0 in stage 115.0 (TID 192). 4942 bytes result sent to driver
23/10/22 14:57:29.969 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 192) in 172 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:29.987 Executor task launch worker for task 5.0 in stage 115.0 (TID 190) INFO Executor: Finished task 5.0 in stage 115.0 (TID 190). 4942 bytes result sent to driver
23/10/22 14:57:29.989 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 190) in 192 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:30.014 Executor task launch worker for task 6.0 in stage 115.0 (TID 191) INFO Executor: Finished task 6.0 in stage 115.0 (TID 191). 5028 bytes result sent to driver
23/10/22 14:57:30.014 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 191) in 217 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:30.059 Executor task launch worker for task 3.0 in stage 115.0 (TID 188) INFO Executor: Finished task 3.0 in stage 115.0 (TID 188). 4985 bytes result sent to driver
23/10/22 14:57:30.060 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 188) in 263 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:30.071 Executor task launch worker for task 0.0 in stage 115.0 (TID 185) INFO Executor: Finished task 0.0 in stage 115.0 (TID 185). 4942 bytes result sent to driver
23/10/22 14:57:30.072 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 185) in 275 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:30.081 Executor task launch worker for task 4.0 in stage 115.0 (TID 189) INFO Executor: Finished task 4.0 in stage 115.0 (TID 189). 4942 bytes result sent to driver
23/10/22 14:57:30.082 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 189) in 284 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:30.090 Executor task launch worker for task 2.0 in stage 115.0 (TID 187) INFO Executor: Finished task 2.0 in stage 115.0 (TID 187). 4985 bytes result sent to driver
23/10/22 14:57:30.091 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 187) in 294 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:30.098 Executor task launch worker for task 1.0 in stage 115.0 (TID 186) INFO Executor: Finished task 1.0 in stage 115.0 (TID 186). 4985 bytes result sent to driver
23/10/22 14:57:30.099 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 186) in 302 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:30.099 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
23/10/22 14:57:30.100 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 115 (rdd at LinearRegression.scala:348) finished in 0.302 s
23/10/22 14:57:30.100 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:30.100 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:30.100 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:30.100 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:30.106 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(36), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:30.156 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 40.4164 ms
23/10/22 14:57:30.180 nioEventLoopGroup-2-2 WARN Instrumentation: [4eca27bf] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 14:57:30.222 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:30.230 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 14:57:30.230 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 249 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 37
23/10/22 14:57:30.230 dag-scheduler-event-loop INFO DAGScheduler: Got job 64 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 14:57:30.230 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 119 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 14:57:30.230 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
23/10/22 14:57:30.230 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 118)
23/10/22 14:57:30.230 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[249] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:30.247 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 93.3 KiB, free 1037.0 MiB)
23/10/22 14:57:30.247 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1037.0 MiB)
23/10/22 14:57:30.247 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:57170 (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 14:57:30.247 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:30.247 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[249] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:30.247 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 118.0 with 8 tasks resource profile 0
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 193) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 194) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 195) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 196) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 197) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 198) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 199) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 200) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:30.247 Executor task launch worker for task 0.0 in stage 118.0 (TID 193) INFO Executor: Running task 0.0 in stage 118.0 (TID 193)
23/10/22 14:57:30.257 Executor task launch worker for task 6.0 in stage 118.0 (TID 199) INFO Executor: Running task 6.0 in stage 118.0 (TID 199)
23/10/22 14:57:30.257 Executor task launch worker for task 7.0 in stage 118.0 (TID 200) INFO Executor: Running task 7.0 in stage 118.0 (TID 200)
23/10/22 14:57:30.257 Executor task launch worker for task 2.0 in stage 118.0 (TID 195) INFO Executor: Running task 2.0 in stage 118.0 (TID 195)
23/10/22 14:57:30.247 Executor task launch worker for task 5.0 in stage 118.0 (TID 198) INFO Executor: Running task 5.0 in stage 118.0 (TID 198)
23/10/22 14:57:30.257 Executor task launch worker for task 3.0 in stage 118.0 (TID 196) INFO Executor: Running task 3.0 in stage 118.0 (TID 196)
23/10/22 14:57:30.247 Executor task launch worker for task 1.0 in stage 118.0 (TID 194) INFO Executor: Running task 1.0 in stage 118.0 (TID 194)
23/10/22 14:57:30.258 Executor task launch worker for task 4.0 in stage 118.0 (TID 197) INFO Executor: Running task 4.0 in stage 118.0 (TID 197)
23/10/22 14:57:30.268 Executor task launch worker for task 7.0 in stage 118.0 (TID 200) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.268 Executor task launch worker for task 0.0 in stage 118.0 (TID 193) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.268 Executor task launch worker for task 2.0 in stage 118.0 (TID 195) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.268 Executor task launch worker for task 7.0 in stage 118.0 (TID 200) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:30.275 Executor task launch worker for task 5.0 in stage 118.0 (TID 198) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.275 Executor task launch worker for task 5.0 in stage 118.0 (TID 198) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:30.276 Executor task launch worker for task 6.0 in stage 118.0 (TID 199) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.276 Executor task launch worker for task 6.0 in stage 118.0 (TID 199) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:30.278 Executor task launch worker for task 4.0 in stage 118.0 (TID 197) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.278 Executor task launch worker for task 1.0 in stage 118.0 (TID 194) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.279 Executor task launch worker for task 4.0 in stage 118.0 (TID 197) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:30.279 Executor task launch worker for task 0.0 in stage 118.0 (TID 193) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
23/10/22 14:57:30.280 Executor task launch worker for task 2.0 in stage 118.0 (TID 195) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
23/10/22 14:57:30.281 Executor task launch worker for task 1.0 in stage 118.0 (TID 194) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 14:57:30.285 Executor task launch worker for task 3.0 in stage 118.0 (TID 196) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.285 Executor task launch worker for task 3.0 in stage 118.0 (TID 196) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:30.298 Executor task launch worker for task 7.0 in stage 118.0 (TID 200) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.298 Executor task launch worker for task 2.0 in stage 118.0 (TID 195) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.313 Executor task launch worker for task 1.0 in stage 118.0 (TID 194) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.313 Executor task launch worker for task 6.0 in stage 118.0 (TID 199) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.338 Executor task launch worker for task 5.0 in stage 118.0 (TID 198) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.338 Executor task launch worker for task 4.0 in stage 118.0 (TID 197) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.338 Executor task launch worker for task 3.0 in stage 118.0 (TID 196) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.349 Executor task launch worker for task 0.0 in stage 118.0 (TID 193) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:30.414 Executor task launch worker for task 6.0 in stage 118.0 (TID 199) INFO Executor: Finished task 6.0 in stage 118.0 (TID 199). 6605 bytes result sent to driver
23/10/22 14:57:30.414 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 199) in 167 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:30.437 Executor task launch worker for task 2.0 in stage 118.0 (TID 195) INFO Executor: Finished task 2.0 in stage 118.0 (TID 195). 6562 bytes result sent to driver
23/10/22 14:57:30.439 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 195) in 191 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:30.450 Executor task launch worker for task 7.0 in stage 118.0 (TID 200) INFO Executor: Finished task 7.0 in stage 118.0 (TID 200). 6562 bytes result sent to driver
23/10/22 14:57:30.452 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 200) in 205 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:30.467 Executor task launch worker for task 4.0 in stage 118.0 (TID 197) INFO Executor: Finished task 4.0 in stage 118.0 (TID 197). 6562 bytes result sent to driver
23/10/22 14:57:30.468 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 197) in 221 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:30.482 Executor task launch worker for task 5.0 in stage 118.0 (TID 198) INFO Executor: Finished task 5.0 in stage 118.0 (TID 198). 6605 bytes result sent to driver
23/10/22 14:57:30.484 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 198) in 237 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:30.489 Executor task launch worker for task 1.0 in stage 118.0 (TID 194) INFO Executor: Finished task 1.0 in stage 118.0 (TID 194). 6605 bytes result sent to driver
23/10/22 14:57:30.489 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 194) in 242 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:30.520 Executor task launch worker for task 0.0 in stage 118.0 (TID 193) INFO Executor: Finished task 0.0 in stage 118.0 (TID 193). 6605 bytes result sent to driver
23/10/22 14:57:30.520 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 193) in 273 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:30.531 Executor task launch worker for task 3.0 in stage 118.0 (TID 196) INFO Executor: Finished task 3.0 in stage 118.0 (TID 196). 6562 bytes result sent to driver
23/10/22 14:57:30.531 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 196) in 284 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:30.531 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
23/10/22 14:57:30.531 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 118 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.301 s
23/10/22 14:57:30.531 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:30.536 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:30.536 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 119)
23/10/22 14:57:30.536 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:30.537 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[251] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:30.539 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 94.4 KiB, free 1036.9 MiB)
23/10/22 14:57:30.546 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 14:57:30.547 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:57170 (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 14:57:30.547 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:30.547 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 119 (MapPartitionsRDD[251] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:30.547 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks resource profile 0
23/10/22 14:57:30.549 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 201) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:30.549 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 202) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:30.549 Executor task launch worker for task 0.0 in stage 119.0 (TID 201) INFO Executor: Running task 0.0 in stage 119.0 (TID 201)
23/10/22 14:57:30.549 Executor task launch worker for task 1.0 in stage 119.0 (TID 202) INFO Executor: Running task 1.0 in stage 119.0 (TID 202)
23/10/22 14:57:30.557 Executor task launch worker for task 1.0 in stage 119.0 (TID 202) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.557 Executor task launch worker for task 0.0 in stage 119.0 (TID 201) INFO ShuffleBlockFetcherIterator: Getting 4 (2.0 KiB) non-empty blocks including 4 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:30.557 Executor task launch worker for task 1.0 in stage 119.0 (TID 202) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:30.562 Executor task launch worker for task 0.0 in stage 119.0 (TID 201) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:30.573 Executor task launch worker for task 1.0 in stage 119.0 (TID 202) INFO Executor: Finished task 1.0 in stage 119.0 (TID 202). 6817 bytes result sent to driver
23/10/22 14:57:30.573 Executor task launch worker for task 0.0 in stage 119.0 (TID 201) INFO Executor: Finished task 0.0 in stage 119.0 (TID 201). 6817 bytes result sent to driver
23/10/22 14:57:30.573 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 202) in 24 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:30.575 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 201) in 26 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:30.575 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
23/10/22 14:57:30.575 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 119 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.038 s
23/10/22 14:57:30.575 dag-scheduler-event-loop INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:30.575 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished
23/10/22 14:57:30.575 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 64 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.336697 s
23/10/22 14:57:30.575 nioEventLoopGroup-2-2 INFO Instrumentation: [4eca27bf] Number of instances: 3785.
23/10/22 14:57:30.748 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 254 (rdd at LinearRegression.scala:921) as input to shuffle 38
23/10/22 14:57:30.748 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 65 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 14:57:30.748 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 120 (rdd at LinearRegression.scala:921)
23/10/22 14:57:30.748 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:30.748 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:30.748 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[254] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:30.764 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 14:57:30.764 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 14:57:30.764 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 14:57:30.764 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:30.764 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[254] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:30.764 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0
23/10/22 14:57:31.197 dispatcher-event-loop-4 WARN TaskSetManager: Stage 120 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:31.197 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 203) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:31.197 Executor task launch worker for task 0.0 in stage 120.0 (TID 203) INFO Executor: Running task 0.0 in stage 120.0 (TID 203)
23/10/22 14:57:31.397 Executor task launch worker for task 0.0 in stage 120.0 (TID 203) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.107 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:57170 in memory (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 14:57:32.109 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:57170 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 14:57:32.396 Executor task launch worker for task 0.0 in stage 120.0 (TID 203) INFO Executor: Finished task 0.0 in stage 120.0 (TID 203). 2147 bytes result sent to driver
23/10/22 14:57:32.397 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 203) in 1633 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:32.397 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
23/10/22 14:57:32.397 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 120 (rdd at LinearRegression.scala:921) finished in 1.649 s
23/10/22 14:57:32.397 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:32.397 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:32.397 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:32.397 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:32.397 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:32.407 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 258 (rdd at LinearRegression.scala:921) as input to shuffle 39
23/10/22 14:57:32.407 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 66 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 14:57:32.407 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 122 (rdd at LinearRegression.scala:921)
23/10/22 14:57:32.407 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
23/10/22 14:57:32.409 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:32.409 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[258] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:32.409 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 14:57:32.413 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:32.413 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:32.414 dag-scheduler-event-loop INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:32.414 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[258] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:32.414 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 122.0 with 8 tasks resource profile 0
23/10/22 14:57:32.414 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 204) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.414 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 205) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.414 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 122.0 (TID 206) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.414 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 122.0 (TID 207) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.414 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 122.0 (TID 208) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.414 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 122.0 (TID 209) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.417 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 122.0 (TID 210) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.417 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 122.0 (TID 211) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.417 Executor task launch worker for task 1.0 in stage 122.0 (TID 205) INFO Executor: Running task 1.0 in stage 122.0 (TID 205)
23/10/22 14:57:32.418 Executor task launch worker for task 3.0 in stage 122.0 (TID 207) INFO Executor: Running task 3.0 in stage 122.0 (TID 207)
23/10/22 14:57:32.417 Executor task launch worker for task 0.0 in stage 122.0 (TID 204) INFO Executor: Running task 0.0 in stage 122.0 (TID 204)
23/10/22 14:57:32.417 Executor task launch worker for task 2.0 in stage 122.0 (TID 206) INFO Executor: Running task 2.0 in stage 122.0 (TID 206)
23/10/22 14:57:32.418 Executor task launch worker for task 7.0 in stage 122.0 (TID 211) INFO Executor: Running task 7.0 in stage 122.0 (TID 211)
23/10/22 14:57:32.418 Executor task launch worker for task 5.0 in stage 122.0 (TID 209) INFO Executor: Running task 5.0 in stage 122.0 (TID 209)
23/10/22 14:57:32.418 Executor task launch worker for task 4.0 in stage 122.0 (TID 208) INFO Executor: Running task 4.0 in stage 122.0 (TID 208)
23/10/22 14:57:32.418 Executor task launch worker for task 6.0 in stage 122.0 (TID 210) INFO Executor: Running task 6.0 in stage 122.0 (TID 210)
23/10/22 14:57:32.422 Executor task launch worker for task 1.0 in stage 122.0 (TID 205) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.422 Executor task launch worker for task 1.0 in stage 122.0 (TID 205) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.422 Executor task launch worker for task 4.0 in stage 122.0 (TID 208) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.422 Executor task launch worker for task 4.0 in stage 122.0 (TID 208) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.422 Executor task launch worker for task 3.0 in stage 122.0 (TID 207) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.423 Executor task launch worker for task 3.0 in stage 122.0 (TID 207) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:32.423 Executor task launch worker for task 5.0 in stage 122.0 (TID 209) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.423 Executor task launch worker for task 5.0 in stage 122.0 (TID 209) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.426 Executor task launch worker for task 7.0 in stage 122.0 (TID 211) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.426 Executor task launch worker for task 7.0 in stage 122.0 (TID 211) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.426 Executor task launch worker for task 2.0 in stage 122.0 (TID 206) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.426 Executor task launch worker for task 2.0 in stage 122.0 (TID 206) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.426 Executor task launch worker for task 0.0 in stage 122.0 (TID 204) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.426 Executor task launch worker for task 0.0 in stage 122.0 (TID 204) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.427 Executor task launch worker for task 6.0 in stage 122.0 (TID 210) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.427 Executor task launch worker for task 6.0 in stage 122.0 (TID 210) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.435 Executor task launch worker for task 4.0 in stage 122.0 (TID 208) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.437 Executor task launch worker for task 1.0 in stage 122.0 (TID 205) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.437 Executor task launch worker for task 7.0 in stage 122.0 (TID 211) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.437 Executor task launch worker for task 2.0 in stage 122.0 (TID 206) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.443 Executor task launch worker for task 6.0 in stage 122.0 (TID 210) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.450 Executor task launch worker for task 5.0 in stage 122.0 (TID 209) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.458 Executor task launch worker for task 0.0 in stage 122.0 (TID 204) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.462 Executor task launch worker for task 4.0 in stage 122.0 (TID 208) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.462 Executor task launch worker for task 7.0 in stage 122.0 (TID 211) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.470 Executor task launch worker for task 1.0 in stage 122.0 (TID 205) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.470 Executor task launch worker for task 3.0 in stage 122.0 (TID 207) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.480 Executor task launch worker for task 2.0 in stage 122.0 (TID 206) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.491 Executor task launch worker for task 6.0 in stage 122.0 (TID 210) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.499 Executor task launch worker for task 5.0 in stage 122.0 (TID 209) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.514 Executor task launch worker for task 0.0 in stage 122.0 (TID 204) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.519 Executor task launch worker for task 3.0 in stage 122.0 (TID 207) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.641 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:32.688 Executor task launch worker for task 7.0 in stage 122.0 (TID 211) INFO Executor: Finished task 7.0 in stage 122.0 (TID 211). 4899 bytes result sent to driver
23/10/22 14:57:32.690 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 122.0 (TID 211) in 273 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:32.698 Executor task launch worker for task 5.0 in stage 122.0 (TID 209) INFO Executor: Finished task 5.0 in stage 122.0 (TID 209). 4899 bytes result sent to driver
23/10/22 14:57:32.699 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 122.0 (TID 209) in 285 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:32.706 Executor task launch worker for task 6.0 in stage 122.0 (TID 210) INFO Executor: Finished task 6.0 in stage 122.0 (TID 210). 4899 bytes result sent to driver
23/10/22 14:57:32.706 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 122.0 (TID 210) in 292 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:32.715 Executor task launch worker for task 4.0 in stage 122.0 (TID 208) INFO Executor: Finished task 4.0 in stage 122.0 (TID 208). 4899 bytes result sent to driver
23/10/22 14:57:32.715 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 122.0 (TID 208) in 301 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:32.723 Executor task launch worker for task 1.0 in stage 122.0 (TID 205) INFO Executor: Finished task 1.0 in stage 122.0 (TID 205). 4899 bytes result sent to driver
23/10/22 14:57:32.723 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 205) in 309 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:32.763 Executor task launch worker for task 2.0 in stage 122.0 (TID 206) INFO Executor: Finished task 2.0 in stage 122.0 (TID 206). 4942 bytes result sent to driver
23/10/22 14:57:32.779 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 122.0 (TID 206) in 365 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:32.780 Executor task launch worker for task 3.0 in stage 122.0 (TID 207) INFO Executor: Finished task 3.0 in stage 122.0 (TID 207). 4899 bytes result sent to driver
23/10/22 14:57:32.780 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 122.0 (TID 207) in 366 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:32.780 Executor task launch worker for task 0.0 in stage 122.0 (TID 204) INFO Executor: Finished task 0.0 in stage 122.0 (TID 204). 4942 bytes result sent to driver
23/10/22 14:57:32.780 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 204) in 366 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:32.780 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
23/10/22 14:57:32.796 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 122 (rdd at LinearRegression.scala:921) finished in 0.387 s
23/10/22 14:57:32.796 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:32.796 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:32.796 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:32.796 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:32.798 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:32.820 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.8341 ms
23/10/22 14:57:32.847 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 268 (treeAggregate at Statistics.scala:58) as input to shuffle 40
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Got job 67 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 126 (treeAggregate at Statistics.scala:58)
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 125)
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 125 (MapPartitionsRDD[268] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 83.8 KiB, free 1037.0 MiB)
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1036.9 MiB)
23/10/22 14:57:32.863 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:57170 (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 125 (MapPartitionsRDD[268] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:32.863 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 125.0 with 8 tasks resource profile 0
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 212) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 213) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 125.0 (TID 214) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 125.0 (TID 215) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 125.0 (TID 216) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 125.0 (TID 217) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 125.0 (TID 218) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 125.0 (TID 219) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:32.863 Executor task launch worker for task 1.0 in stage 125.0 (TID 213) INFO Executor: Running task 1.0 in stage 125.0 (TID 213)
23/10/22 14:57:32.863 Executor task launch worker for task 4.0 in stage 125.0 (TID 216) INFO Executor: Running task 4.0 in stage 125.0 (TID 216)
23/10/22 14:57:32.863 Executor task launch worker for task 6.0 in stage 125.0 (TID 218) INFO Executor: Running task 6.0 in stage 125.0 (TID 218)
23/10/22 14:57:32.876 Executor task launch worker for task 7.0 in stage 125.0 (TID 219) INFO Executor: Running task 7.0 in stage 125.0 (TID 219)
23/10/22 14:57:32.863 Executor task launch worker for task 5.0 in stage 125.0 (TID 217) INFO Executor: Running task 5.0 in stage 125.0 (TID 217)
23/10/22 14:57:32.863 Executor task launch worker for task 0.0 in stage 125.0 (TID 212) INFO Executor: Running task 0.0 in stage 125.0 (TID 212)
23/10/22 14:57:32.863 Executor task launch worker for task 2.0 in stage 125.0 (TID 214) INFO Executor: Running task 2.0 in stage 125.0 (TID 214)
23/10/22 14:57:32.863 Executor task launch worker for task 3.0 in stage 125.0 (TID 215) INFO Executor: Running task 3.0 in stage 125.0 (TID 215)
23/10/22 14:57:32.885 Executor task launch worker for task 7.0 in stage 125.0 (TID 219) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.885 Executor task launch worker for task 0.0 in stage 125.0 (TID 212) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.886 Executor task launch worker for task 7.0 in stage 125.0 (TID 219) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.885 Executor task launch worker for task 1.0 in stage 125.0 (TID 213) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.886 Executor task launch worker for task 1.0 in stage 125.0 (TID 213) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:32.886 Executor task launch worker for task 2.0 in stage 125.0 (TID 214) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.886 Executor task launch worker for task 2.0 in stage 125.0 (TID 214) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.885 Executor task launch worker for task 5.0 in stage 125.0 (TID 217) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.886 Executor task launch worker for task 5.0 in stage 125.0 (TID 217) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:32.886 Executor task launch worker for task 3.0 in stage 125.0 (TID 215) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.887 Executor task launch worker for task 3.0 in stage 125.0 (TID 215) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.887 Executor task launch worker for task 0.0 in stage 125.0 (TID 212) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:32.888 Executor task launch worker for task 6.0 in stage 125.0 (TID 218) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.889 Executor task launch worker for task 6.0 in stage 125.0 (TID 218) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.890 Executor task launch worker for task 4.0 in stage 125.0 (TID 216) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:32.890 Executor task launch worker for task 4.0 in stage 125.0 (TID 216) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:32.904 Executor task launch worker for task 3.0 in stage 125.0 (TID 215) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.905 Executor task launch worker for task 1.0 in stage 125.0 (TID 213) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.905 Executor task launch worker for task 7.0 in stage 125.0 (TID 219) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.906 Executor task launch worker for task 6.0 in stage 125.0 (TID 218) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.907 Executor task launch worker for task 0.0 in stage 125.0 (TID 212) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.914 Executor task launch worker for task 4.0 in stage 125.0 (TID 216) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.920 Executor task launch worker for task 2.0 in stage 125.0 (TID 214) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.933 Executor task launch worker for task 5.0 in stage 125.0 (TID 217) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:32.986 Executor task launch worker for task 6.0 in stage 125.0 (TID 218) INFO Executor: Finished task 6.0 in stage 125.0 (TID 218). 6562 bytes result sent to driver
23/10/22 14:57:32.987 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 125.0 (TID 218) in 124 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:32.997 Executor task launch worker for task 7.0 in stage 125.0 (TID 219) INFO Executor: Finished task 7.0 in stage 125.0 (TID 219). 6605 bytes result sent to driver
23/10/22 14:57:32.998 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 125.0 (TID 219) in 135 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:33.009 Executor task launch worker for task 0.0 in stage 125.0 (TID 212) INFO Executor: Finished task 0.0 in stage 125.0 (TID 212). 6605 bytes result sent to driver
23/10/22 14:57:33.010 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 212) in 147 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:33.019 Executor task launch worker for task 1.0 in stage 125.0 (TID 213) INFO Executor: Finished task 1.0 in stage 125.0 (TID 213). 6605 bytes result sent to driver
23/10/22 14:57:33.021 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 213) in 158 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:33.031 Executor task launch worker for task 4.0 in stage 125.0 (TID 216) INFO Executor: Finished task 4.0 in stage 125.0 (TID 216). 6605 bytes result sent to driver
23/10/22 14:57:33.032 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 125.0 (TID 216) in 169 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:33.041 Executor task launch worker for task 3.0 in stage 125.0 (TID 215) INFO Executor: Finished task 3.0 in stage 125.0 (TID 215). 6605 bytes result sent to driver
23/10/22 14:57:33.042 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 125.0 (TID 215) in 179 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:33.051 Executor task launch worker for task 2.0 in stage 125.0 (TID 214) INFO Executor: Finished task 2.0 in stage 125.0 (TID 214). 6605 bytes result sent to driver
23/10/22 14:57:33.051 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 125.0 (TID 214) in 188 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:33.063 Executor task launch worker for task 5.0 in stage 125.0 (TID 217) INFO Executor: Finished task 5.0 in stage 125.0 (TID 217). 6605 bytes result sent to driver
23/10/22 14:57:33.063 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 125.0 (TID 217) in 200 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:33.063 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
23/10/22 14:57:33.063 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 125 (treeAggregate at Statistics.scala:58) finished in 0.200 s
23/10/22 14:57:33.063 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:33.065 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:33.065 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 126)
23/10/22 14:57:33.065 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:33.066 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[270] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:33.066 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 84.9 KiB, free 1036.8 MiB)
23/10/22 14:57:33.070 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 1036.8 MiB)
23/10/22 14:57:33.070 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:57170 (size: 36.1 KiB, free: 1037.0 MiB)
23/10/22 14:57:33.070 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:33.070 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 126 (MapPartitionsRDD[270] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:33.070 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 126.0 with 2 tasks resource profile 0
23/10/22 14:57:33.070 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 220) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:33.070 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 221) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:33.070 Executor task launch worker for task 1.0 in stage 126.0 (TID 221) INFO Executor: Running task 1.0 in stage 126.0 (TID 221)
23/10/22 14:57:33.070 Executor task launch worker for task 0.0 in stage 126.0 (TID 220) INFO Executor: Running task 0.0 in stage 126.0 (TID 220)
23/10/22 14:57:33.081 Executor task launch worker for task 1.0 in stage 126.0 (TID 221) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:33.081 Executor task launch worker for task 1.0 in stage 126.0 (TID 221) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:33.081 Executor task launch worker for task 0.0 in stage 126.0 (TID 220) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:33.081 Executor task launch worker for task 0.0 in stage 126.0 (TID 220) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:33.081 Executor task launch worker for task 1.0 in stage 126.0 (TID 221) INFO Executor: Finished task 1.0 in stage 126.0 (TID 221). 7587 bytes result sent to driver
23/10/22 14:57:33.081 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 221) in 11 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:33.081 Executor task launch worker for task 0.0 in stage 126.0 (TID 220) INFO Executor: Finished task 0.0 in stage 126.0 (TID 220). 7587 bytes result sent to driver
23/10/22 14:57:33.096 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 220) in 26 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:33.096 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
23/10/22 14:57:33.097 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 126 (treeAggregate at Statistics.scala:58) finished in 0.030 s
23/10/22 14:57:33.097 dag-scheduler-event-loop INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:33.097 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
23/10/22 14:57:33.097 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 67 finished: treeAggregate at Statistics.scala:58, took 0.235678 s
23/10/22 14:57:33.097 nioEventLoopGroup-2-2 INFO Instrumentation: [415f26a8] training finished
23/10/22 14:57:33.613 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO DAGScheduler: Got job 68 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 127 (collect at utils.scala:26)
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[272] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:33.613 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[272] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:33.613 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0
23/10/22 14:57:33.613 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 222) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:33.613 Executor task launch worker for task 0.0 in stage 127.0 (TID 222) INFO Executor: Running task 0.0 in stage 127.0 (TID 222)
23/10/22 14:57:33.630 Executor task launch worker for task 0.0 in stage 127.0 (TID 222) INFO Executor: Finished task 0.0 in stage 127.0 (TID 222). 1370 bytes result sent to driver
23/10/22 14:57:33.630 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 222) in 17 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:33.630 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
23/10/22 14:57:33.630 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 127 (collect at utils.scala:26) finished in 0.017 s
23/10/22 14:57:33.630 dag-scheduler-event-loop INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:33.630 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished
23/10/22 14:57:33.630 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 68 finished: collect at utils.scala:26, took 0.008567 s
23/10/22 14:57:33.913 nioEventLoopGroup-2-2 INFO Instrumentation: [72387099] training finished
23/10/22 14:57:34.013 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Got job 69 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 128 (collect at utils.scala:26)
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[274] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:34.013 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[274] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0
23/10/22 14:57:34.013 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 223) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:34.013 Executor task launch worker for task 0.0 in stage 128.0 (TID 223) INFO Executor: Running task 0.0 in stage 128.0 (TID 223)
23/10/22 14:57:34.013 Executor task launch worker for task 0.0 in stage 128.0 (TID 223) INFO Executor: Finished task 0.0 in stage 128.0 (TID 223). 1284 bytes result sent to driver
23/10/22 14:57:34.013 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 223) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:34.013 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 128 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:34.013 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished
23/10/22 14:57:34.013 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 69 finished: collect at utils.scala:26, took 0.007351 s
23/10/22 14:57:34.603 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:34.604 dag-scheduler-event-loop INFO DAGScheduler: Got job 70 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:34.604 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 129 (collect at utils.scala:26)
23/10/22 14:57:34.604 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:34.604 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:34.604 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[276] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:34.605 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:34.606 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:34.606 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:34.606 dag-scheduler-event-loop INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:34.607 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[276] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:34.607 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
23/10/22 14:57:34.607 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 224) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:34.608 Executor task launch worker for task 0.0 in stage 129.0 (TID 224) INFO Executor: Running task 0.0 in stage 129.0 (TID 224)
23/10/22 14:57:34.609 Executor task launch worker for task 0.0 in stage 129.0 (TID 224) INFO Executor: Finished task 0.0 in stage 129.0 (TID 224). 1284 bytes result sent to driver
23/10/22 14:57:34.610 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 224) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:34.610 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
23/10/22 14:57:34.610 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 129 (collect at utils.scala:26) finished in 0.005 s
23/10/22 14:57:34.610 dag-scheduler-event-loop INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:34.610 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
23/10/22 14:57:34.611 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 70 finished: collect at utils.scala:26, took 0.006851 s
23/10/22 14:57:35.318 nioEventLoopGroup-2-2 INFO Instrumentation: [52e9c5c3] training finished
23/10/22 14:57:35.341 nioEventLoopGroup-2-2 INFO Instrumentation: [3310c8b5] training finished
23/10/22 14:57:35.349 nioEventLoopGroup-2-2 INFO Instrumentation: [56c12338] Stage class: LinearRegression
23/10/22 14:57:35.349 nioEventLoopGroup-2-2 INFO Instrumentation: [56c12338] Stage uid: linear_regression__085d4775_e1da_4aaa_b485_7937b085129c
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 279 (rdd at Instrumentation.scala:62) as input to shuffle 41
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 71 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 130 (rdd at Instrumentation.scala:62)
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[279] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 32.7 KiB, free 1036.7 MiB)
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 14:57:35.381 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[279] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:35.381 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
23/10/22 14:57:35.600 dispatcher-event-loop-5 WARN TaskSetManager: Stage 130 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:35.600 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 225) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:35.601 Executor task launch worker for task 0.0 in stage 130.0 (TID 225) INFO Executor: Running task 0.0 in stage 130.0 (TID 225)
23/10/22 14:57:35.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 14:57:35.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:35.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:57170 in memory (size: 36.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:35.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:57170 in memory (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 14:57:35.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:35.624 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 14:57:35.767 Executor task launch worker for task 0.0 in stage 130.0 (TID 225) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:35.966 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:36.815 Executor task launch worker for task 0.0 in stage 130.0 (TID 225) INFO Executor: Finished task 0.0 in stage 130.0 (TID 225). 2147 bytes result sent to driver
23/10/22 14:57:36.815 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 225) in 1434 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:36.815 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 130 (rdd at Instrumentation.scala:62) finished in 1.434 s
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:36.815 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 283 (rdd at Instrumentation.scala:62) as input to shuffle 42
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 72 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 132 (rdd at Instrumentation.scala:62)
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[283] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 14:57:36.815 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:36.829 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:36.830 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:36.830 dag-scheduler-event-loop INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:36.831 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[283] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:36.831 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 132.0 with 8 tasks resource profile 0
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 226) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 227) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 132.0 (TID 228) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 132.0 (TID 229) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 132.0 (TID 230) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 132.0 (TID 231) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 132.0 (TID 232) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 132.0 (TID 233) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:36.831 Executor task launch worker for task 2.0 in stage 132.0 (TID 228) INFO Executor: Running task 2.0 in stage 132.0 (TID 228)
23/10/22 14:57:36.833 Executor task launch worker for task 3.0 in stage 132.0 (TID 229) INFO Executor: Running task 3.0 in stage 132.0 (TID 229)
23/10/22 14:57:36.833 Executor task launch worker for task 6.0 in stage 132.0 (TID 232) INFO Executor: Running task 6.0 in stage 132.0 (TID 232)
23/10/22 14:57:36.833 Executor task launch worker for task 7.0 in stage 132.0 (TID 233) INFO Executor: Running task 7.0 in stage 132.0 (TID 233)
23/10/22 14:57:36.831 Executor task launch worker for task 0.0 in stage 132.0 (TID 226) INFO Executor: Running task 0.0 in stage 132.0 (TID 226)
23/10/22 14:57:36.831 Executor task launch worker for task 1.0 in stage 132.0 (TID 227) INFO Executor: Running task 1.0 in stage 132.0 (TID 227)
23/10/22 14:57:36.833 Executor task launch worker for task 5.0 in stage 132.0 (TID 231) INFO Executor: Running task 5.0 in stage 132.0 (TID 231)
23/10/22 14:57:36.833 Executor task launch worker for task 4.0 in stage 132.0 (TID 230) INFO Executor: Running task 4.0 in stage 132.0 (TID 230)
23/10/22 14:57:36.833 Executor task launch worker for task 2.0 in stage 132.0 (TID 228) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 2.0 in stage 132.0 (TID 228) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 3.0 in stage 132.0 (TID 229) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 3.0 in stage 132.0 (TID 229) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 4.0 in stage 132.0 (TID 230) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 4.0 in stage 132.0 (TID 230) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 0.0 in stage 132.0 (TID 226) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 0.0 in stage 132.0 (TID 226) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 5.0 in stage 132.0 (TID 231) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 5.0 in stage 132.0 (TID 231) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 6.0 in stage 132.0 (TID 232) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 6.0 in stage 132.0 (TID 232) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 1.0 in stage 132.0 (TID 227) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 1.0 in stage 132.0 (TID 227) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.833 Executor task launch worker for task 7.0 in stage 132.0 (TID 233) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:36.833 Executor task launch worker for task 7.0 in stage 132.0 (TID 233) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:36.849 Executor task launch worker for task 2.0 in stage 132.0 (TID 228) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.849 Executor task launch worker for task 6.0 in stage 132.0 (TID 232) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.849 Executor task launch worker for task 5.0 in stage 132.0 (TID 231) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.850 Executor task launch worker for task 1.0 in stage 132.0 (TID 227) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.868 Executor task launch worker for task 4.0 in stage 132.0 (TID 230) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.868 Executor task launch worker for task 3.0 in stage 132.0 (TID 229) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.872 Executor task launch worker for task 6.0 in stage 132.0 (TID 232) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.874 Executor task launch worker for task 2.0 in stage 132.0 (TID 228) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.881 Executor task launch worker for task 0.0 in stage 132.0 (TID 226) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.886 Executor task launch worker for task 7.0 in stage 132.0 (TID 233) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.896 Executor task launch worker for task 4.0 in stage 132.0 (TID 230) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.898 Executor task launch worker for task 5.0 in stage 132.0 (TID 231) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.898 Executor task launch worker for task 3.0 in stage 132.0 (TID 229) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.913 Executor task launch worker for task 1.0 in stage 132.0 (TID 227) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.930 Executor task launch worker for task 7.0 in stage 132.0 (TID 233) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:36.936 Executor task launch worker for task 0.0 in stage 132.0 (TID 226) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:37.029 Executor task launch worker for task 6.0 in stage 132.0 (TID 232) INFO Executor: Finished task 6.0 in stage 132.0 (TID 232). 4899 bytes result sent to driver
23/10/22 14:57:37.032 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 132.0 (TID 232) in 201 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:37.043 Executor task launch worker for task 2.0 in stage 132.0 (TID 228) INFO Executor: Finished task 2.0 in stage 132.0 (TID 228). 4942 bytes result sent to driver
23/10/22 14:57:37.048 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 132.0 (TID 228) in 217 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:37.065 Executor task launch worker for task 1.0 in stage 132.0 (TID 227) INFO Executor: Finished task 1.0 in stage 132.0 (TID 227). 4942 bytes result sent to driver
23/10/22 14:57:37.066 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 227) in 235 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:37.078 Executor task launch worker for task 4.0 in stage 132.0 (TID 230) INFO Executor: Finished task 4.0 in stage 132.0 (TID 230). 4899 bytes result sent to driver
23/10/22 14:57:37.079 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 132.0 (TID 230) in 248 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:37.084 Executor task launch worker for task 7.0 in stage 132.0 (TID 233) INFO Executor: Finished task 7.0 in stage 132.0 (TID 233). 4899 bytes result sent to driver
23/10/22 14:57:37.085 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 132.0 (TID 233) in 254 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:37.092 Executor task launch worker for task 3.0 in stage 132.0 (TID 229) INFO Executor: Finished task 3.0 in stage 132.0 (TID 229). 4899 bytes result sent to driver
23/10/22 14:57:37.092 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 132.0 (TID 229) in 261 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:37.104 Executor task launch worker for task 0.0 in stage 132.0 (TID 226) INFO Executor: Finished task 0.0 in stage 132.0 (TID 226). 4899 bytes result sent to driver
23/10/22 14:57:37.104 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 226) in 273 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:37.112 Executor task launch worker for task 5.0 in stage 132.0 (TID 231) INFO Executor: Finished task 5.0 in stage 132.0 (TID 231). 4899 bytes result sent to driver
23/10/22 14:57:37.113 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 132.0 (TID 231) in 282 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:37.113 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
23/10/22 14:57:37.113 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 132 (rdd at Instrumentation.scala:62) finished in 0.298 s
23/10/22 14:57:37.113 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:37.113 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:37.113 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:37.115 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:37.121 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(42), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:37.147 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.2923 ms
23/10/22 14:57:37.160 nioEventLoopGroup-2-2 INFO Instrumentation: [56c12338] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 14:57:37.160 nioEventLoopGroup-2-2 INFO Instrumentation: [56c12338] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 14:57:37.162 nioEventLoopGroup-2-2 INFO Instrumentation: [56c12338] {"numFeatures":3}
23/10/22 14:57:37.232 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 292 (rdd at LinearRegression.scala:348) as input to shuffle 43
23/10/22 14:57:37.232 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 73 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 14:57:37.232 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 133 (rdd at LinearRegression.scala:348)
23/10/22 14:57:37.232 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:37.232 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:37.232 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 133 (MapPartitionsRDD[292] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:37.240 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 14:57:37.240 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 14:57:37.240 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:37.242 dag-scheduler-event-loop INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:37.242 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 133 (MapPartitionsRDD[292] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:37.242 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
23/10/22 14:57:37.537 dispatcher-event-loop-7 WARN TaskSetManager: Stage 133 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:37.537 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 234) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:37.537 Executor task launch worker for task 0.0 in stage 133.0 (TID 234) INFO Executor: Running task 0.0 in stage 133.0 (TID 234)
23/10/22 14:57:37.692 Executor task launch worker for task 0.0 in stage 133.0 (TID 234) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:37.832 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:38.658 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:38.680 Executor task launch worker for task 0.0 in stage 133.0 (TID 234) INFO Executor: Finished task 0.0 in stage 133.0 (TID 234). 2104 bytes result sent to driver
23/10/22 14:57:38.680 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 234) in 1438 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:38.680 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 133 (rdd at LinearRegression.scala:348) finished in 1.448 s
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:38.680 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(43), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 296 (rdd at LinearRegression.scala:348) as input to shuffle 44
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 74 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 135 (rdd at LinearRegression.scala:348)
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:38.680 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 135 (MapPartitionsRDD[296] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 14:57:38.696 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 14:57:38.697 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 14:57:38.697 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:38.697 dag-scheduler-event-loop INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:38.697 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 135 (MapPartitionsRDD[296] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:38.697 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 135.0 with 8 tasks resource profile 0
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 235) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 236) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 237) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 238) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 239) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 240) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 241) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 242) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:38.697 Executor task launch worker for task 1.0 in stage 135.0 (TID 236) INFO Executor: Running task 1.0 in stage 135.0 (TID 236)
23/10/22 14:57:38.697 Executor task launch worker for task 3.0 in stage 135.0 (TID 238) INFO Executor: Running task 3.0 in stage 135.0 (TID 238)
23/10/22 14:57:38.700 Executor task launch worker for task 4.0 in stage 135.0 (TID 239) INFO Executor: Running task 4.0 in stage 135.0 (TID 239)
23/10/22 14:57:38.697 Executor task launch worker for task 2.0 in stage 135.0 (TID 237) INFO Executor: Running task 2.0 in stage 135.0 (TID 237)
23/10/22 14:57:38.697 Executor task launch worker for task 0.0 in stage 135.0 (TID 235) INFO Executor: Running task 0.0 in stage 135.0 (TID 235)
23/10/22 14:57:38.700 Executor task launch worker for task 6.0 in stage 135.0 (TID 241) INFO Executor: Running task 6.0 in stage 135.0 (TID 241)
23/10/22 14:57:38.700 Executor task launch worker for task 7.0 in stage 135.0 (TID 242) INFO Executor: Running task 7.0 in stage 135.0 (TID 242)
23/10/22 14:57:38.700 Executor task launch worker for task 5.0 in stage 135.0 (TID 240) INFO Executor: Running task 5.0 in stage 135.0 (TID 240)
23/10/22 14:57:38.704 Executor task launch worker for task 6.0 in stage 135.0 (TID 241) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.704 Executor task launch worker for task 6.0 in stage 135.0 (TID 241) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.704 Executor task launch worker for task 3.0 in stage 135.0 (TID 238) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.704 Executor task launch worker for task 3.0 in stage 135.0 (TID 238) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.705 Executor task launch worker for task 5.0 in stage 135.0 (TID 240) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.705 Executor task launch worker for task 5.0 in stage 135.0 (TID 240) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.706 Executor task launch worker for task 1.0 in stage 135.0 (TID 236) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.706 Executor task launch worker for task 1.0 in stage 135.0 (TID 236) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.706 Executor task launch worker for task 2.0 in stage 135.0 (TID 237) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.706 Executor task launch worker for task 4.0 in stage 135.0 (TID 239) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.706 Executor task launch worker for task 2.0 in stage 135.0 (TID 237) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.706 Executor task launch worker for task 4.0 in stage 135.0 (TID 239) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.706 Executor task launch worker for task 7.0 in stage 135.0 (TID 242) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.706 Executor task launch worker for task 7.0 in stage 135.0 (TID 242) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.706 Executor task launch worker for task 0.0 in stage 135.0 (TID 235) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:38.706 Executor task launch worker for task 0.0 in stage 135.0 (TID 235) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:38.713 Executor task launch worker for task 6.0 in stage 135.0 (TID 241) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.715 Executor task launch worker for task 1.0 in stage 135.0 (TID 236) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.715 Executor task launch worker for task 5.0 in stage 135.0 (TID 240) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.715 Executor task launch worker for task 3.0 in stage 135.0 (TID 238) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.716 Executor task launch worker for task 7.0 in stage 135.0 (TID 242) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.731 Executor task launch worker for task 0.0 in stage 135.0 (TID 235) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.735 Executor task launch worker for task 6.0 in stage 135.0 (TID 241) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.735 Executor task launch worker for task 2.0 in stage 135.0 (TID 237) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.735 Executor task launch worker for task 3.0 in stage 135.0 (TID 238) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.746 Executor task launch worker for task 1.0 in stage 135.0 (TID 236) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.747 Executor task launch worker for task 7.0 in stage 135.0 (TID 242) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.749 Executor task launch worker for task 4.0 in stage 135.0 (TID 239) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.762 Executor task launch worker for task 0.0 in stage 135.0 (TID 235) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.762 Executor task launch worker for task 5.0 in stage 135.0 (TID 240) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.780 Executor task launch worker for task 4.0 in stage 135.0 (TID 239) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.797 Executor task launch worker for task 2.0 in stage 135.0 (TID 237) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:38.856 Executor task launch worker for task 7.0 in stage 135.0 (TID 242) INFO Executor: Finished task 7.0 in stage 135.0 (TID 242). 4899 bytes result sent to driver
23/10/22 14:57:38.857 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 242) in 160 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:38.869 Executor task launch worker for task 3.0 in stage 135.0 (TID 238) INFO Executor: Finished task 3.0 in stage 135.0 (TID 238). 4899 bytes result sent to driver
23/10/22 14:57:38.869 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 238) in 172 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:38.882 Executor task launch worker for task 6.0 in stage 135.0 (TID 241) INFO Executor: Finished task 6.0 in stage 135.0 (TID 241). 4899 bytes result sent to driver
23/10/22 14:57:38.883 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 241) in 186 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:38.889 Executor task launch worker for task 4.0 in stage 135.0 (TID 239) INFO Executor: Finished task 4.0 in stage 135.0 (TID 239). 4899 bytes result sent to driver
23/10/22 14:57:38.890 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 239) in 193 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:38.899 Executor task launch worker for task 5.0 in stage 135.0 (TID 240) INFO Executor: Finished task 5.0 in stage 135.0 (TID 240). 4899 bytes result sent to driver
23/10/22 14:57:38.901 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 240) in 204 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:38.906 Executor task launch worker for task 1.0 in stage 135.0 (TID 236) INFO Executor: Finished task 1.0 in stage 135.0 (TID 236). 4899 bytes result sent to driver
23/10/22 14:57:38.908 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 236) in 211 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:38.916 Executor task launch worker for task 0.0 in stage 135.0 (TID 235) INFO Executor: Finished task 0.0 in stage 135.0 (TID 235). 4899 bytes result sent to driver
23/10/22 14:57:38.916 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 235) in 219 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:38.921 Executor task launch worker for task 2.0 in stage 135.0 (TID 237) INFO Executor: Finished task 2.0 in stage 135.0 (TID 237). 4899 bytes result sent to driver
23/10/22 14:57:38.921 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 237) in 224 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:38.921 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
23/10/22 14:57:38.921 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 135 (rdd at LinearRegression.scala:348) finished in 0.241 s
23/10/22 14:57:38.921 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:38.921 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:38.921 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:38.921 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:38.930 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(44), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:38.975 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 32.2499 ms
23/10/22 14:57:38.989 nioEventLoopGroup-2-2 WARN Instrumentation: [56c12338] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 14:57:39.013 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 305 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 45
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Got job 75 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 139 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 138)
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[305] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 98.9 KiB, free 1036.9 MiB)
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 1036.9 MiB)
23/10/22 14:57:39.013 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:57170 (size: 39.0 KiB, free: 1037.1 MiB)
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[305] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:39.013 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 138.0 with 8 tasks resource profile 0
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 243) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 244) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 138.0 (TID 245) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 138.0 (TID 246) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 138.0 (TID 247) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 138.0 (TID 248) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.013 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 138.0 (TID 249) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.029 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 138.0 (TID 250) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:39.029 Executor task launch worker for task 0.0 in stage 138.0 (TID 243) INFO Executor: Running task 0.0 in stage 138.0 (TID 243)
23/10/22 14:57:39.029 Executor task launch worker for task 1.0 in stage 138.0 (TID 244) INFO Executor: Running task 1.0 in stage 138.0 (TID 244)
23/10/22 14:57:39.029 Executor task launch worker for task 5.0 in stage 138.0 (TID 248) INFO Executor: Running task 5.0 in stage 138.0 (TID 248)
23/10/22 14:57:39.029 Executor task launch worker for task 2.0 in stage 138.0 (TID 245) INFO Executor: Running task 2.0 in stage 138.0 (TID 245)
23/10/22 14:57:39.029 Executor task launch worker for task 4.0 in stage 138.0 (TID 247) INFO Executor: Running task 4.0 in stage 138.0 (TID 247)
23/10/22 14:57:39.029 Executor task launch worker for task 3.0 in stage 138.0 (TID 246) INFO Executor: Running task 3.0 in stage 138.0 (TID 246)
23/10/22 14:57:39.029 Executor task launch worker for task 6.0 in stage 138.0 (TID 249) INFO Executor: Running task 6.0 in stage 138.0 (TID 249)
23/10/22 14:57:39.029 Executor task launch worker for task 7.0 in stage 138.0 (TID 250) INFO Executor: Running task 7.0 in stage 138.0 (TID 250)
23/10/22 14:57:39.048 Executor task launch worker for task 6.0 in stage 138.0 (TID 249) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.049 Executor task launch worker for task 6.0 in stage 138.0 (TID 249) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.048 Executor task launch worker for task 4.0 in stage 138.0 (TID 247) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.049 Executor task launch worker for task 4.0 in stage 138.0 (TID 247) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:39.049 Executor task launch worker for task 5.0 in stage 138.0 (TID 248) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.049 Executor task launch worker for task 5.0 in stage 138.0 (TID 248) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.050 Executor task launch worker for task 3.0 in stage 138.0 (TID 246) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.050 Executor task launch worker for task 3.0 in stage 138.0 (TID 246) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.051 Executor task launch worker for task 7.0 in stage 138.0 (TID 250) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.051 Executor task launch worker for task 7.0 in stage 138.0 (TID 250) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.053 Executor task launch worker for task 1.0 in stage 138.0 (TID 244) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.053 Executor task launch worker for task 1.0 in stage 138.0 (TID 244) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.055 Executor task launch worker for task 2.0 in stage 138.0 (TID 245) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.055 Executor task launch worker for task 2.0 in stage 138.0 (TID 245) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.055 Executor task launch worker for task 0.0 in stage 138.0 (TID 243) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.055 Executor task launch worker for task 0.0 in stage 138.0 (TID 243) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.077 Executor task launch worker for task 6.0 in stage 138.0 (TID 249) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.077 Executor task launch worker for task 4.0 in stage 138.0 (TID 247) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.078 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:39.080 Executor task launch worker for task 7.0 in stage 138.0 (TID 250) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.081 Executor task launch worker for task 1.0 in stage 138.0 (TID 244) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.081 Executor task launch worker for task 3.0 in stage 138.0 (TID 246) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.094 Executor task launch worker for task 5.0 in stage 138.0 (TID 248) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.094 Executor task launch worker for task 0.0 in stage 138.0 (TID 243) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.104 Executor task launch worker for task 2.0 in stage 138.0 (TID 245) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:39.283 Executor task launch worker for task 6.0 in stage 138.0 (TID 249) INFO Executor: Finished task 6.0 in stage 138.0 (TID 249). 6691 bytes result sent to driver
23/10/22 14:57:39.284 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 138.0 (TID 249) in 271 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:39.292 Executor task launch worker for task 4.0 in stage 138.0 (TID 247) INFO Executor: Finished task 4.0 in stage 138.0 (TID 247). 6605 bytes result sent to driver
23/10/22 14:57:39.292 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 138.0 (TID 247) in 279 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:39.302 Executor task launch worker for task 0.0 in stage 138.0 (TID 243) INFO Executor: Finished task 0.0 in stage 138.0 (TID 243). 6648 bytes result sent to driver
23/10/22 14:57:39.303 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 243) in 290 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:39.315 Executor task launch worker for task 2.0 in stage 138.0 (TID 245) INFO Executor: Finished task 2.0 in stage 138.0 (TID 245). 6648 bytes result sent to driver
23/10/22 14:57:39.316 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 138.0 (TID 245) in 302 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:39.325 Executor task launch worker for task 5.0 in stage 138.0 (TID 248) INFO Executor: Finished task 5.0 in stage 138.0 (TID 248). 6648 bytes result sent to driver
23/10/22 14:57:39.325 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 138.0 (TID 248) in 312 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:39.334 Executor task launch worker for task 1.0 in stage 138.0 (TID 244) INFO Executor: Finished task 1.0 in stage 138.0 (TID 244). 6605 bytes result sent to driver
23/10/22 14:57:39.334 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 244) in 321 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:39.334 Executor task launch worker for task 7.0 in stage 138.0 (TID 250) INFO Executor: Finished task 7.0 in stage 138.0 (TID 250). 6605 bytes result sent to driver
23/10/22 14:57:39.334 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 138.0 (TID 250) in 321 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:39.347 Executor task launch worker for task 3.0 in stage 138.0 (TID 246) INFO Executor: Finished task 3.0 in stage 138.0 (TID 246). 6648 bytes result sent to driver
23/10/22 14:57:39.347 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 138.0 (TID 246) in 334 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:39.347 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
23/10/22 14:57:39.347 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 138 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.334 s
23/10/22 14:57:39.347 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:39.347 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:39.347 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 139)
23/10/22 14:57:39.347 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:39.347 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[307] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 14:57:39.362 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 99.9 KiB, free 1036.9 MiB)
23/10/22 14:57:39.364 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 1036.8 MiB)
23/10/22 14:57:39.364 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:57170 (size: 39.5 KiB, free: 1037.1 MiB)
23/10/22 14:57:39.364 dag-scheduler-event-loop INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:39.364 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 139 (MapPartitionsRDD[307] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:39.364 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 139.0 with 2 tasks resource profile 0
23/10/22 14:57:39.364 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 251) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:39.364 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 139.0 (TID 252) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:39.364 Executor task launch worker for task 0.0 in stage 139.0 (TID 251) INFO Executor: Running task 0.0 in stage 139.0 (TID 251)
23/10/22 14:57:39.364 Executor task launch worker for task 1.0 in stage 139.0 (TID 252) INFO Executor: Running task 1.0 in stage 139.0 (TID 252)
23/10/22 14:57:39.379 Executor task launch worker for task 0.0 in stage 139.0 (TID 251) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.379 Executor task launch worker for task 0.0 in stage 139.0 (TID 251) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.380 Executor task launch worker for task 1.0 in stage 139.0 (TID 252) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:39.380 Executor task launch worker for task 1.0 in stage 139.0 (TID 252) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:39.380 Executor task launch worker for task 0.0 in stage 139.0 (TID 251) INFO Executor: Finished task 0.0 in stage 139.0 (TID 251). 6814 bytes result sent to driver
23/10/22 14:57:39.380 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 251) in 16 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:39.380 Executor task launch worker for task 1.0 in stage 139.0 (TID 252) INFO Executor: Finished task 1.0 in stage 139.0 (TID 252). 6814 bytes result sent to driver
23/10/22 14:57:39.380 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 139.0 (TID 252) in 16 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:39.380 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
23/10/22 14:57:39.380 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 139 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.033 s
23/10/22 14:57:39.380 dag-scheduler-event-loop INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:39.380 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished
23/10/22 14:57:39.380 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 75 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.375074 s
23/10/22 14:57:39.380 nioEventLoopGroup-2-2 INFO Instrumentation: [56c12338] Number of instances: 3785.
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 310 (rdd at LinearRegression.scala:921) as input to shuffle 46
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 76 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 140 (rdd at LinearRegression.scala:921)
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[310] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:39.532 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 14:57:39.540 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 14:57:39.540 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 14:57:39.540 dag-scheduler-event-loop INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:39.542 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[310] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:39.542 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0
23/10/22 14:57:39.561 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:40.013 dispatcher-event-loop-4 WARN TaskSetManager: Stage 140 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 14:57:40.013 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 253) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 14:57:40.013 Executor task launch worker for task 0.0 in stage 140.0 (TID 253) INFO Executor: Running task 0.0 in stage 140.0 (TID 253)
23/10/22 14:57:40.196 Executor task launch worker for task 0.0 in stage 140.0 (TID 253) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.130 Executor task launch worker for task 0.0 in stage 140.0 (TID 253) INFO Executor: Finished task 0.0 in stage 140.0 (TID 253). 2061 bytes result sent to driver
23/10/22 14:57:41.130 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 253) in 1588 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:41.130 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
23/10/22 14:57:41.130 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 140 (rdd at LinearRegression.scala:921) finished in 1.598 s
23/10/22 14:57:41.130 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:41.130 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:41.130 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:41.130 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:41.130 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(46), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 314 (rdd at LinearRegression.scala:921) as input to shuffle 47
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 77 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 142 (rdd at LinearRegression.scala:921)
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 141)
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[314] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 37.8 KiB, free 1036.8 MiB)
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1036.8 MiB)
23/10/22 14:57:41.146 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[314] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:41.146 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 142.0 with 8 tasks resource profile 0
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 254) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 142.0 (TID 255) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 142.0 (TID 256) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 142.0 (TID 257) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 142.0 (TID 258) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 142.0 (TID 259) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 142.0 (TID 260) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 142.0 (TID 261) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.146 Executor task launch worker for task 0.0 in stage 142.0 (TID 254) INFO Executor: Running task 0.0 in stage 142.0 (TID 254)
23/10/22 14:57:41.146 Executor task launch worker for task 6.0 in stage 142.0 (TID 260) INFO Executor: Running task 6.0 in stage 142.0 (TID 260)
23/10/22 14:57:41.146 Executor task launch worker for task 2.0 in stage 142.0 (TID 256) INFO Executor: Running task 2.0 in stage 142.0 (TID 256)
23/10/22 14:57:41.146 Executor task launch worker for task 3.0 in stage 142.0 (TID 257) INFO Executor: Running task 3.0 in stage 142.0 (TID 257)
23/10/22 14:57:41.146 Executor task launch worker for task 1.0 in stage 142.0 (TID 255) INFO Executor: Running task 1.0 in stage 142.0 (TID 255)
23/10/22 14:57:41.155 Executor task launch worker for task 7.0 in stage 142.0 (TID 261) INFO Executor: Running task 7.0 in stage 142.0 (TID 261)
23/10/22 14:57:41.155 Executor task launch worker for task 5.0 in stage 142.0 (TID 259) INFO Executor: Running task 5.0 in stage 142.0 (TID 259)
23/10/22 14:57:41.155 Executor task launch worker for task 4.0 in stage 142.0 (TID 258) INFO Executor: Running task 4.0 in stage 142.0 (TID 258)
23/10/22 14:57:41.197 Executor task launch worker for task 7.0 in stage 142.0 (TID 261) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.197 Executor task launch worker for task 0.0 in stage 142.0 (TID 254) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.197 Executor task launch worker for task 7.0 in stage 142.0 (TID 261) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.197 Executor task launch worker for task 0.0 in stage 142.0 (TID 254) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.198 Executor task launch worker for task 6.0 in stage 142.0 (TID 260) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.199 Executor task launch worker for task 6.0 in stage 142.0 (TID 260) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.198 Executor task launch worker for task 3.0 in stage 142.0 (TID 257) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.199 Executor task launch worker for task 4.0 in stage 142.0 (TID 258) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.199 Executor task launch worker for task 3.0 in stage 142.0 (TID 257) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.198 Executor task launch worker for task 5.0 in stage 142.0 (TID 259) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.199 Executor task launch worker for task 4.0 in stage 142.0 (TID 258) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.199 Executor task launch worker for task 5.0 in stage 142.0 (TID 259) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.200 Executor task launch worker for task 2.0 in stage 142.0 (TID 256) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.200 Executor task launch worker for task 2.0 in stage 142.0 (TID 256) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.200 Executor task launch worker for task 1.0 in stage 142.0 (TID 255) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.200 Executor task launch worker for task 1.0 in stage 142.0 (TID 255) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.200 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:57170 in memory (size: 39.0 KiB, free: 1037.1 MiB)
23/10/22 14:57:41.202 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:57170 in memory (size: 39.5 KiB, free: 1037.1 MiB)
23/10/22 14:57:41.234 Executor task launch worker for task 0.0 in stage 142.0 (TID 254) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.234 Executor task launch worker for task 6.0 in stage 142.0 (TID 260) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.236 Executor task launch worker for task 4.0 in stage 142.0 (TID 258) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.237 Executor task launch worker for task 7.0 in stage 142.0 (TID 261) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.245 Executor task launch worker for task 5.0 in stage 142.0 (TID 259) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.245 Executor task launch worker for task 1.0 in stage 142.0 (TID 255) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.234 Executor task launch worker for task 3.0 in stage 142.0 (TID 257) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.252 Executor task launch worker for task 2.0 in stage 142.0 (TID 256) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.261 Executor task launch worker for task 0.0 in stage 142.0 (TID 254) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.264 Executor task launch worker for task 6.0 in stage 142.0 (TID 260) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.266 Executor task launch worker for task 7.0 in stage 142.0 (TID 261) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.270 Executor task launch worker for task 3.0 in stage 142.0 (TID 257) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.270 Executor task launch worker for task 4.0 in stage 142.0 (TID 258) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.280 Executor task launch worker for task 2.0 in stage 142.0 (TID 256) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.307 Executor task launch worker for task 5.0 in stage 142.0 (TID 259) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.324 Executor task launch worker for task 1.0 in stage 142.0 (TID 255) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.402 Executor task launch worker for task 3.0 in stage 142.0 (TID 257) INFO Executor: Finished task 3.0 in stage 142.0 (TID 257). 4942 bytes result sent to driver
23/10/22 14:57:41.404 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 142.0 (TID 257) in 258 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:41.412 Executor task launch worker for task 2.0 in stage 142.0 (TID 256) INFO Executor: Finished task 2.0 in stage 142.0 (TID 256). 4942 bytes result sent to driver
23/10/22 14:57:41.412 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 142.0 (TID 256) in 266 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:41.424 Executor task launch worker for task 7.0 in stage 142.0 (TID 261) INFO Executor: Finished task 7.0 in stage 142.0 (TID 261). 4942 bytes result sent to driver
23/10/22 14:57:41.424 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 142.0 (TID 261) in 278 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:41.433 Executor task launch worker for task 4.0 in stage 142.0 (TID 258) INFO Executor: Finished task 4.0 in stage 142.0 (TID 258). 4942 bytes result sent to driver
23/10/22 14:57:41.434 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 142.0 (TID 258) in 288 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:41.443 Executor task launch worker for task 6.0 in stage 142.0 (TID 260) INFO Executor: Finished task 6.0 in stage 142.0 (TID 260). 4942 bytes result sent to driver
23/10/22 14:57:41.443 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 142.0 (TID 260) in 297 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:41.452 Executor task launch worker for task 5.0 in stage 142.0 (TID 259) INFO Executor: Finished task 5.0 in stage 142.0 (TID 259). 4942 bytes result sent to driver
23/10/22 14:57:41.453 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 142.0 (TID 259) in 307 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:41.462 Executor task launch worker for task 0.0 in stage 142.0 (TID 254) INFO Executor: Finished task 0.0 in stage 142.0 (TID 254). 4942 bytes result sent to driver
23/10/22 14:57:41.464 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 254) in 318 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:41.505 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 14:57:41.514 Executor task launch worker for task 1.0 in stage 142.0 (TID 255) INFO Executor: Finished task 1.0 in stage 142.0 (TID 255). 4942 bytes result sent to driver
23/10/22 14:57:41.514 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 142.0 (TID 255) in 368 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:41.514 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
23/10/22 14:57:41.514 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 142 (rdd at LinearRegression.scala:921) finished in 0.368 s
23/10/22 14:57:41.514 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:41.514 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:41.514 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 14:57:41.514 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:41.514 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(47), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 14:57:41.548 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 23.3798 ms
23/10/22 14:57:41.611 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 14:57:41.612 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 324 (treeAggregate at Statistics.scala:58) as input to shuffle 48
23/10/22 14:57:41.613 dag-scheduler-event-loop INFO DAGScheduler: Got job 78 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 14:57:41.613 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 146 (treeAggregate at Statistics.scala:58)
23/10/22 14:57:41.613 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 145)
23/10/22 14:57:41.613 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 145)
23/10/22 14:57:41.613 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 145 (MapPartitionsRDD[324] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:41.618 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 89.3 KiB, free 1037.0 MiB)
23/10/22 14:57:41.620 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 1037.0 MiB)
23/10/22 14:57:41.620 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:57170 (size: 37.1 KiB, free: 1037.1 MiB)
23/10/22 14:57:41.621 dag-scheduler-event-loop INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:41.621 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 145 (MapPartitionsRDD[324] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 14:57:41.621 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 145.0 with 8 tasks resource profile 0
23/10/22 14:57:41.622 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 262) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.622 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 145.0 (TID 263) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.623 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 145.0 (TID 264) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.623 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 145.0 (TID 265) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.624 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 145.0 (TID 266) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.624 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 145.0 (TID 267) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.624 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 145.0 (TID 268) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.624 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 145.0 (TID 269) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 14:57:41.624 Executor task launch worker for task 1.0 in stage 145.0 (TID 263) INFO Executor: Running task 1.0 in stage 145.0 (TID 263)
23/10/22 14:57:41.624 Executor task launch worker for task 4.0 in stage 145.0 (TID 266) INFO Executor: Running task 4.0 in stage 145.0 (TID 266)
23/10/22 14:57:41.624 Executor task launch worker for task 5.0 in stage 145.0 (TID 267) INFO Executor: Running task 5.0 in stage 145.0 (TID 267)
23/10/22 14:57:41.624 Executor task launch worker for task 2.0 in stage 145.0 (TID 264) INFO Executor: Running task 2.0 in stage 145.0 (TID 264)
23/10/22 14:57:41.624 Executor task launch worker for task 3.0 in stage 145.0 (TID 265) INFO Executor: Running task 3.0 in stage 145.0 (TID 265)
23/10/22 14:57:41.624 Executor task launch worker for task 0.0 in stage 145.0 (TID 262) INFO Executor: Running task 0.0 in stage 145.0 (TID 262)
23/10/22 14:57:41.625 Executor task launch worker for task 7.0 in stage 145.0 (TID 269) INFO Executor: Running task 7.0 in stage 145.0 (TID 269)
23/10/22 14:57:41.625 Executor task launch worker for task 6.0 in stage 145.0 (TID 268) INFO Executor: Running task 6.0 in stage 145.0 (TID 268)
23/10/22 14:57:41.637 Executor task launch worker for task 0.0 in stage 145.0 (TID 262) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.637 Executor task launch worker for task 5.0 in stage 145.0 (TID 267) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.637 Executor task launch worker for task 0.0 in stage 145.0 (TID 262) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.638 Executor task launch worker for task 5.0 in stage 145.0 (TID 267) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.638 Executor task launch worker for task 2.0 in stage 145.0 (TID 264) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.638 Executor task launch worker for task 2.0 in stage 145.0 (TID 264) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.637 Executor task launch worker for task 4.0 in stage 145.0 (TID 266) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.639 Executor task launch worker for task 7.0 in stage 145.0 (TID 269) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.639 Executor task launch worker for task 4.0 in stage 145.0 (TID 266) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 14:57:41.639 Executor task launch worker for task 7.0 in stage 145.0 (TID 269) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.639 Executor task launch worker for task 3.0 in stage 145.0 (TID 265) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.639 Executor task launch worker for task 3.0 in stage 145.0 (TID 265) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.639 Executor task launch worker for task 1.0 in stage 145.0 (TID 263) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.639 Executor task launch worker for task 1.0 in stage 145.0 (TID 263) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.649 Executor task launch worker for task 6.0 in stage 145.0 (TID 268) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.649 Executor task launch worker for task 6.0 in stage 145.0 (TID 268) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.650 Executor task launch worker for task 5.0 in stage 145.0 (TID 267) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.650 Executor task launch worker for task 0.0 in stage 145.0 (TID 262) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.650 Executor task launch worker for task 1.0 in stage 145.0 (TID 263) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.663 Executor task launch worker for task 4.0 in stage 145.0 (TID 266) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.664 Executor task launch worker for task 2.0 in stage 145.0 (TID 264) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.664 Executor task launch worker for task 3.0 in stage 145.0 (TID 265) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.683 Executor task launch worker for task 7.0 in stage 145.0 (TID 269) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.689 Executor task launch worker for task 6.0 in stage 145.0 (TID 268) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 14:57:41.739 Executor task launch worker for task 5.0 in stage 145.0 (TID 267) INFO Executor: Finished task 5.0 in stage 145.0 (TID 267). 6605 bytes result sent to driver
23/10/22 14:57:41.739 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 145.0 (TID 267) in 115 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 14:57:41.748 Executor task launch worker for task 0.0 in stage 145.0 (TID 262) INFO Executor: Finished task 0.0 in stage 145.0 (TID 262). 6605 bytes result sent to driver
23/10/22 14:57:41.754 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 262) in 132 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 14:57:41.763 Executor task launch worker for task 1.0 in stage 145.0 (TID 263) INFO Executor: Finished task 1.0 in stage 145.0 (TID 263). 6562 bytes result sent to driver
23/10/22 14:57:41.766 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 145.0 (TID 263) in 144 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 14:57:41.775 Executor task launch worker for task 3.0 in stage 145.0 (TID 265) INFO Executor: Finished task 3.0 in stage 145.0 (TID 265). 6605 bytes result sent to driver
23/10/22 14:57:41.775 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 145.0 (TID 265) in 152 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 14:57:41.819 Executor task launch worker for task 2.0 in stage 145.0 (TID 264) INFO Executor: Finished task 2.0 in stage 145.0 (TID 264). 6605 bytes result sent to driver
23/10/22 14:57:41.819 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 145.0 (TID 264) in 197 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 14:57:41.834 Executor task launch worker for task 4.0 in stage 145.0 (TID 266) INFO Executor: Finished task 4.0 in stage 145.0 (TID 266). 6605 bytes result sent to driver
23/10/22 14:57:41.834 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 145.0 (TID 266) in 211 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 14:57:41.857 Executor task launch worker for task 6.0 in stage 145.0 (TID 268) INFO Executor: Finished task 6.0 in stage 145.0 (TID 268). 6605 bytes result sent to driver
23/10/22 14:57:41.859 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 145.0 (TID 268) in 235 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 14:57:41.870 Executor task launch worker for task 7.0 in stage 145.0 (TID 269) INFO Executor: Finished task 7.0 in stage 145.0 (TID 269). 6605 bytes result sent to driver
23/10/22 14:57:41.870 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 145.0 (TID 269) in 246 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 14:57:41.870 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
23/10/22 14:57:41.870 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 145 (treeAggregate at Statistics.scala:58) finished in 0.255 s
23/10/22 14:57:41.870 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 14:57:41.870 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 14:57:41.870 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 146)
23/10/22 14:57:41.870 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 14:57:41.870 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[326] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 14:57:41.879 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 90.4 KiB, free 1036.9 MiB)
23/10/22 14:57:41.880 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 14:57:41.880 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:57170 (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 14:57:41.880 dag-scheduler-event-loop INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:41.880 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 146 (MapPartitionsRDD[326] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 14:57:41.880 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 146.0 with 2 tasks resource profile 0
23/10/22 14:57:41.880 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 270) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:41.880 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 271) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 14:57:41.880 Executor task launch worker for task 0.0 in stage 146.0 (TID 270) INFO Executor: Running task 0.0 in stage 146.0 (TID 270)
23/10/22 14:57:41.880 Executor task launch worker for task 1.0 in stage 146.0 (TID 271) INFO Executor: Running task 1.0 in stage 146.0 (TID 271)
23/10/22 14:57:41.900 Executor task launch worker for task 1.0 in stage 146.0 (TID 271) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.900 Executor task launch worker for task 1.0 in stage 146.0 (TID 271) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.900 Executor task launch worker for task 0.0 in stage 146.0 (TID 270) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 14:57:41.900 Executor task launch worker for task 0.0 in stage 146.0 (TID 270) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 14:57:41.909 Executor task launch worker for task 0.0 in stage 146.0 (TID 270) INFO Executor: Finished task 0.0 in stage 146.0 (TID 270). 7630 bytes result sent to driver
23/10/22 14:57:41.909 Executor task launch worker for task 1.0 in stage 146.0 (TID 271) INFO Executor: Finished task 1.0 in stage 146.0 (TID 271). 7587 bytes result sent to driver
23/10/22 14:57:41.909 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 271) in 29 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 14:57:41.912 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 270) in 32 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 14:57:41.912 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
23/10/22 14:57:41.913 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 146 (treeAggregate at Statistics.scala:58) finished in 0.042 s
23/10/22 14:57:41.913 dag-scheduler-event-loop INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:41.913 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished
23/10/22 14:57:41.913 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 78 finished: treeAggregate at Statistics.scala:58, took 0.302639 s
23/10/22 14:57:41.914 nioEventLoopGroup-2-2 INFO Instrumentation: [48366a6e] training finished
23/10/22 14:57:42.629 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Got job 79 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:26)
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[328] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:42.630 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[328] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0
23/10/22 14:57:42.630 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 272) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:42.630 Executor task launch worker for task 0.0 in stage 147.0 (TID 272) INFO Executor: Running task 0.0 in stage 147.0 (TID 272)
23/10/22 14:57:42.630 Executor task launch worker for task 0.0 in stage 147.0 (TID 272) INFO Executor: Finished task 0.0 in stage 147.0 (TID 272). 1284 bytes result sent to driver
23/10/22 14:57:42.630 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 272) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:42.630 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 147 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:42.630 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished
23/10/22 14:57:42.630 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 79 finished: collect at utils.scala:26, took 0.007955 s
23/10/22 14:57:42.913 nioEventLoopGroup-2-2 INFO Instrumentation: [46693493] training finished
23/10/22 14:57:43.013 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:43.014 dag-scheduler-event-loop INFO DAGScheduler: Got job 80 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:43.014 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 148 (collect at utils.scala:26)
23/10/22 14:57:43.014 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:43.014 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:43.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[330] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:43.015 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:43.016 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:43.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:43.016 dag-scheduler-event-loop INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:43.017 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[330] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:43.017 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0
23/10/22 14:57:43.017 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 273) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:43.018 Executor task launch worker for task 0.0 in stage 148.0 (TID 273) INFO Executor: Running task 0.0 in stage 148.0 (TID 273)
23/10/22 14:57:43.019 Executor task launch worker for task 0.0 in stage 148.0 (TID 273) INFO Executor: Finished task 0.0 in stage 148.0 (TID 273). 1284 bytes result sent to driver
23/10/22 14:57:43.020 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 273) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:43.020 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
23/10/22 14:57:43.020 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 148 (collect at utils.scala:26) finished in 0.006 s
23/10/22 14:57:43.020 dag-scheduler-event-loop INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:43.020 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 148: Stage finished
23/10/22 14:57:43.021 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 80 finished: collect at utils.scala:26, took 0.007033 s
23/10/22 14:57:43.513 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Got job 81 (collect at utils.scala:26) with 1 output partitions
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 149 (collect at utils.scala:26)
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[332] at collect at utils.scala:26), which has no missing parents
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 14:57:43.513 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1535
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[332] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks resource profile 0
23/10/22 14:57:43.513 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 274) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 14:57:43.513 Executor task launch worker for task 0.0 in stage 149.0 (TID 274) INFO Executor: Running task 0.0 in stage 149.0 (TID 274)
23/10/22 14:57:43.513 Executor task launch worker for task 0.0 in stage 149.0 (TID 274) INFO Executor: Finished task 0.0 in stage 149.0 (TID 274). 1284 bytes result sent to driver
23/10/22 14:57:43.513 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 274) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 14:57:43.513 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 149 (collect at utils.scala:26) finished in 0.000 s
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 14:57:43.513 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished
23/10/22 14:57:43.513 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 81 finished: collect at utils.scala:26, took 0.006160 s
23/10/22 15:01:12.490 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:12.490 dag-scheduler-event-loop INFO DAGScheduler: Got job 82 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:12.490 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 150 (collect at utils.scala:26)
23/10/22 15:01:12.490 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:12.491 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:12.491 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[334] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:12.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 7.3 KiB, free 1036.8 MiB)
23/10/22 15:01:12.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:12.493 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:12.493 dag-scheduler-event-loop INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:12.493 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[334] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:12.493 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0
23/10/22 15:01:12.494 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 275) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:12.495 Executor task launch worker for task 0.0 in stage 150.0 (TID 275) INFO Executor: Running task 0.0 in stage 150.0 (TID 275)
23/10/22 15:01:12.497 Executor task launch worker for task 0.0 in stage 150.0 (TID 275) INFO Executor: Finished task 0.0 in stage 150.0 (TID 275). 1327 bytes result sent to driver
23/10/22 15:01:12.498 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 275) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:12.498 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
23/10/22 15:01:12.498 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 150 (collect at utils.scala:26) finished in 0.007 s
23/10/22 15:01:12.498 dag-scheduler-event-loop INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:12.498 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished
23/10/22 15:01:12.498 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 82 finished: collect at utils.scala:26, took 0.008361 s
23/10/22 15:01:12.609 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Got job 83 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 151 (collect at utils.scala:26)
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[336] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 7.3 KiB, free 1036.8 MiB)
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:12.609 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[336] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks resource profile 0
23/10/22 15:01:12.609 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 276) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:12.609 Executor task launch worker for task 0.0 in stage 151.0 (TID 276) INFO Executor: Running task 0.0 in stage 151.0 (TID 276)
23/10/22 15:01:12.609 Executor task launch worker for task 0.0 in stage 151.0 (TID 276) INFO Executor: Finished task 0.0 in stage 151.0 (TID 276). 1284 bytes result sent to driver
23/10/22 15:01:12.609 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 276) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:12.609 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 151 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:12.609 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished
23/10/22 15:01:12.609 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 83 finished: collect at utils.scala:26, took 0.005422 s
23/10/22 15:01:13.102 nioEventLoopGroup-2-2 INFO Instrumentation: [a0d29075] training finished
23/10/22 15:01:13.109 nioEventLoopGroup-2-2 INFO Instrumentation: [18a3c37a] training finished
23/10/22 15:01:13.109 nioEventLoopGroup-2-2 INFO Instrumentation: [50ac2f9f] Stage class: LinearRegression
23/10/22 15:01:13.109 nioEventLoopGroup-2-2 INFO Instrumentation: [50ac2f9f] Stage uid: linear_regression__6d38553e_8ffc_48fa_8fe0_9eb526938547
23/10/22 15:01:13.126 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 339 (rdd at Instrumentation.scala:62) as input to shuffle 49
23/10/22 15:01:13.126 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 84 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 15:01:13.126 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 152 (rdd at Instrumentation.scala:62)
23/10/22 15:01:13.126 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:13.126 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:13.126 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 152 (MapPartitionsRDD[339] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:13.142 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 15:01:13.143 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 15:01:13.143 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 15:01:13.143 dag-scheduler-event-loop INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:13.143 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 152 (MapPartitionsRDD[339] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:13.143 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks resource profile 0
23/10/22 15:01:13.293 dispatcher-event-loop-3 WARN TaskSetManager: Stage 152 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:13.293 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 277) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:13.293 Executor task launch worker for task 0.0 in stage 152.0 (TID 277) INFO Executor: Running task 0.0 in stage 152.0 (TID 277)
23/10/22 15:01:13.392 Executor task launch worker for task 0.0 in stage 152.0 (TID 277) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:13.450 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:57170 in memory (size: 37.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.450 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.450 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.456 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.460 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.463 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.463 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:57170 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:13.634 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:14.143 Executor task launch worker for task 0.0 in stage 152.0 (TID 277) INFO Executor: Finished task 0.0 in stage 152.0 (TID 277). 2104 bytes result sent to driver
23/10/22 15:01:14.143 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 277) in 1000 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:14.143 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
23/10/22 15:01:14.143 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 152 (rdd at Instrumentation.scala:62) finished in 1.017 s
23/10/22 15:01:14.143 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:14.143 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:14.143 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:14.143 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:14.159 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(49), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 343 (rdd at Instrumentation.scala:62) as input to shuffle 50
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 85 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 154 (rdd at Instrumentation.scala:62)
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[343] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:14.159 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[343] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:14.159 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 154.0 with 8 tasks resource profile 0
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 278) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 279) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 280) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 281) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 282) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 283) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 284) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 285) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:14.159 Executor task launch worker for task 0.0 in stage 154.0 (TID 278) INFO Executor: Running task 0.0 in stage 154.0 (TID 278)
23/10/22 15:01:14.159 Executor task launch worker for task 3.0 in stage 154.0 (TID 281) INFO Executor: Running task 3.0 in stage 154.0 (TID 281)
23/10/22 15:01:14.159 Executor task launch worker for task 1.0 in stage 154.0 (TID 279) INFO Executor: Running task 1.0 in stage 154.0 (TID 279)
23/10/22 15:01:14.159 Executor task launch worker for task 2.0 in stage 154.0 (TID 280) INFO Executor: Running task 2.0 in stage 154.0 (TID 280)
23/10/22 15:01:14.168 Executor task launch worker for task 4.0 in stage 154.0 (TID 282) INFO Executor: Running task 4.0 in stage 154.0 (TID 282)
23/10/22 15:01:14.168 Executor task launch worker for task 7.0 in stage 154.0 (TID 285) INFO Executor: Running task 7.0 in stage 154.0 (TID 285)
23/10/22 15:01:14.168 Executor task launch worker for task 6.0 in stage 154.0 (TID 284) INFO Executor: Running task 6.0 in stage 154.0 (TID 284)
23/10/22 15:01:14.169 Executor task launch worker for task 5.0 in stage 154.0 (TID 283) INFO Executor: Running task 5.0 in stage 154.0 (TID 283)
23/10/22 15:01:14.171 Executor task launch worker for task 3.0 in stage 154.0 (TID 281) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.171 Executor task launch worker for task 2.0 in stage 154.0 (TID 280) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.171 Executor task launch worker for task 4.0 in stage 154.0 (TID 282) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.171 Executor task launch worker for task 3.0 in stage 154.0 (TID 281) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.171 Executor task launch worker for task 2.0 in stage 154.0 (TID 280) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.171 Executor task launch worker for task 7.0 in stage 154.0 (TID 285) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.171 Executor task launch worker for task 7.0 in stage 154.0 (TID 285) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.171 Executor task launch worker for task 0.0 in stage 154.0 (TID 278) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.171 Executor task launch worker for task 4.0 in stage 154.0 (TID 282) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.172 Executor task launch worker for task 1.0 in stage 154.0 (TID 279) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.172 Executor task launch worker for task 0.0 in stage 154.0 (TID 278) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.172 Executor task launch worker for task 1.0 in stage 154.0 (TID 279) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.172 Executor task launch worker for task 5.0 in stage 154.0 (TID 283) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.172 Executor task launch worker for task 5.0 in stage 154.0 (TID 283) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.172 Executor task launch worker for task 6.0 in stage 154.0 (TID 284) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:14.172 Executor task launch worker for task 6.0 in stage 154.0 (TID 284) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:14.180 Executor task launch worker for task 1.0 in stage 154.0 (TID 279) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.180 Executor task launch worker for task 4.0 in stage 154.0 (TID 282) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.180 Executor task launch worker for task 3.0 in stage 154.0 (TID 281) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.181 Executor task launch worker for task 7.0 in stage 154.0 (TID 285) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.180 Executor task launch worker for task 2.0 in stage 154.0 (TID 280) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.182 Executor task launch worker for task 0.0 in stage 154.0 (TID 278) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.182 Executor task launch worker for task 6.0 in stage 154.0 (TID 284) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.187 Executor task launch worker for task 5.0 in stage 154.0 (TID 283) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.197 Executor task launch worker for task 4.0 in stage 154.0 (TID 282) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.197 Executor task launch worker for task 6.0 in stage 154.0 (TID 284) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.197 Executor task launch worker for task 1.0 in stage 154.0 (TID 279) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.197 Executor task launch worker for task 2.0 in stage 154.0 (TID 280) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.209 Executor task launch worker for task 3.0 in stage 154.0 (TID 281) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.210 Executor task launch worker for task 5.0 in stage 154.0 (TID 283) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.210 Executor task launch worker for task 0.0 in stage 154.0 (TID 278) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.225 Executor task launch worker for task 7.0 in stage 154.0 (TID 285) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:14.303 Executor task launch worker for task 4.0 in stage 154.0 (TID 282) INFO Executor: Finished task 4.0 in stage 154.0 (TID 282). 4985 bytes result sent to driver
23/10/22 15:01:14.309 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 282) in 150 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:14.322 Executor task launch worker for task 5.0 in stage 154.0 (TID 283) INFO Executor: Finished task 5.0 in stage 154.0 (TID 283). 4942 bytes result sent to driver
23/10/22 15:01:14.323 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 283) in 164 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:14.330 Executor task launch worker for task 1.0 in stage 154.0 (TID 279) INFO Executor: Finished task 1.0 in stage 154.0 (TID 279). 4942 bytes result sent to driver
23/10/22 15:01:14.330 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 279) in 171 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:14.338 Executor task launch worker for task 3.0 in stage 154.0 (TID 281) INFO Executor: Finished task 3.0 in stage 154.0 (TID 281). 4985 bytes result sent to driver
23/10/22 15:01:14.338 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 281) in 179 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:14.345 Executor task launch worker for task 6.0 in stage 154.0 (TID 284) INFO Executor: Finished task 6.0 in stage 154.0 (TID 284). 4942 bytes result sent to driver
23/10/22 15:01:14.345 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 284) in 186 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:14.350 Executor task launch worker for task 2.0 in stage 154.0 (TID 280) INFO Executor: Finished task 2.0 in stage 154.0 (TID 280). 4985 bytes result sent to driver
23/10/22 15:01:14.350 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 280) in 191 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:14.354 Executor task launch worker for task 7.0 in stage 154.0 (TID 285) INFO Executor: Finished task 7.0 in stage 154.0 (TID 285). 4942 bytes result sent to driver
23/10/22 15:01:14.355 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 285) in 196 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:14.360 Executor task launch worker for task 0.0 in stage 154.0 (TID 278) INFO Executor: Finished task 0.0 in stage 154.0 (TID 278). 4985 bytes result sent to driver
23/10/22 15:01:14.361 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 278) in 202 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:14.361 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
23/10/22 15:01:14.362 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 154 (rdd at Instrumentation.scala:62) finished in 0.203 s
23/10/22 15:01:14.362 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:14.362 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:14.362 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:14.362 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:14.367 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(50), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:14.376 nioEventLoopGroup-2-2 INFO Instrumentation: [50ac2f9f] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 15:01:14.376 nioEventLoopGroup-2-2 INFO Instrumentation: [50ac2f9f] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 15:01:14.376 nioEventLoopGroup-2-2 INFO Instrumentation: [50ac2f9f] {"numFeatures":1}
23/10/22 15:01:14.426 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 352 (rdd at LinearRegression.scala:348) as input to shuffle 51
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 86 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 155 (rdd at LinearRegression.scala:348)
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[352] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 15:01:14.443 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[352] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:14.443 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks resource profile 0
23/10/22 15:01:14.642 dispatcher-event-loop-4 WARN TaskSetManager: Stage 155 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:14.643 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 286) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:14.643 Executor task launch worker for task 0.0 in stage 155.0 (TID 286) INFO Executor: Running task 0.0 in stage 155.0 (TID 286)
23/10/22 15:01:14.726 Executor task launch worker for task 0.0 in stage 155.0 (TID 286) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.276 Executor task launch worker for task 0.0 in stage 155.0 (TID 286) INFO Executor: Finished task 0.0 in stage 155.0 (TID 286). 2061 bytes result sent to driver
23/10/22 15:01:15.276 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 286) in 833 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:15.276 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
23/10/22 15:01:15.276 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 155 (rdd at LinearRegression.scala:348) finished in 0.833 s
23/10/22 15:01:15.276 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:15.276 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:15.276 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:15.276 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:15.285 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(51), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:15.285 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 356 (rdd at LinearRegression.scala:348) as input to shuffle 52
23/10/22 15:01:15.285 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 87 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 15:01:15.285 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 157 (rdd at LinearRegression.scala:348)
23/10/22 15:01:15.285 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 156)
23/10/22 15:01:15.285 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:15.285 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[356] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:15.292 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 15:01:15.293 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:15.293 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:15.293 dag-scheduler-event-loop INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:15.293 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[356] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:15.293 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 157.0 with 8 tasks resource profile 0
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 287) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 288) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 157.0 (TID 289) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 157.0 (TID 290) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 157.0 (TID 291) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 157.0 (TID 292) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 157.0 (TID 293) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 157.0 (TID 294) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.293 Executor task launch worker for task 4.0 in stage 157.0 (TID 291) INFO Executor: Running task 4.0 in stage 157.0 (TID 291)
23/10/22 15:01:15.295 Executor task launch worker for task 6.0 in stage 157.0 (TID 293) INFO Executor: Running task 6.0 in stage 157.0 (TID 293)
23/10/22 15:01:15.293 Executor task launch worker for task 0.0 in stage 157.0 (TID 287) INFO Executor: Running task 0.0 in stage 157.0 (TID 287)
23/10/22 15:01:15.293 Executor task launch worker for task 2.0 in stage 157.0 (TID 289) INFO Executor: Running task 2.0 in stage 157.0 (TID 289)
23/10/22 15:01:15.293 Executor task launch worker for task 1.0 in stage 157.0 (TID 288) INFO Executor: Running task 1.0 in stage 157.0 (TID 288)
23/10/22 15:01:15.293 Executor task launch worker for task 3.0 in stage 157.0 (TID 290) INFO Executor: Running task 3.0 in stage 157.0 (TID 290)
23/10/22 15:01:15.293 Executor task launch worker for task 5.0 in stage 157.0 (TID 292) INFO Executor: Running task 5.0 in stage 157.0 (TID 292)
23/10/22 15:01:15.295 Executor task launch worker for task 7.0 in stage 157.0 (TID 294) INFO Executor: Running task 7.0 in stage 157.0 (TID 294)
23/10/22 15:01:15.299 Executor task launch worker for task 0.0 in stage 157.0 (TID 287) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.299 Executor task launch worker for task 7.0 in stage 157.0 (TID 294) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.299 Executor task launch worker for task 2.0 in stage 157.0 (TID 289) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.300 Executor task launch worker for task 0.0 in stage 157.0 (TID 287) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.299 Executor task launch worker for task 4.0 in stage 157.0 (TID 291) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.300 Executor task launch worker for task 7.0 in stage 157.0 (TID 294) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.299 Executor task launch worker for task 3.0 in stage 157.0 (TID 290) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.300 Executor task launch worker for task 3.0 in stage 157.0 (TID 290) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.300 Executor task launch worker for task 5.0 in stage 157.0 (TID 292) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.300 Executor task launch worker for task 5.0 in stage 157.0 (TID 292) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.300 Executor task launch worker for task 2.0 in stage 157.0 (TID 289) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.300 Executor task launch worker for task 4.0 in stage 157.0 (TID 291) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.300 Executor task launch worker for task 1.0 in stage 157.0 (TID 288) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.300 Executor task launch worker for task 1.0 in stage 157.0 (TID 288) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.300 Executor task launch worker for task 6.0 in stage 157.0 (TID 293) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.300 Executor task launch worker for task 6.0 in stage 157.0 (TID 293) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.309 Executor task launch worker for task 7.0 in stage 157.0 (TID 294) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.309 Executor task launch worker for task 2.0 in stage 157.0 (TID 289) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.309 Executor task launch worker for task 0.0 in stage 157.0 (TID 287) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.309 Executor task launch worker for task 1.0 in stage 157.0 (TID 288) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.310 Executor task launch worker for task 6.0 in stage 157.0 (TID 293) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.309 Executor task launch worker for task 3.0 in stage 157.0 (TID 290) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.309 Executor task launch worker for task 5.0 in stage 157.0 (TID 292) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.353 Executor task launch worker for task 4.0 in stage 157.0 (TID 291) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.385 Executor task launch worker for task 7.0 in stage 157.0 (TID 294) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.392 Executor task launch worker for task 0.0 in stage 157.0 (TID 287) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.393 Executor task launch worker for task 3.0 in stage 157.0 (TID 290) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.393 Executor task launch worker for task 5.0 in stage 157.0 (TID 292) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.394 Executor task launch worker for task 6.0 in stage 157.0 (TID 293) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.396 Executor task launch worker for task 2.0 in stage 157.0 (TID 289) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.396 Executor task launch worker for task 4.0 in stage 157.0 (TID 291) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.396 Executor task launch worker for task 1.0 in stage 157.0 (TID 288) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.489 Executor task launch worker for task 6.0 in stage 157.0 (TID 293) INFO Executor: Finished task 6.0 in stage 157.0 (TID 293). 4942 bytes result sent to driver
23/10/22 15:01:15.491 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 157.0 (TID 293) in 198 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:15.525 Executor task launch worker for task 7.0 in stage 157.0 (TID 294) INFO Executor: Finished task 7.0 in stage 157.0 (TID 294). 4942 bytes result sent to driver
23/10/22 15:01:15.526 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 157.0 (TID 294) in 233 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:15.533 Executor task launch worker for task 0.0 in stage 157.0 (TID 287) INFO Executor: Finished task 0.0 in stage 157.0 (TID 287). 4942 bytes result sent to driver
23/10/22 15:01:15.537 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 287) in 243 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:15.543 Executor task launch worker for task 2.0 in stage 157.0 (TID 289) INFO Executor: Finished task 2.0 in stage 157.0 (TID 289). 4942 bytes result sent to driver
23/10/22 15:01:15.545 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 157.0 (TID 289) in 252 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:15.555 Executor task launch worker for task 4.0 in stage 157.0 (TID 291) INFO Executor: Finished task 4.0 in stage 157.0 (TID 291). 4942 bytes result sent to driver
23/10/22 15:01:15.556 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 157.0 (TID 291) in 263 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:15.568 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:15.573 Executor task launch worker for task 5.0 in stage 157.0 (TID 292) INFO Executor: Finished task 5.0 in stage 157.0 (TID 292). 4942 bytes result sent to driver
23/10/22 15:01:15.573 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 157.0 (TID 292) in 280 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:15.575 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:15.579 Executor task launch worker for task 3.0 in stage 157.0 (TID 290) INFO Executor: Finished task 3.0 in stage 157.0 (TID 290). 4942 bytes result sent to driver
23/10/22 15:01:15.580 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 157.0 (TID 290) in 287 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:15.585 Executor task launch worker for task 1.0 in stage 157.0 (TID 288) INFO Executor: Finished task 1.0 in stage 157.0 (TID 288). 4942 bytes result sent to driver
23/10/22 15:01:15.585 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 288) in 292 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:15.585 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
23/10/22 15:01:15.585 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 157 (rdd at LinearRegression.scala:348) finished in 0.300 s
23/10/22 15:01:15.585 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:15.585 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:15.585 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:15.585 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:15.592 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(52), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:15.610 nioEventLoopGroup-2-2 WARN Instrumentation: [50ac2f9f] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 15:01:15.627 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 15:01:15.627 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 365 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 53
23/10/22 15:01:15.627 dag-scheduler-event-loop INFO DAGScheduler: Got job 88 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 15:01:15.627 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 161 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 15:01:15.627 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)
23/10/22 15:01:15.627 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 160)
23/10/22 15:01:15.627 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 160 (MapPartitionsRDD[365] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:15.636 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 92.1 KiB, free 1037.0 MiB)
23/10/22 15:01:15.636 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 1037.0 MiB)
23/10/22 15:01:15.636 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:57170 (size: 36.5 KiB, free: 1037.1 MiB)
23/10/22 15:01:15.636 dag-scheduler-event-loop INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:15.636 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 160 (MapPartitionsRDD[365] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:15.636 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 160.0 with 8 tasks resource profile 0
23/10/22 15:01:15.642 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 295) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.642 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 160.0 (TID 296) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.642 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 160.0 (TID 297) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.642 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 160.0 (TID 298) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.643 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 160.0 (TID 299) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.643 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 160.0 (TID 300) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.643 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 160.0 (TID 301) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.643 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 160.0 (TID 302) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:15.643 Executor task launch worker for task 2.0 in stage 160.0 (TID 297) INFO Executor: Running task 2.0 in stage 160.0 (TID 297)
23/10/22 15:01:15.643 Executor task launch worker for task 6.0 in stage 160.0 (TID 301) INFO Executor: Running task 6.0 in stage 160.0 (TID 301)
23/10/22 15:01:15.643 Executor task launch worker for task 0.0 in stage 160.0 (TID 295) INFO Executor: Running task 0.0 in stage 160.0 (TID 295)
23/10/22 15:01:15.643 Executor task launch worker for task 3.0 in stage 160.0 (TID 298) INFO Executor: Running task 3.0 in stage 160.0 (TID 298)
23/10/22 15:01:15.643 Executor task launch worker for task 1.0 in stage 160.0 (TID 296) INFO Executor: Running task 1.0 in stage 160.0 (TID 296)
23/10/22 15:01:15.643 Executor task launch worker for task 4.0 in stage 160.0 (TID 299) INFO Executor: Running task 4.0 in stage 160.0 (TID 299)
23/10/22 15:01:15.643 Executor task launch worker for task 5.0 in stage 160.0 (TID 300) INFO Executor: Running task 5.0 in stage 160.0 (TID 300)
23/10/22 15:01:15.643 Executor task launch worker for task 7.0 in stage 160.0 (TID 302) INFO Executor: Running task 7.0 in stage 160.0 (TID 302)
23/10/22 15:01:15.650 Executor task launch worker for task 2.0 in stage 160.0 (TID 297) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.651 Executor task launch worker for task 2.0 in stage 160.0 (TID 297) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.651 Executor task launch worker for task 1.0 in stage 160.0 (TID 296) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.651 Executor task launch worker for task 3.0 in stage 160.0 (TID 298) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.651 Executor task launch worker for task 3.0 in stage 160.0 (TID 298) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.650 Executor task launch worker for task 5.0 in stage 160.0 (TID 300) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.651 Executor task launch worker for task 1.0 in stage 160.0 (TID 296) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.651 Executor task launch worker for task 5.0 in stage 160.0 (TID 300) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.652 Executor task launch worker for task 7.0 in stage 160.0 (TID 302) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.652 Executor task launch worker for task 7.0 in stage 160.0 (TID 302) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.652 Executor task launch worker for task 0.0 in stage 160.0 (TID 295) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.652 Executor task launch worker for task 0.0 in stage 160.0 (TID 295) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.652 Executor task launch worker for task 6.0 in stage 160.0 (TID 301) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.652 Executor task launch worker for task 6.0 in stage 160.0 (TID 301) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.659 Executor task launch worker for task 4.0 in stage 160.0 (TID 299) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.659 Executor task launch worker for task 4.0 in stage 160.0 (TID 299) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.662 Executor task launch worker for task 1.0 in stage 160.0 (TID 296) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.662 Executor task launch worker for task 3.0 in stage 160.0 (TID 298) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.665 Executor task launch worker for task 7.0 in stage 160.0 (TID 302) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.666 Executor task launch worker for task 6.0 in stage 160.0 (TID 301) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.672 Executor task launch worker for task 2.0 in stage 160.0 (TID 297) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.675 Executor task launch worker for task 5.0 in stage 160.0 (TID 300) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.685 Executor task launch worker for task 4.0 in stage 160.0 (TID 299) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.693 Executor task launch worker for task 0.0 in stage 160.0 (TID 295) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:15.715 Executor task launch worker for task 1.0 in stage 160.0 (TID 296) INFO Executor: Finished task 1.0 in stage 160.0 (TID 296). 6605 bytes result sent to driver
23/10/22 15:01:15.715 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 160.0 (TID 296) in 73 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:15.722 Executor task launch worker for task 6.0 in stage 160.0 (TID 301) INFO Executor: Finished task 6.0 in stage 160.0 (TID 301). 6562 bytes result sent to driver
23/10/22 15:01:15.722 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 160.0 (TID 301) in 79 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:15.729 Executor task launch worker for task 5.0 in stage 160.0 (TID 300) INFO Executor: Finished task 5.0 in stage 160.0 (TID 300). 6562 bytes result sent to driver
23/10/22 15:01:15.729 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 160.0 (TID 300) in 86 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:15.735 Executor task launch worker for task 7.0 in stage 160.0 (TID 302) INFO Executor: Finished task 7.0 in stage 160.0 (TID 302). 6605 bytes result sent to driver
23/10/22 15:01:15.735 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 160.0 (TID 302) in 92 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:15.738 Executor task launch worker for task 3.0 in stage 160.0 (TID 298) INFO Executor: Finished task 3.0 in stage 160.0 (TID 298). 6605 bytes result sent to driver
23/10/22 15:01:15.738 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 160.0 (TID 298) in 96 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:15.746 Executor task launch worker for task 4.0 in stage 160.0 (TID 299) INFO Executor: Finished task 4.0 in stage 160.0 (TID 299). 6562 bytes result sent to driver
23/10/22 15:01:15.747 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 160.0 (TID 299) in 104 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:15.750 Executor task launch worker for task 2.0 in stage 160.0 (TID 297) INFO Executor: Finished task 2.0 in stage 160.0 (TID 297). 6605 bytes result sent to driver
23/10/22 15:01:15.750 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 160.0 (TID 297) in 108 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:15.752 Executor task launch worker for task 0.0 in stage 160.0 (TID 295) INFO Executor: Finished task 0.0 in stage 160.0 (TID 295). 6605 bytes result sent to driver
23/10/22 15:01:15.752 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 295) in 116 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:15.752 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
23/10/22 15:01:15.752 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 160 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.116 s
23/10/22 15:01:15.752 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:15.752 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:15.752 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 161)
23/10/22 15:01:15.752 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:15.752 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[367] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:15.760 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 93.2 KiB, free 1036.9 MiB)
23/10/22 15:01:15.760 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 1036.8 MiB)
23/10/22 15:01:15.760 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:57170 (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 15:01:15.760 dag-scheduler-event-loop INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:15.760 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 161 (MapPartitionsRDD[367] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:15.760 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 161.0 with 2 tasks resource profile 0
23/10/22 15:01:15.760 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 303) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:15.760 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 161.0 (TID 304) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:15.760 Executor task launch worker for task 1.0 in stage 161.0 (TID 304) INFO Executor: Running task 1.0 in stage 161.0 (TID 304)
23/10/22 15:01:15.760 Executor task launch worker for task 0.0 in stage 161.0 (TID 303) INFO Executor: Running task 0.0 in stage 161.0 (TID 303)
23/10/22 15:01:15.764 Executor task launch worker for task 1.0 in stage 161.0 (TID 304) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.764 Executor task launch worker for task 0.0 in stage 161.0 (TID 303) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:15.768 Executor task launch worker for task 1.0 in stage 161.0 (TID 304) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.768 Executor task launch worker for task 0.0 in stage 161.0 (TID 303) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:15.768 Executor task launch worker for task 0.0 in stage 161.0 (TID 303) INFO Executor: Finished task 0.0 in stage 161.0 (TID 303). 6699 bytes result sent to driver
23/10/22 15:01:15.768 Executor task launch worker for task 1.0 in stage 161.0 (TID 304) INFO Executor: Finished task 1.0 in stage 161.0 (TID 304). 6699 bytes result sent to driver
23/10/22 15:01:15.773 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 161.0 (TID 304) in 13 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:15.773 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 303) in 13 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:15.773 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
23/10/22 15:01:15.773 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 161 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.021 s
23/10/22 15:01:15.773 dag-scheduler-event-loop INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:15.773 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished
23/10/22 15:01:15.773 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 88 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.140598 s
23/10/22 15:01:15.773 nioEventLoopGroup-2-2 INFO Instrumentation: [50ac2f9f] Number of instances: 3785.
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 370 (rdd at LinearRegression.scala:921) as input to shuffle 54
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 89 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 162 (rdd at LinearRegression.scala:921)
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[370] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 15:01:15.876 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[370] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:15.876 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0
23/10/22 15:01:16.026 dispatcher-event-loop-2 WARN TaskSetManager: Stage 162 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:16.026 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 305) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:16.026 Executor task launch worker for task 0.0 in stage 162.0 (TID 305) INFO Executor: Running task 0.0 in stage 162.0 (TID 305)
23/10/22 15:01:16.129 Executor task launch worker for task 0.0 in stage 162.0 (TID 305) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:57170 in memory (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 15:01:16.355 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:57170 in memory (size: 36.5 KiB, free: 1037.1 MiB)
23/10/22 15:01:16.496 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:16.809 Executor task launch worker for task 0.0 in stage 162.0 (TID 305) INFO Executor: Finished task 0.0 in stage 162.0 (TID 305). 2104 bytes result sent to driver
23/10/22 15:01:16.809 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 305) in 933 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:16.809 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 162 (rdd at LinearRegression.scala:921) finished in 0.933 s
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:16.809 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 374 (rdd at LinearRegression.scala:921) as input to shuffle 55
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 90 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 164 (rdd at LinearRegression.scala:921)
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 163)
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[374] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:16.809 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[374] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:16.809 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 164.0 with 8 tasks resource profile 0
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 306) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 164.0 (TID 307) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 164.0 (TID 308) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 164.0 (TID 309) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 164.0 (TID 310) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 164.0 (TID 311) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 164.0 (TID 312) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 164.0 (TID 313) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:16.809 Executor task launch worker for task 0.0 in stage 164.0 (TID 306) INFO Executor: Running task 0.0 in stage 164.0 (TID 306)
23/10/22 15:01:16.809 Executor task launch worker for task 5.0 in stage 164.0 (TID 311) INFO Executor: Running task 5.0 in stage 164.0 (TID 311)
23/10/22 15:01:16.809 Executor task launch worker for task 3.0 in stage 164.0 (TID 309) INFO Executor: Running task 3.0 in stage 164.0 (TID 309)
23/10/22 15:01:16.822 Executor task launch worker for task 6.0 in stage 164.0 (TID 312) INFO Executor: Running task 6.0 in stage 164.0 (TID 312)
23/10/22 15:01:16.809 Executor task launch worker for task 1.0 in stage 164.0 (TID 307) INFO Executor: Running task 1.0 in stage 164.0 (TID 307)
23/10/22 15:01:16.809 Executor task launch worker for task 4.0 in stage 164.0 (TID 310) INFO Executor: Running task 4.0 in stage 164.0 (TID 310)
23/10/22 15:01:16.809 Executor task launch worker for task 2.0 in stage 164.0 (TID 308) INFO Executor: Running task 2.0 in stage 164.0 (TID 308)
23/10/22 15:01:16.822 Executor task launch worker for task 7.0 in stage 164.0 (TID 313) INFO Executor: Running task 7.0 in stage 164.0 (TID 313)
23/10/22 15:01:16.825 Executor task launch worker for task 0.0 in stage 164.0 (TID 306) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.826 Executor task launch worker for task 0.0 in stage 164.0 (TID 306) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.826 Executor task launch worker for task 4.0 in stage 164.0 (TID 310) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.826 Executor task launch worker for task 2.0 in stage 164.0 (TID 308) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.825 Executor task launch worker for task 3.0 in stage 164.0 (TID 309) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.825 Executor task launch worker for task 6.0 in stage 164.0 (TID 312) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.826 Executor task launch worker for task 2.0 in stage 164.0 (TID 308) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.826 Executor task launch worker for task 3.0 in stage 164.0 (TID 309) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.825 Executor task launch worker for task 5.0 in stage 164.0 (TID 311) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.826 Executor task launch worker for task 6.0 in stage 164.0 (TID 312) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.826 Executor task launch worker for task 4.0 in stage 164.0 (TID 310) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.826 Executor task launch worker for task 7.0 in stage 164.0 (TID 313) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.827 Executor task launch worker for task 5.0 in stage 164.0 (TID 311) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.827 Executor task launch worker for task 7.0 in stage 164.0 (TID 313) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.828 Executor task launch worker for task 1.0 in stage 164.0 (TID 307) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:16.828 Executor task launch worker for task 1.0 in stage 164.0 (TID 307) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:16.830 Executor task launch worker for task 7.0 in stage 164.0 (TID 313) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.830 Executor task launch worker for task 1.0 in stage 164.0 (TID 307) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.836 Executor task launch worker for task 5.0 in stage 164.0 (TID 311) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.837 Executor task launch worker for task 2.0 in stage 164.0 (TID 308) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.837 Executor task launch worker for task 6.0 in stage 164.0 (TID 312) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.837 Executor task launch worker for task 0.0 in stage 164.0 (TID 306) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.837 Executor task launch worker for task 4.0 in stage 164.0 (TID 310) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.845 Executor task launch worker for task 3.0 in stage 164.0 (TID 309) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.859 Executor task launch worker for task 5.0 in stage 164.0 (TID 311) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.860 Executor task launch worker for task 7.0 in stage 164.0 (TID 313) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.860 Executor task launch worker for task 2.0 in stage 164.0 (TID 308) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.860 Executor task launch worker for task 1.0 in stage 164.0 (TID 307) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.860 Executor task launch worker for task 0.0 in stage 164.0 (TID 306) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.860 Executor task launch worker for task 6.0 in stage 164.0 (TID 312) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.880 Executor task launch worker for task 4.0 in stage 164.0 (TID 310) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.912 Executor task launch worker for task 3.0 in stage 164.0 (TID 309) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:16.957 Executor task launch worker for task 5.0 in stage 164.0 (TID 311) INFO Executor: Finished task 5.0 in stage 164.0 (TID 311). 4899 bytes result sent to driver
23/10/22 15:01:16.960 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 164.0 (TID 311) in 151 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:16.967 Executor task launch worker for task 1.0 in stage 164.0 (TID 307) INFO Executor: Finished task 1.0 in stage 164.0 (TID 307). 4899 bytes result sent to driver
23/10/22 15:01:16.969 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 164.0 (TID 307) in 160 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:16.977 Executor task launch worker for task 7.0 in stage 164.0 (TID 313) INFO Executor: Finished task 7.0 in stage 164.0 (TID 313). 4899 bytes result sent to driver
23/10/22 15:01:16.977 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 164.0 (TID 313) in 168 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:16.993 Executor task launch worker for task 4.0 in stage 164.0 (TID 310) INFO Executor: Finished task 4.0 in stage 164.0 (TID 310). 4899 bytes result sent to driver
23/10/22 15:01:16.995 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 164.0 (TID 310) in 186 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:17.000 Executor task launch worker for task 2.0 in stage 164.0 (TID 308) INFO Executor: Finished task 2.0 in stage 164.0 (TID 308). 4942 bytes result sent to driver
23/10/22 15:01:17.000 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 164.0 (TID 308) in 191 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:17.005 Executor task launch worker for task 0.0 in stage 164.0 (TID 306) INFO Executor: Finished task 0.0 in stage 164.0 (TID 306). 4942 bytes result sent to driver
23/10/22 15:01:17.005 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 306) in 196 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:17.010 Executor task launch worker for task 3.0 in stage 164.0 (TID 309) INFO Executor: Finished task 3.0 in stage 164.0 (TID 309). 4899 bytes result sent to driver
23/10/22 15:01:17.010 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 164.0 (TID 309) in 201 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:17.012 Executor task launch worker for task 6.0 in stage 164.0 (TID 312) INFO Executor: Finished task 6.0 in stage 164.0 (TID 312). 4899 bytes result sent to driver
23/10/22 15:01:17.012 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 164.0 (TID 312) in 203 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:17.012 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
23/10/22 15:01:17.012 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 164 (rdd at LinearRegression.scala:921) finished in 0.203 s
23/10/22 15:01:17.012 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:17.012 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:17.012 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:17.012 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:17.012 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:17.043 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 384 (treeAggregate at Statistics.scala:58) as input to shuffle 56
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO DAGScheduler: Got job 91 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 168 (treeAggregate at Statistics.scala:58)
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 167)
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 167)
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 167 (MapPartitionsRDD[384] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 82.5 KiB, free 1037.0 MiB)
23/10/22 15:01:17.043 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1036.9 MiB)
23/10/22 15:01:17.058 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:57170 (size: 35.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:17.058 dag-scheduler-event-loop INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:17.058 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 167 (MapPartitionsRDD[384] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:17.058 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 167.0 with 8 tasks resource profile 0
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 314) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 315) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 167.0 (TID 316) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 167.0 (TID 317) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 167.0 (TID 318) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 167.0 (TID 319) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 167.0 (TID 320) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 167.0 (TID 321) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:17.059 Executor task launch worker for task 1.0 in stage 167.0 (TID 315) INFO Executor: Running task 1.0 in stage 167.0 (TID 315)
23/10/22 15:01:17.059 Executor task launch worker for task 3.0 in stage 167.0 (TID 317) INFO Executor: Running task 3.0 in stage 167.0 (TID 317)
23/10/22 15:01:17.059 Executor task launch worker for task 2.0 in stage 167.0 (TID 316) INFO Executor: Running task 2.0 in stage 167.0 (TID 316)
23/10/22 15:01:17.059 Executor task launch worker for task 4.0 in stage 167.0 (TID 318) INFO Executor: Running task 4.0 in stage 167.0 (TID 318)
23/10/22 15:01:17.062 Executor task launch worker for task 6.0 in stage 167.0 (TID 320) INFO Executor: Running task 6.0 in stage 167.0 (TID 320)
23/10/22 15:01:17.059 Executor task launch worker for task 0.0 in stage 167.0 (TID 314) INFO Executor: Running task 0.0 in stage 167.0 (TID 314)
23/10/22 15:01:17.062 Executor task launch worker for task 7.0 in stage 167.0 (TID 321) INFO Executor: Running task 7.0 in stage 167.0 (TID 321)
23/10/22 15:01:17.062 Executor task launch worker for task 5.0 in stage 167.0 (TID 319) INFO Executor: Running task 5.0 in stage 167.0 (TID 319)
23/10/22 15:01:17.068 Executor task launch worker for task 6.0 in stage 167.0 (TID 320) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.069 Executor task launch worker for task 6.0 in stage 167.0 (TID 320) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.069 Executor task launch worker for task 7.0 in stage 167.0 (TID 321) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.069 Executor task launch worker for task 7.0 in stage 167.0 (TID 321) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.070 Executor task launch worker for task 0.0 in stage 167.0 (TID 314) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.071 Executor task launch worker for task 2.0 in stage 167.0 (TID 316) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.071 Executor task launch worker for task 0.0 in stage 167.0 (TID 314) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.071 Executor task launch worker for task 2.0 in stage 167.0 (TID 316) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.068 Executor task launch worker for task 5.0 in stage 167.0 (TID 319) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.071 Executor task launch worker for task 5.0 in stage 167.0 (TID 319) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:17.071 Executor task launch worker for task 1.0 in stage 167.0 (TID 315) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.071 Executor task launch worker for task 1.0 in stage 167.0 (TID 315) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.073 Executor task launch worker for task 4.0 in stage 167.0 (TID 318) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.074 Executor task launch worker for task 4.0 in stage 167.0 (TID 318) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.073 Executor task launch worker for task 3.0 in stage 167.0 (TID 317) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.074 Executor task launch worker for task 3.0 in stage 167.0 (TID 317) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.078 Executor task launch worker for task 5.0 in stage 167.0 (TID 319) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.078 Executor task launch worker for task 6.0 in stage 167.0 (TID 320) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.084 Executor task launch worker for task 7.0 in stage 167.0 (TID 321) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.084 Executor task launch worker for task 1.0 in stage 167.0 (TID 315) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.084 Executor task launch worker for task 4.0 in stage 167.0 (TID 318) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.091 Executor task launch worker for task 2.0 in stage 167.0 (TID 316) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.098 Executor task launch worker for task 3.0 in stage 167.0 (TID 317) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.109 Executor task launch worker for task 0.0 in stage 167.0 (TID 314) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:17.142 Executor task launch worker for task 5.0 in stage 167.0 (TID 319) INFO Executor: Finished task 5.0 in stage 167.0 (TID 319). 6648 bytes result sent to driver
23/10/22 15:01:17.146 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:17.147 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 167.0 (TID 319) in 88 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:17.151 Executor task launch worker for task 4.0 in stage 167.0 (TID 318) INFO Executor: Finished task 4.0 in stage 167.0 (TID 318). 6605 bytes result sent to driver
23/10/22 15:01:17.151 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 167.0 (TID 318) in 92 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:17.163 Executor task launch worker for task 3.0 in stage 167.0 (TID 317) INFO Executor: Finished task 3.0 in stage 167.0 (TID 317). 6691 bytes result sent to driver
23/10/22 15:01:17.163 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 167.0 (TID 317) in 104 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:17.167 Executor task launch worker for task 7.0 in stage 167.0 (TID 321) INFO Executor: Finished task 7.0 in stage 167.0 (TID 321). 6648 bytes result sent to driver
23/10/22 15:01:17.170 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 167.0 (TID 321) in 111 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:17.177 Executor task launch worker for task 6.0 in stage 167.0 (TID 320) INFO Executor: Finished task 6.0 in stage 167.0 (TID 320). 6648 bytes result sent to driver
23/10/22 15:01:17.177 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 167.0 (TID 320) in 118 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:17.185 Executor task launch worker for task 0.0 in stage 167.0 (TID 314) INFO Executor: Finished task 0.0 in stage 167.0 (TID 314). 6605 bytes result sent to driver
23/10/22 15:01:17.185 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 314) in 126 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:17.191 Executor task launch worker for task 1.0 in stage 167.0 (TID 315) INFO Executor: Finished task 1.0 in stage 167.0 (TID 315). 6648 bytes result sent to driver
23/10/22 15:01:17.192 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 315) in 133 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:17.195 Executor task launch worker for task 2.0 in stage 167.0 (TID 316) INFO Executor: Finished task 2.0 in stage 167.0 (TID 316). 6648 bytes result sent to driver
23/10/22 15:01:17.195 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 167.0 (TID 316) in 136 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:17.195 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 167 (treeAggregate at Statistics.scala:58) finished in 0.152 s
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 168)
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[386] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 83.6 KiB, free 1036.9 MiB)
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1036.9 MiB)
23/10/22 15:01:17.195 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:57170 (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 168 (MapPartitionsRDD[386] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:17.195 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 168.0 with 2 tasks resource profile 0
23/10/22 15:01:17.195 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 322) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:17.195 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 168.0 (TID 323) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:17.195 Executor task launch worker for task 0.0 in stage 168.0 (TID 322) INFO Executor: Running task 0.0 in stage 168.0 (TID 322)
23/10/22 15:01:17.195 Executor task launch worker for task 1.0 in stage 168.0 (TID 323) INFO Executor: Running task 1.0 in stage 168.0 (TID 323)
23/10/22 15:01:17.210 Executor task launch worker for task 1.0 in stage 168.0 (TID 323) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.210 Executor task launch worker for task 1.0 in stage 168.0 (TID 323) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.210 Executor task launch worker for task 0.0 in stage 168.0 (TID 322) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:17.210 Executor task launch worker for task 0.0 in stage 168.0 (TID 322) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:17.214 Executor task launch worker for task 0.0 in stage 168.0 (TID 322) INFO Executor: Finished task 0.0 in stage 168.0 (TID 322). 7630 bytes result sent to driver
23/10/22 15:01:17.214 Executor task launch worker for task 1.0 in stage 168.0 (TID 323) INFO Executor: Finished task 1.0 in stage 168.0 (TID 323). 7630 bytes result sent to driver
23/10/22 15:01:17.218 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 322) in 23 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:17.219 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 168.0 (TID 323) in 24 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:17.219 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
23/10/22 15:01:17.219 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 168 (treeAggregate at Statistics.scala:58) finished in 0.024 s
23/10/22 15:01:17.219 dag-scheduler-event-loop INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:17.219 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 168: Stage finished
23/10/22 15:01:17.219 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 91 finished: treeAggregate at Statistics.scala:58, took 0.166742 s
23/10/22 15:01:17.219 nioEventLoopGroup-2-2 INFO Instrumentation: [54af5e61] training finished
23/10/22 15:01:17.312 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:17.492 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Got job 92 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 169 (collect at utils.scala:26)
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[388] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 15:01:17.492 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[388] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 169.0 with 1 tasks resource profile 0
23/10/22 15:01:17.492 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 324) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:17.492 Executor task launch worker for task 0.0 in stage 169.0 (TID 324) INFO Executor: Running task 0.0 in stage 169.0 (TID 324)
23/10/22 15:01:17.492 Executor task launch worker for task 0.0 in stage 169.0 (TID 324) INFO Executor: Finished task 0.0 in stage 169.0 (TID 324). 1284 bytes result sent to driver
23/10/22 15:01:17.492 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 324) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:17.492 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 169 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:17.492 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished
23/10/22 15:01:17.492 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 92 finished: collect at utils.scala:26, took 0.005788 s
23/10/22 15:01:17.659 nioEventLoopGroup-2-2 INFO Instrumentation: [10bde0b0] training finished
23/10/22 15:01:17.726 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Got job 93 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 170 (collect at utils.scala:26)
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[390] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 15:01:17.726 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[390] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0
23/10/22 15:01:17.726 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 325) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:17.726 Executor task launch worker for task 0.0 in stage 170.0 (TID 325) INFO Executor: Running task 0.0 in stage 170.0 (TID 325)
23/10/22 15:01:17.726 Executor task launch worker for task 0.0 in stage 170.0 (TID 325) INFO Executor: Finished task 0.0 in stage 170.0 (TID 325). 1284 bytes result sent to driver
23/10/22 15:01:17.726 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 325) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:17.726 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 170 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:17.726 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 170: Stage finished
23/10/22 15:01:17.726 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 93 finished: collect at utils.scala:26, took 0.005450 s
23/10/22 15:01:18.042 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO DAGScheduler: Got job 94 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 171 (collect at utils.scala:26)
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 171 (MapPartitionsRDD[392] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 15:01:18.042 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (MapPartitionsRDD[392] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:18.042 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 171.0 with 1 tasks resource profile 0
23/10/22 15:01:18.042 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 326) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:18.042 Executor task launch worker for task 0.0 in stage 171.0 (TID 326) INFO Executor: Running task 0.0 in stage 171.0 (TID 326)
23/10/22 15:01:18.059 Executor task launch worker for task 0.0 in stage 171.0 (TID 326) INFO Executor: Finished task 0.0 in stage 171.0 (TID 326). 1327 bytes result sent to driver
23/10/22 15:01:18.059 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 326) in 17 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:18.059 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
23/10/22 15:01:18.059 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 171 (collect at utils.scala:26) finished in 0.017 s
23/10/22 15:01:18.059 dag-scheduler-event-loop INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:18.059 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 171: Stage finished
23/10/22 15:01:18.059 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 94 finished: collect at utils.scala:26, took 0.005762 s
23/10/22 15:01:18.531 nioEventLoopGroup-2-2 INFO Instrumentation: [9a98dead] training finished
23/10/22 15:01:18.543 nioEventLoopGroup-2-2 INFO Instrumentation: [bee0234c] training finished
23/10/22 15:01:18.551 nioEventLoopGroup-2-2 INFO Instrumentation: [f34953d7] Stage class: LinearRegression
23/10/22 15:01:18.551 nioEventLoopGroup-2-2 INFO Instrumentation: [f34953d7] Stage uid: linear_regression__2f89ade9_8014_4a5b_8647_4c7d64d3fbb7
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 395 (rdd at Instrumentation.scala:62) as input to shuffle 57
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 95 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 172 (rdd at Instrumentation.scala:62)
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 172 (MapPartitionsRDD[395] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:18.572 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 15:01:18.574 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 15:01:18.574 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 15:01:18.574 dag-scheduler-event-loop INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:18.574 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 172 (MapPartitionsRDD[395] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:18.574 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0
23/10/22 15:01:18.726 dispatcher-event-loop-0 WARN TaskSetManager: Stage 172 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:18.726 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 327) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:18.726 Executor task launch worker for task 0.0 in stage 172.0 (TID 327) INFO Executor: Running task 0.0 in stage 172.0 (TID 327)
23/10/22 15:01:18.809 Executor task launch worker for task 0.0 in stage 172.0 (TID 327) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.476 Executor task launch worker for task 0.0 in stage 172.0 (TID 327) INFO Executor: Finished task 0.0 in stage 172.0 (TID 327). 2061 bytes result sent to driver
23/10/22 15:01:19.476 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 327) in 902 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:19.476 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 172 (rdd at Instrumentation.scala:62) finished in 0.904 s
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:19.476 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(57), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 399 (rdd at Instrumentation.scala:62) as input to shuffle 58
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 96 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 174 (rdd at Instrumentation.scala:62)
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 173)
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:19.476 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 174 (MapPartitionsRDD[399] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:19.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 37.8 KiB, free 1036.8 MiB)
23/10/22 15:01:19.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1036.8 MiB)
23/10/22 15:01:19.492 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 15:01:19.492 dag-scheduler-event-loop INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:19.492 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 174 (MapPartitionsRDD[399] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:19.492 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 174.0 with 8 tasks resource profile 0
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 328) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 174.0 (TID 329) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 174.0 (TID 330) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 174.0 (TID 331) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 174.0 (TID 332) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 174.0 (TID 333) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 174.0 (TID 334) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 174.0 (TID 335) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:19.492 Executor task launch worker for task 0.0 in stage 174.0 (TID 328) INFO Executor: Running task 0.0 in stage 174.0 (TID 328)
23/10/22 15:01:19.496 Executor task launch worker for task 2.0 in stage 174.0 (TID 330) INFO Executor: Running task 2.0 in stage 174.0 (TID 330)
23/10/22 15:01:19.492 Executor task launch worker for task 3.0 in stage 174.0 (TID 331) INFO Executor: Running task 3.0 in stage 174.0 (TID 331)
23/10/22 15:01:19.492 Executor task launch worker for task 1.0 in stage 174.0 (TID 329) INFO Executor: Running task 1.0 in stage 174.0 (TID 329)
23/10/22 15:01:19.496 Executor task launch worker for task 7.0 in stage 174.0 (TID 335) INFO Executor: Running task 7.0 in stage 174.0 (TID 335)
23/10/22 15:01:19.496 Executor task launch worker for task 6.0 in stage 174.0 (TID 334) INFO Executor: Running task 6.0 in stage 174.0 (TID 334)
23/10/22 15:01:19.496 Executor task launch worker for task 5.0 in stage 174.0 (TID 333) INFO Executor: Running task 5.0 in stage 174.0 (TID 333)
23/10/22 15:01:19.496 Executor task launch worker for task 4.0 in stage 174.0 (TID 332) INFO Executor: Running task 4.0 in stage 174.0 (TID 332)
23/10/22 15:01:19.543 Executor task launch worker for task 1.0 in stage 174.0 (TID 329) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.543 Executor task launch worker for task 4.0 in stage 174.0 (TID 332) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.543 Executor task launch worker for task 2.0 in stage 174.0 (TID 330) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.543 Executor task launch worker for task 3.0 in stage 174.0 (TID 331) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.543 Executor task launch worker for task 7.0 in stage 174.0 (TID 335) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.544 Executor task launch worker for task 3.0 in stage 174.0 (TID 331) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:19.544 Executor task launch worker for task 1.0 in stage 174.0 (TID 329) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:19.544 Executor task launch worker for task 2.0 in stage 174.0 (TID 330) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:19.544 Executor task launch worker for task 7.0 in stage 174.0 (TID 335) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:19.544 Executor task launch worker for task 0.0 in stage 174.0 (TID 328) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.544 Executor task launch worker for task 4.0 in stage 174.0 (TID 332) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:19.544 Executor task launch worker for task 0.0 in stage 174.0 (TID 328) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:19.544 Executor task launch worker for task 6.0 in stage 174.0 (TID 334) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.544 Executor task launch worker for task 6.0 in stage 174.0 (TID 334) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:19.544 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:57170 in memory (size: 35.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.544 Executor task launch worker for task 5.0 in stage 174.0 (TID 333) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:19.544 Executor task launch worker for task 5.0 in stage 174.0 (TID 333) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:19.579 Executor task launch worker for task 3.0 in stage 174.0 (TID 331) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.579 Executor task launch worker for task 6.0 in stage 174.0 (TID 334) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.579 Executor task launch worker for task 1.0 in stage 174.0 (TID 329) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.579 Executor task launch worker for task 2.0 in stage 174.0 (TID 330) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.579 Executor task launch worker for task 0.0 in stage 174.0 (TID 328) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.580 Executor task launch worker for task 7.0 in stage 174.0 (TID 335) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.582 Executor task launch worker for task 5.0 in stage 174.0 (TID 333) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.585 Executor task launch worker for task 4.0 in stage 174.0 (TID 332) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.585 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.596 Executor task launch worker for task 3.0 in stage 174.0 (TID 331) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.596 Executor task launch worker for task 6.0 in stage 174.0 (TID 334) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.603 Executor task launch worker for task 1.0 in stage 174.0 (TID 329) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.605 Executor task launch worker for task 2.0 in stage 174.0 (TID 330) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.606 Executor task launch worker for task 7.0 in stage 174.0 (TID 335) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.607 Executor task launch worker for task 5.0 in stage 174.0 (TID 333) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.608 Executor task launch worker for task 4.0 in stage 174.0 (TID 332) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.612 Executor task launch worker for task 0.0 in stage 174.0 (TID 328) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:19.612 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.732 Executor task launch worker for task 1.0 in stage 174.0 (TID 329) INFO Executor: Finished task 1.0 in stage 174.0 (TID 329). 4942 bytes result sent to driver
23/10/22 15:01:19.734 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 174.0 (TID 329) in 242 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:19.750 Executor task launch worker for task 6.0 in stage 174.0 (TID 334) INFO Executor: Finished task 6.0 in stage 174.0 (TID 334). 4942 bytes result sent to driver
23/10/22 15:01:19.752 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 174.0 (TID 334) in 260 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:19.754 Executor task launch worker for task 2.0 in stage 174.0 (TID 330) INFO Executor: Finished task 2.0 in stage 174.0 (TID 330). 4942 bytes result sent to driver
23/10/22 15:01:19.755 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 174.0 (TID 330) in 263 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:19.762 Executor task launch worker for task 5.0 in stage 174.0 (TID 333) INFO Executor: Finished task 5.0 in stage 174.0 (TID 333). 4942 bytes result sent to driver
23/10/22 15:01:19.763 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 174.0 (TID 333) in 271 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:19.769 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.783 Executor task launch worker for task 3.0 in stage 174.0 (TID 331) INFO Executor: Finished task 3.0 in stage 174.0 (TID 331). 4985 bytes result sent to driver
23/10/22 15:01:19.783 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 174.0 (TID 331) in 291 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:19.789 Executor task launch worker for task 7.0 in stage 174.0 (TID 335) INFO Executor: Finished task 7.0 in stage 174.0 (TID 335). 4942 bytes result sent to driver
23/10/22 15:01:19.791 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 174.0 (TID 335) in 299 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:19.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.802 Executor task launch worker for task 0.0 in stage 174.0 (TID 328) INFO Executor: Finished task 0.0 in stage 174.0 (TID 328). 4942 bytes result sent to driver
23/10/22 15:01:19.802 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 328) in 310 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:19.812 Executor task launch worker for task 4.0 in stage 174.0 (TID 332) INFO Executor: Finished task 4.0 in stage 174.0 (TID 332). 4942 bytes result sent to driver
23/10/22 15:01:19.814 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 174.0 (TID 332) in 322 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:19.815 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
23/10/22 15:01:19.815 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 174 (rdd at Instrumentation.scala:62) finished in 0.323 s
23/10/22 15:01:19.815 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:19.815 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:19.815 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:19.815 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:19.817 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:57170 in memory (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.824 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(58), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:19.853 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.335 ms
23/10/22 15:01:19.863 nioEventLoopGroup-2-2 INFO Instrumentation: [f34953d7] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 15:01:19.864 nioEventLoopGroup-2-2 INFO Instrumentation: [f34953d7] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 15:01:19.865 nioEventLoopGroup-2-2 INFO Instrumentation: [f34953d7] {"numFeatures":1}
23/10/22 15:01:19.918 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 408 (rdd at LinearRegression.scala:348) as input to shuffle 59
23/10/22 15:01:19.918 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 97 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 15:01:19.918 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 175 (rdd at LinearRegression.scala:348)
23/10/22 15:01:19.918 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:19.918 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:19.918 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 175 (MapPartitionsRDD[408] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:19.919 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 15:01:19.920 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 15:01:19.920 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:19.921 dag-scheduler-event-loop INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:19.921 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 175 (MapPartitionsRDD[408] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:19.921 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0
23/10/22 15:01:20.076 dispatcher-event-loop-4 WARN TaskSetManager: Stage 175 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:20.076 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 336) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:20.076 Executor task launch worker for task 0.0 in stage 175.0 (TID 336) INFO Executor: Running task 0.0 in stage 175.0 (TID 336)
23/10/22 15:01:20.171 Executor task launch worker for task 0.0 in stage 175.0 (TID 336) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.839 Executor task launch worker for task 0.0 in stage 175.0 (TID 336) INFO Executor: Finished task 0.0 in stage 175.0 (TID 336). 2147 bytes result sent to driver
23/10/22 15:01:20.839 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 336) in 918 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:20.839 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
23/10/22 15:01:20.840 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 175 (rdd at LinearRegression.scala:348) finished in 0.921 s
23/10/22 15:01:20.840 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:20.840 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:20.840 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:20.840 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:20.843 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(59), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 412 (rdd at LinearRegression.scala:348) as input to shuffle 60
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 98 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 177 (rdd at LinearRegression.scala:348)
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 176)
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 177 (MapPartitionsRDD[412] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:20.843 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 15:01:20.850 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:20.850 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:20.850 dag-scheduler-event-loop INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:20.850 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 177 (MapPartitionsRDD[412] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:20.850 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 177.0 with 8 tasks resource profile 0
23/10/22 15:01:20.850 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 337) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 338) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 339) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 340) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 177.0 (TID 341) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 177.0 (TID 342) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 177.0 (TID 343) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 177.0 (TID 344) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:20.852 Executor task launch worker for task 1.0 in stage 177.0 (TID 338) INFO Executor: Running task 1.0 in stage 177.0 (TID 338)
23/10/22 15:01:20.854 Executor task launch worker for task 5.0 in stage 177.0 (TID 342) INFO Executor: Running task 5.0 in stage 177.0 (TID 342)
23/10/22 15:01:20.852 Executor task launch worker for task 0.0 in stage 177.0 (TID 337) INFO Executor: Running task 0.0 in stage 177.0 (TID 337)
23/10/22 15:01:20.854 Executor task launch worker for task 6.0 in stage 177.0 (TID 343) INFO Executor: Running task 6.0 in stage 177.0 (TID 343)
23/10/22 15:01:20.852 Executor task launch worker for task 2.0 in stage 177.0 (TID 339) INFO Executor: Running task 2.0 in stage 177.0 (TID 339)
23/10/22 15:01:20.854 Executor task launch worker for task 3.0 in stage 177.0 (TID 340) INFO Executor: Running task 3.0 in stage 177.0 (TID 340)
23/10/22 15:01:20.854 Executor task launch worker for task 4.0 in stage 177.0 (TID 341) INFO Executor: Running task 4.0 in stage 177.0 (TID 341)
23/10/22 15:01:20.854 Executor task launch worker for task 7.0 in stage 177.0 (TID 344) INFO Executor: Running task 7.0 in stage 177.0 (TID 344)
23/10/22 15:01:20.854 Executor task launch worker for task 1.0 in stage 177.0 (TID 338) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.854 Executor task launch worker for task 4.0 in stage 177.0 (TID 341) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.858 Executor task launch worker for task 4.0 in stage 177.0 (TID 341) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.858 Executor task launch worker for task 1.0 in stage 177.0 (TID 338) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.854 Executor task launch worker for task 2.0 in stage 177.0 (TID 339) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.858 Executor task launch worker for task 2.0 in stage 177.0 (TID 339) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:20.860 Executor task launch worker for task 0.0 in stage 177.0 (TID 337) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.860 Executor task launch worker for task 0.0 in stage 177.0 (TID 337) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.860 Executor task launch worker for task 3.0 in stage 177.0 (TID 340) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.861 Executor task launch worker for task 3.0 in stage 177.0 (TID 340) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.862 Executor task launch worker for task 5.0 in stage 177.0 (TID 342) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.862 Executor task launch worker for task 5.0 in stage 177.0 (TID 342) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.864 Executor task launch worker for task 6.0 in stage 177.0 (TID 343) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.864 Executor task launch worker for task 6.0 in stage 177.0 (TID 343) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.864 Executor task launch worker for task 7.0 in stage 177.0 (TID 344) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:20.864 Executor task launch worker for task 7.0 in stage 177.0 (TID 344) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:20.875 Executor task launch worker for task 5.0 in stage 177.0 (TID 342) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.875 Executor task launch worker for task 3.0 in stage 177.0 (TID 340) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.875 Executor task launch worker for task 2.0 in stage 177.0 (TID 339) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.878 Executor task launch worker for task 6.0 in stage 177.0 (TID 343) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.893 Executor task launch worker for task 7.0 in stage 177.0 (TID 344) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.906 Executor task launch worker for task 1.0 in stage 177.0 (TID 338) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.906 Executor task launch worker for task 4.0 in stage 177.0 (TID 341) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.917 Executor task launch worker for task 0.0 in stage 177.0 (TID 337) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.930 Executor task launch worker for task 3.0 in stage 177.0 (TID 340) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.931 Executor task launch worker for task 6.0 in stage 177.0 (TID 343) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.935 Executor task launch worker for task 2.0 in stage 177.0 (TID 339) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.935 Executor task launch worker for task 7.0 in stage 177.0 (TID 344) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.948 Executor task launch worker for task 5.0 in stage 177.0 (TID 342) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.964 Executor task launch worker for task 1.0 in stage 177.0 (TID 338) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.967 Executor task launch worker for task 4.0 in stage 177.0 (TID 341) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:20.977 Executor task launch worker for task 0.0 in stage 177.0 (TID 337) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.084 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:21.120 Executor task launch worker for task 3.0 in stage 177.0 (TID 340) INFO Executor: Finished task 3.0 in stage 177.0 (TID 340). 4899 bytes result sent to driver
23/10/22 15:01:21.128 Executor task launch worker for task 2.0 in stage 177.0 (TID 339) INFO Executor: Finished task 2.0 in stage 177.0 (TID 339). 4899 bytes result sent to driver
23/10/22 15:01:21.129 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 340) in 277 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:21.129 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 339) in 277 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:21.136 Executor task launch worker for task 5.0 in stage 177.0 (TID 342) INFO Executor: Finished task 5.0 in stage 177.0 (TID 342). 4899 bytes result sent to driver
23/10/22 15:01:21.137 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 177.0 (TID 342) in 285 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:21.144 Executor task launch worker for task 7.0 in stage 177.0 (TID 344) INFO Executor: Finished task 7.0 in stage 177.0 (TID 344). 4942 bytes result sent to driver
23/10/22 15:01:21.145 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 177.0 (TID 344) in 293 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:21.150 Executor task launch worker for task 6.0 in stage 177.0 (TID 343) INFO Executor: Finished task 6.0 in stage 177.0 (TID 343). 4899 bytes result sent to driver
23/10/22 15:01:21.152 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 177.0 (TID 343) in 300 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:21.156 Executor task launch worker for task 4.0 in stage 177.0 (TID 341) INFO Executor: Finished task 4.0 in stage 177.0 (TID 341). 4899 bytes result sent to driver
23/10/22 15:01:21.156 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 177.0 (TID 341) in 304 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:21.162 Executor task launch worker for task 0.0 in stage 177.0 (TID 337) INFO Executor: Finished task 0.0 in stage 177.0 (TID 337). 4899 bytes result sent to driver
23/10/22 15:01:21.162 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 337) in 312 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:21.162 Executor task launch worker for task 1.0 in stage 177.0 (TID 338) INFO Executor: Finished task 1.0 in stage 177.0 (TID 338). 4899 bytes result sent to driver
23/10/22 15:01:21.162 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 338) in 310 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:21.162 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
23/10/22 15:01:21.162 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 177 (rdd at LinearRegression.scala:348) finished in 0.319 s
23/10/22 15:01:21.162 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:21.162 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:21.162 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:21.162 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:21.162 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(60), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:21.195 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 20.6713 ms
23/10/22 15:01:21.202 nioEventLoopGroup-2-2 WARN Instrumentation: [f34953d7] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 15:01:21.209 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 421 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 61
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Got job 99 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 181 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[421] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 92.6 KiB, free 1037.0 MiB)
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1036.9 MiB)
23/10/22 15:01:21.209 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:57170 (size: 36.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[421] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:21.209 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 180.0 with 8 tasks resource profile 0
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 345) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 346) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 180.0 (TID 347) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 180.0 (TID 348) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 180.0 (TID 349) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 180.0 (TID 350) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.209 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 180.0 (TID 351) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.225 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 180.0 (TID 352) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:21.225 Executor task launch worker for task 2.0 in stage 180.0 (TID 347) INFO Executor: Running task 2.0 in stage 180.0 (TID 347)
23/10/22 15:01:21.225 Executor task launch worker for task 1.0 in stage 180.0 (TID 346) INFO Executor: Running task 1.0 in stage 180.0 (TID 346)
23/10/22 15:01:21.225 Executor task launch worker for task 5.0 in stage 180.0 (TID 350) INFO Executor: Running task 5.0 in stage 180.0 (TID 350)
23/10/22 15:01:21.225 Executor task launch worker for task 6.0 in stage 180.0 (TID 351) INFO Executor: Running task 6.0 in stage 180.0 (TID 351)
23/10/22 15:01:21.225 Executor task launch worker for task 0.0 in stage 180.0 (TID 345) INFO Executor: Running task 0.0 in stage 180.0 (TID 345)
23/10/22 15:01:21.225 Executor task launch worker for task 3.0 in stage 180.0 (TID 348) INFO Executor: Running task 3.0 in stage 180.0 (TID 348)
23/10/22 15:01:21.225 Executor task launch worker for task 4.0 in stage 180.0 (TID 349) INFO Executor: Running task 4.0 in stage 180.0 (TID 349)
23/10/22 15:01:21.225 Executor task launch worker for task 7.0 in stage 180.0 (TID 352) INFO Executor: Running task 7.0 in stage 180.0 (TID 352)
23/10/22 15:01:21.232 Executor task launch worker for task 6.0 in stage 180.0 (TID 351) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.233 Executor task launch worker for task 6.0 in stage 180.0 (TID 351) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.233 Executor task launch worker for task 1.0 in stage 180.0 (TID 346) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.233 Executor task launch worker for task 1.0 in stage 180.0 (TID 346) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.233 Executor task launch worker for task 2.0 in stage 180.0 (TID 347) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.233 Executor task launch worker for task 2.0 in stage 180.0 (TID 347) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.232 Executor task launch worker for task 0.0 in stage 180.0 (TID 345) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.233 Executor task launch worker for task 0.0 in stage 180.0 (TID 345) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:21.236 Executor task launch worker for task 7.0 in stage 180.0 (TID 352) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.236 Executor task launch worker for task 7.0 in stage 180.0 (TID 352) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.237 Executor task launch worker for task 4.0 in stage 180.0 (TID 349) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.237 Executor task launch worker for task 4.0 in stage 180.0 (TID 349) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.238 Executor task launch worker for task 3.0 in stage 180.0 (TID 348) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.238 Executor task launch worker for task 3.0 in stage 180.0 (TID 348) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.240 Executor task launch worker for task 5.0 in stage 180.0 (TID 350) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.240 Executor task launch worker for task 5.0 in stage 180.0 (TID 350) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.247 Executor task launch worker for task 6.0 in stage 180.0 (TID 351) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.248 Executor task launch worker for task 0.0 in stage 180.0 (TID 345) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.247 Executor task launch worker for task 2.0 in stage 180.0 (TID 347) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.250 Executor task launch worker for task 1.0 in stage 180.0 (TID 346) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.251 Executor task launch worker for task 3.0 in stage 180.0 (TID 348) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.254 Executor task launch worker for task 4.0 in stage 180.0 (TID 349) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.276 Executor task launch worker for task 5.0 in stage 180.0 (TID 350) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.276 Executor task launch worker for task 7.0 in stage 180.0 (TID 352) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.297 Executor task launch worker for task 6.0 in stage 180.0 (TID 351) INFO Executor: Finished task 6.0 in stage 180.0 (TID 351). 6562 bytes result sent to driver
23/10/22 15:01:21.298 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 180.0 (TID 351) in 89 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:21.305 Executor task launch worker for task 1.0 in stage 180.0 (TID 346) INFO Executor: Finished task 1.0 in stage 180.0 (TID 346). 6562 bytes result sent to driver
23/10/22 15:01:21.306 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 346) in 97 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:21.312 Executor task launch worker for task 0.0 in stage 180.0 (TID 345) INFO Executor: Finished task 0.0 in stage 180.0 (TID 345). 6562 bytes result sent to driver
23/10/22 15:01:21.312 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 345) in 103 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:21.320 Executor task launch worker for task 4.0 in stage 180.0 (TID 349) INFO Executor: Finished task 4.0 in stage 180.0 (TID 349). 6562 bytes result sent to driver
23/10/22 15:01:21.321 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 180.0 (TID 349) in 112 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:21.327 Executor task launch worker for task 2.0 in stage 180.0 (TID 347) INFO Executor: Finished task 2.0 in stage 180.0 (TID 347). 6562 bytes result sent to driver
23/10/22 15:01:21.328 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 180.0 (TID 347) in 119 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:21.332 Executor task launch worker for task 3.0 in stage 180.0 (TID 348) INFO Executor: Finished task 3.0 in stage 180.0 (TID 348). 6562 bytes result sent to driver
23/10/22 15:01:21.332 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 180.0 (TID 348) in 123 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:21.338 Executor task launch worker for task 5.0 in stage 180.0 (TID 350) INFO Executor: Finished task 5.0 in stage 180.0 (TID 350). 6605 bytes result sent to driver
23/10/22 15:01:21.339 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 180.0 (TID 350) in 130 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:21.342 Executor task launch worker for task 7.0 in stage 180.0 (TID 352) INFO Executor: Finished task 7.0 in stage 180.0 (TID 352). 6562 bytes result sent to driver
23/10/22 15:01:21.343 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 180.0 (TID 352) in 134 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:21.343 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
23/10/22 15:01:21.343 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 180 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.134 s
23/10/22 15:01:21.343 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:21.343 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:21.343 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 181)
23/10/22 15:01:21.343 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:21.344 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[423] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:21.346 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 93.6 KiB, free 1036.8 MiB)
23/10/22 15:01:21.347 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 1036.8 MiB)
23/10/22 15:01:21.347 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:57170 (size: 37.4 KiB, free: 1037.0 MiB)
23/10/22 15:01:21.347 dag-scheduler-event-loop INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:21.348 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 181 (MapPartitionsRDD[423] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:21.348 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 181.0 with 2 tasks resource profile 0
23/10/22 15:01:21.348 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 353) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:21.349 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 354) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:21.349 Executor task launch worker for task 0.0 in stage 181.0 (TID 353) INFO Executor: Running task 0.0 in stage 181.0 (TID 353)
23/10/22 15:01:21.349 Executor task launch worker for task 1.0 in stage 181.0 (TID 354) INFO Executor: Running task 1.0 in stage 181.0 (TID 354)
23/10/22 15:01:21.354 Executor task launch worker for task 1.0 in stage 181.0 (TID 354) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.354 Executor task launch worker for task 0.0 in stage 181.0 (TID 353) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:21.354 Executor task launch worker for task 1.0 in stage 181.0 (TID 354) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.354 Executor task launch worker for task 0.0 in stage 181.0 (TID 353) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:21.358 Executor task launch worker for task 0.0 in stage 181.0 (TID 353) INFO Executor: Finished task 0.0 in stage 181.0 (TID 353). 6699 bytes result sent to driver
23/10/22 15:01:21.358 Executor task launch worker for task 1.0 in stage 181.0 (TID 354) INFO Executor: Finished task 1.0 in stage 181.0 (TID 354). 6699 bytes result sent to driver
23/10/22 15:01:21.358 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 353) in 10 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:21.358 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 354) in 9 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:21.358 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
23/10/22 15:01:21.360 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 181 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.016 s
23/10/22 15:01:21.360 dag-scheduler-event-loop INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:21.360 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
23/10/22 15:01:21.360 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 99 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.141585 s
23/10/22 15:01:21.360 nioEventLoopGroup-2-2 INFO Instrumentation: [f34953d7] Number of instances: 3785.
23/10/22 15:01:21.427 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 426 (rdd at LinearRegression.scala:921) as input to shuffle 62
23/10/22 15:01:21.428 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 100 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 15:01:21.428 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 182 (rdd at LinearRegression.scala:921)
23/10/22 15:01:21.428 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:21.428 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:21.428 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[426] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:21.429 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 15:01:21.430 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 15:01:21.430 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 15:01:21.431 dag-scheduler-event-loop INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:21.431 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[426] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:21.431 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0
23/10/22 15:01:21.592 dispatcher-event-loop-3 WARN TaskSetManager: Stage 182 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:21.592 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 355) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:21.592 Executor task launch worker for task 0.0 in stage 182.0 (TID 355) INFO Executor: Running task 0.0 in stage 182.0 (TID 355)
23/10/22 15:01:21.659 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 15:01:21.659 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:57170 in memory (size: 36.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:21.659 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:57170 in memory (size: 37.4 KiB, free: 1037.1 MiB)
23/10/22 15:01:21.735 Executor task launch worker for task 0.0 in stage 182.0 (TID 355) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:21.876 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:22.435 Executor task launch worker for task 0.0 in stage 182.0 (TID 355) INFO Executor: Finished task 0.0 in stage 182.0 (TID 355). 2147 bytes result sent to driver
23/10/22 15:01:22.435 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 355) in 1004 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:22.435 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
23/10/22 15:01:22.435 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 182 (rdd at LinearRegression.scala:921) finished in 1.007 s
23/10/22 15:01:22.435 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:22.435 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:22.435 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:22.435 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:22.435 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(62), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:22.444 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 430 (rdd at LinearRegression.scala:921) as input to shuffle 63
23/10/22 15:01:22.444 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 101 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 15:01:22.444 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 184 (rdd at LinearRegression.scala:921)
23/10/22 15:01:22.445 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 183)
23/10/22 15:01:22.445 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:22.445 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 184 (MapPartitionsRDD[430] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:22.447 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:22.447 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 15:01:22.448 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:57170 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 15:01:22.448 dag-scheduler-event-loop INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:22.448 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 184 (MapPartitionsRDD[430] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:22.448 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 184.0 with 8 tasks resource profile 0
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 356) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 184.0 (TID 357) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 184.0 (TID 358) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 184.0 (TID 359) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 184.0 (TID 360) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 184.0 (TID 361) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 184.0 (TID 362) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.449 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 184.0 (TID 363) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.450 Executor task launch worker for task 3.0 in stage 184.0 (TID 359) INFO Executor: Running task 3.0 in stage 184.0 (TID 359)
23/10/22 15:01:22.450 Executor task launch worker for task 2.0 in stage 184.0 (TID 358) INFO Executor: Running task 2.0 in stage 184.0 (TID 358)
23/10/22 15:01:22.450 Executor task launch worker for task 1.0 in stage 184.0 (TID 357) INFO Executor: Running task 1.0 in stage 184.0 (TID 357)
23/10/22 15:01:22.450 Executor task launch worker for task 5.0 in stage 184.0 (TID 361) INFO Executor: Running task 5.0 in stage 184.0 (TID 361)
23/10/22 15:01:22.450 Executor task launch worker for task 0.0 in stage 184.0 (TID 356) INFO Executor: Running task 0.0 in stage 184.0 (TID 356)
23/10/22 15:01:22.450 Executor task launch worker for task 4.0 in stage 184.0 (TID 360) INFO Executor: Running task 4.0 in stage 184.0 (TID 360)
23/10/22 15:01:22.450 Executor task launch worker for task 7.0 in stage 184.0 (TID 363) INFO Executor: Running task 7.0 in stage 184.0 (TID 363)
23/10/22 15:01:22.450 Executor task launch worker for task 6.0 in stage 184.0 (TID 362) INFO Executor: Running task 6.0 in stage 184.0 (TID 362)
23/10/22 15:01:22.454 Executor task launch worker for task 1.0 in stage 184.0 (TID 357) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.454 Executor task launch worker for task 1.0 in stage 184.0 (TID 357) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.454 Executor task launch worker for task 6.0 in stage 184.0 (TID 362) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.454 Executor task launch worker for task 6.0 in stage 184.0 (TID 362) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.454 Executor task launch worker for task 7.0 in stage 184.0 (TID 363) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.454 Executor task launch worker for task 7.0 in stage 184.0 (TID 363) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.455 Executor task launch worker for task 4.0 in stage 184.0 (TID 360) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.455 Executor task launch worker for task 4.0 in stage 184.0 (TID 360) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.455 Executor task launch worker for task 5.0 in stage 184.0 (TID 361) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.455 Executor task launch worker for task 5.0 in stage 184.0 (TID 361) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.456 Executor task launch worker for task 3.0 in stage 184.0 (TID 359) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.456 Executor task launch worker for task 3.0 in stage 184.0 (TID 359) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.456 Executor task launch worker for task 0.0 in stage 184.0 (TID 356) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.456 Executor task launch worker for task 0.0 in stage 184.0 (TID 356) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.458 Executor task launch worker for task 2.0 in stage 184.0 (TID 358) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.458 Executor task launch worker for task 2.0 in stage 184.0 (TID 358) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.465 Executor task launch worker for task 1.0 in stage 184.0 (TID 357) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.465 Executor task launch worker for task 5.0 in stage 184.0 (TID 361) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.465 Executor task launch worker for task 7.0 in stage 184.0 (TID 363) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.467 Executor task launch worker for task 3.0 in stage 184.0 (TID 359) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.467 Executor task launch worker for task 0.0 in stage 184.0 (TID 356) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.480 Executor task launch worker for task 6.0 in stage 184.0 (TID 362) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.480 Executor task launch worker for task 2.0 in stage 184.0 (TID 358) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.480 Executor task launch worker for task 1.0 in stage 184.0 (TID 357) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.480 Executor task launch worker for task 5.0 in stage 184.0 (TID 361) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.492 Executor task launch worker for task 7.0 in stage 184.0 (TID 363) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.498 Executor task launch worker for task 4.0 in stage 184.0 (TID 360) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.498 Executor task launch worker for task 6.0 in stage 184.0 (TID 362) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.510 Executor task launch worker for task 3.0 in stage 184.0 (TID 359) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.529 Executor task launch worker for task 0.0 in stage 184.0 (TID 356) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.529 Executor task launch worker for task 4.0 in stage 184.0 (TID 360) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.566 Executor task launch worker for task 2.0 in stage 184.0 (TID 358) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.639 Executor task launch worker for task 1.0 in stage 184.0 (TID 357) INFO Executor: Finished task 1.0 in stage 184.0 (TID 357). 4899 bytes result sent to driver
23/10/22 15:01:22.642 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 184.0 (TID 357) in 193 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:22.657 Executor task launch worker for task 5.0 in stage 184.0 (TID 361) INFO Executor: Finished task 5.0 in stage 184.0 (TID 361). 4899 bytes result sent to driver
23/10/22 15:01:22.658 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 184.0 (TID 361) in 209 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:22.668 Executor task launch worker for task 7.0 in stage 184.0 (TID 363) INFO Executor: Finished task 7.0 in stage 184.0 (TID 363). 4899 bytes result sent to driver
23/10/22 15:01:22.668 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 184.0 (TID 363) in 219 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:22.673 Executor task launch worker for task 2.0 in stage 184.0 (TID 358) INFO Executor: Finished task 2.0 in stage 184.0 (TID 358). 4942 bytes result sent to driver
23/10/22 15:01:22.674 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 184.0 (TID 358) in 225 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:22.679 Executor task launch worker for task 0.0 in stage 184.0 (TID 356) INFO Executor: Finished task 0.0 in stage 184.0 (TID 356). 4899 bytes result sent to driver
23/10/22 15:01:22.680 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 356) in 231 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:22.685 Executor task launch worker for task 3.0 in stage 184.0 (TID 359) INFO Executor: Finished task 3.0 in stage 184.0 (TID 359). 4899 bytes result sent to driver
23/10/22 15:01:22.685 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 184.0 (TID 359) in 236 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:22.690 Executor task launch worker for task 4.0 in stage 184.0 (TID 360) INFO Executor: Finished task 4.0 in stage 184.0 (TID 360). 4899 bytes result sent to driver
23/10/22 15:01:22.691 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 184.0 (TID 360) in 242 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:22.696 Executor task launch worker for task 6.0 in stage 184.0 (TID 362) INFO Executor: Finished task 6.0 in stage 184.0 (TID 362). 4899 bytes result sent to driver
23/10/22 15:01:22.696 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 184.0 (TID 362) in 247 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:22.696 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
23/10/22 15:01:22.697 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 184 (rdd at LinearRegression.scala:921) finished in 0.252 s
23/10/22 15:01:22.697 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:22.697 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:22.697 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:22.697 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:22.700 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:22.710 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.6423 ms
23/10/22 15:01:22.730 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 440 (treeAggregate at Statistics.scala:58) as input to shuffle 64
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Got job 102 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 188 (treeAggregate at Statistics.scala:58)
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 187)
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 187)
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 187 (MapPartitionsRDD[440] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 83.1 KiB, free 1037.0 MiB)
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1036.9 MiB)
23/10/22 15:01:22.730 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:57170 (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 187 (MapPartitionsRDD[440] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:22.730 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 187.0 with 8 tasks resource profile 0
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 364) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 187.0 (TID 365) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 187.0 (TID 366) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 187.0 (TID 367) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 187.0 (TID 368) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 187.0 (TID 369) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.730 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 187.0 (TID 370) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.742 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 187.0 (TID 371) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:22.742 Executor task launch worker for task 1.0 in stage 187.0 (TID 365) INFO Executor: Running task 1.0 in stage 187.0 (TID 365)
23/10/22 15:01:22.742 Executor task launch worker for task 5.0 in stage 187.0 (TID 369) INFO Executor: Running task 5.0 in stage 187.0 (TID 369)
23/10/22 15:01:22.742 Executor task launch worker for task 4.0 in stage 187.0 (TID 368) INFO Executor: Running task 4.0 in stage 187.0 (TID 368)
23/10/22 15:01:22.742 Executor task launch worker for task 0.0 in stage 187.0 (TID 364) INFO Executor: Running task 0.0 in stage 187.0 (TID 364)
23/10/22 15:01:22.742 Executor task launch worker for task 2.0 in stage 187.0 (TID 366) INFO Executor: Running task 2.0 in stage 187.0 (TID 366)
23/10/22 15:01:22.742 Executor task launch worker for task 7.0 in stage 187.0 (TID 371) INFO Executor: Running task 7.0 in stage 187.0 (TID 371)
23/10/22 15:01:22.742 Executor task launch worker for task 3.0 in stage 187.0 (TID 367) INFO Executor: Running task 3.0 in stage 187.0 (TID 367)
23/10/22 15:01:22.742 Executor task launch worker for task 6.0 in stage 187.0 (TID 370) INFO Executor: Running task 6.0 in stage 187.0 (TID 370)
23/10/22 15:01:22.749 Executor task launch worker for task 7.0 in stage 187.0 (TID 371) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.749 Executor task launch worker for task 0.0 in stage 187.0 (TID 364) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.749 Executor task launch worker for task 7.0 in stage 187.0 (TID 371) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.749 Executor task launch worker for task 0.0 in stage 187.0 (TID 364) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.749 Executor task launch worker for task 5.0 in stage 187.0 (TID 369) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.750 Executor task launch worker for task 2.0 in stage 187.0 (TID 366) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.750 Executor task launch worker for task 4.0 in stage 187.0 (TID 368) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.750 Executor task launch worker for task 4.0 in stage 187.0 (TID 368) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.749 Executor task launch worker for task 1.0 in stage 187.0 (TID 365) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.751 Executor task launch worker for task 1.0 in stage 187.0 (TID 365) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.750 Executor task launch worker for task 2.0 in stage 187.0 (TID 366) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.750 Executor task launch worker for task 5.0 in stage 187.0 (TID 369) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.751 Executor task launch worker for task 6.0 in stage 187.0 (TID 370) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.751 Executor task launch worker for task 6.0 in stage 187.0 (TID 370) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.755 Executor task launch worker for task 3.0 in stage 187.0 (TID 367) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.755 Executor task launch worker for task 3.0 in stage 187.0 (TID 367) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.763 Executor task launch worker for task 2.0 in stage 187.0 (TID 366) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.763 Executor task launch worker for task 0.0 in stage 187.0 (TID 364) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.764 Executor task launch worker for task 5.0 in stage 187.0 (TID 369) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.765 Executor task launch worker for task 6.0 in stage 187.0 (TID 370) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.765 Executor task launch worker for task 1.0 in stage 187.0 (TID 365) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.768 Executor task launch worker for task 3.0 in stage 187.0 (TID 367) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.793 Executor task launch worker for task 7.0 in stage 187.0 (TID 371) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.793 Executor task launch worker for task 4.0 in stage 187.0 (TID 368) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:22.812 Executor task launch worker for task 5.0 in stage 187.0 (TID 369) INFO Executor: Finished task 5.0 in stage 187.0 (TID 369). 6562 bytes result sent to driver
23/10/22 15:01:22.813 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 187.0 (TID 369) in 83 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:22.819 Executor task launch worker for task 6.0 in stage 187.0 (TID 370) INFO Executor: Finished task 6.0 in stage 187.0 (TID 370). 6562 bytes result sent to driver
23/10/22 15:01:22.820 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 187.0 (TID 370) in 90 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:22.827 Executor task launch worker for task 1.0 in stage 187.0 (TID 365) INFO Executor: Finished task 1.0 in stage 187.0 (TID 365). 6562 bytes result sent to driver
23/10/22 15:01:22.828 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 187.0 (TID 365) in 98 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:22.833 Executor task launch worker for task 3.0 in stage 187.0 (TID 367) INFO Executor: Finished task 3.0 in stage 187.0 (TID 367). 6605 bytes result sent to driver
23/10/22 15:01:22.834 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 187.0 (TID 367) in 104 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:22.839 Executor task launch worker for task 2.0 in stage 187.0 (TID 366) INFO Executor: Finished task 2.0 in stage 187.0 (TID 366). 6562 bytes result sent to driver
23/10/22 15:01:22.839 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 187.0 (TID 366) in 109 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:22.844 Executor task launch worker for task 0.0 in stage 187.0 (TID 364) INFO Executor: Finished task 0.0 in stage 187.0 (TID 364). 6562 bytes result sent to driver
23/10/22 15:01:22.845 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 364) in 115 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:22.852 Executor task launch worker for task 7.0 in stage 187.0 (TID 371) INFO Executor: Finished task 7.0 in stage 187.0 (TID 371). 6562 bytes result sent to driver
23/10/22 15:01:22.853 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 187.0 (TID 371) in 123 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:22.858 Executor task launch worker for task 4.0 in stage 187.0 (TID 368) INFO Executor: Finished task 4.0 in stage 187.0 (TID 368). 6562 bytes result sent to driver
23/10/22 15:01:22.859 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 187.0 (TID 368) in 129 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:22.859 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool 
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 187 (treeAggregate at Statistics.scala:58) finished in 0.129 s
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 188)
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[442] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 84.2 KiB, free 1036.8 MiB)
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 1036.8 MiB)
23/10/22 15:01:22.859 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:57170 (size: 35.9 KiB, free: 1037.0 MiB)
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 188 (MapPartitionsRDD[442] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:22.859 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 188.0 with 2 tasks resource profile 0
23/10/22 15:01:22.859 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 372) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:22.859 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 188.0 (TID 373) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:22.859 Executor task launch worker for task 0.0 in stage 188.0 (TID 372) INFO Executor: Running task 0.0 in stage 188.0 (TID 372)
23/10/22 15:01:22.859 Executor task launch worker for task 1.0 in stage 188.0 (TID 373) INFO Executor: Running task 1.0 in stage 188.0 (TID 373)
23/10/22 15:01:22.865 Executor task launch worker for task 0.0 in stage 188.0 (TID 372) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.865 Executor task launch worker for task 1.0 in stage 188.0 (TID 373) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:22.869 Executor task launch worker for task 0.0 in stage 188.0 (TID 372) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.869 Executor task launch worker for task 1.0 in stage 188.0 (TID 373) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:22.869 Executor task launch worker for task 0.0 in stage 188.0 (TID 372) INFO Executor: Finished task 0.0 in stage 188.0 (TID 372). 7630 bytes result sent to driver
23/10/22 15:01:22.869 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 372) in 10 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:22.869 Executor task launch worker for task 1.0 in stage 188.0 (TID 373) INFO Executor: Finished task 1.0 in stage 188.0 (TID 373). 7630 bytes result sent to driver
23/10/22 15:01:22.869 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 188.0 (TID 373) in 10 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:22.869 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
23/10/22 15:01:22.869 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 188 (treeAggregate at Statistics.scala:58) finished in 0.010 s
23/10/22 15:01:22.869 dag-scheduler-event-loop INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:22.869 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 188: Stage finished
23/10/22 15:01:22.869 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 102 finished: treeAggregate at Statistics.scala:58, took 0.138623 s
23/10/22 15:01:22.875 nioEventLoopGroup-2-2 INFO Instrumentation: [d4dbad1e] training finished
23/10/22 15:01:23.092 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:23.108 dag-scheduler-event-loop INFO DAGScheduler: Got job 103 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:23.108 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 189 (collect at utils.scala:26)
23/10/22 15:01:23.108 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:23.108 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:23.108 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[444] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:23.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:23.110 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[444] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 189.0 with 1 tasks resource profile 0
23/10/22 15:01:23.110 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 374) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:23.110 Executor task launch worker for task 0.0 in stage 189.0 (TID 374) INFO Executor: Running task 0.0 in stage 189.0 (TID 374)
23/10/22 15:01:23.110 Executor task launch worker for task 0.0 in stage 189.0 (TID 374) INFO Executor: Finished task 0.0 in stage 189.0 (TID 374). 1284 bytes result sent to driver
23/10/22 15:01:23.110 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 374) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:23.110 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool 
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 189 (collect at utils.scala:26) finished in 0.002 s
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:23.110 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished
23/10/22 15:01:23.110 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 103 finished: collect at utils.scala:26, took 0.007352 s
23/10/22 15:01:23.309 nioEventLoopGroup-2-2 INFO Instrumentation: [1ecd3a64] training finished
23/10/22 15:01:23.375 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:23.375 dag-scheduler-event-loop INFO DAGScheduler: Got job 104 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:23.375 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 190 (collect at utils.scala:26)
23/10/22 15:01:23.375 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:23.375 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[446] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:23.376 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[446] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 190.0 with 1 tasks resource profile 0
23/10/22 15:01:23.376 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 375) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:23.376 Executor task launch worker for task 0.0 in stage 190.0 (TID 375) INFO Executor: Running task 0.0 in stage 190.0 (TID 375)
23/10/22 15:01:23.376 Executor task launch worker for task 0.0 in stage 190.0 (TID 375) INFO Executor: Finished task 0.0 in stage 190.0 (TID 375). 1284 bytes result sent to driver
23/10/22 15:01:23.376 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 375) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:23.376 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 190 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:23.376 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 190: Stage finished
23/10/22 15:01:23.376 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 104 finished: collect at utils.scala:26, took 0.005137 s
23/10/22 15:01:23.692 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Got job 105 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 191 (collect at utils.scala:26)
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[448] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:23.692 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (MapPartitionsRDD[448] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 191.0 with 1 tasks resource profile 0
23/10/22 15:01:23.692 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 376) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:23.692 Executor task launch worker for task 0.0 in stage 191.0 (TID 376) INFO Executor: Running task 0.0 in stage 191.0 (TID 376)
23/10/22 15:01:23.692 Executor task launch worker for task 0.0 in stage 191.0 (TID 376) INFO Executor: Finished task 0.0 in stage 191.0 (TID 376). 1284 bytes result sent to driver
23/10/22 15:01:23.692 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 376) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:23.692 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 191 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:23.692 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 191: Stage finished
23/10/22 15:01:23.692 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 105 finished: collect at utils.scala:26, took 0.005345 s
23/10/22 15:01:24.204 nioEventLoopGroup-2-2 INFO Instrumentation: [c589b1ca] training finished
23/10/22 15:01:24.213 nioEventLoopGroup-2-2 INFO Instrumentation: [6b26f45e] training finished
23/10/22 15:01:24.217 nioEventLoopGroup-2-2 INFO Instrumentation: [66019354] Stage class: LinearRegression
23/10/22 15:01:24.218 nioEventLoopGroup-2-2 INFO Instrumentation: [66019354] Stage uid: linear_regression__9cc15aff_0b50_43e9_aea8_4c6f7c35c76d
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 451 (rdd at Instrumentation.scala:62) as input to shuffle 65
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 106 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 192 (rdd at Instrumentation.scala:62)
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 192 (MapPartitionsRDD[451] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:24.233 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 32.7 KiB, free 1036.7 MiB)
23/10/22 15:01:24.242 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 15:01:24.242 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 15:01:24.242 dag-scheduler-event-loop INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:24.242 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 192 (MapPartitionsRDD[451] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:24.242 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 192.0 with 1 tasks resource profile 0
23/10/22 15:01:24.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:57170 in memory (size: 35.9 KiB, free: 1037.1 MiB)
23/10/22 15:01:24.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:57170 in memory (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 15:01:24.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:24.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:57170 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 15:01:24.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:24.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:24.418 dispatcher-event-loop-1 WARN TaskSetManager: Stage 192 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:24.418 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 377) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:24.418 Executor task launch worker for task 0.0 in stage 192.0 (TID 377) INFO Executor: Running task 0.0 in stage 192.0 (TID 377)
23/10/22 15:01:24.534 Executor task launch worker for task 0.0 in stage 192.0 (TID 377) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:24.681 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:25.248 Executor task launch worker for task 0.0 in stage 192.0 (TID 377) INFO Executor: Finished task 0.0 in stage 192.0 (TID 377). 2147 bytes result sent to driver
23/10/22 15:01:25.249 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 377) in 1006 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:25.249 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool 
23/10/22 15:01:25.249 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 192 (rdd at Instrumentation.scala:62) finished in 1.016 s
23/10/22 15:01:25.249 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:25.249 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:25.249 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:25.249 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:25.253 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(65), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:25.255 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 455 (rdd at Instrumentation.scala:62) as input to shuffle 66
23/10/22 15:01:25.255 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 107 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 15:01:25.255 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 194 (rdd at Instrumentation.scala:62)
23/10/22 15:01:25.255 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 193)
23/10/22 15:01:25.255 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:25.255 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 194 (MapPartitionsRDD[455] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:25.257 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:25.258 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:25.258 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:25.259 dag-scheduler-event-loop INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:25.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 194 (MapPartitionsRDD[455] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:25.259 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 194.0 with 8 tasks resource profile 0
23/10/22 15:01:25.260 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 378) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.260 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 194.0 (TID 379) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.260 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 194.0 (TID 380) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.260 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 194.0 (TID 381) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.260 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 194.0 (TID 382) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.260 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 194.0 (TID 383) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.261 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 194.0 (TID 384) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.261 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 194.0 (TID 385) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:25.261 Executor task launch worker for task 1.0 in stage 194.0 (TID 379) INFO Executor: Running task 1.0 in stage 194.0 (TID 379)
23/10/22 15:01:25.261 Executor task launch worker for task 4.0 in stage 194.0 (TID 382) INFO Executor: Running task 4.0 in stage 194.0 (TID 382)
23/10/22 15:01:25.261 Executor task launch worker for task 6.0 in stage 194.0 (TID 384) INFO Executor: Running task 6.0 in stage 194.0 (TID 384)
23/10/22 15:01:25.261 Executor task launch worker for task 3.0 in stage 194.0 (TID 381) INFO Executor: Running task 3.0 in stage 194.0 (TID 381)
23/10/22 15:01:25.261 Executor task launch worker for task 2.0 in stage 194.0 (TID 380) INFO Executor: Running task 2.0 in stage 194.0 (TID 380)
23/10/22 15:01:25.261 Executor task launch worker for task 0.0 in stage 194.0 (TID 378) INFO Executor: Running task 0.0 in stage 194.0 (TID 378)
23/10/22 15:01:25.261 Executor task launch worker for task 7.0 in stage 194.0 (TID 385) INFO Executor: Running task 7.0 in stage 194.0 (TID 385)
23/10/22 15:01:25.261 Executor task launch worker for task 5.0 in stage 194.0 (TID 383) INFO Executor: Running task 5.0 in stage 194.0 (TID 383)
23/10/22 15:01:25.265 Executor task launch worker for task 2.0 in stage 194.0 (TID 380) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.265 Executor task launch worker for task 2.0 in stage 194.0 (TID 380) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.265 Executor task launch worker for task 3.0 in stage 194.0 (TID 381) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.265 Executor task launch worker for task 3.0 in stage 194.0 (TID 381) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.265 Executor task launch worker for task 1.0 in stage 194.0 (TID 379) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.265 Executor task launch worker for task 1.0 in stage 194.0 (TID 379) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.265 Executor task launch worker for task 0.0 in stage 194.0 (TID 378) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.266 Executor task launch worker for task 0.0 in stage 194.0 (TID 378) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:25.266 Executor task launch worker for task 5.0 in stage 194.0 (TID 383) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.266 Executor task launch worker for task 5.0 in stage 194.0 (TID 383) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.267 Executor task launch worker for task 4.0 in stage 194.0 (TID 382) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.267 Executor task launch worker for task 4.0 in stage 194.0 (TID 382) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.267 Executor task launch worker for task 6.0 in stage 194.0 (TID 384) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.267 Executor task launch worker for task 7.0 in stage 194.0 (TID 385) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:25.267 Executor task launch worker for task 6.0 in stage 194.0 (TID 384) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.268 Executor task launch worker for task 7.0 in stage 194.0 (TID 385) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:25.275 Executor task launch worker for task 2.0 in stage 194.0 (TID 380) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.275 Executor task launch worker for task 0.0 in stage 194.0 (TID 378) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.276 Executor task launch worker for task 3.0 in stage 194.0 (TID 381) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.277 Executor task launch worker for task 4.0 in stage 194.0 (TID 382) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.277 Executor task launch worker for task 6.0 in stage 194.0 (TID 384) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.284 Executor task launch worker for task 7.0 in stage 194.0 (TID 385) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.293 Executor task launch worker for task 1.0 in stage 194.0 (TID 379) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.294 Executor task launch worker for task 5.0 in stage 194.0 (TID 383) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.303 Executor task launch worker for task 4.0 in stage 194.0 (TID 382) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.303 Executor task launch worker for task 0.0 in stage 194.0 (TID 378) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.307 Executor task launch worker for task 2.0 in stage 194.0 (TID 380) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.317 Executor task launch worker for task 1.0 in stage 194.0 (TID 379) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.320 Executor task launch worker for task 5.0 in stage 194.0 (TID 383) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.323 Executor task launch worker for task 3.0 in stage 194.0 (TID 381) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.325 Executor task launch worker for task 6.0 in stage 194.0 (TID 384) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.347 Executor task launch worker for task 7.0 in stage 194.0 (TID 385) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.415 Executor task launch worker for task 4.0 in stage 194.0 (TID 382) INFO Executor: Finished task 4.0 in stage 194.0 (TID 382). 4899 bytes result sent to driver
23/10/22 15:01:25.416 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 194.0 (TID 382) in 156 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:25.453 Executor task launch worker for task 1.0 in stage 194.0 (TID 379) INFO Executor: Finished task 1.0 in stage 194.0 (TID 379). 4899 bytes result sent to driver
23/10/22 15:01:25.454 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 194.0 (TID 379) in 194 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:25.460 Executor task launch worker for task 2.0 in stage 194.0 (TID 380) INFO Executor: Finished task 2.0 in stage 194.0 (TID 380). 4899 bytes result sent to driver
23/10/22 15:01:25.460 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 194.0 (TID 380) in 200 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:25.467 Executor task launch worker for task 6.0 in stage 194.0 (TID 384) INFO Executor: Finished task 6.0 in stage 194.0 (TID 384). 4899 bytes result sent to driver
23/10/22 15:01:25.467 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 194.0 (TID 384) in 207 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:25.473 Executor task launch worker for task 5.0 in stage 194.0 (TID 383) INFO Executor: Finished task 5.0 in stage 194.0 (TID 383). 4899 bytes result sent to driver
23/10/22 15:01:25.474 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 194.0 (TID 383) in 214 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:25.479 Executor task launch worker for task 0.0 in stage 194.0 (TID 378) INFO Executor: Finished task 0.0 in stage 194.0 (TID 378). 4899 bytes result sent to driver
23/10/22 15:01:25.479 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 378) in 219 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:25.484 Executor task launch worker for task 7.0 in stage 194.0 (TID 385) INFO Executor: Finished task 7.0 in stage 194.0 (TID 385). 4899 bytes result sent to driver
23/10/22 15:01:25.484 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 194.0 (TID 385) in 223 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:25.484 Executor task launch worker for task 3.0 in stage 194.0 (TID 381) INFO Executor: Finished task 3.0 in stage 194.0 (TID 381). 4899 bytes result sent to driver
23/10/22 15:01:25.484 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 194.0 (TID 381) in 224 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:25.484 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
23/10/22 15:01:25.484 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 194 (rdd at Instrumentation.scala:62) finished in 0.228 s
23/10/22 15:01:25.484 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:25.484 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:25.484 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:25.484 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:25.493 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(66), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:25.493 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.858 ms
23/10/22 15:01:25.509 nioEventLoopGroup-2-2 INFO Instrumentation: [66019354] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 15:01:25.509 nioEventLoopGroup-2-2 INFO Instrumentation: [66019354] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 15:01:25.509 nioEventLoopGroup-2-2 INFO Instrumentation: [66019354] {"numFeatures":2}
23/10/22 15:01:25.559 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 464 (rdd at LinearRegression.scala:348) as input to shuffle 67
23/10/22 15:01:25.559 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 108 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 15:01:25.559 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 195 (rdd at LinearRegression.scala:348)
23/10/22 15:01:25.559 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:25.559 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:25.559 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 195 (MapPartitionsRDD[464] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:25.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 15:01:25.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 15:01:25.562 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:25.562 dag-scheduler-event-loop INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:25.562 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 195 (MapPartitionsRDD[464] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:25.562 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 195.0 with 1 tasks resource profile 0
23/10/22 15:01:25.716 dispatcher-event-loop-3 WARN TaskSetManager: Stage 195 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:25.716 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 386) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:25.716 Executor task launch worker for task 0.0 in stage 195.0 (TID 386) INFO Executor: Running task 0.0 in stage 195.0 (TID 386)
23/10/22 15:01:25.792 Executor task launch worker for task 0.0 in stage 195.0 (TID 386) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:25.879 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:26.527 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:26.738 Executor task launch worker for task 0.0 in stage 195.0 (TID 386) INFO Executor: Finished task 0.0 in stage 195.0 (TID 386). 2104 bytes result sent to driver
23/10/22 15:01:26.739 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 386) in 1176 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:26.739 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
23/10/22 15:01:26.739 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 195 (rdd at LinearRegression.scala:348) finished in 1.179 s
23/10/22 15:01:26.739 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:26.739 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:26.739 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:26.739 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:26.745 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(67), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:26.747 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 468 (rdd at LinearRegression.scala:348) as input to shuffle 68
23/10/22 15:01:26.747 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 109 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 15:01:26.747 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 197 (rdd at LinearRegression.scala:348)
23/10/22 15:01:26.747 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 196)
23/10/22 15:01:26.748 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:26.748 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 197 (MapPartitionsRDD[468] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:26.749 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:26.750 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:26.751 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:26.751 dag-scheduler-event-loop INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:26.751 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 197 (MapPartitionsRDD[468] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:26.751 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 197.0 with 8 tasks resource profile 0
23/10/22 15:01:26.752 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 387) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.752 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 197.0 (TID 388) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.752 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 197.0 (TID 389) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.752 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 197.0 (TID 390) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.752 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 197.0 (TID 391) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.753 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 197.0 (TID 392) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.753 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 197.0 (TID 393) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.753 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 197.0 (TID 394) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:26.753 Executor task launch worker for task 3.0 in stage 197.0 (TID 390) INFO Executor: Running task 3.0 in stage 197.0 (TID 390)
23/10/22 15:01:26.753 Executor task launch worker for task 5.0 in stage 197.0 (TID 392) INFO Executor: Running task 5.0 in stage 197.0 (TID 392)
23/10/22 15:01:26.753 Executor task launch worker for task 2.0 in stage 197.0 (TID 389) INFO Executor: Running task 2.0 in stage 197.0 (TID 389)
23/10/22 15:01:26.753 Executor task launch worker for task 0.0 in stage 197.0 (TID 387) INFO Executor: Running task 0.0 in stage 197.0 (TID 387)
23/10/22 15:01:26.753 Executor task launch worker for task 1.0 in stage 197.0 (TID 388) INFO Executor: Running task 1.0 in stage 197.0 (TID 388)
23/10/22 15:01:26.753 Executor task launch worker for task 6.0 in stage 197.0 (TID 393) INFO Executor: Running task 6.0 in stage 197.0 (TID 393)
23/10/22 15:01:26.753 Executor task launch worker for task 7.0 in stage 197.0 (TID 394) INFO Executor: Running task 7.0 in stage 197.0 (TID 394)
23/10/22 15:01:26.753 Executor task launch worker for task 4.0 in stage 197.0 (TID 391) INFO Executor: Running task 4.0 in stage 197.0 (TID 391)
23/10/22 15:01:26.757 Executor task launch worker for task 5.0 in stage 197.0 (TID 392) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.757 Executor task launch worker for task 6.0 in stage 197.0 (TID 393) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.757 Executor task launch worker for task 7.0 in stage 197.0 (TID 394) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.757 Executor task launch worker for task 5.0 in stage 197.0 (TID 392) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.757 Executor task launch worker for task 1.0 in stage 197.0 (TID 388) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.757 Executor task launch worker for task 7.0 in stage 197.0 (TID 394) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.757 Executor task launch worker for task 4.0 in stage 197.0 (TID 391) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.757 Executor task launch worker for task 6.0 in stage 197.0 (TID 393) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.757 Executor task launch worker for task 4.0 in stage 197.0 (TID 391) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.757 Executor task launch worker for task 1.0 in stage 197.0 (TID 388) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.758 Executor task launch worker for task 0.0 in stage 197.0 (TID 387) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.758 Executor task launch worker for task 0.0 in stage 197.0 (TID 387) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.759 Executor task launch worker for task 3.0 in stage 197.0 (TID 390) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.759 Executor task launch worker for task 3.0 in stage 197.0 (TID 390) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.759 Executor task launch worker for task 2.0 in stage 197.0 (TID 389) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:26.759 Executor task launch worker for task 2.0 in stage 197.0 (TID 389) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:26.760 Executor task launch worker for task 1.0 in stage 197.0 (TID 388) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.760 Executor task launch worker for task 7.0 in stage 197.0 (TID 394) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.760 Executor task launch worker for task 4.0 in stage 197.0 (TID 391) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.760 Executor task launch worker for task 5.0 in stage 197.0 (TID 392) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.760 Executor task launch worker for task 0.0 in stage 197.0 (TID 387) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.777 Executor task launch worker for task 6.0 in stage 197.0 (TID 393) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.777 Executor task launch worker for task 2.0 in stage 197.0 (TID 389) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.792 Executor task launch worker for task 4.0 in stage 197.0 (TID 391) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.796 Executor task launch worker for task 0.0 in stage 197.0 (TID 387) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.798 Executor task launch worker for task 5.0 in stage 197.0 (TID 392) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.803 Executor task launch worker for task 1.0 in stage 197.0 (TID 388) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.814 Executor task launch worker for task 3.0 in stage 197.0 (TID 390) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.816 Executor task launch worker for task 2.0 in stage 197.0 (TID 389) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.827 Executor task launch worker for task 7.0 in stage 197.0 (TID 394) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.829 Executor task launch worker for task 6.0 in stage 197.0 (TID 393) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.851 Executor task launch worker for task 3.0 in stage 197.0 (TID 390) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:26.922 Executor task launch worker for task 4.0 in stage 197.0 (TID 391) INFO Executor: Finished task 4.0 in stage 197.0 (TID 391). 4942 bytes result sent to driver
23/10/22 15:01:26.923 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 197.0 (TID 391) in 171 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:26.940 Executor task launch worker for task 5.0 in stage 197.0 (TID 392) INFO Executor: Finished task 5.0 in stage 197.0 (TID 392). 4985 bytes result sent to driver
23/10/22 15:01:26.942 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 197.0 (TID 392) in 190 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:26.957 Executor task launch worker for task 7.0 in stage 197.0 (TID 394) INFO Executor: Finished task 7.0 in stage 197.0 (TID 394). 4942 bytes result sent to driver
23/10/22 15:01:26.959 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 197.0 (TID 394) in 206 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:26.966 Executor task launch worker for task 1.0 in stage 197.0 (TID 388) INFO Executor: Finished task 1.0 in stage 197.0 (TID 388). 4942 bytes result sent to driver
23/10/22 15:01:26.967 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 197.0 (TID 388) in 215 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:26.974 Executor task launch worker for task 6.0 in stage 197.0 (TID 393) INFO Executor: Finished task 6.0 in stage 197.0 (TID 393). 4942 bytes result sent to driver
23/10/22 15:01:26.975 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 197.0 (TID 393) in 222 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:26.981 Executor task launch worker for task 0.0 in stage 197.0 (TID 387) INFO Executor: Finished task 0.0 in stage 197.0 (TID 387). 4942 bytes result sent to driver
23/10/22 15:01:26.981 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 387) in 229 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:26.988 Executor task launch worker for task 3.0 in stage 197.0 (TID 390) INFO Executor: Finished task 3.0 in stage 197.0 (TID 390). 4899 bytes result sent to driver
23/10/22 15:01:26.988 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 197.0 (TID 390) in 236 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:26.995 Executor task launch worker for task 2.0 in stage 197.0 (TID 389) INFO Executor: Finished task 2.0 in stage 197.0 (TID 389). 4942 bytes result sent to driver
23/10/22 15:01:26.995 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 197.0 (TID 389) in 243 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:26.995 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
23/10/22 15:01:26.995 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 197 (rdd at LinearRegression.scala:348) finished in 0.247 s
23/10/22 15:01:26.995 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:27.001 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:27.001 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:27.001 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:27.001 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(68), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:27.046 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 29.4186 ms
23/10/22 15:01:27.058 nioEventLoopGroup-2-2 WARN Instrumentation: [66019354] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 15:01:27.083 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 15:01:27.083 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 477 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 69
23/10/22 15:01:27.083 dag-scheduler-event-loop INFO DAGScheduler: Got job 110 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 15:01:27.083 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 201 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 15:01:27.083 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 200)
23/10/22 15:01:27.083 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 200)
23/10/22 15:01:27.083 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 200 (MapPartitionsRDD[477] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:27.094 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 93.3 KiB, free 1037.0 MiB)
23/10/22 15:01:27.096 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1036.9 MiB)
23/10/22 15:01:27.097 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:57170 (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 15:01:27.097 dag-scheduler-event-loop INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:27.097 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 200 (MapPartitionsRDD[477] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:27.097 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 200.0 with 8 tasks resource profile 0
23/10/22 15:01:27.099 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 395) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.099 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 396) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.099 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 397) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.100 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 398) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.100 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 399) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.100 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 400) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.100 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 401) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.100 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 402) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:27.101 Executor task launch worker for task 2.0 in stage 200.0 (TID 397) INFO Executor: Running task 2.0 in stage 200.0 (TID 397)
23/10/22 15:01:27.101 Executor task launch worker for task 5.0 in stage 200.0 (TID 400) INFO Executor: Running task 5.0 in stage 200.0 (TID 400)
23/10/22 15:01:27.101 Executor task launch worker for task 7.0 in stage 200.0 (TID 402) INFO Executor: Running task 7.0 in stage 200.0 (TID 402)
23/10/22 15:01:27.101 Executor task launch worker for task 3.0 in stage 200.0 (TID 398) INFO Executor: Running task 3.0 in stage 200.0 (TID 398)
23/10/22 15:01:27.101 Executor task launch worker for task 1.0 in stage 200.0 (TID 396) INFO Executor: Running task 1.0 in stage 200.0 (TID 396)
23/10/22 15:01:27.101 Executor task launch worker for task 0.0 in stage 200.0 (TID 395) INFO Executor: Running task 0.0 in stage 200.0 (TID 395)
23/10/22 15:01:27.101 Executor task launch worker for task 6.0 in stage 200.0 (TID 401) INFO Executor: Running task 6.0 in stage 200.0 (TID 401)
23/10/22 15:01:27.101 Executor task launch worker for task 4.0 in stage 200.0 (TID 399) INFO Executor: Running task 4.0 in stage 200.0 (TID 399)
23/10/22 15:01:27.112 Executor task launch worker for task 4.0 in stage 200.0 (TID 399) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.112 Executor task launch worker for task 0.0 in stage 200.0 (TID 395) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.112 Executor task launch worker for task 0.0 in stage 200.0 (TID 395) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.112 Executor task launch worker for task 6.0 in stage 200.0 (TID 401) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.112 Executor task launch worker for task 6.0 in stage 200.0 (TID 401) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.112 Executor task launch worker for task 4.0 in stage 200.0 (TID 399) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.114 Executor task launch worker for task 5.0 in stage 200.0 (TID 400) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.114 Executor task launch worker for task 5.0 in stage 200.0 (TID 400) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.116 Executor task launch worker for task 2.0 in stage 200.0 (TID 397) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.116 Executor task launch worker for task 2.0 in stage 200.0 (TID 397) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.116 Executor task launch worker for task 3.0 in stage 200.0 (TID 398) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.117 Executor task launch worker for task 3.0 in stage 200.0 (TID 398) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.121 Executor task launch worker for task 7.0 in stage 200.0 (TID 402) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.121 Executor task launch worker for task 7.0 in stage 200.0 (TID 402) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.122 Executor task launch worker for task 1.0 in stage 200.0 (TID 396) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.122 Executor task launch worker for task 1.0 in stage 200.0 (TID 396) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:27.134 Executor task launch worker for task 0.0 in stage 200.0 (TID 395) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.134 Executor task launch worker for task 4.0 in stage 200.0 (TID 399) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.134 Executor task launch worker for task 5.0 in stage 200.0 (TID 400) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.136 Executor task launch worker for task 2.0 in stage 200.0 (TID 397) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.136 Executor task launch worker for task 3.0 in stage 200.0 (TID 398) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.142 Executor task launch worker for task 7.0 in stage 200.0 (TID 402) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.159 Executor task launch worker for task 6.0 in stage 200.0 (TID 401) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.167 Executor task launch worker for task 1.0 in stage 200.0 (TID 396) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:27.257 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:27.298 Executor task launch worker for task 0.0 in stage 200.0 (TID 395) INFO Executor: Finished task 0.0 in stage 200.0 (TID 395). 6605 bytes result sent to driver
23/10/22 15:01:27.300 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 395) in 202 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:27.315 Executor task launch worker for task 2.0 in stage 200.0 (TID 397) INFO Executor: Finished task 2.0 in stage 200.0 (TID 397). 6648 bytes result sent to driver
23/10/22 15:01:27.316 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 397) in 217 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:27.327 Executor task launch worker for task 5.0 in stage 200.0 (TID 400) INFO Executor: Finished task 5.0 in stage 200.0 (TID 400). 6605 bytes result sent to driver
23/10/22 15:01:27.329 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 400) in 229 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:27.338 Executor task launch worker for task 3.0 in stage 200.0 (TID 398) INFO Executor: Finished task 3.0 in stage 200.0 (TID 398). 6648 bytes result sent to driver
23/10/22 15:01:27.340 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 398) in 241 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:27.352 Executor task launch worker for task 4.0 in stage 200.0 (TID 399) INFO Executor: Finished task 4.0 in stage 200.0 (TID 399). 6605 bytes result sent to driver
23/10/22 15:01:27.354 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 399) in 254 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:27.368 Executor task launch worker for task 6.0 in stage 200.0 (TID 401) INFO Executor: Finished task 6.0 in stage 200.0 (TID 401). 6605 bytes result sent to driver
23/10/22 15:01:27.370 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 401) in 270 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:27.382 Executor task launch worker for task 7.0 in stage 200.0 (TID 402) INFO Executor: Finished task 7.0 in stage 200.0 (TID 402). 6648 bytes result sent to driver
23/10/22 15:01:27.382 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 402) in 282 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:27.428 Executor task launch worker for task 1.0 in stage 200.0 (TID 396) INFO Executor: Finished task 1.0 in stage 200.0 (TID 396). 6605 bytes result sent to driver
23/10/22 15:01:27.429 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 396) in 330 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:27.429 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
23/10/22 15:01:27.429 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 200 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.346 s
23/10/22 15:01:27.430 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:27.430 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:27.430 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 201)
23/10/22 15:01:27.430 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:27.430 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 201 (MapPartitionsRDD[479] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:27.438 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 94.4 KiB, free 1036.9 MiB)
23/10/22 15:01:27.440 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 15:01:27.442 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:57170 (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:27.442 dag-scheduler-event-loop INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:27.443 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 201 (MapPartitionsRDD[479] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:27.443 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 201.0 with 2 tasks resource profile 0
23/10/22 15:01:27.443 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 403) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:27.443 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 201.0 (TID 404) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:27.443 Executor task launch worker for task 0.0 in stage 201.0 (TID 403) INFO Executor: Running task 0.0 in stage 201.0 (TID 403)
23/10/22 15:01:27.443 Executor task launch worker for task 1.0 in stage 201.0 (TID 404) INFO Executor: Running task 1.0 in stage 201.0 (TID 404)
23/10/22 15:01:27.458 Executor task launch worker for task 0.0 in stage 201.0 (TID 403) INFO ShuffleBlockFetcherIterator: Getting 4 (2.0 KiB) non-empty blocks including 4 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.458 Executor task launch worker for task 1.0 in stage 201.0 (TID 404) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:27.458 Executor task launch worker for task 0.0 in stage 201.0 (TID 403) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:27.458 Executor task launch worker for task 1.0 in stage 201.0 (TID 404) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:27.465 Executor task launch worker for task 1.0 in stage 201.0 (TID 404) INFO Executor: Finished task 1.0 in stage 201.0 (TID 404). 6731 bytes result sent to driver
23/10/22 15:01:27.471 Executor task launch worker for task 0.0 in stage 201.0 (TID 403) INFO Executor: Finished task 0.0 in stage 201.0 (TID 403). 6731 bytes result sent to driver
23/10/22 15:01:27.471 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 201.0 (TID 404) in 28 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:27.473 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 403) in 30 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:27.473 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
23/10/22 15:01:27.473 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 201 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.041 s
23/10/22 15:01:27.473 dag-scheduler-event-loop INFO DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:27.473 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 201: Stage finished
23/10/22 15:01:27.473 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 110 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.387153 s
23/10/22 15:01:27.475 nioEventLoopGroup-2-2 INFO Instrumentation: [66019354] Number of instances: 3785.
23/10/22 15:01:27.602 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:27.708 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 482 (rdd at LinearRegression.scala:921) as input to shuffle 70
23/10/22 15:01:27.709 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 111 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 15:01:27.709 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 202 (rdd at LinearRegression.scala:921)
23/10/22 15:01:27.709 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:27.709 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:27.709 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 202 (MapPartitionsRDD[482] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:27.712 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 32.7 KiB, free 1036.9 MiB)
23/10/22 15:01:27.714 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 15:01:27.715 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:27.715 dag-scheduler-event-loop INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:27.716 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 202 (MapPartitionsRDD[482] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:27.716 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 202.0 with 1 tasks resource profile 0
23/10/22 15:01:28.160 dispatcher-event-loop-0 WARN TaskSetManager: Stage 202 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:28.160 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 202.0 (TID 405) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:28.161 Executor task launch worker for task 0.0 in stage 202.0 (TID 405) INFO Executor: Running task 0.0 in stage 202.0 (TID 405)
23/10/22 15:01:28.343 Executor task launch worker for task 0.0 in stage 202.0 (TID 405) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:28.873 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:57170 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:28.875 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:57170 in memory (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 15:01:29.648 Executor task launch worker for task 0.0 in stage 202.0 (TID 405) INFO Executor: Finished task 0.0 in stage 202.0 (TID 405). 2147 bytes result sent to driver
23/10/22 15:01:29.649 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 202.0 (TID 405) in 1931 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:29.649 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool 
23/10/22 15:01:29.650 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 202 (rdd at LinearRegression.scala:921) finished in 1.940 s
23/10/22 15:01:29.651 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:29.651 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:29.651 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:29.651 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:29.659 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(70), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:29.666 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 486 (rdd at LinearRegression.scala:921) as input to shuffle 71
23/10/22 15:01:29.666 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 112 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 15:01:29.666 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 204 (rdd at LinearRegression.scala:921)
23/10/22 15:01:29.666 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 203)
23/10/22 15:01:29.667 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:29.667 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 204 (MapPartitionsRDD[486] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:29.671 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:29.672 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 15:01:29.673 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:57170 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 15:01:29.674 dag-scheduler-event-loop INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:29.674 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 204 (MapPartitionsRDD[486] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:29.674 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 204.0 with 8 tasks resource profile 0
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 406) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 204.0 (TID 407) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 204.0 (TID 408) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 204.0 (TID 409) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 204.0 (TID 410) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 204.0 (TID 411) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 204.0 (TID 412) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 204.0 (TID 413) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:29.675 Executor task launch worker for task 1.0 in stage 204.0 (TID 407) INFO Executor: Running task 1.0 in stage 204.0 (TID 407)
23/10/22 15:01:29.677 Executor task launch worker for task 0.0 in stage 204.0 (TID 406) INFO Executor: Running task 0.0 in stage 204.0 (TID 406)
23/10/22 15:01:29.677 Executor task launch worker for task 7.0 in stage 204.0 (TID 413) INFO Executor: Running task 7.0 in stage 204.0 (TID 413)
23/10/22 15:01:29.677 Executor task launch worker for task 6.0 in stage 204.0 (TID 412) INFO Executor: Running task 6.0 in stage 204.0 (TID 412)
23/10/22 15:01:29.677 Executor task launch worker for task 5.0 in stage 204.0 (TID 411) INFO Executor: Running task 5.0 in stage 204.0 (TID 411)
23/10/22 15:01:29.677 Executor task launch worker for task 2.0 in stage 204.0 (TID 408) INFO Executor: Running task 2.0 in stage 204.0 (TID 408)
23/10/22 15:01:29.675 Executor task launch worker for task 3.0 in stage 204.0 (TID 409) INFO Executor: Running task 3.0 in stage 204.0 (TID 409)
23/10/22 15:01:29.685 Executor task launch worker for task 2.0 in stage 204.0 (TID 408) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.685 Executor task launch worker for task 3.0 in stage 204.0 (TID 409) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.685 Executor task launch worker for task 2.0 in stage 204.0 (TID 408) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:29.685 Executor task launch worker for task 3.0 in stage 204.0 (TID 409) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:29.686 Executor task launch worker for task 6.0 in stage 204.0 (TID 412) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.686 Executor task launch worker for task 6.0 in stage 204.0 (TID 412) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:29.687 Executor task launch worker for task 5.0 in stage 204.0 (TID 411) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.687 Executor task launch worker for task 5.0 in stage 204.0 (TID 411) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:29.677 Executor task launch worker for task 4.0 in stage 204.0 (TID 410) INFO Executor: Running task 4.0 in stage 204.0 (TID 410)
23/10/22 15:01:29.688 Executor task launch worker for task 7.0 in stage 204.0 (TID 413) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.688 Executor task launch worker for task 7.0 in stage 204.0 (TID 413) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:29.690 Executor task launch worker for task 1.0 in stage 204.0 (TID 407) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.690 Executor task launch worker for task 1.0 in stage 204.0 (TID 407) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:29.697 Executor task launch worker for task 4.0 in stage 204.0 (TID 410) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.697 Executor task launch worker for task 4.0 in stage 204.0 (TID 410) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:29.699 Executor task launch worker for task 0.0 in stage 204.0 (TID 406) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:29.699 Executor task launch worker for task 0.0 in stage 204.0 (TID 406) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 15:01:29.704 Executor task launch worker for task 2.0 in stage 204.0 (TID 408) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.714 Executor task launch worker for task 4.0 in stage 204.0 (TID 410) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.715 Executor task launch worker for task 5.0 in stage 204.0 (TID 411) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.715 Executor task launch worker for task 3.0 in stage 204.0 (TID 409) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.718 Executor task launch worker for task 6.0 in stage 204.0 (TID 412) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.735 Executor task launch worker for task 1.0 in stage 204.0 (TID 407) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.739 Executor task launch worker for task 7.0 in stage 204.0 (TID 413) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.759 Executor task launch worker for task 5.0 in stage 204.0 (TID 411) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.764 Executor task launch worker for task 0.0 in stage 204.0 (TID 406) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.771 Executor task launch worker for task 6.0 in stage 204.0 (TID 412) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.783 Executor task launch worker for task 4.0 in stage 204.0 (TID 410) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.799 Executor task launch worker for task 3.0 in stage 204.0 (TID 409) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.804 Executor task launch worker for task 7.0 in stage 204.0 (TID 413) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.811 Executor task launch worker for task 2.0 in stage 204.0 (TID 408) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.838 Executor task launch worker for task 1.0 in stage 204.0 (TID 407) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:29.861 Executor task launch worker for task 0.0 in stage 204.0 (TID 406) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.037 Executor task launch worker for task 5.0 in stage 204.0 (TID 411) INFO Executor: Finished task 5.0 in stage 204.0 (TID 411). 4899 bytes result sent to driver
23/10/22 15:01:30.041 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 204.0 (TID 411) in 365 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:30.061 Executor task launch worker for task 4.0 in stage 204.0 (TID 410) INFO Executor: Finished task 4.0 in stage 204.0 (TID 410). 4942 bytes result sent to driver
23/10/22 15:01:30.063 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 204.0 (TID 410) in 388 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:30.087 Executor task launch worker for task 0.0 in stage 204.0 (TID 406) INFO Executor: Finished task 0.0 in stage 204.0 (TID 406). 4942 bytes result sent to driver
23/10/22 15:01:30.088 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 406) in 413 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:30.097 Executor task launch worker for task 6.0 in stage 204.0 (TID 412) INFO Executor: Finished task 6.0 in stage 204.0 (TID 412). 4899 bytes result sent to driver
23/10/22 15:01:30.098 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 204.0 (TID 412) in 423 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:30.119 Executor task launch worker for task 7.0 in stage 204.0 (TID 413) INFO Executor: Finished task 7.0 in stage 204.0 (TID 413). 4899 bytes result sent to driver
23/10/22 15:01:30.121 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 204.0 (TID 413) in 446 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:30.151 Executor task launch worker for task 3.0 in stage 204.0 (TID 409) INFO Executor: Finished task 3.0 in stage 204.0 (TID 409). 4942 bytes result sent to driver
23/10/22 15:01:30.154 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 204.0 (TID 409) in 479 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:30.180 Executor task launch worker for task 2.0 in stage 204.0 (TID 408) INFO Executor: Finished task 2.0 in stage 204.0 (TID 408). 4899 bytes result sent to driver
23/10/22 15:01:30.180 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 204.0 (TID 408) in 505 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:30.196 Executor task launch worker for task 1.0 in stage 204.0 (TID 407) INFO Executor: Finished task 1.0 in stage 204.0 (TID 407). 4899 bytes result sent to driver
23/10/22 15:01:30.197 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 204.0 (TID 407) in 522 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:30.197 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
23/10/22 15:01:30.198 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 204 (rdd at LinearRegression.scala:921) finished in 0.530 s
23/10/22 15:01:30.198 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:30.198 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:30.198 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:30.199 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:30.210 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(71), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:30.244 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.6601 ms
23/10/22 15:01:30.314 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:01:30.314 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 496 (treeAggregate at Statistics.scala:58) as input to shuffle 72
23/10/22 15:01:30.314 dag-scheduler-event-loop INFO DAGScheduler: Got job 113 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:01:30.314 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 208 (treeAggregate at Statistics.scala:58)
23/10/22 15:01:30.314 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 207)
23/10/22 15:01:30.314 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 207)
23/10/22 15:01:30.314 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 207 (MapPartitionsRDD[496] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:30.322 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 83.8 KiB, free 1037.0 MiB)
23/10/22 15:01:30.324 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 35.7 KiB, free 1036.9 MiB)
23/10/22 15:01:30.324 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:57170 (size: 35.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:30.324 dag-scheduler-event-loop INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:30.324 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 207 (MapPartitionsRDD[496] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:30.324 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 207.0 with 8 tasks resource profile 0
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 414) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 415) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 207.0 (TID 416) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 207.0 (TID 417) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 207.0 (TID 418) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 207.0 (TID 419) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 207.0 (TID 420) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 207.0 (TID 421) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:30.324 Executor task launch worker for task 0.0 in stage 207.0 (TID 414) INFO Executor: Running task 0.0 in stage 207.0 (TID 414)
23/10/22 15:01:30.331 Executor task launch worker for task 5.0 in stage 207.0 (TID 419) INFO Executor: Running task 5.0 in stage 207.0 (TID 419)
23/10/22 15:01:30.324 Executor task launch worker for task 4.0 in stage 207.0 (TID 418) INFO Executor: Running task 4.0 in stage 207.0 (TID 418)
23/10/22 15:01:30.331 Executor task launch worker for task 7.0 in stage 207.0 (TID 421) INFO Executor: Running task 7.0 in stage 207.0 (TID 421)
23/10/22 15:01:30.331 Executor task launch worker for task 6.0 in stage 207.0 (TID 420) INFO Executor: Running task 6.0 in stage 207.0 (TID 420)
23/10/22 15:01:30.331 Executor task launch worker for task 1.0 in stage 207.0 (TID 415) INFO Executor: Running task 1.0 in stage 207.0 (TID 415)
23/10/22 15:01:30.331 Executor task launch worker for task 3.0 in stage 207.0 (TID 417) INFO Executor: Running task 3.0 in stage 207.0 (TID 417)
23/10/22 15:01:30.331 Executor task launch worker for task 2.0 in stage 207.0 (TID 416) INFO Executor: Running task 2.0 in stage 207.0 (TID 416)
23/10/22 15:01:30.345 Executor task launch worker for task 5.0 in stage 207.0 (TID 419) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.347 Executor task launch worker for task 1.0 in stage 207.0 (TID 415) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.345 Executor task launch worker for task 2.0 in stage 207.0 (TID 416) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.348 Executor task launch worker for task 1.0 in stage 207.0 (TID 415) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:30.348 Executor task launch worker for task 4.0 in stage 207.0 (TID 418) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.348 Executor task launch worker for task 4.0 in stage 207.0 (TID 418) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:30.347 Executor task launch worker for task 5.0 in stage 207.0 (TID 419) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:30.347 Executor task launch worker for task 0.0 in stage 207.0 (TID 414) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.350 Executor task launch worker for task 0.0 in stage 207.0 (TID 414) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 15:01:30.347 Executor task launch worker for task 3.0 in stage 207.0 (TID 417) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.349 Executor task launch worker for task 7.0 in stage 207.0 (TID 421) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.348 Executor task launch worker for task 2.0 in stage 207.0 (TID 416) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:30.350 Executor task launch worker for task 3.0 in stage 207.0 (TID 417) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 15:01:30.350 Executor task launch worker for task 7.0 in stage 207.0 (TID 421) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:30.353 Executor task launch worker for task 6.0 in stage 207.0 (TID 420) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.353 Executor task launch worker for task 6.0 in stage 207.0 (TID 420) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:30.382 Executor task launch worker for task 4.0 in stage 207.0 (TID 418) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.382 Executor task launch worker for task 1.0 in stage 207.0 (TID 415) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.382 Executor task launch worker for task 0.0 in stage 207.0 (TID 414) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.385 Executor task launch worker for task 2.0 in stage 207.0 (TID 416) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.385 Executor task launch worker for task 7.0 in stage 207.0 (TID 421) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.395 Executor task launch worker for task 5.0 in stage 207.0 (TID 419) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.426 Executor task launch worker for task 3.0 in stage 207.0 (TID 417) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.426 Executor task launch worker for task 6.0 in stage 207.0 (TID 420) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:30.515 Executor task launch worker for task 1.0 in stage 207.0 (TID 415) INFO Executor: Finished task 1.0 in stage 207.0 (TID 415). 6605 bytes result sent to driver
23/10/22 15:01:30.516 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 415) in 192 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:30.532 Executor task launch worker for task 2.0 in stage 207.0 (TID 416) INFO Executor: Finished task 2.0 in stage 207.0 (TID 416). 6562 bytes result sent to driver
23/10/22 15:01:30.533 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 207.0 (TID 416) in 209 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:30.548 Executor task launch worker for task 5.0 in stage 207.0 (TID 419) INFO Executor: Finished task 5.0 in stage 207.0 (TID 419). 6562 bytes result sent to driver
23/10/22 15:01:30.548 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 207.0 (TID 419) in 224 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:30.561 Executor task launch worker for task 0.0 in stage 207.0 (TID 414) INFO Executor: Finished task 0.0 in stage 207.0 (TID 414). 6562 bytes result sent to driver
23/10/22 15:01:30.564 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 414) in 240 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:30.575 Executor task launch worker for task 3.0 in stage 207.0 (TID 417) INFO Executor: Finished task 3.0 in stage 207.0 (TID 417). 6605 bytes result sent to driver
23/10/22 15:01:30.575 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 207.0 (TID 417) in 251 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:30.585 Executor task launch worker for task 4.0 in stage 207.0 (TID 418) INFO Executor: Finished task 4.0 in stage 207.0 (TID 418). 6562 bytes result sent to driver
23/10/22 15:01:30.587 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 207.0 (TID 418) in 263 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:30.596 Executor task launch worker for task 7.0 in stage 207.0 (TID 421) INFO Executor: Finished task 7.0 in stage 207.0 (TID 421). 6605 bytes result sent to driver
23/10/22 15:01:30.598 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 207.0 (TID 421) in 273 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:30.604 Executor task launch worker for task 6.0 in stage 207.0 (TID 420) INFO Executor: Finished task 6.0 in stage 207.0 (TID 420). 6605 bytes result sent to driver
23/10/22 15:01:30.606 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 207.0 (TID 420) in 282 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:30.606 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
23/10/22 15:01:30.606 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 207 (treeAggregate at Statistics.scala:58) finished in 0.292 s
23/10/22 15:01:30.606 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:30.606 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:30.606 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 208)
23/10/22 15:01:30.606 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:30.606 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 208 (MapPartitionsRDD[498] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:30.609 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 84.9 KiB, free 1036.8 MiB)
23/10/22 15:01:30.610 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 1036.8 MiB)
23/10/22 15:01:30.610 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:57170 (size: 36.1 KiB, free: 1037.0 MiB)
23/10/22 15:01:30.611 dag-scheduler-event-loop INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:30.611 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 208 (MapPartitionsRDD[498] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:30.611 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 208.0 with 2 tasks resource profile 0
23/10/22 15:01:30.612 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 422) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:30.612 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 208.0 (TID 423) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:30.612 Executor task launch worker for task 1.0 in stage 208.0 (TID 423) INFO Executor: Running task 1.0 in stage 208.0 (TID 423)
23/10/22 15:01:30.612 Executor task launch worker for task 0.0 in stage 208.0 (TID 422) INFO Executor: Running task 0.0 in stage 208.0 (TID 422)
23/10/22 15:01:30.617 Executor task launch worker for task 0.0 in stage 208.0 (TID 422) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.617 Executor task launch worker for task 1.0 in stage 208.0 (TID 423) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:30.617 Executor task launch worker for task 0.0 in stage 208.0 (TID 422) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:30.617 Executor task launch worker for task 1.0 in stage 208.0 (TID 423) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:30.621 Executor task launch worker for task 0.0 in stage 208.0 (TID 422) INFO Executor: Finished task 0.0 in stage 208.0 (TID 422). 7630 bytes result sent to driver
23/10/22 15:01:30.621 Executor task launch worker for task 1.0 in stage 208.0 (TID 423) INFO Executor: Finished task 1.0 in stage 208.0 (TID 423). 7630 bytes result sent to driver
23/10/22 15:01:30.621 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 422) in 9 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:30.621 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 208.0 (TID 423) in 9 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:30.621 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
23/10/22 15:01:30.622 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 208 (treeAggregate at Statistics.scala:58) finished in 0.015 s
23/10/22 15:01:30.622 dag-scheduler-event-loop INFO DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:30.622 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished
23/10/22 15:01:30.622 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 113 finished: treeAggregate at Statistics.scala:58, took 0.307545 s
23/10/22 15:01:30.623 nioEventLoopGroup-2-2 INFO Instrumentation: [4649d649] training finished
23/10/22 15:01:31.556 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:31.557 dag-scheduler-event-loop INFO DAGScheduler: Got job 114 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:31.557 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 209 (collect at utils.scala:26)
23/10/22 15:01:31.558 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:31.558 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:31.558 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[500] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:31.560 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:31.562 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:31.563 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:31.564 dag-scheduler-event-loop INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:31.565 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (MapPartitionsRDD[500] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:31.565 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 209.0 with 1 tasks resource profile 0
23/10/22 15:01:31.565 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 424) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:31.565 Executor task launch worker for task 0.0 in stage 209.0 (TID 424) INFO Executor: Running task 0.0 in stage 209.0 (TID 424)
23/10/22 15:01:31.565 Executor task launch worker for task 0.0 in stage 209.0 (TID 424) INFO Executor: Finished task 0.0 in stage 209.0 (TID 424). 1370 bytes result sent to driver
23/10/22 15:01:31.575 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 424) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:31.575 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
23/10/22 15:01:31.576 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 209 (collect at utils.scala:26) finished in 0.015 s
23/10/22 15:01:31.576 dag-scheduler-event-loop INFO DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:31.576 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 209: Stage finished
23/10/22 15:01:31.576 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 114 finished: collect at utils.scala:26, took 0.019236 s
23/10/22 15:01:32.195 nioEventLoopGroup-2-2 INFO Instrumentation: [4df17f32] training finished
23/10/22 15:01:32.335 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:32.335 dag-scheduler-event-loop INFO DAGScheduler: Got job 115 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:32.335 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 210 (collect at utils.scala:26)
23/10/22 15:01:32.335 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:32.335 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:32.335 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[502] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:32.350 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:32.350 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:32.350 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:32.350 dag-scheduler-event-loop INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:32.354 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[502] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:32.354 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 210.0 with 1 tasks resource profile 0
23/10/22 15:01:32.354 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 425) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:32.355 Executor task launch worker for task 0.0 in stage 210.0 (TID 425) INFO Executor: Running task 0.0 in stage 210.0 (TID 425)
23/10/22 15:01:32.357 Executor task launch worker for task 0.0 in stage 210.0 (TID 425) INFO Executor: Finished task 0.0 in stage 210.0 (TID 425). 1327 bytes result sent to driver
23/10/22 15:01:32.358 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 425) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:32.358 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
23/10/22 15:01:32.358 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 210 (collect at utils.scala:26) finished in 0.023 s
23/10/22 15:01:32.359 dag-scheduler-event-loop INFO DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:32.359 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 210: Stage finished
23/10/22 15:01:32.359 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 115 finished: collect at utils.scala:26, took 0.010563 s
23/10/22 15:01:32.976 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Got job 116 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 211 (collect at utils.scala:26)
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[504] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:32.976 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 211 (MapPartitionsRDD[504] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 211.0 with 1 tasks resource profile 0
23/10/22 15:01:32.976 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 426) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:32.976 Executor task launch worker for task 0.0 in stage 211.0 (TID 426) INFO Executor: Running task 0.0 in stage 211.0 (TID 426)
23/10/22 15:01:32.976 Executor task launch worker for task 0.0 in stage 211.0 (TID 426) INFO Executor: Finished task 0.0 in stage 211.0 (TID 426). 1284 bytes result sent to driver
23/10/22 15:01:32.976 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 426) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:32.976 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 211 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO DAGScheduler: Job 116 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:32.976 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 211: Stage finished
23/10/22 15:01:32.976 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 116 finished: collect at utils.scala:26, took 0.006187 s
23/10/22 15:01:33.715 nioEventLoopGroup-2-2 INFO Instrumentation: [1b28f5b7] training finished
23/10/22 15:01:33.726 nioEventLoopGroup-2-2 INFO Instrumentation: [e77a95fa] training finished
23/10/22 15:01:33.726 nioEventLoopGroup-2-2 INFO Instrumentation: [ce9fcf5f] Stage class: LinearRegression
23/10/22 15:01:33.726 nioEventLoopGroup-2-2 INFO Instrumentation: [ce9fcf5f] Stage uid: linear_regression__7431b09c_0fdc_4d4e_ac90_4f48db12cb99
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 507 (rdd at Instrumentation.scala:62) as input to shuffle 73
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 117 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 212 (rdd at Instrumentation.scala:62)
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 212 (MapPartitionsRDD[507] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:33.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:57170 in memory (size: 35.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 32.7 KiB, free 1036.9 MiB)
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.9 MiB)
23/10/22 15:01:33.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:57170 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 212 (MapPartitionsRDD[507] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:33.759 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 212.0 with 1 tasks resource profile 0
23/10/22 15:01:33.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.775 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.776 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:57170 in memory (size: 36.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:33.992 dispatcher-event-loop-4 WARN TaskSetManager: Stage 212 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:33.992 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 427) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:33.992 Executor task launch worker for task 0.0 in stage 212.0 (TID 427) INFO Executor: Running task 0.0 in stage 212.0 (TID 427)
23/10/22 15:01:34.164 Executor task launch worker for task 0.0 in stage 212.0 (TID 427) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:34.299 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:35.256 Executor task launch worker for task 0.0 in stage 212.0 (TID 427) INFO Executor: Finished task 0.0 in stage 212.0 (TID 427). 2147 bytes result sent to driver
23/10/22 15:01:35.256 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 427) in 1497 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:35.256 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
23/10/22 15:01:35.258 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 212 (rdd at Instrumentation.scala:62) finished in 1.499 s
23/10/22 15:01:35.258 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:35.258 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:35.258 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:35.258 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:35.259 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(73), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 511 (rdd at Instrumentation.scala:62) as input to shuffle 74
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 118 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 214 (rdd at Instrumentation.scala:62)
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 213)
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 214 (MapPartitionsRDD[511] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:35.259 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 214 (MapPartitionsRDD[511] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:35.259 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 214.0 with 8 tasks resource profile 0
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 428) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 214.0 (TID 429) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 214.0 (TID 430) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 214.0 (TID 431) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 214.0 (TID 432) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 214.0 (TID 433) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 214.0 (TID 434) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 214.0 (TID 435) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:35.259 Executor task launch worker for task 2.0 in stage 214.0 (TID 430) INFO Executor: Running task 2.0 in stage 214.0 (TID 430)
23/10/22 15:01:35.270 Executor task launch worker for task 6.0 in stage 214.0 (TID 434) INFO Executor: Running task 6.0 in stage 214.0 (TID 434)
23/10/22 15:01:35.259 Executor task launch worker for task 3.0 in stage 214.0 (TID 431) INFO Executor: Running task 3.0 in stage 214.0 (TID 431)
23/10/22 15:01:35.259 Executor task launch worker for task 1.0 in stage 214.0 (TID 429) INFO Executor: Running task 1.0 in stage 214.0 (TID 429)
23/10/22 15:01:35.259 Executor task launch worker for task 4.0 in stage 214.0 (TID 432) INFO Executor: Running task 4.0 in stage 214.0 (TID 432)
23/10/22 15:01:35.259 Executor task launch worker for task 0.0 in stage 214.0 (TID 428) INFO Executor: Running task 0.0 in stage 214.0 (TID 428)
23/10/22 15:01:35.270 Executor task launch worker for task 5.0 in stage 214.0 (TID 433) INFO Executor: Running task 5.0 in stage 214.0 (TID 433)
23/10/22 15:01:35.270 Executor task launch worker for task 7.0 in stage 214.0 (TID 435) INFO Executor: Running task 7.0 in stage 214.0 (TID 435)
23/10/22 15:01:35.274 Executor task launch worker for task 4.0 in stage 214.0 (TID 432) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.274 Executor task launch worker for task 4.0 in stage 214.0 (TID 432) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.274 Executor task launch worker for task 1.0 in stage 214.0 (TID 429) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.275 Executor task launch worker for task 1.0 in stage 214.0 (TID 429) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.274 Executor task launch worker for task 7.0 in stage 214.0 (TID 435) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.275 Executor task launch worker for task 7.0 in stage 214.0 (TID 435) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.275 Executor task launch worker for task 5.0 in stage 214.0 (TID 433) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.275 Executor task launch worker for task 5.0 in stage 214.0 (TID 433) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.274 Executor task launch worker for task 3.0 in stage 214.0 (TID 431) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.275 Executor task launch worker for task 3.0 in stage 214.0 (TID 431) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:35.276 Executor task launch worker for task 0.0 in stage 214.0 (TID 428) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.276 Executor task launch worker for task 0.0 in stage 214.0 (TID 428) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.276 Executor task launch worker for task 6.0 in stage 214.0 (TID 434) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.276 Executor task launch worker for task 6.0 in stage 214.0 (TID 434) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.276 Executor task launch worker for task 2.0 in stage 214.0 (TID 430) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:35.276 Executor task launch worker for task 2.0 in stage 214.0 (TID 430) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:35.276 Executor task launch worker for task 1.0 in stage 214.0 (TID 429) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.276 Executor task launch worker for task 7.0 in stage 214.0 (TID 435) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.276 Executor task launch worker for task 4.0 in stage 214.0 (TID 432) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.276 Executor task launch worker for task 0.0 in stage 214.0 (TID 428) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.276 Executor task launch worker for task 5.0 in stage 214.0 (TID 433) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.290 Executor task launch worker for task 6.0 in stage 214.0 (TID 434) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.300 Executor task launch worker for task 4.0 in stage 214.0 (TID 432) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.300 Executor task launch worker for task 7.0 in stage 214.0 (TID 435) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.300 Executor task launch worker for task 5.0 in stage 214.0 (TID 433) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.315 Executor task launch worker for task 6.0 in stage 214.0 (TID 434) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.317 Executor task launch worker for task 0.0 in stage 214.0 (TID 428) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.331 Executor task launch worker for task 1.0 in stage 214.0 (TID 429) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.331 Executor task launch worker for task 3.0 in stage 214.0 (TID 431) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.359 Executor task launch worker for task 3.0 in stage 214.0 (TID 431) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.359 Executor task launch worker for task 2.0 in stage 214.0 (TID 430) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.411 Executor task launch worker for task 2.0 in stage 214.0 (TID 430) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:35.488 Executor task launch worker for task 0.0 in stage 214.0 (TID 428) INFO Executor: Finished task 0.0 in stage 214.0 (TID 428). 4942 bytes result sent to driver
23/10/22 15:01:35.490 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 428) in 231 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:35.498 Executor task launch worker for task 1.0 in stage 214.0 (TID 429) INFO Executor: Finished task 1.0 in stage 214.0 (TID 429). 4899 bytes result sent to driver
23/10/22 15:01:35.499 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 214.0 (TID 429) in 240 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:35.507 Executor task launch worker for task 7.0 in stage 214.0 (TID 435) INFO Executor: Finished task 7.0 in stage 214.0 (TID 435). 4899 bytes result sent to driver
23/10/22 15:01:35.508 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 214.0 (TID 435) in 249 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:35.516 Executor task launch worker for task 4.0 in stage 214.0 (TID 432) INFO Executor: Finished task 4.0 in stage 214.0 (TID 432). 4899 bytes result sent to driver
23/10/22 15:01:35.516 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 214.0 (TID 432) in 257 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:35.526 Executor task launch worker for task 6.0 in stage 214.0 (TID 434) INFO Executor: Finished task 6.0 in stage 214.0 (TID 434). 4899 bytes result sent to driver
23/10/22 15:01:35.529 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 214.0 (TID 434) in 270 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:35.535 Executor task launch worker for task 5.0 in stage 214.0 (TID 433) INFO Executor: Finished task 5.0 in stage 214.0 (TID 433). 4899 bytes result sent to driver
23/10/22 15:01:35.535 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 214.0 (TID 433) in 276 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:35.561 Executor task launch worker for task 3.0 in stage 214.0 (TID 431) INFO Executor: Finished task 3.0 in stage 214.0 (TID 431). 4899 bytes result sent to driver
23/10/22 15:01:35.561 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 214.0 (TID 431) in 302 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:35.564 Executor task launch worker for task 2.0 in stage 214.0 (TID 430) INFO Executor: Finished task 2.0 in stage 214.0 (TID 430). 4942 bytes result sent to driver
23/10/22 15:01:35.564 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 214.0 (TID 430) in 305 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:35.564 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
23/10/22 15:01:35.564 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 214 (rdd at Instrumentation.scala:62) finished in 0.305 s
23/10/22 15:01:35.564 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:35.564 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:35.564 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:35.564 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:35.571 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(74), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:35.593 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.3714 ms
23/10/22 15:01:35.608 nioEventLoopGroup-2-2 INFO Instrumentation: [ce9fcf5f] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 15:01:35.609 nioEventLoopGroup-2-2 INFO Instrumentation: [ce9fcf5f] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 15:01:35.610 nioEventLoopGroup-2-2 INFO Instrumentation: [ce9fcf5f] {"numFeatures":3}
23/10/22 15:01:35.673 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 520 (rdd at LinearRegression.scala:348) as input to shuffle 75
23/10/22 15:01:35.673 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 119 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 15:01:35.673 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 215 (rdd at LinearRegression.scala:348)
23/10/22 15:01:35.673 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:35.673 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:35.673 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 215 (MapPartitionsRDD[520] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:35.676 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 15:01:35.676 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 15:01:35.676 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:35.676 dag-scheduler-event-loop INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:35.676 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 215 (MapPartitionsRDD[520] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:35.676 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 215.0 with 1 tasks resource profile 0
23/10/22 15:01:36.009 dispatcher-event-loop-0 WARN TaskSetManager: Stage 215 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:36.009 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 436) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:36.009 Executor task launch worker for task 0.0 in stage 215.0 (TID 436) INFO Executor: Running task 0.0 in stage 215.0 (TID 436)
23/10/22 15:01:36.132 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:36.214 Executor task launch worker for task 0.0 in stage 215.0 (TID 436) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:36.416 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:37.258 Executor task launch worker for task 0.0 in stage 215.0 (TID 436) INFO Executor: Finished task 0.0 in stage 215.0 (TID 436). 2147 bytes result sent to driver
23/10/22 15:01:37.259 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 436) in 1583 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:37.259 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 215 (rdd at LinearRegression.scala:348) finished in 1.586 s
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:37.259 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(75), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 524 (rdd at LinearRegression.scala:348) as input to shuffle 76
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 120 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 217 (rdd at LinearRegression.scala:348)
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 216)
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 217 (MapPartitionsRDD[524] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:37.259 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 217 (MapPartitionsRDD[524] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:37.259 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 217.0 with 8 tasks resource profile 0
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 437) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 217.0 (TID 438) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 217.0 (TID 439) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 217.0 (TID 440) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 217.0 (TID 441) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 217.0 (TID 442) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 217.0 (TID 443) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 217.0 (TID 444) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.259 Executor task launch worker for task 3.0 in stage 217.0 (TID 440) INFO Executor: Running task 3.0 in stage 217.0 (TID 440)
23/10/22 15:01:37.273 Executor task launch worker for task 7.0 in stage 217.0 (TID 444) INFO Executor: Running task 7.0 in stage 217.0 (TID 444)
23/10/22 15:01:37.259 Executor task launch worker for task 4.0 in stage 217.0 (TID 441) INFO Executor: Running task 4.0 in stage 217.0 (TID 441)
23/10/22 15:01:37.259 Executor task launch worker for task 2.0 in stage 217.0 (TID 439) INFO Executor: Running task 2.0 in stage 217.0 (TID 439)
23/10/22 15:01:37.259 Executor task launch worker for task 0.0 in stage 217.0 (TID 437) INFO Executor: Running task 0.0 in stage 217.0 (TID 437)
23/10/22 15:01:37.259 Executor task launch worker for task 1.0 in stage 217.0 (TID 438) INFO Executor: Running task 1.0 in stage 217.0 (TID 438)
23/10/22 15:01:37.273 Executor task launch worker for task 5.0 in stage 217.0 (TID 442) INFO Executor: Running task 5.0 in stage 217.0 (TID 442)
23/10/22 15:01:37.273 Executor task launch worker for task 6.0 in stage 217.0 (TID 443) INFO Executor: Running task 6.0 in stage 217.0 (TID 443)
23/10/22 15:01:37.277 Executor task launch worker for task 5.0 in stage 217.0 (TID 442) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.277 Executor task launch worker for task 3.0 in stage 217.0 (TID 440) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.277 Executor task launch worker for task 5.0 in stage 217.0 (TID 442) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.277 Executor task launch worker for task 4.0 in stage 217.0 (TID 441) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.277 Executor task launch worker for task 4.0 in stage 217.0 (TID 441) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.277 Executor task launch worker for task 1.0 in stage 217.0 (TID 438) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.277 Executor task launch worker for task 1.0 in stage 217.0 (TID 438) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.279 Executor task launch worker for task 0.0 in stage 217.0 (TID 437) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.279 Executor task launch worker for task 0.0 in stage 217.0 (TID 437) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.280 Executor task launch worker for task 6.0 in stage 217.0 (TID 443) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.280 Executor task launch worker for task 6.0 in stage 217.0 (TID 443) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.277 Executor task launch worker for task 2.0 in stage 217.0 (TID 439) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.280 Executor task launch worker for task 2.0 in stage 217.0 (TID 439) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 15:01:37.277 Executor task launch worker for task 3.0 in stage 217.0 (TID 440) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.281 Executor task launch worker for task 7.0 in stage 217.0 (TID 444) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.281 Executor task launch worker for task 7.0 in stage 217.0 (TID 444) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.281 Executor task launch worker for task 4.0 in stage 217.0 (TID 441) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.281 Executor task launch worker for task 5.0 in stage 217.0 (TID 442) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.287 Executor task launch worker for task 1.0 in stage 217.0 (TID 438) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.287 Executor task launch worker for task 0.0 in stage 217.0 (TID 437) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.287 Executor task launch worker for task 2.0 in stage 217.0 (TID 439) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.297 Executor task launch worker for task 7.0 in stage 217.0 (TID 444) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.297 Executor task launch worker for task 3.0 in stage 217.0 (TID 440) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.309 Executor task launch worker for task 5.0 in stage 217.0 (TID 442) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.310 Executor task launch worker for task 4.0 in stage 217.0 (TID 441) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.310 Executor task launch worker for task 2.0 in stage 217.0 (TID 439) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.321 Executor task launch worker for task 6.0 in stage 217.0 (TID 443) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.322 Executor task launch worker for task 7.0 in stage 217.0 (TID 444) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.326 Executor task launch worker for task 3.0 in stage 217.0 (TID 440) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.344 Executor task launch worker for task 0.0 in stage 217.0 (TID 437) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.344 Executor task launch worker for task 6.0 in stage 217.0 (TID 443) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.344 Executor task launch worker for task 1.0 in stage 217.0 (TID 438) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.479 Executor task launch worker for task 0.0 in stage 217.0 (TID 437) INFO Executor: Finished task 0.0 in stage 217.0 (TID 437). 4899 bytes result sent to driver
23/10/22 15:01:37.483 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 437) in 224 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:37.487 Executor task launch worker for task 7.0 in stage 217.0 (TID 444) INFO Executor: Finished task 7.0 in stage 217.0 (TID 444). 4899 bytes result sent to driver
23/10/22 15:01:37.487 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 217.0 (TID 444) in 228 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:37.497 Executor task launch worker for task 2.0 in stage 217.0 (TID 439) INFO Executor: Finished task 2.0 in stage 217.0 (TID 439). 4899 bytes result sent to driver
23/10/22 15:01:37.497 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 217.0 (TID 439) in 238 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:37.505 Executor task launch worker for task 5.0 in stage 217.0 (TID 442) INFO Executor: Finished task 5.0 in stage 217.0 (TID 442). 4899 bytes result sent to driver
23/10/22 15:01:37.506 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 217.0 (TID 442) in 247 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:37.515 Executor task launch worker for task 4.0 in stage 217.0 (TID 441) INFO Executor: Finished task 4.0 in stage 217.0 (TID 441). 4899 bytes result sent to driver
23/10/22 15:01:37.516 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 217.0 (TID 441) in 257 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:37.523 Executor task launch worker for task 6.0 in stage 217.0 (TID 443) INFO Executor: Finished task 6.0 in stage 217.0 (TID 443). 4899 bytes result sent to driver
23/10/22 15:01:37.524 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 217.0 (TID 443) in 265 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:37.531 Executor task launch worker for task 1.0 in stage 217.0 (TID 438) INFO Executor: Finished task 1.0 in stage 217.0 (TID 438). 4942 bytes result sent to driver
23/10/22 15:01:37.532 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 217.0 (TID 438) in 273 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:37.547 Executor task launch worker for task 3.0 in stage 217.0 (TID 440) INFO Executor: Finished task 3.0 in stage 217.0 (TID 440). 4942 bytes result sent to driver
23/10/22 15:01:37.548 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 217.0 (TID 440) in 289 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:37.548 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
23/10/22 15:01:37.548 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 217 (rdd at LinearRegression.scala:348) finished in 0.289 s
23/10/22 15:01:37.548 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:37.549 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:37.549 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:37.549 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:37.554 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(76), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:37.592 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 26.2053 ms
23/10/22 15:01:37.605 nioEventLoopGroup-2-2 WARN Instrumentation: [ce9fcf5f] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 15:01:37.626 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 15:01:37.641 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 533 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 77
23/10/22 15:01:37.641 dag-scheduler-event-loop INFO DAGScheduler: Got job 121 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 15:01:37.642 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 221 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 15:01:37.642 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 220)
23/10/22 15:01:37.642 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 220)
23/10/22 15:01:37.642 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 220 (MapPartitionsRDD[533] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:37.643 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 98.9 KiB, free 1036.9 MiB)
23/10/22 15:01:37.643 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 1036.9 MiB)
23/10/22 15:01:37.643 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:57170 (size: 38.9 KiB, free: 1037.1 MiB)
23/10/22 15:01:37.643 dag-scheduler-event-loop INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:37.643 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 220 (MapPartitionsRDD[533] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:37.643 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 220.0 with 8 tasks resource profile 0
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 445) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 220.0 (TID 446) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 220.0 (TID 447) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 220.0 (TID 448) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 220.0 (TID 449) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 220.0 (TID 450) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 220.0 (TID 451) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 220.0 (TID 452) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:37.653 Executor task launch worker for task 2.0 in stage 220.0 (TID 447) INFO Executor: Running task 2.0 in stage 220.0 (TID 447)
23/10/22 15:01:37.653 Executor task launch worker for task 5.0 in stage 220.0 (TID 450) INFO Executor: Running task 5.0 in stage 220.0 (TID 450)
23/10/22 15:01:37.653 Executor task launch worker for task 3.0 in stage 220.0 (TID 448) INFO Executor: Running task 3.0 in stage 220.0 (TID 448)
23/10/22 15:01:37.653 Executor task launch worker for task 1.0 in stage 220.0 (TID 446) INFO Executor: Running task 1.0 in stage 220.0 (TID 446)
23/10/22 15:01:37.653 Executor task launch worker for task 0.0 in stage 220.0 (TID 445) INFO Executor: Running task 0.0 in stage 220.0 (TID 445)
23/10/22 15:01:37.655 Executor task launch worker for task 4.0 in stage 220.0 (TID 449) INFO Executor: Running task 4.0 in stage 220.0 (TID 449)
23/10/22 15:01:37.655 Executor task launch worker for task 7.0 in stage 220.0 (TID 452) INFO Executor: Running task 7.0 in stage 220.0 (TID 452)
23/10/22 15:01:37.655 Executor task launch worker for task 6.0 in stage 220.0 (TID 451) INFO Executor: Running task 6.0 in stage 220.0 (TID 451)
23/10/22 15:01:37.665 Executor task launch worker for task 1.0 in stage 220.0 (TID 446) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.665 Executor task launch worker for task 5.0 in stage 220.0 (TID 450) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.665 Executor task launch worker for task 1.0 in stage 220.0 (TID 446) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.665 Executor task launch worker for task 5.0 in stage 220.0 (TID 450) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.665 Executor task launch worker for task 3.0 in stage 220.0 (TID 448) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.665 Executor task launch worker for task 3.0 in stage 220.0 (TID 448) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.666 Executor task launch worker for task 6.0 in stage 220.0 (TID 451) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.666 Executor task launch worker for task 7.0 in stage 220.0 (TID 452) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.666 Executor task launch worker for task 7.0 in stage 220.0 (TID 452) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.666 Executor task launch worker for task 6.0 in stage 220.0 (TID 451) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.672 Executor task launch worker for task 4.0 in stage 220.0 (TID 449) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.672 Executor task launch worker for task 4.0 in stage 220.0 (TID 449) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.675 Executor task launch worker for task 2.0 in stage 220.0 (TID 447) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.675 Executor task launch worker for task 0.0 in stage 220.0 (TID 445) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.676 Executor task launch worker for task 2.0 in stage 220.0 (TID 447) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.676 Executor task launch worker for task 0.0 in stage 220.0 (TID 445) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.687 Executor task launch worker for task 7.0 in stage 220.0 (TID 452) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.692 Executor task launch worker for task 1.0 in stage 220.0 (TID 446) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.694 Executor task launch worker for task 2.0 in stage 220.0 (TID 447) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.695 Executor task launch worker for task 6.0 in stage 220.0 (TID 451) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.699 Executor task launch worker for task 0.0 in stage 220.0 (TID 445) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.711 Executor task launch worker for task 4.0 in stage 220.0 (TID 449) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.715 Executor task launch worker for task 5.0 in stage 220.0 (TID 450) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.731 Executor task launch worker for task 3.0 in stage 220.0 (TID 448) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:37.789 Executor task launch worker for task 1.0 in stage 220.0 (TID 446) INFO Executor: Finished task 1.0 in stage 220.0 (TID 446). 6605 bytes result sent to driver
23/10/22 15:01:37.793 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 220.0 (TID 446) in 140 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:37.796 Executor task launch worker for task 2.0 in stage 220.0 (TID 447) INFO Executor: Finished task 2.0 in stage 220.0 (TID 447). 6562 bytes result sent to driver
23/10/22 15:01:37.797 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 220.0 (TID 447) in 144 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:37.814 Executor task launch worker for task 0.0 in stage 220.0 (TID 445) INFO Executor: Finished task 0.0 in stage 220.0 (TID 445). 6605 bytes result sent to driver
23/10/22 15:01:37.815 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 445) in 163 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:37.826 Executor task launch worker for task 4.0 in stage 220.0 (TID 449) INFO Executor: Finished task 4.0 in stage 220.0 (TID 449). 6562 bytes result sent to driver
23/10/22 15:01:37.828 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 220.0 (TID 449) in 175 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:37.837 Executor task launch worker for task 7.0 in stage 220.0 (TID 452) INFO Executor: Finished task 7.0 in stage 220.0 (TID 452). 6605 bytes result sent to driver
23/10/22 15:01:37.837 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 220.0 (TID 452) in 184 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:37.849 Executor task launch worker for task 6.0 in stage 220.0 (TID 451) INFO Executor: Finished task 6.0 in stage 220.0 (TID 451). 6605 bytes result sent to driver
23/10/22 15:01:37.849 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 220.0 (TID 451) in 196 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:37.860 Executor task launch worker for task 5.0 in stage 220.0 (TID 450) INFO Executor: Finished task 5.0 in stage 220.0 (TID 450). 6605 bytes result sent to driver
23/10/22 15:01:37.861 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 220.0 (TID 450) in 208 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:37.867 Executor task launch worker for task 3.0 in stage 220.0 (TID 448) INFO Executor: Finished task 3.0 in stage 220.0 (TID 448). 6605 bytes result sent to driver
23/10/22 15:01:37.867 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 220.0 (TID 448) in 214 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:37.867 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
23/10/22 15:01:37.867 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 220 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.224 s
23/10/22 15:01:37.867 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:37.867 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:37.875 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 221)
23/10/22 15:01:37.875 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:37.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[535] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:01:37.878 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 99.9 KiB, free 1036.8 MiB)
23/10/22 15:01:37.878 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 1036.8 MiB)
23/10/22 15:01:37.878 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:57170 (size: 39.4 KiB, free: 1037.0 MiB)
23/10/22 15:01:37.878 dag-scheduler-event-loop INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:37.878 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 221 (MapPartitionsRDD[535] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:37.878 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 221.0 with 2 tasks resource profile 0
23/10/22 15:01:37.878 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 453) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:37.878 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 454) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:37.878 Executor task launch worker for task 0.0 in stage 221.0 (TID 453) INFO Executor: Running task 0.0 in stage 221.0 (TID 453)
23/10/22 15:01:37.878 Executor task launch worker for task 1.0 in stage 221.0 (TID 454) INFO Executor: Running task 1.0 in stage 221.0 (TID 454)
23/10/22 15:01:37.893 Executor task launch worker for task 0.0 in stage 221.0 (TID 453) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.893 Executor task launch worker for task 0.0 in stage 221.0 (TID 453) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.893 Executor task launch worker for task 1.0 in stage 221.0 (TID 454) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:37.896 Executor task launch worker for task 1.0 in stage 221.0 (TID 454) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:37.896 Executor task launch worker for task 0.0 in stage 221.0 (TID 453) INFO Executor: Finished task 0.0 in stage 221.0 (TID 453). 6857 bytes result sent to driver
23/10/22 15:01:37.896 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 453) in 18 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:37.896 Executor task launch worker for task 1.0 in stage 221.0 (TID 454) INFO Executor: Finished task 1.0 in stage 221.0 (TID 454). 6857 bytes result sent to driver
23/10/22 15:01:37.896 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 454) in 18 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:37.896 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
23/10/22 15:01:37.896 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 221 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.020 s
23/10/22 15:01:37.896 dag-scheduler-event-loop INFO DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:37.896 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished
23/10/22 15:01:37.896 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 121 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.263376 s
23/10/22 15:01:37.896 nioEventLoopGroup-2-2 INFO Instrumentation: [ce9fcf5f] Number of instances: 3785.
23/10/22 15:01:38.010 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 538 (rdd at LinearRegression.scala:921) as input to shuffle 78
23/10/22 15:01:38.010 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 122 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 15:01:38.010 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 222 (rdd at LinearRegression.scala:921)
23/10/22 15:01:38.010 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:38.010 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:38.010 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 222 (MapPartitionsRDD[538] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:38.025 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 32.7 KiB, free 1036.7 MiB)
23/10/22 15:01:38.026 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 15:01:38.026 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:57170 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 15:01:38.026 dag-scheduler-event-loop INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:38.026 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 222 (MapPartitionsRDD[538] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:38.026 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0
23/10/22 15:01:38.459 dispatcher-event-loop-6 WARN TaskSetManager: Stage 222 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:38.459 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 455) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:38.459 Executor task launch worker for task 0.0 in stage 222.0 (TID 455) INFO Executor: Running task 0.0 in stage 222.0 (TID 455)
23/10/22 15:01:38.544 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:57170 in memory (size: 38.9 KiB, free: 1037.1 MiB)
23/10/22 15:01:38.545 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:57170 in memory (size: 39.4 KiB, free: 1037.1 MiB)
23/10/22 15:01:38.545 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:38.692 Executor task launch worker for task 0.0 in stage 222.0 (TID 455) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:38.887 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:39.948 Executor task launch worker for task 0.0 in stage 222.0 (TID 455) INFO Executor: Finished task 0.0 in stage 222.0 (TID 455). 2147 bytes result sent to driver
23/10/22 15:01:39.948 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 455) in 1922 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:39.948 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
23/10/22 15:01:39.948 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 222 (rdd at LinearRegression.scala:921) finished in 1.938 s
23/10/22 15:01:39.948 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:39.948 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:39.948 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:39.948 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:39.948 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(78), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:01:39.959 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 542 (rdd at LinearRegression.scala:921) as input to shuffle 79
23/10/22 15:01:39.960 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 123 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 15:01:39.960 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 224 (rdd at LinearRegression.scala:921)
23/10/22 15:01:39.960 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 223)
23/10/22 15:01:39.960 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:39.960 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 224 (MapPartitionsRDD[542] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:01:39.962 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 15:01:39.962 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 15:01:39.963 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:57170 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:39.963 dag-scheduler-event-loop INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:39.963 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 224 (MapPartitionsRDD[542] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:39.964 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 224.0 with 8 tasks resource profile 0
23/10/22 15:01:39.964 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 456) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 457) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 458) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 459) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 460) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 461) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 462) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 463) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:39.965 Executor task launch worker for task 0.0 in stage 224.0 (TID 456) INFO Executor: Running task 0.0 in stage 224.0 (TID 456)
23/10/22 15:01:39.965 Executor task launch worker for task 2.0 in stage 224.0 (TID 458) INFO Executor: Running task 2.0 in stage 224.0 (TID 458)
23/10/22 15:01:39.965 Executor task launch worker for task 5.0 in stage 224.0 (TID 461) INFO Executor: Running task 5.0 in stage 224.0 (TID 461)
23/10/22 15:01:39.965 Executor task launch worker for task 4.0 in stage 224.0 (TID 460) INFO Executor: Running task 4.0 in stage 224.0 (TID 460)
23/10/22 15:01:39.965 Executor task launch worker for task 7.0 in stage 224.0 (TID 463) INFO Executor: Running task 7.0 in stage 224.0 (TID 463)
23/10/22 15:01:39.965 Executor task launch worker for task 3.0 in stage 224.0 (TID 459) INFO Executor: Running task 3.0 in stage 224.0 (TID 459)
23/10/22 15:01:39.965 Executor task launch worker for task 1.0 in stage 224.0 (TID 457) INFO Executor: Running task 1.0 in stage 224.0 (TID 457)
23/10/22 15:01:39.965 Executor task launch worker for task 6.0 in stage 224.0 (TID 462) INFO Executor: Running task 6.0 in stage 224.0 (TID 462)
23/10/22 15:01:39.969 Executor task launch worker for task 2.0 in stage 224.0 (TID 458) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.969 Executor task launch worker for task 2.0 in stage 224.0 (TID 458) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.970 Executor task launch worker for task 4.0 in stage 224.0 (TID 460) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.970 Executor task launch worker for task 4.0 in stage 224.0 (TID 460) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.969 Executor task launch worker for task 5.0 in stage 224.0 (TID 461) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.970 Executor task launch worker for task 5.0 in stage 224.0 (TID 461) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.969 Executor task launch worker for task 7.0 in stage 224.0 (TID 463) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.972 Executor task launch worker for task 7.0 in stage 224.0 (TID 463) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 15:01:39.972 Executor task launch worker for task 0.0 in stage 224.0 (TID 456) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.972 Executor task launch worker for task 1.0 in stage 224.0 (TID 457) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.973 Executor task launch worker for task 0.0 in stage 224.0 (TID 456) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.973 Executor task launch worker for task 1.0 in stage 224.0 (TID 457) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.972 Executor task launch worker for task 6.0 in stage 224.0 (TID 462) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.973 Executor task launch worker for task 3.0 in stage 224.0 (TID 459) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:39.973 Executor task launch worker for task 6.0 in stage 224.0 (TID 462) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.973 Executor task launch worker for task 3.0 in stage 224.0 (TID 459) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:39.982 Executor task launch worker for task 2.0 in stage 224.0 (TID 458) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:39.982 Executor task launch worker for task 5.0 in stage 224.0 (TID 461) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:39.982 Executor task launch worker for task 7.0 in stage 224.0 (TID 463) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:39.988 Executor task launch worker for task 6.0 in stage 224.0 (TID 462) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:39.993 Executor task launch worker for task 0.0 in stage 224.0 (TID 456) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.001 Executor task launch worker for task 3.0 in stage 224.0 (TID 459) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.014 Executor task launch worker for task 4.0 in stage 224.0 (TID 460) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.017 Executor task launch worker for task 2.0 in stage 224.0 (TID 458) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.020 Executor task launch worker for task 1.0 in stage 224.0 (TID 457) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.023 Executor task launch worker for task 0.0 in stage 224.0 (TID 456) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.025 Executor task launch worker for task 6.0 in stage 224.0 (TID 462) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.037 Executor task launch worker for task 3.0 in stage 224.0 (TID 459) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.048 Executor task launch worker for task 5.0 in stage 224.0 (TID 461) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.052 Executor task launch worker for task 7.0 in stage 224.0 (TID 463) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.095 Executor task launch worker for task 4.0 in stage 224.0 (TID 460) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.116 Executor task launch worker for task 1.0 in stage 224.0 (TID 457) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.148 Executor task launch worker for task 2.0 in stage 224.0 (TID 458) INFO Executor: Finished task 2.0 in stage 224.0 (TID 458). 4899 bytes result sent to driver
23/10/22 15:01:40.149 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 458) in 184 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:40.158 Executor task launch worker for task 6.0 in stage 224.0 (TID 462) INFO Executor: Finished task 6.0 in stage 224.0 (TID 462). 4899 bytes result sent to driver
23/10/22 15:01:40.159 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 462) in 194 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:40.168 Executor task launch worker for task 0.0 in stage 224.0 (TID 456) INFO Executor: Finished task 0.0 in stage 224.0 (TID 456). 4899 bytes result sent to driver
23/10/22 15:01:40.169 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 456) in 205 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:40.287 Executor task launch worker for task 7.0 in stage 224.0 (TID 463) INFO Executor: Finished task 7.0 in stage 224.0 (TID 463). 4899 bytes result sent to driver
23/10/22 15:01:40.288 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 463) in 323 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:40.302 Executor task launch worker for task 3.0 in stage 224.0 (TID 459) INFO Executor: Finished task 3.0 in stage 224.0 (TID 459). 4899 bytes result sent to driver
23/10/22 15:01:40.310 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 459) in 345 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:40.320 Executor task launch worker for task 4.0 in stage 224.0 (TID 460) INFO Executor: Finished task 4.0 in stage 224.0 (TID 460). 4899 bytes result sent to driver
23/10/22 15:01:40.322 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 460) in 357 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:40.333 Executor task launch worker for task 1.0 in stage 224.0 (TID 457) INFO Executor: Finished task 1.0 in stage 224.0 (TID 457). 4899 bytes result sent to driver
23/10/22 15:01:40.334 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 457) in 370 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:40.340 Executor task launch worker for task 5.0 in stage 224.0 (TID 461) INFO Executor: Finished task 5.0 in stage 224.0 (TID 461). 4899 bytes result sent to driver
23/10/22 15:01:40.341 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 461) in 376 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:40.341 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
23/10/22 15:01:40.342 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 224 (rdd at LinearRegression.scala:921) finished in 0.381 s
23/10/22 15:01:40.342 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:40.342 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:40.342 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:40.342 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:40.349 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(79), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:01:40.377 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.0176 ms
23/10/22 15:01:40.413 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:01:40.413 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 552 (treeAggregate at Statistics.scala:58) as input to shuffle 80
23/10/22 15:01:40.413 dag-scheduler-event-loop INFO DAGScheduler: Got job 124 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:01:40.413 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 228 (treeAggregate at Statistics.scala:58)
23/10/22 15:01:40.413 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 227)
23/10/22 15:01:40.413 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 227)
23/10/22 15:01:40.413 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 227 (MapPartitionsRDD[552] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:40.425 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 89.3 KiB, free 1037.0 MiB)
23/10/22 15:01:40.427 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 1036.9 MiB)
23/10/22 15:01:40.427 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:57170 (size: 37.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:40.427 dag-scheduler-event-loop INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:40.427 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 227 (MapPartitionsRDD[552] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:01:40.427 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 227.0 with 8 tasks resource profile 0
23/10/22 15:01:40.460 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 464) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.460 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 227.0 (TID 465) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 227.0 (TID 466) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 227.0 (TID 467) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 227.0 (TID 468) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 227.0 (TID 469) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 227.0 (TID 470) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 227.0 (TID 471) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:40.462 Executor task launch worker for task 0.0 in stage 227.0 (TID 464) INFO Executor: Running task 0.0 in stage 227.0 (TID 464)
23/10/22 15:01:40.462 Executor task launch worker for task 6.0 in stage 227.0 (TID 470) INFO Executor: Running task 6.0 in stage 227.0 (TID 470)
23/10/22 15:01:40.462 Executor task launch worker for task 5.0 in stage 227.0 (TID 469) INFO Executor: Running task 5.0 in stage 227.0 (TID 469)
23/10/22 15:01:40.462 Executor task launch worker for task 7.0 in stage 227.0 (TID 471) INFO Executor: Running task 7.0 in stage 227.0 (TID 471)
23/10/22 15:01:40.463 Executor task launch worker for task 1.0 in stage 227.0 (TID 465) INFO Executor: Running task 1.0 in stage 227.0 (TID 465)
23/10/22 15:01:40.464 Executor task launch worker for task 2.0 in stage 227.0 (TID 466) INFO Executor: Running task 2.0 in stage 227.0 (TID 466)
23/10/22 15:01:40.466 Executor task launch worker for task 6.0 in stage 227.0 (TID 470) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.466 Executor task launch worker for task 5.0 in stage 227.0 (TID 469) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.473 Executor task launch worker for task 3.0 in stage 227.0 (TID 467) INFO Executor: Running task 3.0 in stage 227.0 (TID 467)
23/10/22 15:01:40.473 Executor task launch worker for task 6.0 in stage 227.0 (TID 470) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:40.473 Executor task launch worker for task 5.0 in stage 227.0 (TID 469) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:40.474 Executor task launch worker for task 7.0 in stage 227.0 (TID 471) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.474 Executor task launch worker for task 7.0 in stage 227.0 (TID 471) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:40.474 Executor task launch worker for task 2.0 in stage 227.0 (TID 466) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.475 Executor task launch worker for task 2.0 in stage 227.0 (TID 466) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:01:40.476 Executor task launch worker for task 4.0 in stage 227.0 (TID 468) INFO Executor: Running task 4.0 in stage 227.0 (TID 468)
23/10/22 15:01:40.478 Executor task launch worker for task 0.0 in stage 227.0 (TID 464) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.478 Executor task launch worker for task 0.0 in stage 227.0 (TID 464) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
23/10/22 15:01:40.478 Executor task launch worker for task 3.0 in stage 227.0 (TID 467) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.478 Executor task launch worker for task 1.0 in stage 227.0 (TID 465) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.483 Executor task launch worker for task 3.0 in stage 227.0 (TID 467) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:40.483 Executor task launch worker for task 1.0 in stage 227.0 (TID 465) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:40.488 Executor task launch worker for task 4.0 in stage 227.0 (TID 468) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.488 Executor task launch worker for task 4.0 in stage 227.0 (TID 468) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:40.493 Executor task launch worker for task 5.0 in stage 227.0 (TID 469) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.494 Executor task launch worker for task 7.0 in stage 227.0 (TID 471) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.494 Executor task launch worker for task 6.0 in stage 227.0 (TID 470) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.498 Executor task launch worker for task 2.0 in stage 227.0 (TID 466) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.500 Executor task launch worker for task 0.0 in stage 227.0 (TID 464) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.537 Executor task launch worker for task 1.0 in stage 227.0 (TID 465) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.563 Executor task launch worker for task 3.0 in stage 227.0 (TID 467) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.565 Executor task launch worker for task 4.0 in stage 227.0 (TID 468) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:01:40.644 Executor task launch worker for task 5.0 in stage 227.0 (TID 469) INFO Executor: Finished task 5.0 in stage 227.0 (TID 469). 6562 bytes result sent to driver
23/10/22 15:01:40.644 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 227.0 (TID 469) in 183 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:01:40.657 Executor task launch worker for task 1.0 in stage 227.0 (TID 465) INFO Executor: Finished task 1.0 in stage 227.0 (TID 465). 6562 bytes result sent to driver
23/10/22 15:01:40.658 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 227.0 (TID 465) in 198 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:01:40.665 Executor task launch worker for task 0.0 in stage 227.0 (TID 464) INFO Executor: Finished task 0.0 in stage 227.0 (TID 464). 6562 bytes result sent to driver
23/10/22 15:01:40.669 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 464) in 209 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:01:40.676 Executor task launch worker for task 7.0 in stage 227.0 (TID 471) INFO Executor: Finished task 7.0 in stage 227.0 (TID 471). 6605 bytes result sent to driver
23/10/22 15:01:40.680 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 227.0 (TID 471) in 219 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:01:40.682 Executor task launch worker for task 2.0 in stage 227.0 (TID 466) INFO Executor: Finished task 2.0 in stage 227.0 (TID 466). 6562 bytes result sent to driver
23/10/22 15:01:40.682 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 227.0 (TID 466) in 222 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:01:40.693 Executor task launch worker for task 6.0 in stage 227.0 (TID 470) INFO Executor: Finished task 6.0 in stage 227.0 (TID 470). 6562 bytes result sent to driver
23/10/22 15:01:40.693 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 227.0 (TID 470) in 232 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:01:40.700 Executor task launch worker for task 3.0 in stage 227.0 (TID 467) INFO Executor: Finished task 3.0 in stage 227.0 (TID 467). 6562 bytes result sent to driver
23/10/22 15:01:40.700 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 227.0 (TID 467) in 239 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:01:40.709 Executor task launch worker for task 4.0 in stage 227.0 (TID 468) INFO Executor: Finished task 4.0 in stage 227.0 (TID 468). 6562 bytes result sent to driver
23/10/22 15:01:40.709 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 227.0 (TID 468) in 248 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:01:40.709 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool 
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 227 (treeAggregate at Statistics.scala:58) finished in 0.296 s
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 228)
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 228 (MapPartitionsRDD[554] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 90.4 KiB, free 1036.8 MiB)
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 37.5 KiB, free 1036.8 MiB)
23/10/22 15:01:40.709 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:57170 (size: 37.5 KiB, free: 1037.0 MiB)
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 228 (MapPartitionsRDD[554] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:01:40.709 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 228.0 with 2 tasks resource profile 0
23/10/22 15:01:40.709 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 472) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:40.709 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 228.0 (TID 473) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:01:40.709 Executor task launch worker for task 0.0 in stage 228.0 (TID 472) INFO Executor: Running task 0.0 in stage 228.0 (TID 472)
23/10/22 15:01:40.709 Executor task launch worker for task 1.0 in stage 228.0 (TID 473) INFO Executor: Running task 1.0 in stage 228.0 (TID 473)
23/10/22 15:01:40.726 Executor task launch worker for task 0.0 in stage 228.0 (TID 472) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.726 Executor task launch worker for task 0.0 in stage 228.0 (TID 472) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:40.726 Executor task launch worker for task 1.0 in stage 228.0 (TID 473) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:40.726 Executor task launch worker for task 1.0 in stage 228.0 (TID 473) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:40.726 Executor task launch worker for task 0.0 in stage 228.0 (TID 472) INFO Executor: Finished task 0.0 in stage 228.0 (TID 472). 7587 bytes result sent to driver
23/10/22 15:01:40.726 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 472) in 17 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:01:40.726 Executor task launch worker for task 1.0 in stage 228.0 (TID 473) INFO Executor: Finished task 1.0 in stage 228.0 (TID 473). 7630 bytes result sent to driver
23/10/22 15:01:40.726 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 228.0 (TID 473) in 17 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:01:40.726 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool 
23/10/22 15:01:40.742 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 228 (treeAggregate at Statistics.scala:58) finished in 0.033 s
23/10/22 15:01:40.742 dag-scheduler-event-loop INFO DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:40.742 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 228: Stage finished
23/10/22 15:01:40.742 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 124 finished: treeAggregate at Statistics.scala:58, took 0.323545 s
23/10/22 15:01:40.743 nioEventLoopGroup-2-2 INFO Instrumentation: [6df1cb8a] training finished
23/10/22 15:01:41.325 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Got job 125 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 229 (collect at utils.scala:26)
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[556] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:41.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 229 (MapPartitionsRDD[556] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 229.0 with 1 tasks resource profile 0
23/10/22 15:01:41.326 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 474) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:41.326 Executor task launch worker for task 0.0 in stage 229.0 (TID 474) INFO Executor: Running task 0.0 in stage 229.0 (TID 474)
23/10/22 15:01:41.326 Executor task launch worker for task 0.0 in stage 229.0 (TID 474) INFO Executor: Finished task 0.0 in stage 229.0 (TID 474). 1327 bytes result sent to driver
23/10/22 15:01:41.326 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 474) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:41.326 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool 
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 229 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:41.326 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 229: Stage finished
23/10/22 15:01:41.326 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 125 finished: collect at utils.scala:26, took 0.008181 s
23/10/22 15:01:41.793 nioEventLoopGroup-2-2 INFO Instrumentation: [e296311c] training finished
23/10/22 15:01:41.902 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:41.902 dag-scheduler-event-loop INFO DAGScheduler: Got job 126 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:41.902 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 230 (collect at utils.scala:26)
23/10/22 15:01:41.902 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:41.902 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:41.908 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[558] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:41.909 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 230 (MapPartitionsRDD[558] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 230.0 with 1 tasks resource profile 0
23/10/22 15:01:41.909 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 475) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:41.909 Executor task launch worker for task 0.0 in stage 230.0 (TID 475) INFO Executor: Running task 0.0 in stage 230.0 (TID 475)
23/10/22 15:01:41.909 Executor task launch worker for task 0.0 in stage 230.0 (TID 475) INFO Executor: Finished task 0.0 in stage 230.0 (TID 475). 1284 bytes result sent to driver
23/10/22 15:01:41.909 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 475) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:41.909 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool 
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 230 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:41.909 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 230: Stage finished
23/10/22 15:01:41.909 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 126 finished: collect at utils.scala:26, took 0.007702 s
23/10/22 15:01:42.442 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Got job 127 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 231 (collect at utils.scala:26)
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[560] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:01:42.442 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[560] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 231.0 with 1 tasks resource profile 0
23/10/22 15:01:42.442 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 476) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:42.442 Executor task launch worker for task 0.0 in stage 231.0 (TID 476) INFO Executor: Running task 0.0 in stage 231.0 (TID 476)
23/10/22 15:01:42.442 Executor task launch worker for task 0.0 in stage 231.0 (TID 476) INFO Executor: Finished task 0.0 in stage 231.0 (TID 476). 1284 bytes result sent to driver
23/10/22 15:01:42.442 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 476) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:42.442 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool 
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 231 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:42.442 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished
23/10/22 15:01:42.442 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 127 finished: collect at utils.scala:26, took 0.005972 s
23/10/22 15:01:47.983 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.9185 ms
23/10/22 15:01:47.994 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Got job 128 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 232 (collect at utils.scala:26)
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 232 (MapPartitionsRDD[562] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 7.2 KiB, free 1036.8 MiB)
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.7 MiB)
23/10/22 15:01:47.994 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 232 (MapPartitionsRDD[562] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 232.0 with 1 tasks resource profile 0
23/10/22 15:01:47.994 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 477) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:01:47.994 Executor task launch worker for task 0.0 in stage 232.0 (TID 477) INFO Executor: Running task 0.0 in stage 232.0 (TID 477)
23/10/22 15:01:47.994 Executor task launch worker for task 0.0 in stage 232.0 (TID 477) INFO Executor: Finished task 0.0 in stage 232.0 (TID 477). 1327 bytes result sent to driver
23/10/22 15:01:47.994 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 477) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:47.994 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 232 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:47.994 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 232: Stage finished
23/10/22 15:01:47.994 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 128 finished: collect at utils.scala:26, took 0.007291 s
23/10/22 15:01:48.010 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.6876 ms
23/10/22 15:01:48.112 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:01:48.134 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:57170 in memory (size: 37.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.134 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.134 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:57170 in memory (size: 37.5 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.137 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.137 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 564 (collect at utils.scala:26) as input to shuffle 81
23/10/22 15:01:48.137 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 129 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:48.137 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 233 (collect at utils.scala:26)
23/10/22 15:01:48.137 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:01:48.137 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:48.137 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 233 (MapPartitionsRDD[564] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:48.137 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.138 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:57170 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 44.1 KiB, free 1037.0 MiB)
23/10/22 15:01:48.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1037.0 MiB)
23/10/22 15:01:48.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:57170 (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.139 dag-scheduler-event-loop INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:48.139 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 233 (MapPartitionsRDD[564] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:48.139 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 233.0 with 1 tasks resource profile 0
23/10/22 15:01:48.327 dispatcher-event-loop-5 WARN TaskSetManager: Stage 233 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:01:48.327 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 478) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:01:48.327 Executor task launch worker for task 0.0 in stage 233.0 (TID 478) INFO Executor: Running task 0.0 in stage 233.0 (TID 478)
23/10/22 15:01:48.603 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:57170 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.881 Executor task launch worker for task 0.0 in stage 233.0 (TID 478) INFO Executor: Finished task 0.0 in stage 233.0 (TID 478). 2349 bytes result sent to driver
23/10/22 15:01:48.881 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 478) in 739 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:48.881 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool 
23/10/22 15:01:48.882 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 233 (collect at utils.scala:26) finished in 0.745 s
23/10/22 15:01:48.882 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:48.882 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:48.882 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:48.882 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:48.887 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(81), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 15:01:48.896 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:01:48.907 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 567 (collect at utils.scala:26) as input to shuffle 82
23/10/22 15:01:48.907 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 130 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:48.907 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 235 (collect at utils.scala:26)
23/10/22 15:01:48.907 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 234)
23/10/22 15:01:48.907 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:48.907 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 235 (MapPartitionsRDD[567] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:48.910 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 65.5 KiB, free 1037.0 MiB)
23/10/22 15:01:48.911 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1037.0 MiB)
23/10/22 15:01:48.912 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:57170 (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 15:01:48.912 dag-scheduler-event-loop INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:48.913 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 235 (MapPartitionsRDD[567] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:48.913 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 235.0 with 1 tasks resource profile 0
23/10/22 15:01:48.915 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 479) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:48.915 Executor task launch worker for task 0.0 in stage 235.0 (TID 479) INFO Executor: Running task 0.0 in stage 235.0 (TID 479)
23/10/22 15:01:48.918 Executor task launch worker for task 0.0 in stage 235.0 (TID 479) INFO ShuffleBlockFetcherIterator: Getting 1 (483.5 KiB) non-empty blocks including 1 (483.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:48.918 Executor task launch worker for task 0.0 in stage 235.0 (TID 479) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:48.994 Executor task launch worker for task 0.0 in stage 235.0 (TID 479) INFO Executor: Finished task 0.0 in stage 235.0 (TID 479). 5381 bytes result sent to driver
23/10/22 15:01:48.995 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 479) in 81 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:48.995 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool 
23/10/22 15:01:48.995 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 235 (collect at utils.scala:26) finished in 0.087 s
23/10/22 15:01:48.995 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:48.995 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:48.995 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:48.995 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:48.995 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(82), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 15:01:49.012 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:01:49.053 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 31.1808 ms
23/10/22 15:01:49.065 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 570 (collect at utils.scala:26) as input to shuffle 83
23/10/22 15:01:49.065 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 131 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:49.065 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 238 (collect at utils.scala:26)
23/10/22 15:01:49.065 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 237)
23/10/22 15:01:49.065 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:49.065 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 238 (MapPartitionsRDD[570] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:49.068 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 106.1 KiB, free 1036.9 MiB)
23/10/22 15:01:49.069 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 38.6 KiB, free 1036.8 MiB)
23/10/22 15:01:49.070 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:57170 (size: 38.6 KiB, free: 1037.1 MiB)
23/10/22 15:01:49.070 dag-scheduler-event-loop INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:49.070 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 238 (MapPartitionsRDD[570] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:49.070 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 238.0 with 1 tasks resource profile 0
23/10/22 15:01:49.071 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 480) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:01:49.071 Executor task launch worker for task 0.0 in stage 238.0 (TID 480) INFO Executor: Running task 0.0 in stage 238.0 (TID 480)
23/10/22 15:01:49.114 Executor task launch worker for task 0.0 in stage 238.0 (TID 480) INFO ShuffleBlockFetcherIterator: Getting 1 (96.8 KiB) non-empty blocks including 1 (96.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:49.114 Executor task launch worker for task 0.0 in stage 238.0 (TID 480) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:49.132 Executor task launch worker for task 0.0 in stage 238.0 (TID 480) INFO Executor: Finished task 0.0 in stage 238.0 (TID 480). 7334 bytes result sent to driver
23/10/22 15:01:49.133 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 480) in 62 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:49.133 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool 
23/10/22 15:01:49.133 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 238 (collect at utils.scala:26) finished in 0.067 s
23/10/22 15:01:49.133 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:01:49.133 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:01:49.133 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:01:49.133 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:01:49.169 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 20.5906 ms
23/10/22 15:01:49.176 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:01:49.177 dag-scheduler-event-loop INFO DAGScheduler: Got job 132 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:01:49.177 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 242 (collect at utils.scala:26)
23/10/22 15:01:49.177 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 241)
23/10/22 15:01:49.177 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:01:49.177 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 242 (MapPartitionsRDD[573] at collect at utils.scala:26), which has no missing parents
23/10/22 15:01:49.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 57.4 KiB, free 1036.8 MiB)
23/10/22 15:01:49.180 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 1036.8 MiB)
23/10/22 15:01:49.180 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:57170 (size: 17.9 KiB, free: 1037.0 MiB)
23/10/22 15:01:49.180 dag-scheduler-event-loop INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1535
23/10/22 15:01:49.181 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 242 (MapPartitionsRDD[573] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:01:49.181 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 242.0 with 1 tasks resource profile 0
23/10/22 15:01:49.181 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 481) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 15:01:49.182 Executor task launch worker for task 0.0 in stage 242.0 (TID 481) INFO Executor: Running task 0.0 in stage 242.0 (TID 481)
23/10/22 15:01:49.184 Executor task launch worker for task 0.0 in stage 242.0 (TID 481) INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:01:49.184 Executor task launch worker for task 0.0 in stage 242.0 (TID 481) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:01:49.189 Executor task launch worker for task 0.0 in stage 242.0 (TID 481) INFO Executor: Finished task 0.0 in stage 242.0 (TID 481). 4277 bytes result sent to driver
23/10/22 15:01:49.190 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 481) in 8 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:01:49.190 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
23/10/22 15:01:49.190 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 242 (collect at utils.scala:26) finished in 0.012 s
23/10/22 15:01:49.190 dag-scheduler-event-loop INFO DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:01:49.190 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 242: Stage finished
23/10/22 15:01:49.190 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 132 finished: collect at utils.scala:26, took 0.014002 s
23/10/22 15:01:49.196 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.0753 ms
23/10/22 15:02:33.625 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:02:33.631 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 575 (collect at utils.scala:26) as input to shuffle 84
23/10/22 15:02:33.631 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 133 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:02:33.631 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 243 (collect at utils.scala:26)
23/10/22 15:02:33.631 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:02:33.631 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:02:33.631 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 243 (MapPartitionsRDD[575] at collect at utils.scala:26), which has no missing parents
23/10/22 15:02:33.633 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 43.9 KiB, free 1036.7 MiB)
23/10/22 15:02:33.634 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1036.7 MiB)
23/10/22 15:02:33.634 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:57170 (size: 19.1 KiB, free: 1037.0 MiB)
23/10/22 15:02:33.635 dag-scheduler-event-loop INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1535
23/10/22 15:02:33.635 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 243 (MapPartitionsRDD[575] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:02:33.635 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 243.0 with 1 tasks resource profile 0
23/10/22 15:02:33.805 dispatcher-event-loop-6 WARN TaskSetManager: Stage 243 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:02:33.805 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 482) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:02:33.806 Executor task launch worker for task 0.0 in stage 243.0 (TID 482) INFO Executor: Running task 0.0 in stage 243.0 (TID 482)
23/10/22 15:02:34.091 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:57170 in memory (size: 25.8 KiB, free: 1037.0 MiB)
23/10/22 15:02:34.093 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:57170 in memory (size: 38.6 KiB, free: 1037.1 MiB)
23/10/22 15:02:34.267 Executor task launch worker for task 0.0 in stage 243.0 (TID 482) INFO Executor: Finished task 0.0 in stage 243.0 (TID 482). 2349 bytes result sent to driver
23/10/22 15:02:34.268 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 482) in 633 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:02:34.268 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool 
23/10/22 15:02:34.268 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 243 (collect at utils.scala:26) finished in 0.636 s
23/10/22 15:02:34.268 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:02:34.268 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:02:34.268 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:02:34.268 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:02:34.272 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 15:02:34.277 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:02:34.284 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 578 (collect at utils.scala:26) as input to shuffle 85
23/10/22 15:02:34.284 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 134 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:02:34.284 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 245 (collect at utils.scala:26)
23/10/22 15:02:34.284 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 244)
23/10/22 15:02:34.284 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:02:34.284 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 245 (MapPartitionsRDD[578] at collect at utils.scala:26), which has no missing parents
23/10/22 15:02:34.287 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 65.0 KiB, free 1036.9 MiB)
23/10/22 15:02:34.287 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1036.9 MiB)
23/10/22 15:02:34.288 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:57170 (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 15:02:34.288 dag-scheduler-event-loop INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1535
23/10/22 15:02:34.288 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 245 (MapPartitionsRDD[578] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:02:34.288 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 245.0 with 1 tasks resource profile 0
23/10/22 15:02:34.289 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 245.0 (TID 483) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:02:34.289 Executor task launch worker for task 0.0 in stage 245.0 (TID 483) INFO Executor: Running task 0.0 in stage 245.0 (TID 483)
23/10/22 15:02:34.293 Executor task launch worker for task 0.0 in stage 245.0 (TID 483) INFO ShuffleBlockFetcherIterator: Getting 1 (483.5 KiB) non-empty blocks including 1 (483.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:02:34.293 Executor task launch worker for task 0.0 in stage 245.0 (TID 483) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:02:34.343 Executor task launch worker for task 0.0 in stage 245.0 (TID 483) INFO Executor: Finished task 0.0 in stage 245.0 (TID 483). 5381 bytes result sent to driver
23/10/22 15:02:34.344 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 245.0 (TID 483) in 55 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:02:34.344 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool 
23/10/22 15:02:34.344 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 245 (collect at utils.scala:26) finished in 0.059 s
23/10/22 15:02:34.344 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:02:34.344 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:02:34.344 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:02:34.344 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:02:34.347 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 15:02:34.352 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:02:34.363 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 581 (collect at utils.scala:26) as input to shuffle 86
23/10/22 15:02:34.364 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 135 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:02:34.364 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 248 (collect at utils.scala:26)
23/10/22 15:02:34.364 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 247)
23/10/22 15:02:34.364 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:02:34.364 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 248 (MapPartitionsRDD[581] at collect at utils.scala:26), which has no missing parents
23/10/22 15:02:34.366 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 103.1 KiB, free 1036.8 MiB)
23/10/22 15:02:34.367 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 38.1 KiB, free 1036.7 MiB)
23/10/22 15:02:34.367 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:57170 (size: 38.1 KiB, free: 1037.0 MiB)
23/10/22 15:02:34.367 dag-scheduler-event-loop INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1535
23/10/22 15:02:34.367 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[581] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:02:34.367 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 248.0 with 1 tasks resource profile 0
23/10/22 15:02:34.368 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 484) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:02:34.368 Executor task launch worker for task 0.0 in stage 248.0 (TID 484) INFO Executor: Running task 0.0 in stage 248.0 (TID 484)
23/10/22 15:02:34.372 Executor task launch worker for task 0.0 in stage 248.0 (TID 484) INFO ShuffleBlockFetcherIterator: Getting 1 (96.8 KiB) non-empty blocks including 1 (96.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:02:34.372 Executor task launch worker for task 0.0 in stage 248.0 (TID 484) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:02:34.420 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:57170 in memory (size: 17.9 KiB, free: 1037.0 MiB)
23/10/22 15:02:34.430 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:57170 in memory (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 15:02:34.456 Executor task launch worker for task 0.0 in stage 248.0 (TID 484) INFO Executor: Finished task 0.0 in stage 248.0 (TID 484). 7341 bytes result sent to driver
23/10/22 15:02:34.457 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 484) in 89 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:02:34.457 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool 
23/10/22 15:02:34.457 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 248 (collect at utils.scala:26) finished in 0.093 s
23/10/22 15:02:34.457 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:02:34.457 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:02:34.457 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:02:34.457 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:02:34.460 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(86), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 15:02:34.460 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 15:02:34.496 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:02:34.497 dag-scheduler-event-loop INFO DAGScheduler: Got job 136 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:02:34.497 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 252 (collect at utils.scala:26)
23/10/22 15:02:34.497 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 251)
23/10/22 15:02:34.497 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:02:34.497 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 252 (MapPartitionsRDD[584] at collect at utils.scala:26), which has no missing parents
23/10/22 15:02:34.500 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 106.0 KiB, free 1036.7 MiB)
23/10/22 15:02:34.501 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 37.9 KiB, free 1036.7 MiB)
23/10/22 15:02:34.501 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:57170 (size: 37.9 KiB, free: 1037.0 MiB)
23/10/22 15:02:34.501 dag-scheduler-event-loop INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1535
23/10/22 15:02:34.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 252 (MapPartitionsRDD[584] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:02:34.502 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 252.0 with 1 tasks resource profile 0
23/10/22 15:02:34.502 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 485) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 15:02:34.503 Executor task launch worker for task 0.0 in stage 252.0 (TID 485) INFO Executor: Running task 0.0 in stage 252.0 (TID 485)
23/10/22 15:02:34.508 Executor task launch worker for task 0.0 in stage 252.0 (TID 485) INFO ShuffleBlockFetcherIterator: Getting 1 (182.3 KiB) non-empty blocks including 1 (182.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:02:34.508 Executor task launch worker for task 0.0 in stage 252.0 (TID 485) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:02:34.520 Executor task launch worker for task 0.0 in stage 252.0 (TID 485) INFO Executor: Finished task 0.0 in stage 252.0 (TID 485). 107013 bytes result sent to driver
23/10/22 15:02:34.520 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 485) in 18 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:02:34.520 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool 
23/10/22 15:02:34.520 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 252 (collect at utils.scala:26) finished in 0.022 s
23/10/22 15:02:34.521 dag-scheduler-event-loop INFO DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:02:34.521 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
23/10/22 15:02:34.521 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 136 finished: collect at utils.scala:26, took 0.024296 s
23/10/22 15:03:51.632 nioEventLoopGroup-2-2 INFO Instrumentation: [e611583e] training finished
23/10/22 15:03:51.672 nioEventLoopGroup-2-2 INFO Instrumentation: [481f0282] training finished
23/10/22 15:03:51.673 nioEventLoopGroup-2-2 INFO Instrumentation: [4731fe68] Stage class: LinearRegression
23/10/22 15:03:51.673 nioEventLoopGroup-2-2 INFO Instrumentation: [4731fe68] Stage uid: linear_regression__43ef130f_8354_401e_9230_5f626d47372a
23/10/22 15:03:51.714 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 587 (rdd at Instrumentation.scala:62) as input to shuffle 87
23/10/22 15:03:51.714 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 137 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 15:03:51.714 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 253 (rdd at Instrumentation.scala:62)
23/10/22 15:03:51.714 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:03:51.714 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:51.715 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 253 (MapPartitionsRDD[587] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:03:51.715 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 34.0 KiB, free 1036.7 MiB)
23/10/22 15:03:51.716 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 1036.7 MiB)
23/10/22 15:03:51.716 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:57170 (size: 15.3 KiB, free: 1037.0 MiB)
23/10/22 15:03:51.716 dag-scheduler-event-loop INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:51.717 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 253 (MapPartitionsRDD[587] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 15:03:51.717 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 253.0 with 1 tasks resource profile 0
23/10/22 15:03:51.874 dispatcher-event-loop-3 WARN TaskSetManager: Stage 253 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:03:51.874 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 253.0 (TID 486) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:03:51.874 Executor task launch worker for task 0.0 in stage 253.0 (TID 486) INFO Executor: Running task 0.0 in stage 253.0 (TID 486)
23/10/22 15:03:52.014 Executor task launch worker for task 0.0 in stage 253.0 (TID 486) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:57170 in memory (size: 25.8 KiB, free: 1037.0 MiB)
23/10/22 15:03:52.356 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:57170 in memory (size: 38.1 KiB, free: 1037.1 MiB)
23/10/22 15:03:52.358 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:57170 in memory (size: 37.9 KiB, free: 1037.1 MiB)
23/10/22 15:03:52.539 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:57170 in memory (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 15:03:52.832 Executor task launch worker for task 0.0 in stage 253.0 (TID 486) INFO Executor: Finished task 0.0 in stage 253.0 (TID 486). 2104 bytes result sent to driver
23/10/22 15:03:52.832 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 253.0 (TID 486) in 1115 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:03:52.832 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool 
23/10/22 15:03:52.832 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 253 (rdd at Instrumentation.scala:62) finished in 1.117 s
23/10/22 15:03:52.832 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:52.832 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:52.832 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:03:52.832 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:52.841 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(87), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 591 (rdd at Instrumentation.scala:62) as input to shuffle 88
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 138 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 255 (rdd at Instrumentation.scala:62)
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 254)
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 255 (MapPartitionsRDD[591] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 39.0 KiB, free 1037.1 MiB)
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1037.0 MiB)
23/10/22 15:03:52.841 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:57170 (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 255 (MapPartitionsRDD[591] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:03:52.841 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 255.0 with 8 tasks resource profile 0
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 255.0 (TID 487) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 255.0 (TID 488) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 255.0 (TID 489) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 255.0 (TID 490) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 255.0 (TID 491) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 255.0 (TID 492) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 255.0 (TID 493) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 255.0 (TID 494) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:52.841 Executor task launch worker for task 0.0 in stage 255.0 (TID 487) INFO Executor: Running task 0.0 in stage 255.0 (TID 487)
23/10/22 15:03:52.841 Executor task launch worker for task 1.0 in stage 255.0 (TID 488) INFO Executor: Running task 1.0 in stage 255.0 (TID 488)
23/10/22 15:03:52.841 Executor task launch worker for task 2.0 in stage 255.0 (TID 489) INFO Executor: Running task 2.0 in stage 255.0 (TID 489)
23/10/22 15:03:52.841 Executor task launch worker for task 3.0 in stage 255.0 (TID 490) INFO Executor: Running task 3.0 in stage 255.0 (TID 490)
23/10/22 15:03:52.841 Executor task launch worker for task 4.0 in stage 255.0 (TID 491) INFO Executor: Running task 4.0 in stage 255.0 (TID 491)
23/10/22 15:03:52.841 Executor task launch worker for task 5.0 in stage 255.0 (TID 492) INFO Executor: Running task 5.0 in stage 255.0 (TID 492)
23/10/22 15:03:52.851 Executor task launch worker for task 6.0 in stage 255.0 (TID 493) INFO Executor: Running task 6.0 in stage 255.0 (TID 493)
23/10/22 15:03:52.851 Executor task launch worker for task 7.0 in stage 255.0 (TID 494) INFO Executor: Running task 7.0 in stage 255.0 (TID 494)
23/10/22 15:03:52.853 Executor task launch worker for task 0.0 in stage 255.0 (TID 487) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.853 Executor task launch worker for task 4.0 in stage 255.0 (TID 491) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.853 Executor task launch worker for task 3.0 in stage 255.0 (TID 490) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.853 Executor task launch worker for task 2.0 in stage 255.0 (TID 489) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.853 Executor task launch worker for task 0.0 in stage 255.0 (TID 487) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.853 Executor task launch worker for task 2.0 in stage 255.0 (TID 489) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.853 Executor task launch worker for task 4.0 in stage 255.0 (TID 491) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.853 Executor task launch worker for task 3.0 in stage 255.0 (TID 490) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.853 Executor task launch worker for task 5.0 in stage 255.0 (TID 492) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.853 Executor task launch worker for task 5.0 in stage 255.0 (TID 492) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.854 Executor task launch worker for task 7.0 in stage 255.0 (TID 494) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.854 Executor task launch worker for task 7.0 in stage 255.0 (TID 494) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.855 Executor task launch worker for task 1.0 in stage 255.0 (TID 488) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.855 Executor task launch worker for task 1.0 in stage 255.0 (TID 488) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.860 Executor task launch worker for task 6.0 in stage 255.0 (TID 493) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:52.861 Executor task launch worker for task 6.0 in stage 255.0 (TID 493) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:52.862 Executor task launch worker for task 4.0 in stage 255.0 (TID 491) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.862 Executor task launch worker for task 3.0 in stage 255.0 (TID 490) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.863 Executor task launch worker for task 1.0 in stage 255.0 (TID 488) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.863 Executor task launch worker for task 0.0 in stage 255.0 (TID 487) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.863 Executor task launch worker for task 7.0 in stage 255.0 (TID 494) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.864 Executor task launch worker for task 5.0 in stage 255.0 (TID 492) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.864 Executor task launch worker for task 2.0 in stage 255.0 (TID 489) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.874 Executor task launch worker for task 6.0 in stage 255.0 (TID 493) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.885 Executor task launch worker for task 3.0 in stage 255.0 (TID 490) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.885 Executor task launch worker for task 1.0 in stage 255.0 (TID 488) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.886 Executor task launch worker for task 7.0 in stage 255.0 (TID 494) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.887 Executor task launch worker for task 5.0 in stage 255.0 (TID 492) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.887 Executor task launch worker for task 4.0 in stage 255.0 (TID 491) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.889 Executor task launch worker for task 0.0 in stage 255.0 (TID 487) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.889 Executor task launch worker for task 2.0 in stage 255.0 (TID 489) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.893 Executor task launch worker for task 6.0 in stage 255.0 (TID 493) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:52.984 Executor task launch worker for task 7.0 in stage 255.0 (TID 494) INFO Executor: Finished task 7.0 in stage 255.0 (TID 494). 4899 bytes result sent to driver
23/10/22 15:03:52.985 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 255.0 (TID 494) in 144 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:03:52.990 Executor task launch worker for task 5.0 in stage 255.0 (TID 492) INFO Executor: Finished task 5.0 in stage 255.0 (TID 492). 4942 bytes result sent to driver
23/10/22 15:03:52.990 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 255.0 (TID 492) in 149 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:03:52.995 Executor task launch worker for task 0.0 in stage 255.0 (TID 487) INFO Executor: Finished task 0.0 in stage 255.0 (TID 487). 4942 bytes result sent to driver
23/10/22 15:03:52.995 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 255.0 (TID 487) in 154 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:03:52.998 Executor task launch worker for task 1.0 in stage 255.0 (TID 488) INFO Executor: Finished task 1.0 in stage 255.0 (TID 488). 4899 bytes result sent to driver
23/10/22 15:03:52.998 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 255.0 (TID 488) in 157 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:03:53.001 Executor task launch worker for task 6.0 in stage 255.0 (TID 493) INFO Executor: Finished task 6.0 in stage 255.0 (TID 493). 4899 bytes result sent to driver
23/10/22 15:03:53.001 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 255.0 (TID 493) in 160 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:03:53.004 Executor task launch worker for task 2.0 in stage 255.0 (TID 489) INFO Executor: Finished task 2.0 in stage 255.0 (TID 489). 4942 bytes result sent to driver
23/10/22 15:03:53.005 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 255.0 (TID 489) in 164 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:03:53.010 Executor task launch worker for task 4.0 in stage 255.0 (TID 491) INFO Executor: Finished task 4.0 in stage 255.0 (TID 491). 4942 bytes result sent to driver
23/10/22 15:03:53.010 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 255.0 (TID 491) in 169 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:03:53.013 Executor task launch worker for task 3.0 in stage 255.0 (TID 490) INFO Executor: Finished task 3.0 in stage 255.0 (TID 490). 4899 bytes result sent to driver
23/10/22 15:03:53.013 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 255.0 (TID 490) in 172 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:03:53.014 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool 
23/10/22 15:03:53.014 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 255 (rdd at Instrumentation.scala:62) finished in 0.173 s
23/10/22 15:03:53.014 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:53.014 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:53.014 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:03:53.014 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:53.017 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(88), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:03:53.025 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:57170 in memory (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:03:53.032 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.9342 ms
23/10/22 15:03:53.039 nioEventLoopGroup-2-2 INFO Instrumentation: [4731fe68] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 15:03:53.039 nioEventLoopGroup-2-2 INFO Instrumentation: [4731fe68] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 15:03:53.039 nioEventLoopGroup-2-2 INFO Instrumentation: [4731fe68] {"numFeatures":3}
23/10/22 15:03:53.079 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 600 (rdd at LinearRegression.scala:348) as input to shuffle 89
23/10/22 15:03:53.079 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 139 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 15:03:53.079 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 256 (rdd at LinearRegression.scala:348)
23/10/22 15:03:53.079 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:03:53.079 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:53.079 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 256 (MapPartitionsRDD[600] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:03:53.081 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 34.0 KiB, free 1037.1 MiB)
23/10/22 15:03:53.081 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 1037.0 MiB)
23/10/22 15:03:53.082 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:57170 (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:03:53.082 dag-scheduler-event-loop INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:53.082 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 256 (MapPartitionsRDD[600] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 15:03:53.082 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 256.0 with 1 tasks resource profile 0
23/10/22 15:03:53.238 dispatcher-event-loop-1 WARN TaskSetManager: Stage 256 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:03:53.238 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 256.0 (TID 495) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:03:53.238 Executor task launch worker for task 0.0 in stage 256.0 (TID 495) INFO Executor: Running task 0.0 in stage 256.0 (TID 495)
23/10/22 15:03:53.380 Executor task launch worker for task 0.0 in stage 256.0 (TID 495) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:53.493 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:57170 in memory (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.062 Executor task launch worker for task 0.0 in stage 256.0 (TID 495) INFO Executor: Finished task 0.0 in stage 256.0 (TID 495). 2147 bytes result sent to driver
23/10/22 15:03:54.062 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 256.0 (TID 495) in 979 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:03:54.062 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool 
23/10/22 15:03:54.063 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 256 (rdd at LinearRegression.scala:348) finished in 0.983 s
23/10/22 15:03:54.063 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:54.063 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:54.063 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:03:54.063 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:54.066 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(89), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:03:54.068 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 604 (rdd at LinearRegression.scala:348) as input to shuffle 90
23/10/22 15:03:54.068 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 140 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 15:03:54.068 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 258 (rdd at LinearRegression.scala:348)
23/10/22 15:03:54.068 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 257)
23/10/22 15:03:54.068 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:54.068 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 258 (MapPartitionsRDD[604] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 15:03:54.070 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 39.0 KiB, free 1037.1 MiB)
23/10/22 15:03:54.071 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1037.0 MiB)
23/10/22 15:03:54.071 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:57170 (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.071 dag-scheduler-event-loop INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:54.071 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 258 (MapPartitionsRDD[604] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:03:54.071 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 258.0 with 8 tasks resource profile 0
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 258.0 (TID 496) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 258.0 (TID 497) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 258.0 (TID 498) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 258.0 (TID 499) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 258.0 (TID 500) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 258.0 (TID 501) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.073 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 258.0 (TID 502) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.074 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 258.0 (TID 503) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.074 Executor task launch worker for task 2.0 in stage 258.0 (TID 498) INFO Executor: Running task 2.0 in stage 258.0 (TID 498)
23/10/22 15:03:54.074 Executor task launch worker for task 4.0 in stage 258.0 (TID 500) INFO Executor: Running task 4.0 in stage 258.0 (TID 500)
23/10/22 15:03:54.074 Executor task launch worker for task 0.0 in stage 258.0 (TID 496) INFO Executor: Running task 0.0 in stage 258.0 (TID 496)
23/10/22 15:03:54.074 Executor task launch worker for task 6.0 in stage 258.0 (TID 502) INFO Executor: Running task 6.0 in stage 258.0 (TID 502)
23/10/22 15:03:54.074 Executor task launch worker for task 1.0 in stage 258.0 (TID 497) INFO Executor: Running task 1.0 in stage 258.0 (TID 497)
23/10/22 15:03:54.074 Executor task launch worker for task 5.0 in stage 258.0 (TID 501) INFO Executor: Running task 5.0 in stage 258.0 (TID 501)
23/10/22 15:03:54.074 Executor task launch worker for task 3.0 in stage 258.0 (TID 499) INFO Executor: Running task 3.0 in stage 258.0 (TID 499)
23/10/22 15:03:54.074 Executor task launch worker for task 7.0 in stage 258.0 (TID 503) INFO Executor: Running task 7.0 in stage 258.0 (TID 503)
23/10/22 15:03:54.078 Executor task launch worker for task 3.0 in stage 258.0 (TID 499) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.078 Executor task launch worker for task 3.0 in stage 258.0 (TID 499) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.079 Executor task launch worker for task 1.0 in stage 258.0 (TID 497) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.079 Executor task launch worker for task 1.0 in stage 258.0 (TID 497) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.081 Executor task launch worker for task 7.0 in stage 258.0 (TID 503) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.081 Executor task launch worker for task 0.0 in stage 258.0 (TID 496) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.081 Executor task launch worker for task 7.0 in stage 258.0 (TID 503) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.081 Executor task launch worker for task 2.0 in stage 258.0 (TID 498) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.081 Executor task launch worker for task 0.0 in stage 258.0 (TID 496) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.081 Executor task launch worker for task 2.0 in stage 258.0 (TID 498) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.082 Executor task launch worker for task 4.0 in stage 258.0 (TID 500) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.082 Executor task launch worker for task 4.0 in stage 258.0 (TID 500) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.082 Executor task launch worker for task 6.0 in stage 258.0 (TID 502) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.082 Executor task launch worker for task 6.0 in stage 258.0 (TID 502) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.086 Executor task launch worker for task 5.0 in stage 258.0 (TID 501) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.086 Executor task launch worker for task 5.0 in stage 258.0 (TID 501) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.087 Executor task launch worker for task 1.0 in stage 258.0 (TID 497) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.087 Executor task launch worker for task 3.0 in stage 258.0 (TID 499) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.089 Executor task launch worker for task 7.0 in stage 258.0 (TID 503) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.090 Executor task launch worker for task 2.0 in stage 258.0 (TID 498) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.098 Executor task launch worker for task 4.0 in stage 258.0 (TID 500) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.109 Executor task launch worker for task 7.0 in stage 258.0 (TID 503) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.109 Executor task launch worker for task 2.0 in stage 258.0 (TID 498) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.109 Executor task launch worker for task 5.0 in stage 258.0 (TID 501) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.109 Executor task launch worker for task 1.0 in stage 258.0 (TID 497) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.109 Executor task launch worker for task 3.0 in stage 258.0 (TID 499) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.123 Executor task launch worker for task 0.0 in stage 258.0 (TID 496) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.127 Executor task launch worker for task 6.0 in stage 258.0 (TID 502) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.146 Executor task launch worker for task 0.0 in stage 258.0 (TID 496) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.150 Executor task launch worker for task 6.0 in stage 258.0 (TID 502) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.210 Executor task launch worker for task 4.0 in stage 258.0 (TID 500) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.218 Executor task launch worker for task 3.0 in stage 258.0 (TID 499) INFO Executor: Finished task 3.0 in stage 258.0 (TID 499). 4899 bytes result sent to driver
23/10/22 15:03:54.219 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 258.0 (TID 499) in 146 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:03:54.226 Executor task launch worker for task 5.0 in stage 258.0 (TID 501) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.226 Executor task launch worker for task 2.0 in stage 258.0 (TID 498) INFO Executor: Finished task 2.0 in stage 258.0 (TID 498). 4899 bytes result sent to driver
23/10/22 15:03:54.238 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 258.0 (TID 498) in 165 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:03:54.241 Executor task launch worker for task 7.0 in stage 258.0 (TID 503) INFO Executor: Finished task 7.0 in stage 258.0 (TID 503). 4899 bytes result sent to driver
23/10/22 15:03:54.246 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 258.0 (TID 503) in 172 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:03:54.276 Executor task launch worker for task 0.0 in stage 258.0 (TID 496) INFO Executor: Finished task 0.0 in stage 258.0 (TID 496). 4899 bytes result sent to driver
23/10/22 15:03:54.284 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 258.0 (TID 496) in 211 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:03:54.309 Executor task launch worker for task 6.0 in stage 258.0 (TID 502) INFO Executor: Finished task 6.0 in stage 258.0 (TID 502). 4899 bytes result sent to driver
23/10/22 15:03:54.309 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 258.0 (TID 502) in 236 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:03:54.316 Executor task launch worker for task 1.0 in stage 258.0 (TID 497) INFO Executor: Finished task 1.0 in stage 258.0 (TID 497). 4899 bytes result sent to driver
23/10/22 15:03:54.316 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 258.0 (TID 497) in 243 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:03:54.328 Executor task launch worker for task 4.0 in stage 258.0 (TID 500) INFO Executor: Finished task 4.0 in stage 258.0 (TID 500). 4899 bytes result sent to driver
23/10/22 15:03:54.329 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 258.0 (TID 500) in 256 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:03:54.332 Executor task launch worker for task 5.0 in stage 258.0 (TID 501) INFO Executor: Finished task 5.0 in stage 258.0 (TID 501). 4899 bytes result sent to driver
23/10/22 15:03:54.332 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 258.0 (TID 501) in 259 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:03:54.332 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool 
23/10/22 15:03:54.332 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 258 (rdd at LinearRegression.scala:348) finished in 0.263 s
23/10/22 15:03:54.332 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:54.332 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:54.332 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:03:54.332 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:54.337 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(90), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:03:54.369 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.8777 ms
23/10/22 15:03:54.378 nioEventLoopGroup-2-2 WARN Instrumentation: [4731fe68] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 15:03:54.395 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 613 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 91
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Got job 141 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 262 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 261)
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 261)
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 261 (MapPartitionsRDD[613] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 100.0 KiB, free 1036.9 MiB)
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 1036.9 MiB)
23/10/22 15:03:54.395 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:57170 (size: 39.3 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 261 (MapPartitionsRDD[613] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:03:54.395 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 261.0 with 8 tasks resource profile 0
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 261.0 (TID 504) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 261.0 (TID 505) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 261.0 (TID 506) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 261.0 (TID 507) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 261.0 (TID 508) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 261.0 (TID 509) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 261.0 (TID 510) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 261.0 (TID 511) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:54.395 Executor task launch worker for task 0.0 in stage 261.0 (TID 504) INFO Executor: Running task 0.0 in stage 261.0 (TID 504)
23/10/22 15:03:54.395 Executor task launch worker for task 5.0 in stage 261.0 (TID 509) INFO Executor: Running task 5.0 in stage 261.0 (TID 509)
23/10/22 15:03:54.395 Executor task launch worker for task 3.0 in stage 261.0 (TID 507) INFO Executor: Running task 3.0 in stage 261.0 (TID 507)
23/10/22 15:03:54.395 Executor task launch worker for task 2.0 in stage 261.0 (TID 506) INFO Executor: Running task 2.0 in stage 261.0 (TID 506)
23/10/22 15:03:54.395 Executor task launch worker for task 1.0 in stage 261.0 (TID 505) INFO Executor: Running task 1.0 in stage 261.0 (TID 505)
23/10/22 15:03:54.401 Executor task launch worker for task 7.0 in stage 261.0 (TID 511) INFO Executor: Running task 7.0 in stage 261.0 (TID 511)
23/10/22 15:03:54.401 Executor task launch worker for task 6.0 in stage 261.0 (TID 510) INFO Executor: Running task 6.0 in stage 261.0 (TID 510)
23/10/22 15:03:54.401 Executor task launch worker for task 4.0 in stage 261.0 (TID 508) INFO Executor: Running task 4.0 in stage 261.0 (TID 508)
23/10/22 15:03:54.409 Executor task launch worker for task 1.0 in stage 261.0 (TID 505) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.409 Executor task launch worker for task 1.0 in stage 261.0 (TID 505) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.412 Executor task launch worker for task 2.0 in stage 261.0 (TID 506) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.412 Executor task launch worker for task 2.0 in stage 261.0 (TID 506) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.412 Executor task launch worker for task 6.0 in stage 261.0 (TID 510) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.412 Executor task launch worker for task 6.0 in stage 261.0 (TID 510) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.412 Executor task launch worker for task 3.0 in stage 261.0 (TID 507) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.412 Executor task launch worker for task 0.0 in stage 261.0 (TID 504) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.413 Executor task launch worker for task 0.0 in stage 261.0 (TID 504) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.412 Executor task launch worker for task 7.0 in stage 261.0 (TID 511) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.412 Executor task launch worker for task 4.0 in stage 261.0 (TID 508) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.413 Executor task launch worker for task 7.0 in stage 261.0 (TID 511) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:03:54.413 Executor task launch worker for task 3.0 in stage 261.0 (TID 507) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.413 Executor task launch worker for task 4.0 in stage 261.0 (TID 508) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:03:54.416 Executor task launch worker for task 5.0 in stage 261.0 (TID 509) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.416 Executor task launch worker for task 5.0 in stage 261.0 (TID 509) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.425 Executor task launch worker for task 4.0 in stage 261.0 (TID 508) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.425 Executor task launch worker for task 1.0 in stage 261.0 (TID 505) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.426 Executor task launch worker for task 7.0 in stage 261.0 (TID 511) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.426 Executor task launch worker for task 6.0 in stage 261.0 (TID 510) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.426 Executor task launch worker for task 2.0 in stage 261.0 (TID 506) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.428 Executor task launch worker for task 3.0 in stage 261.0 (TID 507) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.440 Executor task launch worker for task 0.0 in stage 261.0 (TID 504) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.441 Executor task launch worker for task 5.0 in stage 261.0 (TID 509) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:54.485 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:57170 in memory (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.487 Executor task launch worker for task 1.0 in stage 261.0 (TID 505) INFO Executor: Finished task 1.0 in stage 261.0 (TID 505). 6605 bytes result sent to driver
23/10/22 15:03:54.488 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 261.0 (TID 505) in 93 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:03:54.491 Executor task launch worker for task 6.0 in stage 261.0 (TID 510) INFO Executor: Finished task 6.0 in stage 261.0 (TID 510). 6605 bytes result sent to driver
23/10/22 15:03:54.491 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 261.0 (TID 510) in 96 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:03:54.491 Executor task launch worker for task 3.0 in stage 261.0 (TID 507) INFO Executor: Finished task 3.0 in stage 261.0 (TID 507). 6648 bytes result sent to driver
23/10/22 15:03:54.491 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 261.0 (TID 507) in 96 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:03:54.491 Executor task launch worker for task 2.0 in stage 261.0 (TID 506) INFO Executor: Finished task 2.0 in stage 261.0 (TID 506). 6648 bytes result sent to driver
23/10/22 15:03:54.491 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 261.0 (TID 506) in 96 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:03:54.491 Executor task launch worker for task 5.0 in stage 261.0 (TID 509) INFO Executor: Finished task 5.0 in stage 261.0 (TID 509). 6648 bytes result sent to driver
23/10/22 15:03:54.491 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 261.0 (TID 509) in 96 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:03:54.510 Executor task launch worker for task 4.0 in stage 261.0 (TID 508) INFO Executor: Finished task 4.0 in stage 261.0 (TID 508). 6605 bytes result sent to driver
23/10/22 15:03:54.510 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 261.0 (TID 508) in 115 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:03:54.514 Executor task launch worker for task 0.0 in stage 261.0 (TID 504) INFO Executor: Finished task 0.0 in stage 261.0 (TID 504). 6648 bytes result sent to driver
23/10/22 15:03:54.514 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 261.0 (TID 504) in 119 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:03:54.517 Executor task launch worker for task 7.0 in stage 261.0 (TID 511) INFO Executor: Finished task 7.0 in stage 261.0 (TID 511). 6648 bytes result sent to driver
23/10/22 15:03:54.518 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 261.0 (TID 511) in 123 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:03:54.518 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool 
23/10/22 15:03:54.518 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 261 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.123 s
23/10/22 15:03:54.518 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:54.518 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:54.518 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 262)
23/10/22 15:03:54.518 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:54.518 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[615] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 15:03:54.520 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 101.1 KiB, free 1036.9 MiB)
23/10/22 15:03:54.521 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 40.0 KiB, free 1036.8 MiB)
23/10/22 15:03:54.522 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:57170 (size: 40.0 KiB, free: 1037.0 MiB)
23/10/22 15:03:54.523 dag-scheduler-event-loop INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:54.523 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 262 (MapPartitionsRDD[615] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:03:54.523 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 262.0 with 2 tasks resource profile 0
23/10/22 15:03:54.523 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 262.0 (TID 512) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:03:54.524 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 262.0 (TID 513) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:03:54.524 Executor task launch worker for task 1.0 in stage 262.0 (TID 513) INFO Executor: Running task 1.0 in stage 262.0 (TID 513)
23/10/22 15:03:54.524 Executor task launch worker for task 0.0 in stage 262.0 (TID 512) INFO Executor: Running task 0.0 in stage 262.0 (TID 512)
23/10/22 15:03:54.530 Executor task launch worker for task 0.0 in stage 262.0 (TID 512) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.530 Executor task launch worker for task 1.0 in stage 262.0 (TID 513) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:54.531 Executor task launch worker for task 0.0 in stage 262.0 (TID 512) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.531 Executor task launch worker for task 1.0 in stage 262.0 (TID 513) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:54.535 Executor task launch worker for task 0.0 in stage 262.0 (TID 512) INFO Executor: Finished task 0.0 in stage 262.0 (TID 512). 6771 bytes result sent to driver
23/10/22 15:03:54.535 Executor task launch worker for task 1.0 in stage 262.0 (TID 513) INFO Executor: Finished task 1.0 in stage 262.0 (TID 513). 6771 bytes result sent to driver
23/10/22 15:03:54.535 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 262.0 (TID 513) in 11 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:03:54.535 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 262.0 (TID 512) in 12 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:03:54.535 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool 
23/10/22 15:03:54.536 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 262 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.017 s
23/10/22 15:03:54.536 dag-scheduler-event-loop INFO DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:03:54.536 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished
23/10/22 15:03:54.536 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 141 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.140922 s
23/10/22 15:03:54.536 nioEventLoopGroup-2-2 INFO Instrumentation: [4731fe68] Number of instances: 3785.
23/10/22 15:03:54.557 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:57170 in memory (size: 40.0 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.596 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 618 (rdd at LinearRegression.scala:921) as input to shuffle 92
23/10/22 15:03:54.597 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 142 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 15:03:54.597 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 263 (rdd at LinearRegression.scala:921)
23/10/22 15:03:54.597 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:03:54.597 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:54.597 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 263 (MapPartitionsRDD[618] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:03:54.598 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 34.0 KiB, free 1036.9 MiB)
23/10/22 15:03:54.600 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 1036.9 MiB)
23/10/22 15:03:54.601 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:57170 (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.601 dag-scheduler-event-loop INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:54.601 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 263 (MapPartitionsRDD[618] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 15:03:54.601 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 263.0 with 1 tasks resource profile 0
23/10/22 15:03:54.708 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:57170 in memory (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.713 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:57170 in memory (size: 39.3 KiB, free: 1037.1 MiB)
23/10/22 15:03:54.870 dispatcher-event-loop-5 WARN TaskSetManager: Stage 263 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:03:54.870 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 514) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:03:54.871 Executor task launch worker for task 0.0 in stage 263.0 (TID 514) INFO Executor: Running task 0.0 in stage 263.0 (TID 514)
23/10/22 15:03:54.979 Executor task launch worker for task 0.0 in stage 263.0 (TID 514) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.740 Executor task launch worker for task 0.0 in stage 263.0 (TID 514) INFO Executor: Finished task 0.0 in stage 263.0 (TID 514). 2147 bytes result sent to driver
23/10/22 15:03:55.740 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 514) in 1138 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:03:55.740 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool 
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 263 (rdd at LinearRegression.scala:921) finished in 1.143 s
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:55.740 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(92), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 622 (rdd at LinearRegression.scala:921) as input to shuffle 93
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 143 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 265 (rdd at LinearRegression.scala:921)
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 264)
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 265 (MapPartitionsRDD[622] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 15:03:55.740 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 39.0 KiB, free 1037.1 MiB)
23/10/22 15:03:55.756 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1037.0 MiB)
23/10/22 15:03:55.756 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:57170 (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:03:55.756 dag-scheduler-event-loop INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:55.757 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 265 (MapPartitionsRDD[622] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:03:55.757 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 265.0 with 8 tasks resource profile 0
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 265.0 (TID 515) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 265.0 (TID 516) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 265.0 (TID 517) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 265.0 (TID 518) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 265.0 (TID 519) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 265.0 (TID 520) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 265.0 (TID 521) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 265.0 (TID 522) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:55.758 Executor task launch worker for task 0.0 in stage 265.0 (TID 515) INFO Executor: Running task 0.0 in stage 265.0 (TID 515)
23/10/22 15:03:55.759 Executor task launch worker for task 5.0 in stage 265.0 (TID 520) INFO Executor: Running task 5.0 in stage 265.0 (TID 520)
23/10/22 15:03:55.758 Executor task launch worker for task 3.0 in stage 265.0 (TID 518) INFO Executor: Running task 3.0 in stage 265.0 (TID 518)
23/10/22 15:03:55.759 Executor task launch worker for task 6.0 in stage 265.0 (TID 521) INFO Executor: Running task 6.0 in stage 265.0 (TID 521)
23/10/22 15:03:55.759 Executor task launch worker for task 4.0 in stage 265.0 (TID 519) INFO Executor: Running task 4.0 in stage 265.0 (TID 519)
23/10/22 15:03:55.759 Executor task launch worker for task 2.0 in stage 265.0 (TID 517) INFO Executor: Running task 2.0 in stage 265.0 (TID 517)
23/10/22 15:03:55.759 Executor task launch worker for task 1.0 in stage 265.0 (TID 516) INFO Executor: Running task 1.0 in stage 265.0 (TID 516)
23/10/22 15:03:55.759 Executor task launch worker for task 7.0 in stage 265.0 (TID 522) INFO Executor: Running task 7.0 in stage 265.0 (TID 522)
23/10/22 15:03:55.762 Executor task launch worker for task 1.0 in stage 265.0 (TID 516) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.762 Executor task launch worker for task 1.0 in stage 265.0 (TID 516) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.762 Executor task launch worker for task 5.0 in stage 265.0 (TID 520) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.762 Executor task launch worker for task 5.0 in stage 265.0 (TID 520) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.762 Executor task launch worker for task 2.0 in stage 265.0 (TID 517) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.762 Executor task launch worker for task 2.0 in stage 265.0 (TID 517) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.762 Executor task launch worker for task 7.0 in stage 265.0 (TID 522) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.763 Executor task launch worker for task 7.0 in stage 265.0 (TID 522) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.763 Executor task launch worker for task 6.0 in stage 265.0 (TID 521) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.763 Executor task launch worker for task 6.0 in stage 265.0 (TID 521) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.763 Executor task launch worker for task 4.0 in stage 265.0 (TID 519) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.763 Executor task launch worker for task 4.0 in stage 265.0 (TID 519) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.763 Executor task launch worker for task 3.0 in stage 265.0 (TID 518) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.763 Executor task launch worker for task 3.0 in stage 265.0 (TID 518) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.763 Executor task launch worker for task 0.0 in stage 265.0 (TID 515) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:55.763 Executor task launch worker for task 0.0 in stage 265.0 (TID 515) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:55.763 Executor task launch worker for task 1.0 in stage 265.0 (TID 516) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.773 Executor task launch worker for task 3.0 in stage 265.0 (TID 518) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.773 Executor task launch worker for task 4.0 in stage 265.0 (TID 519) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.779 Executor task launch worker for task 7.0 in stage 265.0 (TID 522) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.781 Executor task launch worker for task 2.0 in stage 265.0 (TID 517) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.785 Executor task launch worker for task 5.0 in stage 265.0 (TID 520) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.794 Executor task launch worker for task 6.0 in stage 265.0 (TID 521) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.795 Executor task launch worker for task 1.0 in stage 265.0 (TID 516) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.802 Executor task launch worker for task 4.0 in stage 265.0 (TID 519) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.808 Executor task launch worker for task 0.0 in stage 265.0 (TID 515) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.812 Executor task launch worker for task 5.0 in stage 265.0 (TID 520) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.814 Executor task launch worker for task 7.0 in stage 265.0 (TID 522) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.825 Executor task launch worker for task 3.0 in stage 265.0 (TID 518) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.825 Executor task launch worker for task 0.0 in stage 265.0 (TID 515) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.851 Executor task launch worker for task 2.0 in stage 265.0 (TID 517) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.867 Executor task launch worker for task 6.0 in stage 265.0 (TID 521) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:55.907 Executor task launch worker for task 4.0 in stage 265.0 (TID 519) INFO Executor: Finished task 4.0 in stage 265.0 (TID 519). 4899 bytes result sent to driver
23/10/22 15:03:55.912 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 265.0 (TID 519) in 154 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:03:55.922 Executor task launch worker for task 5.0 in stage 265.0 (TID 520) INFO Executor: Finished task 5.0 in stage 265.0 (TID 520). 4899 bytes result sent to driver
23/10/22 15:03:55.926 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 265.0 (TID 520) in 168 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:03:55.958 Executor task launch worker for task 0.0 in stage 265.0 (TID 515) INFO Executor: Finished task 0.0 in stage 265.0 (TID 515). 4899 bytes result sent to driver
23/10/22 15:03:55.960 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 265.0 (TID 515) in 202 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:03:55.977 Executor task launch worker for task 1.0 in stage 265.0 (TID 516) INFO Executor: Finished task 1.0 in stage 265.0 (TID 516). 4899 bytes result sent to driver
23/10/22 15:03:55.979 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 265.0 (TID 516) in 221 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:03:55.985 Executor task launch worker for task 2.0 in stage 265.0 (TID 517) INFO Executor: Finished task 2.0 in stage 265.0 (TID 517). 4899 bytes result sent to driver
23/10/22 15:03:55.985 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 265.0 (TID 517) in 227 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:03:55.992 Executor task launch worker for task 7.0 in stage 265.0 (TID 522) INFO Executor: Finished task 7.0 in stage 265.0 (TID 522). 4899 bytes result sent to driver
23/10/22 15:03:55.993 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 265.0 (TID 522) in 235 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:03:55.998 Executor task launch worker for task 3.0 in stage 265.0 (TID 518) INFO Executor: Finished task 3.0 in stage 265.0 (TID 518). 4899 bytes result sent to driver
23/10/22 15:03:55.999 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 265.0 (TID 518) in 241 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:03:56.011 Executor task launch worker for task 6.0 in stage 265.0 (TID 521) INFO Executor: Finished task 6.0 in stage 265.0 (TID 521). 4899 bytes result sent to driver
23/10/22 15:03:56.011 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 265.0 (TID 521) in 253 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:03:56.011 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool 
23/10/22 15:03:56.012 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 265 (rdd at LinearRegression.scala:921) finished in 0.272 s
23/10/22 15:03:56.012 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:56.012 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:56.012 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:03:56.012 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:56.016 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(93), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:03:56.023 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.4501 ms
23/10/22 15:03:56.057 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 632 (treeAggregate at Statistics.scala:58) as input to shuffle 94
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Got job 144 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 269 (treeAggregate at Statistics.scala:58)
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 268)
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 268)
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 268 (MapPartitionsRDD[632] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 90.5 KiB, free 1036.9 MiB)
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 1036.9 MiB)
23/10/22 15:03:56.057 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:57170 (size: 37.4 KiB, free: 1037.1 MiB)
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 268 (MapPartitionsRDD[632] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:03:56.057 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 268.0 with 8 tasks resource profile 0
23/10/22 15:03:56.057 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 523) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.057 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 268.0 (TID 524) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.057 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 268.0 (TID 525) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.057 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 268.0 (TID 526) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.057 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 268.0 (TID 527) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.063 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 268.0 (TID 528) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.063 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 268.0 (TID 529) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.063 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 268.0 (TID 530) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:03:56.063 Executor task launch worker for task 3.0 in stage 268.0 (TID 526) INFO Executor: Running task 3.0 in stage 268.0 (TID 526)
23/10/22 15:03:56.063 Executor task launch worker for task 1.0 in stage 268.0 (TID 524) INFO Executor: Running task 1.0 in stage 268.0 (TID 524)
23/10/22 15:03:56.063 Executor task launch worker for task 4.0 in stage 268.0 (TID 527) INFO Executor: Running task 4.0 in stage 268.0 (TID 527)
23/10/22 15:03:56.063 Executor task launch worker for task 2.0 in stage 268.0 (TID 525) INFO Executor: Running task 2.0 in stage 268.0 (TID 525)
23/10/22 15:03:56.063 Executor task launch worker for task 0.0 in stage 268.0 (TID 523) INFO Executor: Running task 0.0 in stage 268.0 (TID 523)
23/10/22 15:03:56.063 Executor task launch worker for task 7.0 in stage 268.0 (TID 530) INFO Executor: Running task 7.0 in stage 268.0 (TID 530)
23/10/22 15:03:56.063 Executor task launch worker for task 6.0 in stage 268.0 (TID 529) INFO Executor: Running task 6.0 in stage 268.0 (TID 529)
23/10/22 15:03:56.063 Executor task launch worker for task 5.0 in stage 268.0 (TID 528) INFO Executor: Running task 5.0 in stage 268.0 (TID 528)
23/10/22 15:03:56.069 Executor task launch worker for task 1.0 in stage 268.0 (TID 524) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.069 Executor task launch worker for task 4.0 in stage 268.0 (TID 527) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.069 Executor task launch worker for task 1.0 in stage 268.0 (TID 524) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.069 Executor task launch worker for task 4.0 in stage 268.0 (TID 527) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.070 Executor task launch worker for task 5.0 in stage 268.0 (TID 528) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.070 Executor task launch worker for task 5.0 in stage 268.0 (TID 528) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.072 Executor task launch worker for task 0.0 in stage 268.0 (TID 523) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.072 Executor task launch worker for task 0.0 in stage 268.0 (TID 523) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.072 Executor task launch worker for task 6.0 in stage 268.0 (TID 529) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.072 Executor task launch worker for task 3.0 in stage 268.0 (TID 526) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.072 Executor task launch worker for task 6.0 in stage 268.0 (TID 529) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.072 Executor task launch worker for task 3.0 in stage 268.0 (TID 526) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.074 Executor task launch worker for task 2.0 in stage 268.0 (TID 525) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.074 Executor task launch worker for task 2.0 in stage 268.0 (TID 525) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.074 Executor task launch worker for task 7.0 in stage 268.0 (TID 530) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.074 Executor task launch worker for task 7.0 in stage 268.0 (TID 530) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.082 Executor task launch worker for task 5.0 in stage 268.0 (TID 528) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.082 Executor task launch worker for task 1.0 in stage 268.0 (TID 524) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.082 Executor task launch worker for task 0.0 in stage 268.0 (TID 523) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.086 Executor task launch worker for task 7.0 in stage 268.0 (TID 530) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.086 Executor task launch worker for task 2.0 in stage 268.0 (TID 525) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.090 Executor task launch worker for task 6.0 in stage 268.0 (TID 529) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.107 Executor task launch worker for task 4.0 in stage 268.0 (TID 527) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.109 Executor task launch worker for task 3.0 in stage 268.0 (TID 526) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:03:56.140 Executor task launch worker for task 0.0 in stage 268.0 (TID 523) INFO Executor: Finished task 0.0 in stage 268.0 (TID 523). 6562 bytes result sent to driver
23/10/22 15:03:56.141 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 523) in 83 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:03:56.147 Executor task launch worker for task 1.0 in stage 268.0 (TID 524) INFO Executor: Finished task 1.0 in stage 268.0 (TID 524). 6605 bytes result sent to driver
23/10/22 15:03:56.147 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 268.0 (TID 524) in 90 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:03:56.156 Executor task launch worker for task 7.0 in stage 268.0 (TID 530) INFO Executor: Finished task 7.0 in stage 268.0 (TID 530). 6562 bytes result sent to driver
23/10/22 15:03:56.156 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 268.0 (TID 530) in 93 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:03:56.163 Executor task launch worker for task 5.0 in stage 268.0 (TID 528) INFO Executor: Finished task 5.0 in stage 268.0 (TID 528). 6562 bytes result sent to driver
23/10/22 15:03:56.164 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 268.0 (TID 528) in 101 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:03:56.170 Executor task launch worker for task 6.0 in stage 268.0 (TID 529) INFO Executor: Finished task 6.0 in stage 268.0 (TID 529). 6605 bytes result sent to driver
23/10/22 15:03:56.170 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 268.0 (TID 529) in 107 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:03:56.174 Executor task launch worker for task 2.0 in stage 268.0 (TID 525) INFO Executor: Finished task 2.0 in stage 268.0 (TID 525). 6562 bytes result sent to driver
23/10/22 15:03:56.175 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 268.0 (TID 525) in 118 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:03:56.181 Executor task launch worker for task 3.0 in stage 268.0 (TID 526) INFO Executor: Finished task 3.0 in stage 268.0 (TID 526). 6605 bytes result sent to driver
23/10/22 15:03:56.181 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 268.0 (TID 526) in 124 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:03:56.185 Executor task launch worker for task 4.0 in stage 268.0 (TID 527) INFO Executor: Finished task 4.0 in stage 268.0 (TID 527). 6605 bytes result sent to driver
23/10/22 15:03:56.186 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 268.0 (TID 527) in 129 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:03:56.186 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool 
23/10/22 15:03:56.187 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 268 (treeAggregate at Statistics.scala:58) finished in 0.130 s
23/10/22 15:03:56.187 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:03:56.187 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:03:56.187 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 269)
23/10/22 15:03:56.187 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:03:56.187 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 269 (MapPartitionsRDD[634] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:03:56.190 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 91.6 KiB, free 1036.8 MiB)
23/10/22 15:03:56.191 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 1036.8 MiB)
23/10/22 15:03:56.191 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:57170 (size: 37.8 KiB, free: 1037.0 MiB)
23/10/22 15:03:56.191 dag-scheduler-event-loop INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:56.191 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 269 (MapPartitionsRDD[634] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:03:56.191 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 269.0 with 2 tasks resource profile 0
23/10/22 15:03:56.191 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 531) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:03:56.191 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 269.0 (TID 532) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:03:56.191 Executor task launch worker for task 1.0 in stage 269.0 (TID 532) INFO Executor: Running task 1.0 in stage 269.0 (TID 532)
23/10/22 15:03:56.191 Executor task launch worker for task 0.0 in stage 269.0 (TID 531) INFO Executor: Running task 0.0 in stage 269.0 (TID 531)
23/10/22 15:03:56.194 Executor task launch worker for task 1.0 in stage 269.0 (TID 532) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.194 Executor task launch worker for task 1.0 in stage 269.0 (TID 532) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.194 Executor task launch worker for task 0.0 in stage 269.0 (TID 531) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:03:56.194 Executor task launch worker for task 0.0 in stage 269.0 (TID 531) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:03:56.201 Executor task launch worker for task 1.0 in stage 269.0 (TID 532) INFO Executor: Finished task 1.0 in stage 269.0 (TID 532). 7630 bytes result sent to driver
23/10/22 15:03:56.201 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 269.0 (TID 532) in 10 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:03:56.201 Executor task launch worker for task 0.0 in stage 269.0 (TID 531) INFO Executor: Finished task 0.0 in stage 269.0 (TID 531). 7630 bytes result sent to driver
23/10/22 15:03:56.201 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 531) in 10 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:03:56.201 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool 
23/10/22 15:03:56.201 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 269 (treeAggregate at Statistics.scala:58) finished in 0.013 s
23/10/22 15:03:56.201 dag-scheduler-event-loop INFO DAGScheduler: Job 144 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:03:56.201 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 269: Stage finished
23/10/22 15:03:56.201 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 144 finished: treeAggregate at Statistics.scala:58, took 0.147831 s
23/10/22 15:03:56.201 nioEventLoopGroup-2-2 INFO Instrumentation: [c7e06a51] training finished
23/10/22 15:03:56.473 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Got job 145 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 270 (collect at utils.scala:26)
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 270 (MapPartitionsRDD[636] at collect at utils.scala:26), which has no missing parents
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:03:56.473 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 270 (MapPartitionsRDD[636] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 270.0 with 1 tasks resource profile 0
23/10/22 15:03:56.473 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 533) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:03:56.473 Executor task launch worker for task 0.0 in stage 270.0 (TID 533) INFO Executor: Running task 0.0 in stage 270.0 (TID 533)
23/10/22 15:03:56.473 Executor task launch worker for task 0.0 in stage 270.0 (TID 533) INFO Executor: Finished task 0.0 in stage 270.0 (TID 533). 1284 bytes result sent to driver
23/10/22 15:03:56.473 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 533) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:03:56.473 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool 
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 270 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:03:56.473 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished
23/10/22 15:03:56.473 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 145 finished: collect at utils.scala:26, took 0.005616 s
23/10/22 15:03:56.657 nioEventLoopGroup-2-2 INFO Instrumentation: [fab22160] training finished
23/10/22 15:03:56.723 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Got job 146 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 271 (collect at utils.scala:26)
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[638] at collect at utils.scala:26), which has no missing parents
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:03:56.723 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[638] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 271.0 with 1 tasks resource profile 0
23/10/22 15:03:56.723 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 534) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:03:56.723 Executor task launch worker for task 0.0 in stage 271.0 (TID 534) INFO Executor: Running task 0.0 in stage 271.0 (TID 534)
23/10/22 15:03:56.723 Executor task launch worker for task 0.0 in stage 271.0 (TID 534) INFO Executor: Finished task 0.0 in stage 271.0 (TID 534). 1284 bytes result sent to driver
23/10/22 15:03:56.723 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 534) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:03:56.723 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool 
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 271 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:03:56.723 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished
23/10/22 15:03:56.723 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 146 finished: collect at utils.scala:26, took 0.005065 s
23/10/22 15:03:57.108 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Got job 147 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 272 (collect at utils.scala:26)
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 272 (MapPartitionsRDD[640] at collect at utils.scala:26), which has no missing parents
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 15:03:57.108 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1535
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[640] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 272.0 with 1 tasks resource profile 0
23/10/22 15:03:57.108 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 272.0 (TID 535) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:03:57.108 Executor task launch worker for task 0.0 in stage 272.0 (TID 535) INFO Executor: Running task 0.0 in stage 272.0 (TID 535)
23/10/22 15:03:57.108 Executor task launch worker for task 0.0 in stage 272.0 (TID 535) INFO Executor: Finished task 0.0 in stage 272.0 (TID 535). 1284 bytes result sent to driver
23/10/22 15:03:57.108 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 272.0 (TID 535) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:03:57.108 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool 
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 272 (collect at utils.scala:26) finished in 0.000 s
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO DAGScheduler: Job 147 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:03:57.108 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 272: Stage finished
23/10/22 15:03:57.108 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 147 finished: collect at utils.scala:26, took 0.004475 s
23/10/22 15:05:36.395 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:57170 in memory (size: 37.8 KiB, free: 1037.1 MiB)
23/10/22 15:05:36.395 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:05:36.400 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:57170 in memory (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:05:36.402 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:57170 in memory (size: 37.4 KiB, free: 1037.1 MiB)
23/10/22 15:05:36.404 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:05:36.406 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:05:36.407 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:57170 in memory (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 643 (collect at utils.scala:26) as input to shuffle 95
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 148 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 273 (collect at utils.scala:26)
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 273 (MapPartitionsRDD[643] at collect at utils.scala:26), which has no missing parents
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 34.0 KiB, free 1037.1 MiB)
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 1037.1 MiB)
23/10/22 15:27:27.701 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:57170 (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1535
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 273 (MapPartitionsRDD[643] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:27:27.701 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 273.0 with 1 tasks resource profile 0
23/10/22 15:27:28.167 dispatcher-event-loop-5 WARN TaskSetManager: Stage 273 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:27:28.168 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 273.0 (TID 536) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:27:28.168 Executor task launch worker for task 0.0 in stage 273.0 (TID 536) INFO Executor: Running task 0.0 in stage 273.0 (TID 536)
23/10/22 15:27:28.377 Executor task launch worker for task 0.0 in stage 273.0 (TID 536) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.640 Executor task launch worker for task 0.0 in stage 273.0 (TID 536) INFO Executor: Finished task 0.0 in stage 273.0 (TID 536). 2104 bytes result sent to driver
23/10/22 15:27:29.640 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 273.0 (TID 536) in 1925 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:27:29.640 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool 
23/10/22 15:27:29.640 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 273 (collect at utils.scala:26) finished in 1.939 s
23/10/22 15:27:29.640 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:27:29.640 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:27:29.640 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:27:29.640 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:27:29.640 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(95), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:27:29.654 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 647 (collect at utils.scala:26) as input to shuffle 96
23/10/22 15:27:29.654 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 149 (collect at utils.scala:26) with 8 output partitions
23/10/22 15:27:29.654 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 275 (collect at utils.scala:26)
23/10/22 15:27:29.654 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 274)
23/10/22 15:27:29.654 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:27:29.654 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 275 (MapPartitionsRDD[647] at collect at utils.scala:26), which has no missing parents
23/10/22 15:27:29.656 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 39.0 KiB, free 1037.1 MiB)
23/10/22 15:27:29.657 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1037.0 MiB)
23/10/22 15:27:29.657 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:57170 (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:27:29.658 dag-scheduler-event-loop INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1535
23/10/22 15:27:29.658 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 275 (MapPartitionsRDD[647] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:27:29.658 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 275.0 with 8 tasks resource profile 0
23/10/22 15:27:29.659 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 537) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.659 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 275.0 (TID 538) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.659 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 275.0 (TID 539) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.659 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 275.0 (TID 540) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.659 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 275.0 (TID 541) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.659 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 275.0 (TID 542) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.660 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 275.0 (TID 543) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.660 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 275.0 (TID 544) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:27:29.660 Executor task launch worker for task 0.0 in stage 275.0 (TID 537) INFO Executor: Running task 0.0 in stage 275.0 (TID 537)
23/10/22 15:27:29.661 Executor task launch worker for task 1.0 in stage 275.0 (TID 538) INFO Executor: Running task 1.0 in stage 275.0 (TID 538)
23/10/22 15:27:29.661 Executor task launch worker for task 2.0 in stage 275.0 (TID 539) INFO Executor: Running task 2.0 in stage 275.0 (TID 539)
23/10/22 15:27:29.661 Executor task launch worker for task 3.0 in stage 275.0 (TID 540) INFO Executor: Running task 3.0 in stage 275.0 (TID 540)
23/10/22 15:27:29.661 Executor task launch worker for task 4.0 in stage 275.0 (TID 541) INFO Executor: Running task 4.0 in stage 275.0 (TID 541)
23/10/22 15:27:29.661 Executor task launch worker for task 5.0 in stage 275.0 (TID 542) INFO Executor: Running task 5.0 in stage 275.0 (TID 542)
23/10/22 15:27:29.662 Executor task launch worker for task 6.0 in stage 275.0 (TID 543) INFO Executor: Running task 6.0 in stage 275.0 (TID 543)
23/10/22 15:27:29.663 Executor task launch worker for task 0.0 in stage 275.0 (TID 537) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.663 Executor task launch worker for task 0.0 in stage 275.0 (TID 537) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.666 Executor task launch worker for task 4.0 in stage 275.0 (TID 541) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.666 Executor task launch worker for task 4.0 in stage 275.0 (TID 541) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.666 Executor task launch worker for task 6.0 in stage 275.0 (TID 543) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.666 Executor task launch worker for task 2.0 in stage 275.0 (TID 539) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.666 Executor task launch worker for task 6.0 in stage 275.0 (TID 543) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.666 Executor task launch worker for task 5.0 in stage 275.0 (TID 542) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.666 Executor task launch worker for task 2.0 in stage 275.0 (TID 539) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.666 Executor task launch worker for task 5.0 in stage 275.0 (TID 542) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.666 Executor task launch worker for task 7.0 in stage 275.0 (TID 544) INFO Executor: Running task 7.0 in stage 275.0 (TID 544)
23/10/22 15:27:29.668 Executor task launch worker for task 3.0 in stage 275.0 (TID 540) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.668 Executor task launch worker for task 3.0 in stage 275.0 (TID 540) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:27:29.668 Executor task launch worker for task 1.0 in stage 275.0 (TID 538) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.668 Executor task launch worker for task 1.0 in stage 275.0 (TID 538) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.671 Executor task launch worker for task 7.0 in stage 275.0 (TID 544) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.671 Executor task launch worker for task 7.0 in stage 275.0 (TID 544) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.676 Executor task launch worker for task 5.0 in stage 275.0 (TID 542) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.676 Executor task launch worker for task 4.0 in stage 275.0 (TID 541) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.676 Executor task launch worker for task 0.0 in stage 275.0 (TID 537) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.676 Executor task launch worker for task 2.0 in stage 275.0 (TID 539) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.680 Executor task launch worker for task 3.0 in stage 275.0 (TID 540) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.680 Executor task launch worker for task 6.0 in stage 275.0 (TID 543) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.683 Executor task launch worker for task 1.0 in stage 275.0 (TID 538) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.696 Executor task launch worker for task 7.0 in stage 275.0 (TID 544) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.703 Executor task launch worker for task 6.0 in stage 275.0 (TID 543) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.704 Executor task launch worker for task 5.0 in stage 275.0 (TID 542) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.712 Executor task launch worker for task 2.0 in stage 275.0 (TID 539) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.715 Executor task launch worker for task 0.0 in stage 275.0 (TID 537) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.715 Executor task launch worker for task 3.0 in stage 275.0 (TID 540) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.716 Executor task launch worker for task 1.0 in stage 275.0 (TID 538) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.719 Executor task launch worker for task 4.0 in stage 275.0 (TID 541) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.747 Executor task launch worker for task 7.0 in stage 275.0 (TID 544) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.849 Executor task launch worker for task 0.0 in stage 275.0 (TID 537) INFO Executor: Finished task 0.0 in stage 275.0 (TID 537). 4985 bytes result sent to driver
23/10/22 15:27:29.851 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 537) in 193 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:27:29.855 Executor task launch worker for task 4.0 in stage 275.0 (TID 541) INFO Executor: Finished task 4.0 in stage 275.0 (TID 541). 4942 bytes result sent to driver
23/10/22 15:27:29.856 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 275.0 (TID 541) in 197 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:27:29.864 Executor task launch worker for task 7.0 in stage 275.0 (TID 544) INFO Executor: Finished task 7.0 in stage 275.0 (TID 544). 4942 bytes result sent to driver
23/10/22 15:27:29.865 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 275.0 (TID 544) in 205 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:27:29.870 Executor task launch worker for task 1.0 in stage 275.0 (TID 538) INFO Executor: Finished task 1.0 in stage 275.0 (TID 538). 4942 bytes result sent to driver
23/10/22 15:27:29.871 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 275.0 (TID 538) in 212 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:27:29.873 Executor task launch worker for task 6.0 in stage 275.0 (TID 543) INFO Executor: Finished task 6.0 in stage 275.0 (TID 543). 4942 bytes result sent to driver
23/10/22 15:27:29.874 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 275.0 (TID 543) in 215 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:27:29.875 Executor task launch worker for task 3.0 in stage 275.0 (TID 540) INFO Executor: Finished task 3.0 in stage 275.0 (TID 540). 4942 bytes result sent to driver
23/10/22 15:27:29.878 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 275.0 (TID 540) in 219 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:27:29.883 Executor task launch worker for task 5.0 in stage 275.0 (TID 542) INFO Executor: Finished task 5.0 in stage 275.0 (TID 542). 4942 bytes result sent to driver
23/10/22 15:27:29.884 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 275.0 (TID 542) in 225 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:27:29.892 Executor task launch worker for task 2.0 in stage 275.0 (TID 539) INFO Executor: Finished task 2.0 in stage 275.0 (TID 539). 4942 bytes result sent to driver
23/10/22 15:27:29.892 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 275.0 (TID 539) in 233 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:27:29.892 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool 
23/10/22 15:27:29.892 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 275 (collect at utils.scala:26) finished in 0.237 s
23/10/22 15:27:29.892 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:27:29.892 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:27:29.892 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:27:29.892 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:27:29.894 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(96), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:27:29.909 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.2457 ms
23/10/22 15:27:29.918 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:27:29.918 dag-scheduler-event-loop INFO DAGScheduler: Got job 150 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:27:29.918 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 278 (collect at utils.scala:26)
23/10/22 15:27:29.918 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 277)
23/10/22 15:27:29.918 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:27:29.919 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[651] at collect at utils.scala:26), which has no missing parents
23/10/22 15:27:29.921 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 51.9 KiB, free 1037.0 MiB)
23/10/22 15:27:29.921 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 1037.0 MiB)
23/10/22 15:27:29.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:57170 (size: 21.9 KiB, free: 1037.1 MiB)
23/10/22 15:27:29.922 dag-scheduler-event-loop INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1535
23/10/22 15:27:29.922 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 278 (MapPartitionsRDD[651] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:27:29.922 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 278.0 with 1 tasks resource profile 0
23/10/22 15:27:29.923 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 545) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 15:27:29.923 Executor task launch worker for task 0.0 in stage 278.0 (TID 545) INFO Executor: Running task 0.0 in stage 278.0 (TID 545)
23/10/22 15:27:29.926 Executor task launch worker for task 0.0 in stage 278.0 (TID 545) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.926 Executor task launch worker for task 0.0 in stage 278.0 (TID 545) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:29.941 Executor task launch worker for task 0.0 in stage 278.0 (TID 545) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:29.975 Executor task launch worker for task 0.0 in stage 278.0 (TID 545) INFO Executor: Finished task 0.0 in stage 278.0 (TID 545). 624717 bytes result sent to driver
23/10/22 15:27:29.975 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 545) in 52 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:27:29.975 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool 
23/10/22 15:27:29.975 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 278 (collect at utils.scala:26) finished in 0.056 s
23/10/22 15:27:29.975 dag-scheduler-event-loop INFO DAGScheduler: Job 150 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:27:29.975 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
23/10/22 15:27:29.975 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 150 finished: collect at utils.scala:26, took 0.062775 s
23/10/22 15:27:29.989 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:27:29.990 dag-scheduler-event-loop INFO DAGScheduler: Got job 151 (collect at utils.scala:26) with 2 output partitions
23/10/22 15:27:29.990 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 281 (collect at utils.scala:26)
23/10/22 15:27:29.990 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 280)
23/10/22 15:27:29.990 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:27:29.990 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 281 (MapPartitionsRDD[651] at collect at utils.scala:26), which has no missing parents
23/10/22 15:27:29.993 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 51.9 KiB, free 1036.9 MiB)
23/10/22 15:27:29.993 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 1036.9 MiB)
23/10/22 15:27:29.994 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:57170 (size: 21.9 KiB, free: 1037.1 MiB)
23/10/22 15:27:29.994 dag-scheduler-event-loop INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1535
23/10/22 15:27:29.994 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 281 (MapPartitionsRDD[651] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 15:27:29.994 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 281.0 with 2 tasks resource profile 0
23/10/22 15:27:29.995 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 281.0 (TID 546) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 15:27:29.995 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 281.0 (TID 547) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 15:27:29.995 Executor task launch worker for task 0.0 in stage 281.0 (TID 546) INFO Executor: Running task 0.0 in stage 281.0 (TID 546)
23/10/22 15:27:29.995 Executor task launch worker for task 1.0 in stage 281.0 (TID 547) INFO Executor: Running task 1.0 in stage 281.0 (TID 547)
23/10/22 15:27:29.998 Executor task launch worker for task 1.0 in stage 281.0 (TID 547) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:29.998 Executor task launch worker for task 1.0 in stage 281.0 (TID 547) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:27:30.017 Executor task launch worker for task 0.0 in stage 281.0 (TID 546) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:27:30.017 Executor task launch worker for task 0.0 in stage 281.0 (TID 546) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
23/10/22 15:27:30.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:57170 in memory (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:27:30.032 Executor task launch worker for task 1.0 in stage 281.0 (TID 547) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:30.033 Executor task launch worker for task 0.0 in stage 281.0 (TID 546) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:27:30.075 Executor task launch worker for task 1.0 in stage 281.0 (TID 547) INFO Executor: Finished task 1.0 in stage 281.0 (TID 547). 576600 bytes result sent to driver
23/10/22 15:27:30.076 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 281.0 (TID 547) in 81 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:27:30.080 Executor task launch worker for task 0.0 in stage 281.0 (TID 546) INFO Executor: Finished task 0.0 in stage 281.0 (TID 546). 609532 bytes result sent to driver
23/10/22 15:27:30.081 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 281.0 (TID 546) in 86 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:27:30.082 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool 
23/10/22 15:27:30.082 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 281 (collect at utils.scala:26) finished in 0.091 s
23/10/22 15:27:30.082 dag-scheduler-event-loop INFO DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:27:30.082 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 281: Stage finished
23/10/22 15:27:30.083 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 151 finished: collect at utils.scala:26, took 0.093281 s
23/10/22 15:29:54.680 nioEventLoopGroup-2-2 INFO Instrumentation: [a121185a] training finished
23/10/22 15:29:54.690 nioEventLoopGroup-2-2 INFO Instrumentation: [df45c76c] training finished
23/10/22 15:29:54.830 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:29:54.830 dag-scheduler-event-loop INFO DAGScheduler: Got job 152 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:29:54.830 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 282 (collect at utils.scala:26)
23/10/22 15:29:54.830 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:29:54.830 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:29:54.830 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 282 (MapPartitionsRDD[653] at collect at utils.scala:26), which has no missing parents
23/10/22 15:29:54.830 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 15:29:54.846 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 15:29:54.847 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:29:54.847 dag-scheduler-event-loop INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:54.847 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (MapPartitionsRDD[653] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:29:54.847 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 282.0 with 1 tasks resource profile 0
23/10/22 15:29:54.880 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 282.0 (TID 548) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:29:54.880 Executor task launch worker for task 0.0 in stage 282.0 (TID 548) INFO Executor: Running task 0.0 in stage 282.0 (TID 548)
23/10/22 15:29:54.880 Executor task launch worker for task 0.0 in stage 282.0 (TID 548) INFO Executor: Finished task 0.0 in stage 282.0 (TID 548). 1327 bytes result sent to driver
23/10/22 15:29:54.880 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 282.0 (TID 548) in 33 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:29:54.880 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool 
23/10/22 15:29:54.880 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 282 (collect at utils.scala:26) finished in 0.050 s
23/10/22 15:29:54.880 dag-scheduler-event-loop INFO DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:29:54.880 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 282: Stage finished
23/10/22 15:29:54.880 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 152 finished: collect at utils.scala:26, took 0.049456 s
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 656 (rdd at RegressionEvaluator.scala:125) as input to shuffle 97
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 153 (rdd at RegressionEvaluator.scala:125) with 1 output partitions
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 283 (rdd at RegressionEvaluator.scala:125)
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 283 (MapPartitionsRDD[656] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 34.0 KiB, free 1036.9 MiB)
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 1036.9 MiB)
23/10/22 15:29:55.330 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:57170 (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 283 (MapPartitionsRDD[656] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0))
23/10/22 15:29:55.330 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 283.0 with 1 tasks resource profile 0
23/10/22 15:29:55.530 dispatcher-event-loop-1 WARN TaskSetManager: Stage 283 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:29:55.530 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 283.0 (TID 549) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:29:55.530 Executor task launch worker for task 0.0 in stage 283.0 (TID 549) INFO Executor: Running task 0.0 in stage 283.0 (TID 549)
23/10/22 15:29:55.645 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:57170 in memory (size: 21.9 KiB, free: 1037.1 MiB)
23/10/22 15:29:55.648 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:57170 in memory (size: 21.9 KiB, free: 1037.1 MiB)
23/10/22 15:29:55.649 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:29:55.729 Executor task launch worker for task 0.0 in stage 283.0 (TID 549) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:55.910 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:57170 in memory (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:29:56.864 Executor task launch worker for task 0.0 in stage 283.0 (TID 549) INFO Executor: Finished task 0.0 in stage 283.0 (TID 549). 2147 bytes result sent to driver
23/10/22 15:29:56.864 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 283.0 (TID 549) in 1534 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:29:56.864 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool 
23/10/22 15:29:56.864 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 283 (rdd at RegressionEvaluator.scala:125) finished in 1.534 s
23/10/22 15:29:56.864 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:29:56.864 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:29:56.864 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:29:56.864 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:29:56.864 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(97), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:29:56.880 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 660 (rdd at RegressionEvaluator.scala:125) as input to shuffle 98
23/10/22 15:29:56.880 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 154 (rdd at RegressionEvaluator.scala:125) with 8 output partitions
23/10/22 15:29:56.880 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 285 (rdd at RegressionEvaluator.scala:125)
23/10/22 15:29:56.880 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 284)
23/10/22 15:29:56.880 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:29:56.880 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 285 (MapPartitionsRDD[660] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 15:29:56.882 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 39.0 KiB, free 1037.1 MiB)
23/10/22 15:29:56.882 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1037.0 MiB)
23/10/22 15:29:56.882 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:57170 (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:29:56.882 dag-scheduler-event-loop INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:56.882 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 285 (MapPartitionsRDD[660] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:29:56.882 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 285.0 with 8 tasks resource profile 0
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 285.0 (TID 550) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 285.0 (TID 551) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 285.0 (TID 552) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 285.0 (TID 553) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 285.0 (TID 554) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 285.0 (TID 555) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 285.0 (TID 556) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 285.0 (TID 557) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:56.882 Executor task launch worker for task 0.0 in stage 285.0 (TID 550) INFO Executor: Running task 0.0 in stage 285.0 (TID 550)
23/10/22 15:29:56.882 Executor task launch worker for task 1.0 in stage 285.0 (TID 551) INFO Executor: Running task 1.0 in stage 285.0 (TID 551)
23/10/22 15:29:56.882 Executor task launch worker for task 2.0 in stage 285.0 (TID 552) INFO Executor: Running task 2.0 in stage 285.0 (TID 552)
23/10/22 15:29:56.882 Executor task launch worker for task 3.0 in stage 285.0 (TID 553) INFO Executor: Running task 3.0 in stage 285.0 (TID 553)
23/10/22 15:29:56.882 Executor task launch worker for task 4.0 in stage 285.0 (TID 554) INFO Executor: Running task 4.0 in stage 285.0 (TID 554)
23/10/22 15:29:56.895 Executor task launch worker for task 7.0 in stage 285.0 (TID 557) INFO Executor: Running task 7.0 in stage 285.0 (TID 557)
23/10/22 15:29:56.896 Executor task launch worker for task 1.0 in stage 285.0 (TID 551) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.896 Executor task launch worker for task 1.0 in stage 285.0 (TID 551) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.896 Executor task launch worker for task 0.0 in stage 285.0 (TID 550) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.896 Executor task launch worker for task 0.0 in stage 285.0 (TID 550) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.896 Executor task launch worker for task 2.0 in stage 285.0 (TID 552) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.896 Executor task launch worker for task 2.0 in stage 285.0 (TID 552) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.897 Executor task launch worker for task 5.0 in stage 285.0 (TID 555) INFO Executor: Running task 5.0 in stage 285.0 (TID 555)
23/10/22 15:29:56.897 Executor task launch worker for task 3.0 in stage 285.0 (TID 553) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.897 Executor task launch worker for task 3.0 in stage 285.0 (TID 553) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.897 Executor task launch worker for task 6.0 in stage 285.0 (TID 556) INFO Executor: Running task 6.0 in stage 285.0 (TID 556)
23/10/22 15:29:56.898 Executor task launch worker for task 7.0 in stage 285.0 (TID 557) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.898 Executor task launch worker for task 7.0 in stage 285.0 (TID 557) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.898 Executor task launch worker for task 4.0 in stage 285.0 (TID 554) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.898 Executor task launch worker for task 4.0 in stage 285.0 (TID 554) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.899 Executor task launch worker for task 6.0 in stage 285.0 (TID 556) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.899 Executor task launch worker for task 6.0 in stage 285.0 (TID 556) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.899 Executor task launch worker for task 5.0 in stage 285.0 (TID 555) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:56.899 Executor task launch worker for task 5.0 in stage 285.0 (TID 555) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:56.904 Executor task launch worker for task 7.0 in stage 285.0 (TID 557) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.904 Executor task launch worker for task 1.0 in stage 285.0 (TID 551) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.905 Executor task launch worker for task 2.0 in stage 285.0 (TID 552) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.905 Executor task launch worker for task 4.0 in stage 285.0 (TID 554) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.914 Executor task launch worker for task 6.0 in stage 285.0 (TID 556) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.914 Executor task launch worker for task 5.0 in stage 285.0 (TID 555) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.916 Executor task launch worker for task 0.0 in stage 285.0 (TID 550) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.924 Executor task launch worker for task 3.0 in stage 285.0 (TID 553) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.930 Executor task launch worker for task 7.0 in stage 285.0 (TID 557) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.934 Executor task launch worker for task 4.0 in stage 285.0 (TID 554) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.935 Executor task launch worker for task 1.0 in stage 285.0 (TID 551) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.947 Executor task launch worker for task 3.0 in stage 285.0 (TID 553) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.947 Executor task launch worker for task 2.0 in stage 285.0 (TID 552) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.965 Executor task launch worker for task 0.0 in stage 285.0 (TID 550) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.981 Executor task launch worker for task 6.0 in stage 285.0 (TID 556) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:56.981 Executor task launch worker for task 5.0 in stage 285.0 (TID 555) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.023 Executor task launch worker for task 4.0 in stage 285.0 (TID 554) INFO Executor: Finished task 4.0 in stage 285.0 (TID 554). 4899 bytes result sent to driver
23/10/22 15:29:57.025 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 285.0 (TID 554) in 143 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:29:57.035 Executor task launch worker for task 7.0 in stage 285.0 (TID 557) INFO Executor: Finished task 7.0 in stage 285.0 (TID 557). 4942 bytes result sent to driver
23/10/22 15:29:57.035 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 285.0 (TID 557) in 153 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:29:57.053 Executor task launch worker for task 3.0 in stage 285.0 (TID 553) INFO Executor: Finished task 3.0 in stage 285.0 (TID 553). 4942 bytes result sent to driver
23/10/22 15:29:57.064 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 285.0 (TID 553) in 181 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:29:57.125 Executor task launch worker for task 2.0 in stage 285.0 (TID 552) INFO Executor: Finished task 2.0 in stage 285.0 (TID 552). 4942 bytes result sent to driver
23/10/22 15:29:57.125 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 285.0 (TID 552) in 243 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:29:57.136 Executor task launch worker for task 5.0 in stage 285.0 (TID 555) INFO Executor: Finished task 5.0 in stage 285.0 (TID 555). 4942 bytes result sent to driver
23/10/22 15:29:57.136 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 285.0 (TID 555) in 254 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:29:57.136 Executor task launch worker for task 0.0 in stage 285.0 (TID 550) INFO Executor: Finished task 0.0 in stage 285.0 (TID 550). 4942 bytes result sent to driver
23/10/22 15:29:57.144 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 285.0 (TID 550) in 262 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:29:57.147 Executor task launch worker for task 6.0 in stage 285.0 (TID 556) INFO Executor: Finished task 6.0 in stage 285.0 (TID 556). 4942 bytes result sent to driver
23/10/22 15:29:57.147 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 285.0 (TID 556) in 265 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:29:57.156 Executor task launch worker for task 1.0 in stage 285.0 (TID 551) INFO Executor: Finished task 1.0 in stage 285.0 (TID 551). 4985 bytes result sent to driver
23/10/22 15:29:57.156 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 285.0 (TID 551) in 274 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:29:57.156 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 285.0, whose tasks have all completed, from pool 
23/10/22 15:29:57.156 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 285 (rdd at RegressionEvaluator.scala:125) finished in 0.274 s
23/10/22 15:29:57.156 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:29:57.156 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:29:57.156 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:29:57.156 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:29:57.156 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(98), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:29:57.180 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.1127 ms
23/10/22 15:29:57.263 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 670 (treeAggregate at Statistics.scala:58) as input to shuffle 99
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Got job 155 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 289 (treeAggregate at Statistics.scala:58)
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 288)
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 288)
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 288 (MapPartitionsRDD[670] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 85.4 KiB, free 1037.0 MiB)
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 1036.9 MiB)
23/10/22 15:29:57.263 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:57170 (size: 36.3 KiB, free: 1037.1 MiB)
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 288 (MapPartitionsRDD[670] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:29:57.263 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 288.0 with 8 tasks resource profile 0
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 288.0 (TID 558) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 288.0 (TID 559) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 288.0 (TID 560) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 288.0 (TID 561) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 288.0 (TID 562) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 288.0 (TID 563) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 288.0 (TID 564) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 288.0 (TID 565) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:57.263 Executor task launch worker for task 0.0 in stage 288.0 (TID 558) INFO Executor: Running task 0.0 in stage 288.0 (TID 558)
23/10/22 15:29:57.263 Executor task launch worker for task 7.0 in stage 288.0 (TID 565) INFO Executor: Running task 7.0 in stage 288.0 (TID 565)
23/10/22 15:29:57.263 Executor task launch worker for task 4.0 in stage 288.0 (TID 562) INFO Executor: Running task 4.0 in stage 288.0 (TID 562)
23/10/22 15:29:57.263 Executor task launch worker for task 6.0 in stage 288.0 (TID 564) INFO Executor: Running task 6.0 in stage 288.0 (TID 564)
23/10/22 15:29:57.278 Executor task launch worker for task 2.0 in stage 288.0 (TID 560) INFO Executor: Running task 2.0 in stage 288.0 (TID 560)
23/10/22 15:29:57.263 Executor task launch worker for task 3.0 in stage 288.0 (TID 561) INFO Executor: Running task 3.0 in stage 288.0 (TID 561)
23/10/22 15:29:57.263 Executor task launch worker for task 1.0 in stage 288.0 (TID 559) INFO Executor: Running task 1.0 in stage 288.0 (TID 559)
23/10/22 15:29:57.278 Executor task launch worker for task 5.0 in stage 288.0 (TID 563) INFO Executor: Running task 5.0 in stage 288.0 (TID 563)
23/10/22 15:29:57.285 Executor task launch worker for task 5.0 in stage 288.0 (TID 563) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.285 Executor task launch worker for task 7.0 in stage 288.0 (TID 565) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.285 Executor task launch worker for task 5.0 in stage 288.0 (TID 563) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.285 Executor task launch worker for task 0.0 in stage 288.0 (TID 558) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.285 Executor task launch worker for task 0.0 in stage 288.0 (TID 558) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.285 Executor task launch worker for task 7.0 in stage 288.0 (TID 565) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.285 Executor task launch worker for task 1.0 in stage 288.0 (TID 559) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.285 Executor task launch worker for task 2.0 in stage 288.0 (TID 560) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.286 Executor task launch worker for task 1.0 in stage 288.0 (TID 559) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.286 Executor task launch worker for task 2.0 in stage 288.0 (TID 560) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.286 Executor task launch worker for task 4.0 in stage 288.0 (TID 562) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.286 Executor task launch worker for task 4.0 in stage 288.0 (TID 562) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.287 Executor task launch worker for task 3.0 in stage 288.0 (TID 561) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.287 Executor task launch worker for task 3.0 in stage 288.0 (TID 561) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.287 Executor task launch worker for task 6.0 in stage 288.0 (TID 564) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.287 Executor task launch worker for task 6.0 in stage 288.0 (TID 564) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.298 Executor task launch worker for task 7.0 in stage 288.0 (TID 565) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.298 Executor task launch worker for task 5.0 in stage 288.0 (TID 563) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.301 Executor task launch worker for task 1.0 in stage 288.0 (TID 559) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.302 Executor task launch worker for task 6.0 in stage 288.0 (TID 564) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.303 Executor task launch worker for task 2.0 in stage 288.0 (TID 560) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.304 Executor task launch worker for task 4.0 in stage 288.0 (TID 562) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.304 Executor task launch worker for task 0.0 in stage 288.0 (TID 558) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.305 Executor task launch worker for task 3.0 in stage 288.0 (TID 561) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:57.409 Executor task launch worker for task 5.0 in stage 288.0 (TID 563) INFO Executor: Finished task 5.0 in stage 288.0 (TID 563). 6648 bytes result sent to driver
23/10/22 15:29:57.410 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:57170 in memory (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:29:57.410 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 288.0 (TID 563) in 147 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:29:57.420 Executor task launch worker for task 2.0 in stage 288.0 (TID 560) INFO Executor: Finished task 2.0 in stage 288.0 (TID 560). 6605 bytes result sent to driver
23/10/22 15:29:57.430 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 288.0 (TID 560) in 166 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:29:57.436 Executor task launch worker for task 1.0 in stage 288.0 (TID 559) INFO Executor: Finished task 1.0 in stage 288.0 (TID 559). 6648 bytes result sent to driver
23/10/22 15:29:57.438 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 288.0 (TID 559) in 174 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:29:57.445 Executor task launch worker for task 7.0 in stage 288.0 (TID 565) INFO Executor: Finished task 7.0 in stage 288.0 (TID 565). 6648 bytes result sent to driver
23/10/22 15:29:57.455 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 288.0 (TID 565) in 192 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:29:57.458 Executor task launch worker for task 6.0 in stage 288.0 (TID 564) INFO Executor: Finished task 6.0 in stage 288.0 (TID 564). 6648 bytes result sent to driver
23/10/22 15:29:57.459 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 288.0 (TID 564) in 196 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:29:57.466 Executor task launch worker for task 3.0 in stage 288.0 (TID 561) INFO Executor: Finished task 3.0 in stage 288.0 (TID 561). 6648 bytes result sent to driver
23/10/22 15:29:57.467 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 288.0 (TID 561) in 204 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:29:57.471 Executor task launch worker for task 4.0 in stage 288.0 (TID 562) INFO Executor: Finished task 4.0 in stage 288.0 (TID 562). 6648 bytes result sent to driver
23/10/22 15:29:57.472 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 288.0 (TID 562) in 209 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:29:57.480 Executor task launch worker for task 0.0 in stage 288.0 (TID 558) INFO Executor: Finished task 0.0 in stage 288.0 (TID 558). 6648 bytes result sent to driver
23/10/22 15:29:57.481 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 288.0 (TID 558) in 218 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:29:57.482 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 288.0, whose tasks have all completed, from pool 
23/10/22 15:29:57.482 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 288 (treeAggregate at Statistics.scala:58) finished in 0.219 s
23/10/22 15:29:57.482 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:29:57.482 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:29:57.482 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 289)
23/10/22 15:29:57.482 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:29:57.483 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 289 (MapPartitionsRDD[672] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:29:57.483 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 86.5 KiB, free 1036.9 MiB)
23/10/22 15:29:57.483 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1036.9 MiB)
23/10/22 15:29:57.483 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:57170 (size: 36.6 KiB, free: 1037.1 MiB)
23/10/22 15:29:57.483 dag-scheduler-event-loop INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:57.483 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 289 (MapPartitionsRDD[672] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:29:57.483 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 289.0 with 2 tasks resource profile 0
23/10/22 15:29:57.483 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 289.0 (TID 566) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:29:57.483 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 289.0 (TID 567) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:29:57.483 Executor task launch worker for task 1.0 in stage 289.0 (TID 567) INFO Executor: Running task 1.0 in stage 289.0 (TID 567)
23/10/22 15:29:57.483 Executor task launch worker for task 0.0 in stage 289.0 (TID 566) INFO Executor: Running task 0.0 in stage 289.0 (TID 566)
23/10/22 15:29:57.496 Executor task launch worker for task 1.0 in stage 289.0 (TID 567) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.496 Executor task launch worker for task 1.0 in stage 289.0 (TID 567) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.496 Executor task launch worker for task 0.0 in stage 289.0 (TID 566) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:57.496 Executor task launch worker for task 0.0 in stage 289.0 (TID 566) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:57.496 Executor task launch worker for task 0.0 in stage 289.0 (TID 566) INFO Executor: Finished task 0.0 in stage 289.0 (TID 566). 7630 bytes result sent to driver
23/10/22 15:29:57.496 Executor task launch worker for task 1.0 in stage 289.0 (TID 567) INFO Executor: Finished task 1.0 in stage 289.0 (TID 567). 7630 bytes result sent to driver
23/10/22 15:29:57.503 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 289.0 (TID 566) in 20 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:29:57.503 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 289.0 (TID 567) in 20 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:29:57.503 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 289.0, whose tasks have all completed, from pool 
23/10/22 15:29:57.503 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 289 (treeAggregate at Statistics.scala:58) finished in 0.020 s
23/10/22 15:29:57.503 dag-scheduler-event-loop INFO DAGScheduler: Job 155 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:29:57.503 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 289: Stage finished
23/10/22 15:29:57.503 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 155 finished: treeAggregate at Statistics.scala:58, took 0.232360 s
23/10/22 15:29:57.600 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:57170 in memory (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:29:57.627 nioEventLoopGroup-2-2 INFO Instrumentation: [a0141d72] training finished
23/10/22 15:29:57.633 nioEventLoopGroup-2-2 INFO Instrumentation: [37edf9bc] training finished
23/10/22 15:29:57.730 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 15:29:57.730 dag-scheduler-event-loop INFO DAGScheduler: Got job 156 (collect at utils.scala:26) with 1 output partitions
23/10/22 15:29:57.730 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 290 (collect at utils.scala:26)
23/10/22 15:29:57.730 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:29:57.730 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:29:57.745 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 290 (MapPartitionsRDD[674] at collect at utils.scala:26), which has no missing parents
23/10/22 15:29:57.746 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 15:29:57.747 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:57170 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 290 (MapPartitionsRDD[674] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 290.0 with 1 tasks resource profile 0
23/10/22 15:29:57.747 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 290.0 (TID 568) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 15:29:57.747 Executor task launch worker for task 0.0 in stage 290.0 (TID 568) INFO Executor: Running task 0.0 in stage 290.0 (TID 568)
23/10/22 15:29:57.747 Executor task launch worker for task 0.0 in stage 290.0 (TID 568) INFO Executor: Finished task 0.0 in stage 290.0 (TID 568). 1327 bytes result sent to driver
23/10/22 15:29:57.747 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 290.0 (TID 568) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:29:57.747 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 290.0, whose tasks have all completed, from pool 
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 290 (collect at utils.scala:26) finished in 0.001 s
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:29:57.747 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 290: Stage finished
23/10/22 15:29:57.747 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 156 finished: collect at utils.scala:26, took 0.008130 s
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 677 (rdd at RegressionEvaluator.scala:125) as input to shuffle 100
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 157 (rdd at RegressionEvaluator.scala:125) with 1 output partitions
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 291 (rdd at RegressionEvaluator.scala:125)
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 291 (MapPartitionsRDD[677] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 34.0 KiB, free 1036.9 MiB)
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 1036.8 MiB)
23/10/22 15:29:58.180 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:57170 (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 291 (MapPartitionsRDD[677] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0))
23/10/22 15:29:58.180 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 291.0 with 1 tasks resource profile 0
23/10/22 15:29:58.446 dispatcher-event-loop-6 WARN TaskSetManager: Stage 291 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 15:29:58.446 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 291.0 (TID 569) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 15:29:58.446 Executor task launch worker for task 0.0 in stage 291.0 (TID 569) INFO Executor: Running task 0.0 in stage 291.0 (TID 569)
23/10/22 15:29:58.597 Executor task launch worker for task 0.0 in stage 291.0 (TID 569) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:58.835 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:57170 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 15:29:58.839 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:57170 in memory (size: 36.6 KiB, free: 1037.1 MiB)
23/10/22 15:29:59.106 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:57170 in memory (size: 36.3 KiB, free: 1037.1 MiB)
23/10/22 15:29:59.597 Executor task launch worker for task 0.0 in stage 291.0 (TID 569) INFO Executor: Finished task 0.0 in stage 291.0 (TID 569). 2104 bytes result sent to driver
23/10/22 15:29:59.597 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 291.0 (TID 569) in 1401 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 15:29:59.597 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 291.0, whose tasks have all completed, from pool 
23/10/22 15:29:59.597 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 291 (rdd at RegressionEvaluator.scala:125) finished in 1.417 s
23/10/22 15:29:59.597 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:29:59.597 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:29:59.597 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:29:59.597 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:29:59.597 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(100), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 15:29:59.613 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 681 (rdd at RegressionEvaluator.scala:125) as input to shuffle 101
23/10/22 15:29:59.613 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 158 (rdd at RegressionEvaluator.scala:125) with 8 output partitions
23/10/22 15:29:59.613 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 293 (rdd at RegressionEvaluator.scala:125)
23/10/22 15:29:59.613 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 292)
23/10/22 15:29:59.614 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 15:29:59.614 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 293 (MapPartitionsRDD[681] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 15:29:59.616 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 39.0 KiB, free 1037.1 MiB)
23/10/22 15:29:59.617 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 1037.0 MiB)
23/10/22 15:29:59.618 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:57170 (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 15:29:59.619 dag-scheduler-event-loop INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:59.619 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 293 (MapPartitionsRDD[681] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:29:59.619 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 293.0 with 8 tasks resource profile 0
23/10/22 15:29:59.620 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 293.0 (TID 570) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.620 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 293.0 (TID 571) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.620 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 293.0 (TID 572) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.620 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 293.0 (TID 573) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.620 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 293.0 (TID 574) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.621 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 293.0 (TID 575) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.621 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 293.0 (TID 576) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.621 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 293.0 (TID 577) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.621 Executor task launch worker for task 1.0 in stage 293.0 (TID 571) INFO Executor: Running task 1.0 in stage 293.0 (TID 571)
23/10/22 15:29:59.621 Executor task launch worker for task 5.0 in stage 293.0 (TID 575) INFO Executor: Running task 5.0 in stage 293.0 (TID 575)
23/10/22 15:29:59.621 Executor task launch worker for task 0.0 in stage 293.0 (TID 570) INFO Executor: Running task 0.0 in stage 293.0 (TID 570)
23/10/22 15:29:59.621 Executor task launch worker for task 2.0 in stage 293.0 (TID 572) INFO Executor: Running task 2.0 in stage 293.0 (TID 572)
23/10/22 15:29:59.621 Executor task launch worker for task 4.0 in stage 293.0 (TID 574) INFO Executor: Running task 4.0 in stage 293.0 (TID 574)
23/10/22 15:29:59.621 Executor task launch worker for task 3.0 in stage 293.0 (TID 573) INFO Executor: Running task 3.0 in stage 293.0 (TID 573)
23/10/22 15:29:59.621 Executor task launch worker for task 7.0 in stage 293.0 (TID 577) INFO Executor: Running task 7.0 in stage 293.0 (TID 577)
23/10/22 15:29:59.621 Executor task launch worker for task 6.0 in stage 293.0 (TID 576) INFO Executor: Running task 6.0 in stage 293.0 (TID 576)
23/10/22 15:29:59.626 Executor task launch worker for task 4.0 in stage 293.0 (TID 574) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.626 Executor task launch worker for task 5.0 in stage 293.0 (TID 575) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.626 Executor task launch worker for task 0.0 in stage 293.0 (TID 570) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.626 Executor task launch worker for task 6.0 in stage 293.0 (TID 576) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.626 Executor task launch worker for task 1.0 in stage 293.0 (TID 571) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.626 Executor task launch worker for task 7.0 in stage 293.0 (TID 577) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.627 Executor task launch worker for task 1.0 in stage 293.0 (TID 571) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.627 Executor task launch worker for task 7.0 in stage 293.0 (TID 577) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.626 Executor task launch worker for task 4.0 in stage 293.0 (TID 574) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.626 Executor task launch worker for task 5.0 in stage 293.0 (TID 575) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.626 Executor task launch worker for task 2.0 in stage 293.0 (TID 572) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.626 Executor task launch worker for task 3.0 in stage 293.0 (TID 573) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.627 Executor task launch worker for task 6.0 in stage 293.0 (TID 576) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.627 Executor task launch worker for task 0.0 in stage 293.0 (TID 570) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.627 Executor task launch worker for task 2.0 in stage 293.0 (TID 572) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.627 Executor task launch worker for task 3.0 in stage 293.0 (TID 573) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.634 Executor task launch worker for task 1.0 in stage 293.0 (TID 571) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.634 Executor task launch worker for task 3.0 in stage 293.0 (TID 573) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.636 Executor task launch worker for task 7.0 in stage 293.0 (TID 577) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.637 Executor task launch worker for task 5.0 in stage 293.0 (TID 575) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.638 Executor task launch worker for task 6.0 in stage 293.0 (TID 576) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.640 Executor task launch worker for task 0.0 in stage 293.0 (TID 570) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.640 Executor task launch worker for task 4.0 in stage 293.0 (TID 574) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.644 Executor task launch worker for task 2.0 in stage 293.0 (TID 572) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.648 Executor task launch worker for task 3.0 in stage 293.0 (TID 573) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.648 Executor task launch worker for task 1.0 in stage 293.0 (TID 571) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.666 Executor task launch worker for task 6.0 in stage 293.0 (TID 576) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.666 Executor task launch worker for task 7.0 in stage 293.0 (TID 577) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.666 Executor task launch worker for task 5.0 in stage 293.0 (TID 575) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.668 Executor task launch worker for task 4.0 in stage 293.0 (TID 574) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.669 Executor task launch worker for task 0.0 in stage 293.0 (TID 570) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.681 Executor task launch worker for task 2.0 in stage 293.0 (TID 572) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.779 Executor task launch worker for task 0.0 in stage 293.0 (TID 570) INFO Executor: Finished task 0.0 in stage 293.0 (TID 570). 4942 bytes result sent to driver
23/10/22 15:29:59.780 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 293.0 (TID 570) in 160 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:29:59.787 Executor task launch worker for task 5.0 in stage 293.0 (TID 575) INFO Executor: Finished task 5.0 in stage 293.0 (TID 575). 4942 bytes result sent to driver
23/10/22 15:29:59.789 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 293.0 (TID 575) in 168 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:29:59.795 Executor task launch worker for task 3.0 in stage 293.0 (TID 573) INFO Executor: Finished task 3.0 in stage 293.0 (TID 573). 4942 bytes result sent to driver
23/10/22 15:29:59.796 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 293.0 (TID 573) in 176 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:29:59.806 Executor task launch worker for task 2.0 in stage 293.0 (TID 572) INFO Executor: Finished task 2.0 in stage 293.0 (TID 572). 4942 bytes result sent to driver
23/10/22 15:29:59.807 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 293.0 (TID 572) in 187 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:29:59.812 Executor task launch worker for task 6.0 in stage 293.0 (TID 576) INFO Executor: Finished task 6.0 in stage 293.0 (TID 576). 4942 bytes result sent to driver
23/10/22 15:29:59.813 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 293.0 (TID 576) in 192 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:29:59.813 Executor task launch worker for task 1.0 in stage 293.0 (TID 571) INFO Executor: Finished task 1.0 in stage 293.0 (TID 571). 4942 bytes result sent to driver
23/10/22 15:29:59.813 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 293.0 (TID 571) in 193 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:29:59.813 Executor task launch worker for task 4.0 in stage 293.0 (TID 574) INFO Executor: Finished task 4.0 in stage 293.0 (TID 574). 4942 bytes result sent to driver
23/10/22 15:29:59.813 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 293.0 (TID 574) in 193 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:29:59.813 Executor task launch worker for task 7.0 in stage 293.0 (TID 577) INFO Executor: Finished task 7.0 in stage 293.0 (TID 577). 4942 bytes result sent to driver
23/10/22 15:29:59.829 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 293.0 (TID 577) in 208 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:29:59.829 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 293.0, whose tasks have all completed, from pool 
23/10/22 15:29:59.829 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 293 (rdd at RegressionEvaluator.scala:125) finished in 0.215 s
23/10/22 15:29:59.829 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:29:59.830 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:29:59.830 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 15:29:59.830 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:29:59.831 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(101), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 15:29:59.851 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.9372 ms
23/10/22 15:29:59.869 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:57170 in memory (size: 15.3 KiB, free: 1037.1 MiB)
23/10/22 15:29:59.897 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 15:29:59.898 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 691 (treeAggregate at Statistics.scala:58) as input to shuffle 102
23/10/22 15:29:59.898 dag-scheduler-event-loop INFO DAGScheduler: Got job 159 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 15:29:59.898 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 297 (treeAggregate at Statistics.scala:58)
23/10/22 15:29:59.898 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 296)
23/10/22 15:29:59.898 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 296)
23/10/22 15:29:59.899 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 296 (MapPartitionsRDD[691] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:29:59.902 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 90.9 KiB, free 1037.0 MiB)
23/10/22 15:29:59.904 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 37.7 KiB, free 1037.0 MiB)
23/10/22 15:29:59.904 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:57170 (size: 37.7 KiB, free: 1037.1 MiB)
23/10/22 15:29:59.904 dag-scheduler-event-loop INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1535
23/10/22 15:29:59.904 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 296 (MapPartitionsRDD[691] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 15:29:59.904 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 296.0 with 8 tasks resource profile 0
23/10/22 15:29:59.905 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 296.0 (TID 578) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.905 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 296.0 (TID 579) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 296.0 (TID 580) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 296.0 (TID 581) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 296.0 (TID 582) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 296.0 (TID 583) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 296.0 (TID 584) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 296.0 (TID 585) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 15:29:59.906 Executor task launch worker for task 0.0 in stage 296.0 (TID 578) INFO Executor: Running task 0.0 in stage 296.0 (TID 578)
23/10/22 15:29:59.906 Executor task launch worker for task 6.0 in stage 296.0 (TID 584) INFO Executor: Running task 6.0 in stage 296.0 (TID 584)
23/10/22 15:29:59.906 Executor task launch worker for task 2.0 in stage 296.0 (TID 580) INFO Executor: Running task 2.0 in stage 296.0 (TID 580)
23/10/22 15:29:59.906 Executor task launch worker for task 4.0 in stage 296.0 (TID 582) INFO Executor: Running task 4.0 in stage 296.0 (TID 582)
23/10/22 15:29:59.906 Executor task launch worker for task 3.0 in stage 296.0 (TID 581) INFO Executor: Running task 3.0 in stage 296.0 (TID 581)
23/10/22 15:29:59.906 Executor task launch worker for task 1.0 in stage 296.0 (TID 579) INFO Executor: Running task 1.0 in stage 296.0 (TID 579)
23/10/22 15:29:59.906 Executor task launch worker for task 5.0 in stage 296.0 (TID 583) INFO Executor: Running task 5.0 in stage 296.0 (TID 583)
23/10/22 15:29:59.906 Executor task launch worker for task 7.0 in stage 296.0 (TID 585) INFO Executor: Running task 7.0 in stage 296.0 (TID 585)
23/10/22 15:29:59.913 Executor task launch worker for task 4.0 in stage 296.0 (TID 582) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.914 Executor task launch worker for task 4.0 in stage 296.0 (TID 582) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.913 Executor task launch worker for task 2.0 in stage 296.0 (TID 580) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.914 Executor task launch worker for task 2.0 in stage 296.0 (TID 580) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.913 Executor task launch worker for task 7.0 in stage 296.0 (TID 585) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.915 Executor task launch worker for task 7.0 in stage 296.0 (TID 585) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 15:29:59.916 Executor task launch worker for task 6.0 in stage 296.0 (TID 584) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.916 Executor task launch worker for task 6.0 in stage 296.0 (TID 584) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.918 Executor task launch worker for task 0.0 in stage 296.0 (TID 578) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.918 Executor task launch worker for task 0.0 in stage 296.0 (TID 578) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.919 Executor task launch worker for task 5.0 in stage 296.0 (TID 583) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.919 Executor task launch worker for task 1.0 in stage 296.0 (TID 579) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.919 Executor task launch worker for task 1.0 in stage 296.0 (TID 579) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.919 Executor task launch worker for task 5.0 in stage 296.0 (TID 583) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.920 Executor task launch worker for task 3.0 in stage 296.0 (TID 581) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:29:59.920 Executor task launch worker for task 3.0 in stage 296.0 (TID 581) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:29:59.928 Executor task launch worker for task 4.0 in stage 296.0 (TID 582) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.930 Executor task launch worker for task 7.0 in stage 296.0 (TID 585) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.930 Executor task launch worker for task 2.0 in stage 296.0 (TID 580) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.933 Executor task launch worker for task 6.0 in stage 296.0 (TID 584) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.933 Executor task launch worker for task 0.0 in stage 296.0 (TID 578) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.946 Executor task launch worker for task 3.0 in stage 296.0 (TID 581) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.949 Executor task launch worker for task 5.0 in stage 296.0 (TID 583) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.958 Executor task launch worker for task 1.0 in stage 296.0 (TID 579) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 15:29:59.981 Executor task launch worker for task 4.0 in stage 296.0 (TID 582) INFO Executor: Finished task 4.0 in stage 296.0 (TID 582). 6605 bytes result sent to driver
23/10/22 15:29:59.982 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 296.0 (TID 582) in 76 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 15:29:59.989 Executor task launch worker for task 2.0 in stage 296.0 (TID 580) INFO Executor: Finished task 2.0 in stage 296.0 (TID 580). 6605 bytes result sent to driver
23/10/22 15:29:59.990 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 296.0 (TID 580) in 85 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 15:29:59.995 Executor task launch worker for task 7.0 in stage 296.0 (TID 585) INFO Executor: Finished task 7.0 in stage 296.0 (TID 585). 6605 bytes result sent to driver
23/10/22 15:29:59.995 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 296.0 (TID 585) in 89 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 15:29:59.997 Executor task launch worker for task 0.0 in stage 296.0 (TID 578) INFO Executor: Finished task 0.0 in stage 296.0 (TID 578). 6562 bytes result sent to driver
23/10/22 15:29:59.997 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 296.0 (TID 578) in 92 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 15:29:59.997 Executor task launch worker for task 6.0 in stage 296.0 (TID 584) INFO Executor: Finished task 6.0 in stage 296.0 (TID 584). 6605 bytes result sent to driver
23/10/22 15:29:59.997 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 296.0 (TID 584) in 91 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 15:29:59.997 Executor task launch worker for task 1.0 in stage 296.0 (TID 579) INFO Executor: Finished task 1.0 in stage 296.0 (TID 579). 6605 bytes result sent to driver
23/10/22 15:29:59.997 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 296.0 (TID 579) in 92 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 15:30:00.014 Executor task launch worker for task 5.0 in stage 296.0 (TID 583) INFO Executor: Finished task 5.0 in stage 296.0 (TID 583). 6605 bytes result sent to driver
23/10/22 15:30:00.014 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 296.0 (TID 583) in 108 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 15:30:00.014 Executor task launch worker for task 3.0 in stage 296.0 (TID 581) INFO Executor: Finished task 3.0 in stage 296.0 (TID 581). 6562 bytes result sent to driver
23/10/22 15:30:00.014 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 296.0 (TID 581) in 108 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 15:30:00.014 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 296.0, whose tasks have all completed, from pool 
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 296 (treeAggregate at Statistics.scala:58) finished in 0.114 s
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 297)
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 297 (MapPartitionsRDD[693] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 92.0 KiB, free 1036.9 MiB)
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 38.2 KiB, free 1036.8 MiB)
23/10/22 15:30:00.014 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:57170 (size: 38.2 KiB, free: 1037.1 MiB)
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1535
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 297 (MapPartitionsRDD[693] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 15:30:00.014 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 297.0 with 2 tasks resource profile 0
23/10/22 15:30:00.014 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 297.0 (TID 586) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 15:30:00.014 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 297.0 (TID 587) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 15:30:00.014 Executor task launch worker for task 1.0 in stage 297.0 (TID 587) INFO Executor: Running task 1.0 in stage 297.0 (TID 587)
23/10/22 15:30:00.014 Executor task launch worker for task 0.0 in stage 297.0 (TID 586) INFO Executor: Running task 0.0 in stage 297.0 (TID 586)
23/10/22 15:30:00.032 Executor task launch worker for task 1.0 in stage 297.0 (TID 587) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:30:00.032 Executor task launch worker for task 1.0 in stage 297.0 (TID 587) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:30:00.034 Executor task launch worker for task 0.0 in stage 297.0 (TID 586) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 15:30:00.035 Executor task launch worker for task 0.0 in stage 297.0 (TID 586) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 15:30:00.036 Executor task launch worker for task 1.0 in stage 297.0 (TID 587) INFO Executor: Finished task 1.0 in stage 297.0 (TID 587). 7673 bytes result sent to driver
23/10/22 15:30:00.037 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 297.0 (TID 587) in 23 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 15:30:00.040 Executor task launch worker for task 0.0 in stage 297.0 (TID 586) INFO Executor: Finished task 0.0 in stage 297.0 (TID 586). 7673 bytes result sent to driver
23/10/22 15:30:00.040 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 297.0 (TID 586) in 26 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 15:30:00.040 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 297.0, whose tasks have all completed, from pool 
23/10/22 15:30:00.041 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 297 (treeAggregate at Statistics.scala:58) finished in 0.026 s
23/10/22 15:30:00.041 dag-scheduler-event-loop INFO DAGScheduler: Job 159 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 15:30:00.041 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 297: Stage finished
23/10/22 15:30:00.041 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 159 finished: treeAggregate at Statistics.scala:58, took 0.144470 s
23/10/22 15:35:36.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:57170 in memory (size: 38.2 KiB, free: 1037.1 MiB)
23/10/22 15:35:36.440 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:57170 in memory (size: 37.7 KiB, free: 1037.1 MiB)
23/10/22 15:35:36.440 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:57170 in memory (size: 17.6 KiB, free: 1037.1 MiB)
23/10/22 19:22:39.536 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 19:22:49.557 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 19:22:59.563 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 19:23:04.467 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 19:23:04.467 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 19:23:04.470 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 19:46:49.633 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 19:46:59.638 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 19:47:04.559 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 19:47:04.560 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 19:52:46.739 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 19:52:51.668 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 20:19:58.446 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 20:20:08.450 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 20:20:18.456 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 20:20:23.357 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 20:20:23.357 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 20:20:23.357 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 20:53:47.641 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 20:53:57.659 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 20:54:07.672 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 20:54:12.562 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 20:54:12.563 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 20:54:12.563 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 21:09:54.718 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 21:10:04.721 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 21:10:14.737 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
23/10/22 21:10:19.641 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 21:10:19.641 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 21:10:19.641 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/10/22 21:32:19.066 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
23/10/22 21:32:19.068 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/10/22 21:32:19.125 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/10/22 21:32:19.162 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/10/22 21:32:19.359 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
23/10/22 21:32:19.360 shutdown-hook-0 INFO BlockManager: BlockManager stopped
23/10/22 21:32:19.363 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
23/10/22 21:32:19.373 dispatcher-event-loop-3 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/10/22 21:32:19.379 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0
java.io.IOException: Failed to delete: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0\sparklyr-master-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
23/10/22 21:32:19.382 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
23/10/22 21:32:19.382 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
23/10/22 21:32:19.383 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0
23/10/22 21:32:19.385 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0
java.io.IOException: Failed to delete: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0\sparklyr-master-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
23/10/22 21:32:19.385 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377
23/10/22 21:32:19.387 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377
java.io.IOException: Failed to delete: C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-b91f7b0c-5116-49d6-ac6a-11f71741d377\userFiles-bb1d68a3-c25a-4a1e-8413-06e5eac1b3b0\sparklyr-master-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
23/10/22 21:32:19.387 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\priya\AppData\Local\Temp\spark-073a8723-835c-4e96-abb7-f290ce3b8b26
23/10/22 21:33:32.786 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/conf/hive-site.xml
23/10/22 21:33:33.148 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.0
23/10/22 21:33:33.297 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/10/22 21:33:33.340 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/10/22 21:33:33.340 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/10/22 21:33:33.341 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/10/22 21:33:33.341 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/10/22 21:33:33.378 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/10/22 21:33:33.396 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/10/22 21:33:33.397 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/10/22 21:33:33.489 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: priya
23/10/22 21:33:33.490 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: priya
23/10/22 21:33:33.491 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/10/22 21:33:33.493 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/10/22 21:33:33.494 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: priya; groups with view permissions: EMPTY; users with modify permissions: priya; groups with modify permissions: EMPTY
23/10/22 21:33:33.700 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 55182.
23/10/22 21:33:33.746 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/10/22 21:33:33.797 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/10/22 21:33:33.822 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/10/22 21:33:33.823 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/10/22 21:33:33.827 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/10/22 21:33:33.852 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\blockmgr-89647be5-2f8c-43fc-8466-7e7f5214c7b9
23/10/22 21:33:33.876 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
23/10/22 21:33:33.898 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/10/22 21:33:33.902 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/local]. Please check your configured local directories.
23/10/22 21:33:34.073 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 127.0.0.1:4040 for SparkUI
23/10/22 21:33:34.159 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/10/22 21:33:34.201 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/priya/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:55182/jars/sparklyr-master-2.12.jar with timestamp 1697981613135
23/10/22 21:33:34.284 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/10/22 21:33:34.292 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/10/22 21:33:34.302 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:55182/jars/sparklyr-master-2.12.jar with timestamp 1697981613135
23/10/22 21:33:34.342 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:55182 after 14 ms (0 ms spent in bootstraps)
23/10/22 21:33:34.349 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:55182/jars/sparklyr-master-2.12.jar to C:\Users\priya\AppData\Local\spark\spark-3.4.0-bin-hadoop3\tmp\local\spark-8c8b5af7-253c-499d-b57b-d622fd53d131\userFiles-42081e2f-6bc1-4606-b277-b6579de802fb\fetchFileTemp18301229663417408075.tmp
23/10/22 21:33:34.467 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/local/spark-8c8b5af7-253c-499d-b57b-d622fd53d131/userFiles-42081e2f-6bc1-4606-b277-b6579de802fb/sparklyr-master-2.12.jar to class loader
23/10/22 21:33:34.496 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55185.
23/10/22 21:33:34.496 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:55185
23/10/22 21:33:34.499 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/10/22 21:33:34.506 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55185, None)
23/10/22 21:33:34.509 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55185 with 1048.8 MiB RAM, BlockManagerId(driver, 127.0.0.1, 55185, None)
23/10/22 21:33:34.512 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55185, None)
23/10/22 21:33:34.513 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55185, None)
23/10/22 21:33:34.866 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
23/10/22 21:33:34.880 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive'.
23/10/22 21:33:40.892 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/10/22 21:33:41.393 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/priya/AppData/Local/spark/spark-3.4.0-bin-hadoop3/tmp/hive
23/10/22 21:33:41.802 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/10/22 21:33:41.805 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/10/22 21:33:41.805 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/10/22 21:33:41.881 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/10/22 21:33:42.146 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/10/22 21:33:42.148 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/10/22 21:33:44.166 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/10/22 21:33:46.350 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/10/22 21:33:46.354 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/10/22 21:33:46.495 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/10/22 21:33:46.495 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.1.72
23/10/22 21:33:46.539 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/10/22 21:33:46.806 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/10/22 21:33:46.810 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/10/22 21:33:46.909 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/10/22 21:33:47.120 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:33:47.123 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:33:47.158 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/10/22 21:33:47.158 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/10/22 21:33:47.161 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/10/22 21:33:47.162 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:33:47.163 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:33:47.167 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:33:47.168 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:33:47.169 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/22 21:33:47.170 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/22 21:33:48.397 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 335.6496 ms
23/10/22 21:33:48.635 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:33:48.647 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.008770 s
23/10/22 21:34:00.825 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.287 ms
23/10/22 21:34:00.866 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:00.897 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:00.898 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
23/10/22 21:34:00.899 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:00.902 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:00.907 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:01.038 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.4 KiB, free 1048.8 MiB)
23/10/22 21:34:01.136 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1048.8 MiB)
23/10/22 21:34:01.144 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 21:34:01.152 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:01.190 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:01.192 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/10/22 21:34:01.327 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 21:34:01.352 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/10/22 21:34:01.547 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1499 bytes result sent to driver
23/10/22 21:34:01.565 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 279 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:01.579 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/10/22 21:34:01.587 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.649 s
23/10/22 21:34:01.593 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:01.595 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/10/22 21:34:01.596 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.727958 s
23/10/22 21:34:01.699 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 35.8504 ms
23/10/22 21:34:02.199 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:02.200 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:02.201 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
23/10/22 21:34:02.201 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:02.201 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:02.203 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:02.208 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.4 KiB, free 1048.8 MiB)
23/10/22 21:34:02.210 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1048.8 MiB)
23/10/22 21:34:02.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 21:34:02.212 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:02.213 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:02.214 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/10/22 21:34:02.216 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 21:34:02.218 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/10/22 21:34:02.226 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1413 bytes result sent to driver
23/10/22 21:34:02.227 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 11 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:02.227 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/10/22 21:34:02.229 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.024 s
23/10/22 21:34:02.229 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:02.229 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/10/22 21:34:02.229 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.029693 s
23/10/22 21:34:02.430 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:34:02.430 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:34:02.434 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:34:02.435 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:34:02.438 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/22 21:34:02.438 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/22 21:34:02.579 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 73.6325 ms
23/10/22 21:34:02.647 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.4658 ms
23/10/22 21:34:02.682 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.0899 ms
23/10/22 21:34:03.016 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 20.6972 ms
23/10/22 21:34:03.102 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:03.104 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:03.104 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
23/10/22 21:34:03.104 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:03.110 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:03.111 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:03.137 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.0 KiB, free 1048.8 MiB)
23/10/22 21:34:03.140 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 1048.8 MiB)
23/10/22 21:34:03.143 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55185 (size: 6.7 KiB, free: 1048.8 MiB)
23/10/22 21:34:03.143 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:03.143 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:03.144 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/10/22 21:34:03.939 dispatcher-event-loop-3 WARN TaskSetManager: Stage 2 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:03.940 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/22 21:34:03.941 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/10/22 21:34:04.289 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 21:34:04.295 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1048.8 MiB)
23/10/22 21:34:07.267 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 11.7 MiB, free 1037.1 MiB)
23/10/22 21:34:07.296 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:55185 (size: 11.7 MiB, free: 1037.1 MiB)
23/10/22 21:34:07.318 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 7.7502 ms
23/10/22 21:34:07.376 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 49.2156 ms
23/10/22 21:34:07.393 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_11_0]
23/10/22 21:34:07.396 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1972 bytes result sent to driver
23/10/22 21:34:07.396 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 4250 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:07.397 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/10/22 21:34:07.397 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 4.284 s
23/10/22 21:34:07.397 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:07.398 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/10/22 21:34:07.398 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 4.295562 s
23/10/22 21:34:07.433 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.5622 ms
23/10/22 21:34:07.560 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:34:07.561 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:34:07.565 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/10/22 21:34:07.565 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_database: default	
23/10/22 21:34:07.567 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/10/22 21:34:07.568 nioEventLoopGroup-2-2 INFO audit: ugi=priya	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/10/22 21:34:08.212 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.5895 ms
23/10/22 21:34:08.224 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:08.225 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:08.226 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
23/10/22 21:34:08.226 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:08.226 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:08.227 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:08.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 21:34:08.234 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 21:34:08.236 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 21:34:08.237 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:08.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:08.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/10/22 21:34:08.239 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 21:34:08.241 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/10/22 21:34:08.249 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1370 bytes result sent to driver
23/10/22 21:34:08.252 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 14 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:08.252 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/10/22 21:34:08.254 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.025 s
23/10/22 21:34:08.254 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:08.255 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/10/22 21:34:08.255 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.030128 s
23/10/22 21:34:08.280 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.2533 ms
23/10/22 21:34:08.705 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
23/10/22 21:34:08.795 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:26) as input to shuffle 0
23/10/22 21:34:08.799 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 5 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:08.800 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 4 (collect at utils.scala:26)
23/10/22 21:34:08.800 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:08.803 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:08.804 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[22] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:08.854 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 54.8 KiB, free 1037.1 MiB)
23/10/22 21:34:08.856 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 1037.0 MiB)
23/10/22 21:34:08.858 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55185 (size: 20.2 KiB, free: 1037.1 MiB)
23/10/22 21:34:08.858 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:08.860 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[22] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:08.860 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/10/22 21:34:09.331 dispatcher-event-loop-1 WARN TaskSetManager: Stage 4 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:09.331 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:34:09.332 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/10/22 21:34:09.612 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO BlockManager: Found block rdd_11_0 locally
23/10/22 21:34:09.682 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 28.1112 ms
23/10/22 21:34:09.985 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 159.7335 ms
23/10/22 21:34:09.995 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 5.6571 ms
23/10/22 21:34:10.035 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO CodeGenerator: Code generated in 28.9776 ms
23/10/22 21:34:10.709 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 21:34:12.519 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55185 in memory (size: 6.7 KiB, free: 1037.1 MiB)
23/10/22 21:34:17.344 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2068 bytes result sent to driver
23/10/22 21:34:17.347 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8483 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:17.347 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/10/22 21:34:17.350 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 4 (collect at utils.scala:26) finished in 8.543 s
23/10/22 21:34:17.351 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:34:17.351 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:34:17.352 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:34:17.352 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:34:17.439 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.3506 ms
23/10/22 21:34:17.464 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:17.466 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:17.466 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
23/10/22 21:34:17.466 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
23/10/22 21:34:17.467 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:17.467 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:17.510 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 117.1 KiB, free 1037.0 MiB)
23/10/22 21:34:17.512 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1036.9 MiB)
23/10/22 21:34:17.513 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55185 (size: 35.0 KiB, free: 1037.1 MiB)
23/10/22 21:34:17.514 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:17.514 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:17.514 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/10/22 21:34:17.518 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:34:17.519 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
23/10/22 21:34:17.568 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:17.571 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
23/10/22 21:34:17.699 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 58.4132 ms
23/10/22 21:34:17.768 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 44.5245 ms
23/10/22 21:34:17.868 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO CodeGenerator: Code generated in 69.2945 ms
23/10/22 21:34:17.925 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 4973 bytes result sent to driver
23/10/22 21:34:17.926 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 410 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:17.926 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/10/22 21:34:17.928 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.451 s
23/10/22 21:34:17.928 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:17.928 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/10/22 21:34:17.930 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.465293 s
23/10/22 21:34:17.945 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.7787 ms
23/10/22 21:34:21.330 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.769 ms
23/10/22 21:34:21.334 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:26) as input to shuffle 1
23/10/22 21:34:21.335 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 7 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:21.335 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 7 (collect at utils.scala:26)
23/10/22 21:34:21.335 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:21.335 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:21.336 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:21.338 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 22.5 KiB, free 1036.9 MiB)
23/10/22 21:34:21.341 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 1036.9 MiB)
23/10/22 21:34:21.341 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55185 (size: 8.6 KiB, free: 1037.1 MiB)
23/10/22 21:34:21.343 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:21.343 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[28] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:21.343 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/10/22 21:34:21.673 dispatcher-event-loop-0 WARN TaskSetManager: Stage 7 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:21.674 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:34:21.675 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
23/10/22 21:34:21.976 Executor task launch worker for task 0.0 in stage 7.0 (TID 6) INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 1839 bytes result sent to driver
23/10/22 21:34:21.977 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 633 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:21.978 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/10/22 21:34:21.979 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:26) finished in 0.642 s
23/10/22 21:34:21.979 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:34:21.980 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:34:21.980 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:34:21.980 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:34:22.026 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.6863 ms
23/10/22 21:34:22.039 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:22.040 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:22.040 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
23/10/22 21:34:22.040 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
23/10/22 21:34:22.040 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:22.041 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:22.042 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.2 KiB, free 1036.9 MiB)
23/10/22 21:34:22.043 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 1036.9 MiB)
23/10/22 21:34:22.045 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55185 (size: 8.9 KiB, free: 1037.1 MiB)
23/10/22 21:34:22.045 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:22.046 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:22.046 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/10/22 21:34:22.047 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:34:22.048 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO Executor: Running task 0.0 in stage 9.0 (TID 7)
23/10/22 21:34:22.050 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:22.051 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:22.054 Executor task launch worker for task 0.0 in stage 9.0 (TID 7) INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 3950 bytes result sent to driver
23/10/22 21:34:22.055 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 8 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:22.055 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/10/22 21:34:22.056 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.015 s
23/10/22 21:34:22.057 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:22.057 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/10/22 21:34:22.057 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.018167 s
23/10/22 21:34:22.070 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.1138 ms
23/10/22 21:34:23.158 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.6343 ms
23/10/22 21:34:23.174 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 34 (collect at utils.scala:26) as input to shuffle 2
23/10/22 21:34:23.175 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 9 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:23.175 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at utils.scala:26)
23/10/22 21:34:23.175 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:23.175 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:23.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:23.180 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 23.1 KiB, free 1036.8 MiB)
23/10/22 21:34:23.184 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 1036.8 MiB)
23/10/22 21:34:23.186 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55185 (size: 11.0 KiB, free: 1037.1 MiB)
23/10/22 21:34:23.187 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:23.187 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:23.187 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/10/22 21:34:23.539 dispatcher-event-loop-5 WARN TaskSetManager: Stage 10 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:23.539 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:34:23.540 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO Executor: Running task 0.0 in stage 10.0 (TID 8)
23/10/22 21:34:23.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55185 in memory (size: 35.0 KiB, free: 1037.1 MiB)
23/10/22 21:34:23.763 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:55185 in memory (size: 8.9 KiB, free: 1037.1 MiB)
23/10/22 21:34:23.826 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 13.5235 ms
23/10/22 21:34:23.853 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 11.9261 ms
23/10/22 21:34:24.883 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 5.1842 ms
23/10/22 21:34:24.893 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.6718 ms
23/10/22 21:34:24.900 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 3.8872 ms
23/10/22 21:34:24.910 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 6.5663 ms
23/10/22 21:34:24.924 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO CodeGenerator: Code generated in 9.384 ms
23/10/22 21:34:25.312 Executor task launch worker for task 0.0 in stage 10.0 (TID 8) INFO Executor: Finished task 0.0 in stage 10.0 (TID 8). 2057 bytes result sent to driver
23/10/22 21:34:25.313 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 2125 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:25.313 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/10/22 21:34:25.315 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:26) finished in 2.138 s
23/10/22 21:34:25.315 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:34:25.315 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:34:25.315 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:34:25.315 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:34:25.369 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 21:34:25.407 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.0236 ms
23/10/22 21:34:25.431 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:25.432 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:25.432 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
23/10/22 21:34:25.432 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
23/10/22 21:34:25.432 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:25.432 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:25.435 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.3 KiB, free 1037.0 MiB)
23/10/22 21:34:25.437 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 1037.0 MiB)
23/10/22 21:34:25.439 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55185 (size: 13.5 KiB, free: 1037.1 MiB)
23/10/22 21:34:25.439 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:25.440 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:25.440 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/10/22 21:34:25.441 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:34:25.442 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO Executor: Running task 0.0 in stage 12.0 (TID 9)
23/10/22 21:34:25.448 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO ShuffleBlockFetcherIterator: Getting 1 (136.8 KiB) non-empty blocks including 1 (136.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:25.448 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 21:34:25.479 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 6.5195 ms
23/10/22 21:34:25.489 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 6.1378 ms
23/10/22 21:34:25.497 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO CodeGenerator: Code generated in 5.4962 ms
23/10/22 21:34:25.509 Executor task launch worker for task 0.0 in stage 12.0 (TID 9) INFO Executor: Finished task 0.0 in stage 12.0 (TID 9). 82209 bytes result sent to driver
23/10/22 21:34:25.511 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 70 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:25.511 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/10/22 21:34:25.513 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.079 s
23/10/22 21:34:25.513 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:25.513 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/10/22 21:34:25.514 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.083146 s
23/10/22 21:34:25.531 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.4936 ms
23/10/22 21:34:25.970 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.2742 ms
23/10/22 21:34:25.978 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:25.979 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:25.979 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
23/10/22 21:34:25.979 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:25.980 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:25.980 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:25.982 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 9.1 KiB, free 1037.0 MiB)
23/10/22 21:34:25.984 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1036.9 MiB)
23/10/22 21:34:25.985 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55185 (size: 4.3 KiB, free: 1037.1 MiB)
23/10/22 21:34:25.986 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:25.986 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[40] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:25.986 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/10/22 21:34:26.267 dispatcher-event-loop-6 WARN TaskSetManager: Stage 13 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:26.267 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/22 21:34:26.268 Executor task launch worker for task 0.0 in stage 13.0 (TID 10) INFO Executor: Running task 0.0 in stage 13.0 (TID 10)
23/10/22 21:34:26.464 Executor task launch worker for task 0.0 in stage 13.0 (TID 10) INFO Executor: Finished task 0.0 in stage 13.0 (TID 10). 47636 bytes result sent to driver
23/10/22 21:34:26.465 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 478 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:26.466 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/10/22 21:34:26.466 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0.485 s
23/10/22 21:34:26.467 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:26.467 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/10/22 21:34:26.467 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.489241 s
23/10/22 21:34:29.355 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.0059 ms
23/10/22 21:34:29.362 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:29.363 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:29.363 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
23/10/22 21:34:29.363 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:29.363 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:29.364 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:29.366 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.2 KiB, free 1036.9 MiB)
23/10/22 21:34:29.368 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 1036.9 MiB)
23/10/22 21:34:29.369 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55185 (size: 5.2 KiB, free: 1037.1 MiB)
23/10/22 21:34:29.370 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:29.370 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[42] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:29.370 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
23/10/22 21:34:29.441 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55185 in memory (size: 13.5 KiB, free: 1037.1 MiB)
23/10/22 21:34:29.638 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55185 in memory (size: 20.2 KiB, free: 1037.1 MiB)
23/10/22 21:34:29.642 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:55185 in memory (size: 8.6 KiB, free: 1037.1 MiB)
23/10/22 21:34:29.647 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:55185 in memory (size: 11.0 KiB, free: 1037.1 MiB)
23/10/22 21:34:29.841 dispatcher-event-loop-0 WARN TaskSetManager: Stage 14 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:29.841 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913681 bytes) 
23/10/22 21:34:29.842 Executor task launch worker for task 0.0 in stage 14.0 (TID 11) INFO Executor: Running task 0.0 in stage 14.0 (TID 11)
23/10/22 21:34:29.990 Executor task launch worker for task 0.0 in stage 14.0 (TID 11) INFO Executor: Finished task 0.0 in stage 14.0 (TID 11). 41088 bytes result sent to driver
23/10/22 21:34:29.992 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 620 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:29.992 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
23/10/22 21:34:29.992 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.627 s
23/10/22 21:34:29.993 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:29.993 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
23/10/22 21:34:29.993 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.630090 s
23/10/22 21:34:30.010 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.0395 ms
23/10/22 21:34:34.148 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.1593 ms
23/10/22 21:34:34.154 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:26) as input to shuffle 3
23/10/22 21:34:34.154 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 13 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:34.154 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at utils.scala:26)
23/10/22 21:34:34.154 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:34:34.155 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:34.155 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[45] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:34.178 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 21:34:34.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.1 MiB)
23/10/22 21:34:34.180 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 21:34:34.181 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:34.181 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[45] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:34.181 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/10/22 21:34:34.458 dispatcher-event-loop-2 WARN TaskSetManager: Stage 15 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:34:34.459 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:34:34.460 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
23/10/22 21:34:34.641 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 8.2752 ms
23/10/22 21:34:34.659 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 10.4092 ms
23/10/22 21:34:34.673 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 9.5286 ms
23/10/22 21:34:34.685 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 5.7927 ms
23/10/22 21:34:34.693 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 4.4333 ms
23/10/22 21:34:34.743 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:34.753 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 4.4833 ms
23/10/22 21:34:34.762 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 4.3138 ms
23/10/22 21:34:34.796 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 25.7066 ms
23/10/22 21:34:34.806 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 5.2916 ms
23/10/22 21:34:34.993 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55185 in memory (size: 4.3 KiB, free: 1037.1 MiB)
23/10/22 21:34:34.998 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55185 in memory (size: 5.2 KiB, free: 1037.1 MiB)
23/10/22 21:34:35.871 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO CodeGenerator: Code generated in 6.6929 ms
23/10/22 21:34:36.661 Executor task launch worker for task 0.0 in stage 15.0 (TID 12) INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 2147 bytes result sent to driver
23/10/22 21:34:36.662 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 2480 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:36.662 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/10/22 21:34:36.663 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:26) finished in 2.506 s
23/10/22 21:34:36.663 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:34:36.663 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:34:36.663 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:34:36.663 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:34:36.669 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 21:34:36.678 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 49 (collect at utils.scala:26) as input to shuffle 4
23/10/22 21:34:36.678 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 14 (collect at utils.scala:26) with 8 output partitions
23/10/22 21:34:36.678 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 17 (collect at utils.scala:26)
23/10/22 21:34:36.678 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
23/10/22 21:34:36.679 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:36.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[49] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:36.683 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 21:34:36.683 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 21:34:36.685 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 21:34:36.685 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:36.685 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[49] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 21:34:36.685 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 8 tasks resource profile 0
23/10/22 21:34:36.686 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.687 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 14) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.688 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 15) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.688 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 16) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.688 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 17) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.688 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 18) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.689 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 17.0 (TID 19) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.689 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 17.0 (TID 20) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 21:34:36.689 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO Executor: Running task 0.0 in stage 17.0 (TID 13)
23/10/22 21:34:36.690 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO Executor: Running task 3.0 in stage 17.0 (TID 16)
23/10/22 21:34:36.690 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO Executor: Running task 2.0 in stage 17.0 (TID 15)
23/10/22 21:34:36.690 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO Executor: Running task 1.0 in stage 17.0 (TID 14)
23/10/22 21:34:36.696 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.696 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.696 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:36.696 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 21:34:36.698 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO Executor: Running task 4.0 in stage 17.0 (TID 17)
23/10/22 21:34:36.699 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.699 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:36.702 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.702 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:36.703 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.703 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:36.706 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO Executor: Running task 5.0 in stage 17.0 (TID 18)
23/10/22 21:34:36.712 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.712 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 7.8727 ms
23/10/22 21:34:36.712 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:36.722 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 7.1522 ms
23/10/22 21:34:36.732 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.740 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.747 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.755 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.759 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.787 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.802 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO Executor: Running task 7.0 in stage 17.0 (TID 20)
23/10/22 21:34:36.806 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO Executor: Running task 6.0 in stage 17.0 (TID 19)
23/10/22 21:34:36.808 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.808 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:36.812 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 24.073 ms
23/10/22 21:34:36.822 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:36.822 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 21:34:36.822 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 6.7728 ms
23/10/22 21:34:36.829 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 4.749 ms
23/10/22 21:34:36.837 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 6.2974 ms
23/10/22 21:34:36.849 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO CodeGenerator: Code generated in 7.7201 ms
23/10/22 21:34:36.851 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.863 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.863 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.871 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO CodeGenerator: Code generated in 6.7923 ms
23/10/22 21:34:36.874 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.876 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.881 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.882 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO CodeGenerator: Code generated in 6.9232 ms
23/10/22 21:34:36.886 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.891 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.903 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.925 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:36.951 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO CodeGenerator: Code generated in 9.7688 ms
23/10/22 21:34:37.034 Executor task launch worker for task 3.0 in stage 17.0 (TID 16) INFO Executor: Finished task 3.0 in stage 17.0 (TID 16). 4942 bytes result sent to driver
23/10/22 21:34:37.037 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 16) in 349 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 21:34:37.062 Executor task launch worker for task 4.0 in stage 17.0 (TID 17) INFO Executor: Finished task 4.0 in stage 17.0 (TID 17). 4899 bytes result sent to driver
23/10/22 21:34:37.079 Executor task launch worker for task 7.0 in stage 17.0 (TID 20) INFO Executor: Finished task 7.0 in stage 17.0 (TID 20). 4899 bytes result sent to driver
23/10/22 21:34:37.089 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 17) in 401 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 21:34:37.089 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 17.0 (TID 20) in 400 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 21:34:37.097 Executor task launch worker for task 0.0 in stage 17.0 (TID 13) INFO Executor: Finished task 0.0 in stage 17.0 (TID 13). 4899 bytes result sent to driver
23/10/22 21:34:37.099 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 413 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 21:34:37.113 Executor task launch worker for task 6.0 in stage 17.0 (TID 19) INFO Executor: Finished task 6.0 in stage 17.0 (TID 19). 4899 bytes result sent to driver
23/10/22 21:34:37.114 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 17.0 (TID 19) in 425 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 21:34:37.117 Executor task launch worker for task 1.0 in stage 17.0 (TID 14) INFO Executor: Finished task 1.0 in stage 17.0 (TID 14). 4899 bytes result sent to driver
23/10/22 21:34:37.118 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 14) in 432 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 21:34:37.121 Executor task launch worker for task 5.0 in stage 17.0 (TID 18) INFO Executor: Finished task 5.0 in stage 17.0 (TID 18). 4942 bytes result sent to driver
23/10/22 21:34:37.121 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 18) in 433 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 21:34:37.123 Executor task launch worker for task 2.0 in stage 17.0 (TID 15) INFO Executor: Finished task 2.0 in stage 17.0 (TID 15). 4942 bytes result sent to driver
23/10/22 21:34:37.123 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 15) in 436 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 21:34:37.124 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/10/22 21:34:37.125 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:26) finished in 0.444 s
23/10/22 21:34:37.125 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:34:37.125 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:34:37.125 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:34:37.125 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:34:37.128 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 21:34:37.139 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:37.140 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:34:37.140 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:26)
23/10/22 21:34:37.140 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
23/10/22 21:34:37.140 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:37.141 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:37.146 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 21:34:37.148 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1037.0 MiB)
23/10/22 21:34:37.149 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55185 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:34:37.149 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:37.149 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:34:37.149 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
23/10/22 21:34:37.150 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 21) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:34:37.151 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO Executor: Running task 0.0 in stage 20.0 (TID 21)
23/10/22 21:34:37.155 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:37.155 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:34:37.168 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.4464 ms
23/10/22 21:34:37.175 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.1596 ms
23/10/22 21:34:37.187 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO CodeGenerator: Code generated in 5.4408 ms
23/10/22 21:34:37.193 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:37.234 Executor task launch worker for task 0.0 in stage 20.0 (TID 21) INFO Executor: Finished task 0.0 in stage 20.0 (TID 21). 778681 bytes result sent to driver
23/10/22 21:34:37.236 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 21) in 86 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:34:37.236 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
23/10/22 21:34:37.236 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collect at utils.scala:26) finished in 0.095 s
23/10/22 21:34:37.237 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:37.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
23/10/22 21:34:37.238 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.097874 s
23/10/22 21:34:37.248 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:34:37.248 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 2 output partitions
23/10/22 21:34:37.249 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
23/10/22 21:34:37.249 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
23/10/22 21:34:37.249 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:34:37.249 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
23/10/22 21:34:37.252 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 43.9 KiB, free 1036.9 MiB)
23/10/22 21:34:37.253 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1036.9 MiB)
23/10/22 21:34:37.253 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:55185 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:34:37.254 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535
23/10/22 21:34:37.255 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 21:34:37.255 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks resource profile 0
23/10/22 21:34:37.256 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 21:34:37.257 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 23) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 21:34:37.257 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO Executor: Running task 1.0 in stage 23.0 (TID 23)
23/10/22 21:34:37.257 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO Executor: Running task 0.0 in stage 23.0 (TID 22)
23/10/22 21:34:37.264 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:37.264 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:34:37.265 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 21:34:37.265 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 21:34:37.278 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:37.279 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:34:37.316 Executor task launch worker for task 1.0 in stage 23.0 (TID 23) INFO Executor: Finished task 1.0 in stage 23.0 (TID 23). 745900 bytes result sent to driver
23/10/22 21:34:37.317 Executor task launch worker for task 0.0 in stage 23.0 (TID 22) INFO Executor: Finished task 0.0 in stage 23.0 (TID 22). 747448 bytes result sent to driver
23/10/22 21:34:37.318 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 23) in 61 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 21:34:37.319 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 63 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 21:34:37.319 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
23/10/22 21:34:37.320 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0.070 s
23/10/22 21:34:37.320 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:34:37.320 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
23/10/22 21:34:37.320 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.072939 s
23/10/22 21:34:37.333 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.4221 ms
23/10/22 21:40:58.198 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 55 (collect at utils.scala:26) as input to shuffle 5
23/10/22 21:40:58.198 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 17 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:40:58.198 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at utils.scala:26)
23/10/22 21:40:58.198 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:40:58.198 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:40:58.198 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[55] at collect at utils.scala:26), which has no missing parents
23/10/22 21:40:58.200 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.7 KiB, free 1036.9 MiB)
23/10/22 21:40:58.201 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.9 MiB)
23/10/22 21:40:58.202 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 21:40:58.202 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1535
23/10/22 21:40:58.202 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[55] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:40:58.202 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/10/22 21:40:58.448 dispatcher-event-loop-2 WARN TaskSetManager: Stage 24 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:40:58.448 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:40:58.449 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
23/10/22 21:40:58.560 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:58.726 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:55185 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:40:58.728 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 21:40:58.730 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:55185 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:40:59.368 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2147 bytes result sent to driver
23/10/22 21:40:59.369 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 1166 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:40:59.369 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/10/22 21:40:59.370 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 24 (collect at utils.scala:26) finished in 1.170 s
23/10/22 21:40:59.370 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:40:59.370 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:40:59.370 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:40:59.370 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:40:59.373 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 21:40:59.380 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 59 (collect at utils.scala:26) as input to shuffle 6
23/10/22 21:40:59.380 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 18 (collect at utils.scala:26) with 8 output partitions
23/10/22 21:40:59.380 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 26 (collect at utils.scala:26)
23/10/22 21:40:59.380 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
23/10/22 21:40:59.380 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:40:59.380 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[59] at collect at utils.scala:26), which has no missing parents
23/10/22 21:40:59.382 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 21:40:59.384 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 21:40:59.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 21:40:59.385 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
23/10/22 21:40:59.386 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[59] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 21:40:59.386 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 8 tasks resource profile 0
23/10/22 21:40:59.390 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.390 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 26) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.390 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 27) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.390 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 28) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.390 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 29) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.391 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 30) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.391 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 31) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.391 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 26.0 (TID 32) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 21:40:59.391 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
23/10/22 21:40:59.392 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO Executor: Running task 1.0 in stage 26.0 (TID 26)
23/10/22 21:40:59.392 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO Executor: Running task 2.0 in stage 26.0 (TID 27)
23/10/22 21:40:59.392 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO Executor: Running task 3.0 in stage 26.0 (TID 28)
23/10/22 21:40:59.393 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO Executor: Running task 6.0 in stage 26.0 (TID 31)
23/10/22 21:40:59.398 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO Executor: Running task 4.0 in stage 26.0 (TID 29)
23/10/22 21:40:59.401 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO Executor: Running task 5.0 in stage 26.0 (TID 30)
23/10/22 21:40:59.401 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO Executor: Running task 7.0 in stage 26.0 (TID 32)
23/10/22 21:40:59.407 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.407 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.407 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.408 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.408 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
23/10/22 21:40:59.408 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
23/10/22 21:40:59.408 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
23/10/22 21:40:59.408 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.408 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 21:40:59.408 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
23/10/22 21:40:59.411 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.423 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.423 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:40:59.425 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.425 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:40:59.425 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.425 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.428 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.436 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.446 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.451 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.458 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.473 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.477 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.479 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 71 ms
23/10/22 21:40:59.492 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.531 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.561 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.584 Executor task launch worker for task 6.0 in stage 26.0 (TID 31) INFO Executor: Finished task 6.0 in stage 26.0 (TID 31). 4942 bytes result sent to driver
23/10/22 21:40:59.594 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.622 Executor task launch worker for task 7.0 in stage 26.0 (TID 32) INFO Executor: Finished task 7.0 in stage 26.0 (TID 32). 4942 bytes result sent to driver
23/10/22 21:40:59.625 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 21:40:59.630 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 31) in 239 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 21:40:59.631 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 26.0 (TID 32) in 240 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 21:40:59.638 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.642 Executor task launch worker for task 2.0 in stage 26.0 (TID 27) INFO Executor: Finished task 2.0 in stage 26.0 (TID 27). 4899 bytes result sent to driver
23/10/22 21:40:59.654 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.655 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 27) in 265 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 21:40:59.672 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.690 Executor task launch worker for task 0.0 in stage 26.0 (TID 25) INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 4942 bytes result sent to driver
23/10/22 21:40:59.692 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 303 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 21:40:59.693 Executor task launch worker for task 3.0 in stage 26.0 (TID 28) INFO Executor: Finished task 3.0 in stage 26.0 (TID 28). 4899 bytes result sent to driver
23/10/22 21:40:59.696 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 28) in 306 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 21:40:59.717 Executor task launch worker for task 1.0 in stage 26.0 (TID 26) INFO Executor: Finished task 1.0 in stage 26.0 (TID 26). 4899 bytes result sent to driver
23/10/22 21:40:59.718 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 26) in 328 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 21:40:59.724 Executor task launch worker for task 5.0 in stage 26.0 (TID 30) INFO Executor: Finished task 5.0 in stage 26.0 (TID 30). 4899 bytes result sent to driver
23/10/22 21:40:59.725 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 30) in 334 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 21:40:59.740 Executor task launch worker for task 4.0 in stage 26.0 (TID 29) INFO Executor: Finished task 4.0 in stage 26.0 (TID 29). 4899 bytes result sent to driver
23/10/22 21:40:59.741 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 29) in 351 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 21:40:59.741 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/10/22 21:40:59.741 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:26) finished in 0.360 s
23/10/22 21:40:59.741 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:40:59.741 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:40:59.741 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:40:59.741 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:40:59.743 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 21:40:59.751 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:40:59.751 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:40:59.751 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:26)
23/10/22 21:40:59.751 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/10/22 21:40:59.751 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:40:59.752 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[62] at collect at utils.scala:26), which has no missing parents
23/10/22 21:40:59.753 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 43.9 KiB, free 1037.0 MiB)
23/10/22 21:40:59.754 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1037.0 MiB)
23/10/22 21:40:59.754 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:55185 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:40:59.755 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535
23/10/22 21:40:59.755 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[62] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:40:59.755 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
23/10/22 21:40:59.755 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 33) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:40:59.756 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO Executor: Running task 0.0 in stage 29.0 (TID 33)
23/10/22 21:40:59.759 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.759 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:40:59.768 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.796 Executor task launch worker for task 0.0 in stage 29.0 (TID 33) INFO Executor: Finished task 0.0 in stage 29.0 (TID 33). 778681 bytes result sent to driver
23/10/22 21:40:59.797 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 33) in 42 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:40:59.797 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/10/22 21:40:59.798 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at utils.scala:26) finished in 0.046 s
23/10/22 21:40:59.799 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:40:59.799 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/10/22 21:40:59.799 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0.047913 s
23/10/22 21:40:59.807 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:40:59.808 dag-scheduler-event-loop INFO DAGScheduler: Got job 20 (collect at utils.scala:26) with 2 output partitions
23/10/22 21:40:59.808 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:26)
23/10/22 21:40:59.808 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
23/10/22 21:40:59.808 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:40:59.809 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[62] at collect at utils.scala:26), which has no missing parents
23/10/22 21:40:59.810 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 43.9 KiB, free 1036.9 MiB)
23/10/22 21:40:59.811 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1036.9 MiB)
23/10/22 21:40:59.812 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:55185 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:40:59.813 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535
23/10/22 21:40:59.813 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[62] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 21:40:59.813 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks resource profile 0
23/10/22 21:40:59.814 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 21:40:59.814 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 35) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 21:40:59.815 Executor task launch worker for task 1.0 in stage 32.0 (TID 35) INFO Executor: Running task 1.0 in stage 32.0 (TID 35)
23/10/22 21:40:59.815 Executor task launch worker for task 0.0 in stage 32.0 (TID 34) INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
23/10/22 21:40:59.820 Executor task launch worker for task 0.0 in stage 32.0 (TID 34) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.820 Executor task launch worker for task 0.0 in stage 32.0 (TID 34) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:40:59.820 Executor task launch worker for task 1.0 in stage 32.0 (TID 35) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:40:59.821 Executor task launch worker for task 1.0 in stage 32.0 (TID 35) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:40:59.832 Executor task launch worker for task 1.0 in stage 32.0 (TID 35) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.834 Executor task launch worker for task 0.0 in stage 32.0 (TID 34) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 21:40:59.862 Executor task launch worker for task 0.0 in stage 32.0 (TID 34) INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 747491 bytes result sent to driver
23/10/22 21:40:59.863 Executor task launch worker for task 1.0 in stage 32.0 (TID 35) INFO Executor: Finished task 1.0 in stage 32.0 (TID 35). 745943 bytes result sent to driver
23/10/22 21:40:59.863 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 50 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 21:40:59.865 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 35) in 51 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 21:40:59.865 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
23/10/22 21:40:59.867 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (collect at utils.scala:26) finished in 0.057 s
23/10/22 21:40:59.868 dag-scheduler-event-loop INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:40:59.868 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
23/10/22 21:40:59.869 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 20 finished: collect at utils.scala:26, took 0.061549 s
23/10/22 21:41:57.264 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.3389 ms
23/10/22 21:41:57.275 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:41:57.276 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:41:57.276 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
23/10/22 21:41:57.276 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:41:57.276 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:41:57.276 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[64] at collect at utils.scala:26), which has no missing parents
23/10/22 21:41:57.278 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.2 KiB, free 1036.9 MiB)
23/10/22 21:41:57.279 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 21:41:57.279 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 21:41:57.280 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
23/10/22 21:41:57.280 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[64] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:41:57.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
23/10/22 21:41:57.284 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 36) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 21:41:57.285 Executor task launch worker for task 0.0 in stage 33.0 (TID 36) INFO Executor: Running task 0.0 in stage 33.0 (TID 36)
23/10/22 21:41:57.292 Executor task launch worker for task 0.0 in stage 33.0 (TID 36) INFO Executor: Finished task 0.0 in stage 33.0 (TID 36). 1413 bytes result sent to driver
23/10/22 21:41:57.293 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 36) in 11 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:41:57.293 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
23/10/22 21:41:57.293 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0.016 s
23/10/22 21:41:57.294 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:41:57.294 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
23/10/22 21:41:57.294 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: collect at utils.scala:26, took 0.017774 s
23/10/22 21:41:57.299 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.9698 ms
23/10/22 21:41:57.473 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:41:57.511 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.5672 ms
23/10/22 21:41:57.521 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 66 (collect at utils.scala:26) as input to shuffle 7
23/10/22 21:41:57.522 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 22 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:41:57.522 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 34 (collect at utils.scala:26)
23/10/22 21:41:57.522 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:41:57.522 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:41:57.522 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[66] at collect at utils.scala:26), which has no missing parents
23/10/22 21:41:57.523 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 44.1 KiB, free 1036.9 MiB)
23/10/22 21:41:57.524 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1036.8 MiB)
23/10/22 21:41:57.525 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:55185 (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 21:41:57.525 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535
23/10/22 21:41:57.525 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[66] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:41:57.525 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
23/10/22 21:41:57.734 dispatcher-event-loop-7 WARN TaskSetManager: Stage 34 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:41:57.734 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 37) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:41:57.735 Executor task launch worker for task 0.0 in stage 34.0 (TID 37) INFO Executor: Running task 0.0 in stage 34.0 (TID 37)
23/10/22 21:41:57.853 Executor task launch worker for task 0.0 in stage 34.0 (TID 37) INFO CodeGenerator: Code generated in 2.6198 ms
23/10/22 21:41:57.857 Executor task launch worker for task 0.0 in stage 34.0 (TID 37) INFO CodeGenerator: Code generated in 3.362 ms
23/10/22 21:41:57.909 Executor task launch worker for task 0.0 in stage 34.0 (TID 37) INFO CodeGenerator: Code generated in 2.703 ms
23/10/22 21:41:58.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:55185 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.295 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:55185 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.299 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.302 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.304 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.460 Executor task launch worker for task 0.0 in stage 34.0 (TID 37) INFO Executor: Finished task 0.0 in stage 34.0 (TID 37). 2306 bytes result sent to driver
23/10/22 21:41:58.461 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 37) in 935 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:41:58.461 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
23/10/22 21:41:58.461 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 34 (collect at utils.scala:26) finished in 0.939 s
23/10/22 21:41:58.461 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:41:58.462 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:41:58.462 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:41:58.462 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:41:58.471 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 21:41:58.485 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:41:58.521 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 31.9832 ms
23/10/22 21:41:58.526 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:26) as input to shuffle 8
23/10/22 21:41:58.526 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 23 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:41:58.526 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 36 (collect at utils.scala:26)
23/10/22 21:41:58.526 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
23/10/22 21:41:58.526 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:41:58.526 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[69] at collect at utils.scala:26), which has no missing parents
23/10/22 21:41:58.528 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 65.5 KiB, free 1037.0 MiB)
23/10/22 21:41:58.529 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1037.0 MiB)
23/10/22 21:41:58.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:55185 (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.530 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535
23/10/22 21:41:58.530 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[69] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:41:58.530 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
23/10/22 21:41:58.531 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 21:41:58.532 Executor task launch worker for task 0.0 in stage 36.0 (TID 38) INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
23/10/22 21:41:58.535 Executor task launch worker for task 0.0 in stage 36.0 (TID 38) INFO ShuffleBlockFetcherIterator: Getting 1 (483.5 KiB) non-empty blocks including 1 (483.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:41:58.536 Executor task launch worker for task 0.0 in stage 36.0 (TID 38) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:41:58.546 Executor task launch worker for task 0.0 in stage 36.0 (TID 38) INFO CodeGenerator: Code generated in 4.2787 ms
23/10/22 21:41:58.554 Executor task launch worker for task 0.0 in stage 36.0 (TID 38) INFO CodeGenerator: Code generated in 4.5084 ms
23/10/22 21:41:58.629 Executor task launch worker for task 0.0 in stage 36.0 (TID 38) INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 5381 bytes result sent to driver
23/10/22 21:41:58.629 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 98 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:41:58.629 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
23/10/22 21:41:58.630 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 36 (collect at utils.scala:26) finished in 0.103 s
23/10/22 21:41:58.630 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:41:58.630 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:41:58.630 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:41:58.630 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:41:58.639 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 21:41:58.651 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:41:58.688 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.5239 ms
23/10/22 21:41:58.697 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 72 (collect at utils.scala:26) as input to shuffle 9
23/10/22 21:41:58.697 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 24 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:41:58.697 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 39 (collect at utils.scala:26)
23/10/22 21:41:58.697 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
23/10/22 21:41:58.697 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:41:58.699 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[72] at collect at utils.scala:26), which has no missing parents
23/10/22 21:41:58.701 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 106.1 KiB, free 1036.9 MiB)
23/10/22 21:41:58.702 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 1036.8 MiB)
23/10/22 21:41:58.703 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:55185 (size: 38.7 KiB, free: 1037.1 MiB)
23/10/22 21:41:58.703 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
23/10/22 21:41:58.703 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[72] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:41:58.703 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
23/10/22 21:41:58.704 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 21:41:58.704 Executor task launch worker for task 0.0 in stage 39.0 (TID 39) INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
23/10/22 21:41:58.712 Executor task launch worker for task 0.0 in stage 39.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 1 (96.8 KiB) non-empty blocks including 1 (96.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:41:58.712 Executor task launch worker for task 0.0 in stage 39.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:41:58.741 Executor task launch worker for task 0.0 in stage 39.0 (TID 39) INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 7377 bytes result sent to driver
23/10/22 21:41:58.743 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 39 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:41:58.743 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
23/10/22 21:41:58.743 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 39 (collect at utils.scala:26) finished in 0.044 s
23/10/22 21:41:58.743 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:41:58.744 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:41:58.744 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:41:58.744 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:41:58.790 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 23.9904 ms
23/10/22 21:41:58.796 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:41:58.798 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:41:58.798 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:26)
23/10/22 21:41:58.798 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
23/10/22 21:41:58.798 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:41:58.798 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
23/10/22 21:41:58.800 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 57.4 KiB, free 1036.8 MiB)
23/10/22 21:41:58.801 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 1036.8 MiB)
23/10/22 21:41:58.802 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:55185 (size: 17.9 KiB, free: 1037.0 MiB)
23/10/22 21:41:58.802 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1535
23/10/22 21:41:58.802 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:41:58.802 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
23/10/22 21:41:58.803 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 40) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:41:58.804 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO Executor: Running task 0.0 in stage 43.0 (TID 40)
23/10/22 21:41:58.807 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:41:58.807 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:41:58.811 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO Executor: Finished task 0.0 in stage 43.0 (TID 40). 4277 bytes result sent to driver
23/10/22 21:41:58.812 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 40) in 9 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:41:58.812 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
23/10/22 21:41:58.813 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 43 (collect at utils.scala:26) finished in 0.013 s
23/10/22 21:41:58.813 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:41:58.813 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
23/10/22 21:41:58.813 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0.017076 s
23/10/22 21:41:58.822 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.4237 ms
23/10/22 21:42:00.125 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:42:00.137 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 77 (collect at utils.scala:26) as input to shuffle 10
23/10/22 21:42:00.138 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 26 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:42:00.138 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 44 (collect at utils.scala:26)
23/10/22 21:42:00.138 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 21:42:00.138 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:42:00.138 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[77] at collect at utils.scala:26), which has no missing parents
23/10/22 21:42:00.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 43.9 KiB, free 1036.7 MiB)
23/10/22 21:42:00.140 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 1036.7 MiB)
23/10/22 21:42:00.140 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:55185 (size: 19.1 KiB, free: 1037.0 MiB)
23/10/22 21:42:00.141 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535
23/10/22 21:42:00.142 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[77] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:42:00.142 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
23/10/22 21:42:00.362 dispatcher-event-loop-4 WARN TaskSetManager: Stage 44 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 21:42:00.362 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 41) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 21:42:00.363 Executor task launch worker for task 0.0 in stage 44.0 (TID 41) INFO Executor: Running task 0.0 in stage 44.0 (TID 41)
23/10/22 21:42:00.588 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:55185 in memory (size: 38.7 KiB, free: 1037.1 MiB)
23/10/22 21:42:00.590 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:55185 in memory (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 21:42:00.593 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:55185 in memory (size: 17.9 KiB, free: 1037.1 MiB)
23/10/22 21:42:00.772 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:55185 in memory (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 21:42:00.879 Executor task launch worker for task 0.0 in stage 44.0 (TID 41) INFO Executor: Finished task 0.0 in stage 44.0 (TID 41). 2306 bytes result sent to driver
23/10/22 21:42:00.879 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 41) in 736 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:42:00.879 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
23/10/22 21:42:00.880 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:26) finished in 0.741 s
23/10/22 21:42:00.880 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:42:00.880 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:42:00.880 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:42:00.880 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:42:00.884 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 21:42:00.888 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:42:00.895 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 80 (collect at utils.scala:26) as input to shuffle 11
23/10/22 21:42:00.895 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 27 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:42:00.895 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 46 (collect at utils.scala:26)
23/10/22 21:42:00.895 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
23/10/22 21:42:00.895 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:42:00.895 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[80] at collect at utils.scala:26), which has no missing parents
23/10/22 21:42:00.897 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 65.0 KiB, free 1037.0 MiB)
23/10/22 21:42:00.898 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1037.0 MiB)
23/10/22 21:42:00.899 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:55185 (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 21:42:00.899 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
23/10/22 21:42:00.899 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[80] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:42:00.899 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
23/10/22 21:42:00.900 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 42) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 21:42:00.900 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO Executor: Running task 0.0 in stage 46.0 (TID 42)
23/10/22 21:42:00.904 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO ShuffleBlockFetcherIterator: Getting 1 (483.5 KiB) non-empty blocks including 1 (483.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:42:00.904 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:42:00.954 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO Executor: Finished task 0.0 in stage 46.0 (TID 42). 5381 bytes result sent to driver
23/10/22 21:42:00.954 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 42) in 54 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:42:00.954 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
23/10/22 21:42:00.955 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 46 (collect at utils.scala:26) finished in 0.059 s
23/10/22 21:42:00.955 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:42:00.955 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:42:00.955 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:42:00.955 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:42:00.959 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 21:42:00.967 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:42:01.009 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 33.0492 ms
23/10/22 21:42:01.014 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 83 (collect at utils.scala:26) as input to shuffle 12
23/10/22 21:42:01.014 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 28 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:42:01.014 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 49 (collect at utils.scala:26)
23/10/22 21:42:01.014 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
23/10/22 21:42:01.014 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:42:01.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[83] at collect at utils.scala:26), which has no missing parents
23/10/22 21:42:01.017 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 103.1 KiB, free 1036.9 MiB)
23/10/22 21:42:01.018 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 38.2 KiB, free 1036.9 MiB)
23/10/22 21:42:01.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:55185 (size: 38.2 KiB, free: 1037.1 MiB)
23/10/22 21:42:01.019 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
23/10/22 21:42:01.019 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[83] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:42:01.019 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
23/10/22 21:42:01.020 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 43) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 21:42:01.021 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO Executor: Running task 0.0 in stage 49.0 (TID 43)
23/10/22 21:42:01.025 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO ShuffleBlockFetcherIterator: Getting 1 (96.8 KiB) non-empty blocks including 1 (96.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:42:01.025 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:42:01.033 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO CodeGenerator: Code generated in 4.8604 ms
23/10/22 21:42:01.040 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO CodeGenerator: Code generated in 3.9202 ms
23/10/22 21:42:01.078 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO CodeGenerator: Code generated in 6.7104 ms
23/10/22 21:42:01.085 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO CodeGenerator: Code generated in 4.4621 ms
23/10/22 21:42:01.142 Executor task launch worker for task 0.0 in stage 49.0 (TID 43) INFO Executor: Finished task 0.0 in stage 49.0 (TID 43). 7341 bytes result sent to driver
23/10/22 21:42:01.143 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 43) in 123 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:42:01.143 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
23/10/22 21:42:01.144 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 49 (collect at utils.scala:26) finished in 0.129 s
23/10/22 21:42:01.144 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 21:42:01.144 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 21:42:01.144 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 21:42:01.144 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 21:42:01.146 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/10/22 21:42:01.153 nioEventLoopGroup-2-2 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
23/10/22 21:42:01.181 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.6981 ms
23/10/22 21:42:01.202 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 21:42:01.203 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (collect at utils.scala:26) with 1 output partitions
23/10/22 21:42:01.203 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (collect at utils.scala:26)
23/10/22 21:42:01.203 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
23/10/22 21:42:01.203 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 21:42:01.203 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[86] at collect at utils.scala:26), which has no missing parents
23/10/22 21:42:01.207 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 106.0 KiB, free 1036.7 MiB)
23/10/22 21:42:01.209 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 37.9 KiB, free 1036.7 MiB)
23/10/22 21:42:01.209 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:55185 (size: 37.9 KiB, free: 1037.0 MiB)
23/10/22 21:42:01.210 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1535
23/10/22 21:42:01.210 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[86] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 21:42:01.210 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
23/10/22 21:42:01.211 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 44) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 21:42:01.212 Executor task launch worker for task 0.0 in stage 53.0 (TID 44) INFO Executor: Running task 0.0 in stage 53.0 (TID 44)
23/10/22 21:42:01.215 Executor task launch worker for task 0.0 in stage 53.0 (TID 44) INFO ShuffleBlockFetcherIterator: Getting 1 (182.3 KiB) non-empty blocks including 1 (182.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 21:42:01.216 Executor task launch worker for task 0.0 in stage 53.0 (TID 44) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 21:42:01.243 Executor task launch worker for task 0.0 in stage 53.0 (TID 44) INFO Executor: Finished task 0.0 in stage 53.0 (TID 44). 107013 bytes result sent to driver
23/10/22 21:42:01.244 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 44) in 33 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 21:42:01.244 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
23/10/22 21:42:01.245 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (collect at utils.scala:26) finished in 0.040 s
23/10/22 21:42:01.245 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 21:42:01.245 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
23/10/22 21:42:01.245 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: collect at utils.scala:26, took 0.043348 s
23/10/22 21:42:01.255 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.7799 ms
23/10/22 22:03:34.811 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:55185 in memory (size: 38.2 KiB, free: 1037.1 MiB)
23/10/22 22:03:34.815 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:55185 in memory (size: 25.8 KiB, free: 1037.1 MiB)
23/10/22 22:03:34.818 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:55185 in memory (size: 19.1 KiB, free: 1037.1 MiB)
23/10/22 22:03:34.821 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:55185 in memory (size: 37.9 KiB, free: 1037.1 MiB)
23/10/22 22:16:50.170 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.5795 ms
23/10/22 22:16:50.180 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:16:50.180 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:16:50.180 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:26)
23/10/22 22:16:50.180 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:50.181 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:50.181 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[88] at collect at utils.scala:26), which has no missing parents
23/10/22 22:16:50.182 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.3 KiB, free 1037.1 MiB)
23/10/22 22:16:50.188 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:16:50.189 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:50.189 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:50.190 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[88] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:50.190 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
23/10/22 22:16:50.191 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 45) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:16:50.192 Executor task launch worker for task 0.0 in stage 54.0 (TID 45) INFO Executor: Running task 0.0 in stage 54.0 (TID 45)
23/10/22 22:16:50.196 Executor task launch worker for task 0.0 in stage 54.0 (TID 45) INFO Executor: Finished task 0.0 in stage 54.0 (TID 45). 1413 bytes result sent to driver
23/10/22 22:16:50.197 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 45) in 6 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:50.197 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
23/10/22 22:16:50.197 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 54 (collect at utils.scala:26) finished in 0.016 s
23/10/22 22:16:50.197 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:50.197 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
23/10/22 22:16:50.198 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: collect at utils.scala:26, took 0.017061 s
23/10/22 22:16:50.205 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.3819 ms
23/10/22 22:16:50.354 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:16:50.355 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:16:50.355 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:26)
23/10/22 22:16:50.355 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:50.355 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:50.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[90] at collect at utils.scala:26), which has no missing parents
23/10/22 22:16:50.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.3 KiB, free 1037.1 MiB)
23/10/22 22:16:50.358 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:16:50.358 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:50.359 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:50.359 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[90] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:50.359 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
23/10/22 22:16:50.360 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 46) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:16:50.361 Executor task launch worker for task 0.0 in stage 55.0 (TID 46) INFO Executor: Running task 0.0 in stage 55.0 (TID 46)
23/10/22 22:16:50.363 Executor task launch worker for task 0.0 in stage 55.0 (TID 46) INFO Executor: Finished task 0.0 in stage 55.0 (TID 46). 1327 bytes result sent to driver
23/10/22 22:16:50.364 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 46) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:50.364 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
23/10/22 22:16:50.364 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 55 (collect at utils.scala:26) finished in 0.009 s
23/10/22 22:16:50.364 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:50.365 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
23/10/22 22:16:50.365 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0.010256 s
23/10/22 22:16:51.034 nioEventLoopGroup-2-2 INFO Instrumentation: [00ab8477] training finished
23/10/22 22:16:51.134 nioEventLoopGroup-2-2 INFO Instrumentation: [8517b133] training finished
23/10/22 22:16:51.145 nioEventLoopGroup-2-2 INFO Instrumentation: [a59c7b5b] Stage class: LinearRegression
23/10/22 22:16:51.145 nioEventLoopGroup-2-2 INFO Instrumentation: [a59c7b5b] Stage uid: linear_regression__88811d7e_1082_4ec8_8338_1d2115351b94
23/10/22 22:16:51.208 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 93 (rdd at Instrumentation.scala:62) as input to shuffle 13
23/10/22 22:16:51.208 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 32 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:16:51.208 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 56 (rdd at Instrumentation.scala:62)
23/10/22 22:16:51.208 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:51.208 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:51.209 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[93] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:16:51.242 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 22:16:51.246 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.1 MiB)
23/10/22 22:16:51.247 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:16:51.247 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:51.248 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[93] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:51.248 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
23/10/22 22:16:51.545 dispatcher-event-loop-3 WARN TaskSetManager: Stage 56 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:16:51.545 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 47) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:16:51.545 Executor task launch worker for task 0.0 in stage 56.0 (TID 47) INFO Executor: Running task 0.0 in stage 56.0 (TID 47)
23/10/22 22:16:51.719 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:51.721 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:51.755 Executor task launch worker for task 0.0 in stage 56.0 (TID 47) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.665 Executor task launch worker for task 0.0 in stage 56.0 (TID 47) INFO Executor: Finished task 0.0 in stage 56.0 (TID 47). 2104 bytes result sent to driver
23/10/22 22:16:52.668 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 47) in 1420 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:52.669 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
23/10/22 22:16:52.670 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 56 (rdd at Instrumentation.scala:62) finished in 1.460 s
23/10/22 22:16:52.670 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:52.670 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:52.670 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:16:52.670 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:52.676 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:16:52.680 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 97 (rdd at Instrumentation.scala:62) as input to shuffle 14
23/10/22 22:16:52.680 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 33 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:16:52.682 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 58 (rdd at Instrumentation.scala:62)
23/10/22 22:16:52.682 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
23/10/22 22:16:52.682 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:52.683 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[97] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:16:52.695 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:16:52.698 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:16:52.721 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:52.722 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:52.722 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[97] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:16:52.722 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 8 tasks resource profile 0
23/10/22 22:16:52.724 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 48) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.724 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 49) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.724 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 58.0 (TID 50) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.724 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 58.0 (TID 51) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.725 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 58.0 (TID 52) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.725 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 58.0 (TID 53) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.725 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 58.0 (TID 54) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.725 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 58.0 (TID 55) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:52.725 Executor task launch worker for task 0.0 in stage 58.0 (TID 48) INFO Executor: Running task 0.0 in stage 58.0 (TID 48)
23/10/22 22:16:52.726 Executor task launch worker for task 1.0 in stage 58.0 (TID 49) INFO Executor: Running task 1.0 in stage 58.0 (TID 49)
23/10/22 22:16:52.726 Executor task launch worker for task 2.0 in stage 58.0 (TID 50) INFO Executor: Running task 2.0 in stage 58.0 (TID 50)
23/10/22 22:16:52.726 Executor task launch worker for task 3.0 in stage 58.0 (TID 51) INFO Executor: Running task 3.0 in stage 58.0 (TID 51)
23/10/22 22:16:52.727 Executor task launch worker for task 4.0 in stage 58.0 (TID 52) INFO Executor: Running task 4.0 in stage 58.0 (TID 52)
23/10/22 22:16:52.730 Executor task launch worker for task 0.0 in stage 58.0 (TID 48) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.730 Executor task launch worker for task 4.0 in stage 58.0 (TID 52) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.731 Executor task launch worker for task 0.0 in stage 58.0 (TID 48) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:52.731 Executor task launch worker for task 4.0 in stage 58.0 (TID 52) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:52.730 Executor task launch worker for task 2.0 in stage 58.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.731 Executor task launch worker for task 2.0 in stage 58.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:52.731 Executor task launch worker for task 3.0 in stage 58.0 (TID 51) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.731 Executor task launch worker for task 3.0 in stage 58.0 (TID 51) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:52.731 Executor task launch worker for task 7.0 in stage 58.0 (TID 55) INFO Executor: Running task 7.0 in stage 58.0 (TID 55)
23/10/22 22:16:52.731 Executor task launch worker for task 5.0 in stage 58.0 (TID 53) INFO Executor: Running task 5.0 in stage 58.0 (TID 53)
23/10/22 22:16:52.732 Executor task launch worker for task 6.0 in stage 58.0 (TID 54) INFO Executor: Running task 6.0 in stage 58.0 (TID 54)
23/10/22 22:16:52.735 Executor task launch worker for task 6.0 in stage 58.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.736 Executor task launch worker for task 6.0 in stage 58.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:52.736 Executor task launch worker for task 5.0 in stage 58.0 (TID 53) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.736 Executor task launch worker for task 5.0 in stage 58.0 (TID 53) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:52.740 Executor task launch worker for task 7.0 in stage 58.0 (TID 55) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.740 Executor task launch worker for task 7.0 in stage 58.0 (TID 55) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:52.743 Executor task launch worker for task 4.0 in stage 58.0 (TID 52) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.743 Executor task launch worker for task 0.0 in stage 58.0 (TID 48) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.744 Executor task launch worker for task 6.0 in stage 58.0 (TID 54) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.745 Executor task launch worker for task 5.0 in stage 58.0 (TID 53) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.747 Executor task launch worker for task 2.0 in stage 58.0 (TID 50) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.763 Executor task launch worker for task 7.0 in stage 58.0 (TID 55) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.769 Executor task launch worker for task 2.0 in stage 58.0 (TID 50) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.779 Executor task launch worker for task 0.0 in stage 58.0 (TID 48) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.779 Executor task launch worker for task 5.0 in stage 58.0 (TID 53) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.782 Executor task launch worker for task 4.0 in stage 58.0 (TID 52) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.816 Executor task launch worker for task 6.0 in stage 58.0 (TID 54) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.831 Executor task launch worker for task 1.0 in stage 58.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:52.831 Executor task launch worker for task 1.0 in stage 58.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:52.840 Executor task launch worker for task 1.0 in stage 58.0 (TID 49) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.864 Executor task launch worker for task 1.0 in stage 58.0 (TID 49) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.871 Executor task launch worker for task 3.0 in stage 58.0 (TID 51) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.910 Executor task launch worker for task 7.0 in stage 58.0 (TID 55) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.920 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:16:52.937 Executor task launch worker for task 0.0 in stage 58.0 (TID 48) INFO Executor: Finished task 0.0 in stage 58.0 (TID 48). 4899 bytes result sent to driver
23/10/22 22:16:52.940 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 48) in 217 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:16:52.942 Executor task launch worker for task 3.0 in stage 58.0 (TID 51) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:52.963 Executor task launch worker for task 2.0 in stage 58.0 (TID 50) INFO Executor: Finished task 2.0 in stage 58.0 (TID 50). 4899 bytes result sent to driver
23/10/22 22:16:52.965 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 58.0 (TID 50) in 241 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:16:52.973 Executor task launch worker for task 5.0 in stage 58.0 (TID 53) INFO Executor: Finished task 5.0 in stage 58.0 (TID 53). 4899 bytes result sent to driver
23/10/22 22:16:52.974 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 58.0 (TID 53) in 249 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:16:52.988 Executor task launch worker for task 6.0 in stage 58.0 (TID 54) INFO Executor: Finished task 6.0 in stage 58.0 (TID 54). 4899 bytes result sent to driver
23/10/22 22:16:52.990 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 58.0 (TID 54) in 265 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:16:52.998 Executor task launch worker for task 1.0 in stage 58.0 (TID 49) INFO Executor: Finished task 1.0 in stage 58.0 (TID 49). 4899 bytes result sent to driver
23/10/22 22:16:52.999 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 49) in 275 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:16:53.002 Executor task launch worker for task 4.0 in stage 58.0 (TID 52) INFO Executor: Finished task 4.0 in stage 58.0 (TID 52). 4899 bytes result sent to driver
23/10/22 22:16:53.003 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 58.0 (TID 52) in 278 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:16:53.007 Executor task launch worker for task 7.0 in stage 58.0 (TID 55) INFO Executor: Finished task 7.0 in stage 58.0 (TID 55). 4942 bytes result sent to driver
23/10/22 22:16:53.007 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 58.0 (TID 55) in 282 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:16:53.035 Executor task launch worker for task 3.0 in stage 58.0 (TID 51) INFO Executor: Finished task 3.0 in stage 58.0 (TID 51). 4899 bytes result sent to driver
23/10/22 22:16:53.036 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 58.0 (TID 51) in 311 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:16:53.036 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
23/10/22 22:16:53.036 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 58 (rdd at Instrumentation.scala:62) finished in 0.353 s
23/10/22 22:16:53.036 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:53.036 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:53.036 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:16:53.036 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:53.042 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:16:53.119 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.2673 ms
23/10/22 22:16:53.168 nioEventLoopGroup-2-2 INFO Instrumentation: [a59c7b5b] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:16:53.184 nioEventLoopGroup-2-2 INFO Instrumentation: [a59c7b5b] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:16:53.192 nioEventLoopGroup-2-2 INFO Instrumentation: [a59c7b5b] {"numFeatures":1}
23/10/22 22:16:53.314 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 106 (rdd at LinearRegression.scala:348) as input to shuffle 15
23/10/22 22:16:53.314 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 34 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:16:53.314 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 59 (rdd at LinearRegression.scala:348)
23/10/22 22:16:53.314 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:53.314 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:53.315 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[106] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:16:53.317 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 22:16:53.319 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:16:53.320 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:16:53.322 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:53.323 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[106] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:53.323 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
23/10/22 22:16:53.537 dispatcher-event-loop-4 WARN TaskSetManager: Stage 59 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:16:53.537 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 56) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:16:53.538 Executor task launch worker for task 0.0 in stage 59.0 (TID 56) INFO Executor: Running task 0.0 in stage 59.0 (TID 56)
23/10/22 22:16:53.565 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:53.696 Executor task launch worker for task 0.0 in stage 59.0 (TID 56) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.591 Executor task launch worker for task 0.0 in stage 59.0 (TID 56) INFO Executor: Finished task 0.0 in stage 59.0 (TID 56). 2104 bytes result sent to driver
23/10/22 22:16:54.592 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 56) in 1268 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:54.592 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
23/10/22 22:16:54.592 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 59 (rdd at LinearRegression.scala:348) finished in 1.277 s
23/10/22 22:16:54.593 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:54.593 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:54.593 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:16:54.593 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:54.598 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:16:54.600 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 110 (rdd at LinearRegression.scala:348) as input to shuffle 16
23/10/22 22:16:54.601 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 35 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:16:54.601 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 61 (rdd at LinearRegression.scala:348)
23/10/22 22:16:54.601 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
23/10/22 22:16:54.601 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:54.601 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[110] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:16:54.603 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:16:54.603 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:16:54.604 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:54.604 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:54.604 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[110] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:16:54.604 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 8 tasks resource profile 0
23/10/22 22:16:54.605 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 57) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.605 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 58) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.606 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 61.0 (TID 59) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.606 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 61.0 (TID 60) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.606 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 61.0 (TID 61) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.606 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 61.0 (TID 62) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.606 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 61.0 (TID 63) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.606 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 61.0 (TID 64) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:54.607 Executor task launch worker for task 3.0 in stage 61.0 (TID 60) INFO Executor: Running task 3.0 in stage 61.0 (TID 60)
23/10/22 22:16:54.607 Executor task launch worker for task 6.0 in stage 61.0 (TID 63) INFO Executor: Running task 6.0 in stage 61.0 (TID 63)
23/10/22 22:16:54.607 Executor task launch worker for task 2.0 in stage 61.0 (TID 59) INFO Executor: Running task 2.0 in stage 61.0 (TID 59)
23/10/22 22:16:54.607 Executor task launch worker for task 7.0 in stage 61.0 (TID 64) INFO Executor: Running task 7.0 in stage 61.0 (TID 64)
23/10/22 22:16:54.607 Executor task launch worker for task 1.0 in stage 61.0 (TID 58) INFO Executor: Running task 1.0 in stage 61.0 (TID 58)
23/10/22 22:16:54.607 Executor task launch worker for task 4.0 in stage 61.0 (TID 61) INFO Executor: Running task 4.0 in stage 61.0 (TID 61)
23/10/22 22:16:54.607 Executor task launch worker for task 5.0 in stage 61.0 (TID 62) INFO Executor: Running task 5.0 in stage 61.0 (TID 62)
23/10/22 22:16:54.607 Executor task launch worker for task 0.0 in stage 61.0 (TID 57) INFO Executor: Running task 0.0 in stage 61.0 (TID 57)
23/10/22 22:16:54.611 Executor task launch worker for task 1.0 in stage 61.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 7.0 in stage 61.0 (TID 64) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 3.0 in stage 61.0 (TID 60) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 2.0 in stage 61.0 (TID 59) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 1.0 in stage 61.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.611 Executor task launch worker for task 7.0 in stage 61.0 (TID 64) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.611 Executor task launch worker for task 3.0 in stage 61.0 (TID 60) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.611 Executor task launch worker for task 4.0 in stage 61.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 2.0 in stage 61.0 (TID 59) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.611 Executor task launch worker for task 4.0 in stage 61.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.611 Executor task launch worker for task 6.0 in stage 61.0 (TID 63) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 6.0 in stage 61.0 (TID 63) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.611 Executor task launch worker for task 5.0 in stage 61.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.611 Executor task launch worker for task 5.0 in stage 61.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.612 Executor task launch worker for task 0.0 in stage 61.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:54.612 Executor task launch worker for task 0.0 in stage 61.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:54.622 Executor task launch worker for task 6.0 in stage 61.0 (TID 63) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.622 Executor task launch worker for task 2.0 in stage 61.0 (TID 59) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.622 Executor task launch worker for task 5.0 in stage 61.0 (TID 62) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.623 Executor task launch worker for task 7.0 in stage 61.0 (TID 64) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.622 Executor task launch worker for task 0.0 in stage 61.0 (TID 57) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.629 Executor task launch worker for task 4.0 in stage 61.0 (TID 61) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.633 Executor task launch worker for task 1.0 in stage 61.0 (TID 58) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.637 Executor task launch worker for task 3.0 in stage 61.0 (TID 60) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.644 Executor task launch worker for task 5.0 in stage 61.0 (TID 62) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.650 Executor task launch worker for task 6.0 in stage 61.0 (TID 63) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.653 Executor task launch worker for task 4.0 in stage 61.0 (TID 61) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.658 Executor task launch worker for task 2.0 in stage 61.0 (TID 59) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.660 Executor task launch worker for task 3.0 in stage 61.0 (TID 60) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.660 Executor task launch worker for task 1.0 in stage 61.0 (TID 58) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.669 Executor task launch worker for task 7.0 in stage 61.0 (TID 64) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.671 Executor task launch worker for task 0.0 in stage 61.0 (TID 57) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:54.797 Executor task launch worker for task 1.0 in stage 61.0 (TID 58) INFO Executor: Finished task 1.0 in stage 61.0 (TID 58). 4942 bytes result sent to driver
23/10/22 22:16:54.801 Executor task launch worker for task 0.0 in stage 61.0 (TID 57) INFO Executor: Finished task 0.0 in stage 61.0 (TID 57). 4942 bytes result sent to driver
23/10/22 22:16:54.801 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 58) in 196 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:16:54.803 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 57) in 198 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:16:54.805 Executor task launch worker for task 7.0 in stage 61.0 (TID 64) INFO Executor: Finished task 7.0 in stage 61.0 (TID 64). 4942 bytes result sent to driver
23/10/22 22:16:54.807 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 61.0 (TID 64) in 201 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:16:54.827 Executor task launch worker for task 6.0 in stage 61.0 (TID 63) INFO Executor: Finished task 6.0 in stage 61.0 (TID 63). 4942 bytes result sent to driver
23/10/22 22:16:54.828 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 61.0 (TID 63) in 222 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:16:54.831 Executor task launch worker for task 4.0 in stage 61.0 (TID 61) INFO Executor: Finished task 4.0 in stage 61.0 (TID 61). 4942 bytes result sent to driver
23/10/22 22:16:54.832 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 61.0 (TID 61) in 226 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:16:54.834 Executor task launch worker for task 5.0 in stage 61.0 (TID 62) INFO Executor: Finished task 5.0 in stage 61.0 (TID 62). 4942 bytes result sent to driver
23/10/22 22:16:54.835 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 61.0 (TID 62) in 229 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:16:54.838 Executor task launch worker for task 2.0 in stage 61.0 (TID 59) INFO Executor: Finished task 2.0 in stage 61.0 (TID 59). 4942 bytes result sent to driver
23/10/22 22:16:54.839 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 61.0 (TID 59) in 233 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:16:54.841 Executor task launch worker for task 3.0 in stage 61.0 (TID 60) INFO Executor: Finished task 3.0 in stage 61.0 (TID 60). 4942 bytes result sent to driver
23/10/22 22:16:54.842 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 61.0 (TID 60) in 236 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:16:54.842 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
23/10/22 22:16:54.842 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 61 (rdd at LinearRegression.scala:348) finished in 0.240 s
23/10/22 22:16:54.842 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:54.842 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:54.842 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:16:54.843 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:54.848 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:16:54.885 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:16:54.899 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 36.8836 ms
23/10/22 22:16:54.946 nioEventLoopGroup-2-2 WARN Instrumentation: [a59c7b5b] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:16:55.023 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:16:55.025 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 119 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 17
23/10/22 22:16:55.026 dag-scheduler-event-loop INFO DAGScheduler: Got job 36 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:16:55.026 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 65 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:16:55.026 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
23/10/22 22:16:55.026 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
23/10/22 22:16:55.027 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[119] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:16:55.040 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 92.1 KiB, free 1037.0 MiB)
23/10/22 22:16:55.041 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 1037.0 MiB)
23/10/22 22:16:55.042 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:55185 (size: 36.5 KiB, free: 1037.1 MiB)
23/10/22 22:16:55.042 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:55.043 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[119] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:16:55.043 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 64.0 with 8 tasks resource profile 0
23/10/22 22:16:55.044 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 65) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.044 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 66) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.045 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 64.0 (TID 67) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.045 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 64.0 (TID 68) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.045 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 64.0 (TID 69) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.045 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 64.0 (TID 70) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.045 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 64.0 (TID 71) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.045 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 64.0 (TID 72) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:55.046 Executor task launch worker for task 0.0 in stage 64.0 (TID 65) INFO Executor: Running task 0.0 in stage 64.0 (TID 65)
23/10/22 22:16:55.046 Executor task launch worker for task 1.0 in stage 64.0 (TID 66) INFO Executor: Running task 1.0 in stage 64.0 (TID 66)
23/10/22 22:16:55.046 Executor task launch worker for task 7.0 in stage 64.0 (TID 72) INFO Executor: Running task 7.0 in stage 64.0 (TID 72)
23/10/22 22:16:55.046 Executor task launch worker for task 3.0 in stage 64.0 (TID 68) INFO Executor: Running task 3.0 in stage 64.0 (TID 68)
23/10/22 22:16:55.046 Executor task launch worker for task 6.0 in stage 64.0 (TID 71) INFO Executor: Running task 6.0 in stage 64.0 (TID 71)
23/10/22 22:16:55.046 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) INFO Executor: Running task 4.0 in stage 64.0 (TID 69)
23/10/22 22:16:55.047 Executor task launch worker for task 5.0 in stage 64.0 (TID 70) INFO Executor: Running task 5.0 in stage 64.0 (TID 70)
23/10/22 22:16:55.046 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO Executor: Running task 2.0 in stage 64.0 (TID 67)
23/10/22 22:16:55.141 Executor task launch worker for task 3.0 in stage 64.0 (TID 68) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 6.0 in stage 64.0 (TID 71) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 1.0 in stage 64.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 6.0 in stage 64.0 (TID 71) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.141 Executor task launch worker for task 3.0 in stage 64.0 (TID 68) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.141 Executor task launch worker for task 1.0 in stage 64.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.141 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.141 Executor task launch worker for task 0.0 in stage 64.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 0.0 in stage 64.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.141 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 7.0 in stage 64.0 (TID 72) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.141 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:55.141 Executor task launch worker for task 7.0 in stage 64.0 (TID 72) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:55.141 Executor task launch worker for task 5.0 in stage 64.0 (TID 70) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.142 Executor task launch worker for task 5.0 in stage 64.0 (TID 70) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.159 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.159 Executor task launch worker for task 3.0 in stage 64.0 (TID 68) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.159 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.162 Executor task launch worker for task 1.0 in stage 64.0 (TID 66) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.176 Executor task launch worker for task 7.0 in stage 64.0 (TID 72) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.181 Executor task launch worker for task 0.0 in stage 64.0 (TID 65) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.185 Executor task launch worker for task 6.0 in stage 64.0 (TID 71) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.188 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO CodeGenerator: Code generated in 12.1512 ms
23/10/22 22:16:55.194 Executor task launch worker for task 5.0 in stage 64.0 (TID 70) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:55.204 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO CodeGenerator: Code generated in 7.2865 ms
23/10/22 22:16:55.236 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO CodeGenerator: Code generated in 7.6909 ms
23/10/22 22:16:55.246 Executor task launch worker for task 1.0 in stage 64.0 (TID 66) INFO CodeGenerator: Code generated in 5.264 ms
23/10/22 22:16:55.267 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS
23/10/22 22:16:55.277 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS
23/10/22 22:16:55.406 Executor task launch worker for task 4.0 in stage 64.0 (TID 69) INFO Executor: Finished task 4.0 in stage 64.0 (TID 69). 6648 bytes result sent to driver
23/10/22 22:16:55.409 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 64.0 (TID 69) in 364 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:16:55.412 Executor task launch worker for task 7.0 in stage 64.0 (TID 72) INFO Executor: Finished task 7.0 in stage 64.0 (TID 72). 6648 bytes result sent to driver
23/10/22 22:16:55.413 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 64.0 (TID 72) in 368 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:16:55.421 Executor task launch worker for task 6.0 in stage 64.0 (TID 71) INFO Executor: Finished task 6.0 in stage 64.0 (TID 71). 6648 bytes result sent to driver
23/10/22 22:16:55.421 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 64.0 (TID 71) in 376 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:16:55.425 Executor task launch worker for task 2.0 in stage 64.0 (TID 67) INFO Executor: Finished task 2.0 in stage 64.0 (TID 67). 6648 bytes result sent to driver
23/10/22 22:16:55.426 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 64.0 (TID 67) in 382 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:16:55.428 Executor task launch worker for task 3.0 in stage 64.0 (TID 68) INFO Executor: Finished task 3.0 in stage 64.0 (TID 68). 6648 bytes result sent to driver
23/10/22 22:16:55.429 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 64.0 (TID 68) in 384 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:16:55.432 Executor task launch worker for task 5.0 in stage 64.0 (TID 70) INFO Executor: Finished task 5.0 in stage 64.0 (TID 70). 6648 bytes result sent to driver
23/10/22 22:16:55.433 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 64.0 (TID 70) in 388 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:16:55.436 Executor task launch worker for task 1.0 in stage 64.0 (TID 66) INFO Executor: Finished task 1.0 in stage 64.0 (TID 66). 6648 bytes result sent to driver
23/10/22 22:16:55.436 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 66) in 392 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:16:55.438 Executor task launch worker for task 0.0 in stage 64.0 (TID 65) INFO Executor: Finished task 0.0 in stage 64.0 (TID 65). 6648 bytes result sent to driver
23/10/22 22:16:55.438 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 65) in 394 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:16:55.438 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
23/10/22 22:16:55.439 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 64 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.410 s
23/10/22 22:16:55.439 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:55.440 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:55.440 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 65)
23/10/22 22:16:55.440 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:55.440 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[121] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:16:55.444 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 93.2 KiB, free 1036.9 MiB)
23/10/22 22:16:55.446 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 1036.8 MiB)
23/10/22 22:16:55.446 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:55185 (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 22:16:55.447 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:55.447 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (MapPartitionsRDD[121] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:16:55.447 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks resource profile 0
23/10/22 22:16:55.448 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 73) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:16:55.449 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 74) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:16:55.449 Executor task launch worker for task 0.0 in stage 65.0 (TID 73) INFO Executor: Running task 0.0 in stage 65.0 (TID 73)
23/10/22 22:16:55.449 Executor task launch worker for task 1.0 in stage 65.0 (TID 74) INFO Executor: Running task 1.0 in stage 65.0 (TID 74)
23/10/22 22:16:55.457 Executor task launch worker for task 1.0 in stage 65.0 (TID 74) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.457 Executor task launch worker for task 0.0 in stage 65.0 (TID 73) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:55.457 Executor task launch worker for task 1.0 in stage 65.0 (TID 74) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.457 Executor task launch worker for task 0.0 in stage 65.0 (TID 73) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:55.475 Executor task launch worker for task 0.0 in stage 65.0 (TID 73) INFO Executor: Finished task 0.0 in stage 65.0 (TID 73). 6742 bytes result sent to driver
23/10/22 22:16:55.475 Executor task launch worker for task 1.0 in stage 65.0 (TID 74) INFO Executor: Finished task 1.0 in stage 65.0 (TID 74). 6742 bytes result sent to driver
23/10/22 22:16:55.476 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 73) in 28 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:16:55.476 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 74) in 28 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:16:55.476 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
23/10/22 22:16:55.476 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 65 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.036 s
23/10/22 22:16:55.477 dag-scheduler-event-loop INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:55.477 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
23/10/22 22:16:55.477 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 36 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.453150 s
23/10/22 22:16:55.478 nioEventLoopGroup-2-2 INFO Instrumentation: [a59c7b5b] Number of instances: 3785.
23/10/22 22:16:55.521 nioEventLoopGroup-2-2 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK
23/10/22 22:16:55.622 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 124 (rdd at LinearRegression.scala:921) as input to shuffle 18
23/10/22 22:16:55.622 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 37 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:16:55.622 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 66 (rdd at LinearRegression.scala:921)
23/10/22 22:16:55.622 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:55.622 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:55.623 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[124] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:16:55.624 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:16:55.626 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:16:55.626 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:16:55.626 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:55.626 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[124] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:55.626 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
23/10/22 22:16:55.835 dispatcher-event-loop-1 WARN TaskSetManager: Stage 66 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:16:55.835 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 75) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:16:55.836 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO Executor: Running task 0.0 in stage 66.0 (TID 75)
23/10/22 22:16:55.868 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:55185 in memory (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 22:16:55.998 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:56.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:55185 in memory (size: 36.5 KiB, free: 1037.1 MiB)
23/10/22 22:16:56.022 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.954 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO Executor: Finished task 0.0 in stage 66.0 (TID 75). 2104 bytes result sent to driver
23/10/22 22:16:56.955 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 75) in 1328 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:56.955 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
23/10/22 22:16:56.956 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 66 (rdd at LinearRegression.scala:921) finished in 1.332 s
23/10/22 22:16:56.956 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:56.956 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:56.956 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:16:56.956 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:56.960 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:16:56.963 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 128 (rdd at LinearRegression.scala:921) as input to shuffle 19
23/10/22 22:16:56.964 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 38 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:16:56.964 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 68 (rdd at LinearRegression.scala:921)
23/10/22 22:16:56.964 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
23/10/22 22:16:56.964 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:56.964 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[128] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:16:56.966 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:16:56.967 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:16:56.968 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:56.968 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:56.968 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[128] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:16:56.968 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 68.0 with 8 tasks resource profile 0
23/10/22 22:16:56.969 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 76) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.969 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 77) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.969 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 78) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.969 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 79) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.970 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 80) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.970 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 68.0 (TID 81) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.970 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 68.0 (TID 82) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.970 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 68.0 (TID 83) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:56.970 Executor task launch worker for task 3.0 in stage 68.0 (TID 79) INFO Executor: Running task 3.0 in stage 68.0 (TID 79)
23/10/22 22:16:56.970 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO Executor: Running task 0.0 in stage 68.0 (TID 76)
23/10/22 22:16:56.970 Executor task launch worker for task 5.0 in stage 68.0 (TID 81) INFO Executor: Running task 5.0 in stage 68.0 (TID 81)
23/10/22 22:16:56.970 Executor task launch worker for task 7.0 in stage 68.0 (TID 83) INFO Executor: Running task 7.0 in stage 68.0 (TID 83)
23/10/22 22:16:56.970 Executor task launch worker for task 1.0 in stage 68.0 (TID 77) INFO Executor: Running task 1.0 in stage 68.0 (TID 77)
23/10/22 22:16:56.970 Executor task launch worker for task 2.0 in stage 68.0 (TID 78) INFO Executor: Running task 2.0 in stage 68.0 (TID 78)
23/10/22 22:16:56.970 Executor task launch worker for task 6.0 in stage 68.0 (TID 82) INFO Executor: Running task 6.0 in stage 68.0 (TID 82)
23/10/22 22:16:56.970 Executor task launch worker for task 4.0 in stage 68.0 (TID 80) INFO Executor: Running task 4.0 in stage 68.0 (TID 80)
23/10/22 22:16:56.974 Executor task launch worker for task 4.0 in stage 68.0 (TID 80) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.974 Executor task launch worker for task 4.0 in stage 68.0 (TID 80) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.974 Executor task launch worker for task 6.0 in stage 68.0 (TID 82) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.974 Executor task launch worker for task 2.0 in stage 68.0 (TID 78) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.974 Executor task launch worker for task 2.0 in stage 68.0 (TID 78) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.974 Executor task launch worker for task 3.0 in stage 68.0 (TID 79) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.974 Executor task launch worker for task 3.0 in stage 68.0 (TID 79) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.975 Executor task launch worker for task 1.0 in stage 68.0 (TID 77) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.975 Executor task launch worker for task 1.0 in stage 68.0 (TID 77) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.974 Executor task launch worker for task 6.0 in stage 68.0 (TID 82) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.975 Executor task launch worker for task 7.0 in stage 68.0 (TID 83) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.975 Executor task launch worker for task 7.0 in stage 68.0 (TID 83) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.976 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.976 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.976 Executor task launch worker for task 5.0 in stage 68.0 (TID 81) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:56.976 Executor task launch worker for task 5.0 in stage 68.0 (TID 81) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:56.982 Executor task launch worker for task 3.0 in stage 68.0 (TID 79) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.982 Executor task launch worker for task 4.0 in stage 68.0 (TID 80) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.984 Executor task launch worker for task 7.0 in stage 68.0 (TID 83) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.991 Executor task launch worker for task 6.0 in stage 68.0 (TID 82) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.994 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.996 Executor task launch worker for task 2.0 in stage 68.0 (TID 78) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:56.996 Executor task launch worker for task 5.0 in stage 68.0 (TID 81) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.005 Executor task launch worker for task 1.0 in stage 68.0 (TID 77) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.018 Executor task launch worker for task 6.0 in stage 68.0 (TID 82) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.019 Executor task launch worker for task 3.0 in stage 68.0 (TID 79) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.019 Executor task launch worker for task 2.0 in stage 68.0 (TID 78) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.038 Executor task launch worker for task 1.0 in stage 68.0 (TID 77) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.038 Executor task launch worker for task 5.0 in stage 68.0 (TID 81) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.038 Executor task launch worker for task 4.0 in stage 68.0 (TID 80) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.090 Executor task launch worker for task 7.0 in stage 68.0 (TID 83) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.116 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.193 Executor task launch worker for task 3.0 in stage 68.0 (TID 79) INFO Executor: Finished task 3.0 in stage 68.0 (TID 79). 4985 bytes result sent to driver
23/10/22 22:16:57.196 Executor task launch worker for task 1.0 in stage 68.0 (TID 77) INFO Executor: Finished task 1.0 in stage 68.0 (TID 77). 4942 bytes result sent to driver
23/10/22 22:16:57.211 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 77) in 242 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:16:57.218 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 79) in 249 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:16:57.241 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:16:57.243 Executor task launch worker for task 4.0 in stage 68.0 (TID 80) INFO Executor: Finished task 4.0 in stage 68.0 (TID 80). 4985 bytes result sent to driver
23/10/22 22:16:57.244 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 80) in 273 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:16:57.248 Executor task launch worker for task 2.0 in stage 68.0 (TID 78) INFO Executor: Finished task 2.0 in stage 68.0 (TID 78). 4985 bytes result sent to driver
23/10/22 22:16:57.249 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 78) in 280 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:16:57.253 Executor task launch worker for task 7.0 in stage 68.0 (TID 83) INFO Executor: Finished task 7.0 in stage 68.0 (TID 83). 4985 bytes result sent to driver
23/10/22 22:16:57.253 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 68.0 (TID 83) in 283 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:16:57.257 Executor task launch worker for task 5.0 in stage 68.0 (TID 81) INFO Executor: Finished task 5.0 in stage 68.0 (TID 81). 4985 bytes result sent to driver
23/10/22 22:16:57.258 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 68.0 (TID 81) in 288 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:16:57.260 Executor task launch worker for task 6.0 in stage 68.0 (TID 82) INFO Executor: Finished task 6.0 in stage 68.0 (TID 82). 4985 bytes result sent to driver
23/10/22 22:16:57.261 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 68.0 (TID 82) in 291 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:16:57.264 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO Executor: Finished task 0.0 in stage 68.0 (TID 76). 4942 bytes result sent to driver
23/10/22 22:16:57.265 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 76) in 295 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:16:57.265 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
23/10/22 22:16:57.266 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 68 (rdd at LinearRegression.scala:921) finished in 0.301 s
23/10/22 22:16:57.266 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:57.266 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:57.266 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:16:57.266 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:57.272 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:16:57.292 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.4379 ms
23/10/22 22:16:57.477 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:16:57.478 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 138 (treeAggregate at Statistics.scala:58) as input to shuffle 20
23/10/22 22:16:57.478 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:16:57.478 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 72 (treeAggregate at Statistics.scala:58)
23/10/22 22:16:57.478 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
23/10/22 22:16:57.478 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
23/10/22 22:16:57.479 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[138] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:16:57.483 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 82.5 KiB, free 1037.0 MiB)
23/10/22 22:16:57.484 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1037.0 MiB)
23/10/22 22:16:57.485 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:55185 (size: 35.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:57.486 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:57.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[138] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:16:57.486 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 71.0 with 8 tasks resource profile 0
23/10/22 22:16:57.487 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 84) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.487 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 85) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.488 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 86) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.488 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 87) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.488 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 88) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.488 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 89) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.488 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 90) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.488 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 91) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:16:57.489 Executor task launch worker for task 1.0 in stage 71.0 (TID 85) INFO Executor: Running task 1.0 in stage 71.0 (TID 85)
23/10/22 22:16:57.489 Executor task launch worker for task 0.0 in stage 71.0 (TID 84) INFO Executor: Running task 0.0 in stage 71.0 (TID 84)
23/10/22 22:16:57.489 Executor task launch worker for task 5.0 in stage 71.0 (TID 89) INFO Executor: Running task 5.0 in stage 71.0 (TID 89)
23/10/22 22:16:57.489 Executor task launch worker for task 6.0 in stage 71.0 (TID 90) INFO Executor: Running task 6.0 in stage 71.0 (TID 90)
23/10/22 22:16:57.489 Executor task launch worker for task 3.0 in stage 71.0 (TID 87) INFO Executor: Running task 3.0 in stage 71.0 (TID 87)
23/10/22 22:16:57.489 Executor task launch worker for task 2.0 in stage 71.0 (TID 86) INFO Executor: Running task 2.0 in stage 71.0 (TID 86)
23/10/22 22:16:57.489 Executor task launch worker for task 7.0 in stage 71.0 (TID 91) INFO Executor: Running task 7.0 in stage 71.0 (TID 91)
23/10/22 22:16:57.489 Executor task launch worker for task 4.0 in stage 71.0 (TID 88) INFO Executor: Running task 4.0 in stage 71.0 (TID 88)
23/10/22 22:16:57.524 Executor task launch worker for task 6.0 in stage 71.0 (TID 90) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.524 Executor task launch worker for task 2.0 in stage 71.0 (TID 86) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.524 Executor task launch worker for task 6.0 in stage 71.0 (TID 90) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:57.525 Executor task launch worker for task 7.0 in stage 71.0 (TID 91) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.525 Executor task launch worker for task 7.0 in stage 71.0 (TID 91) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:57.525 Executor task launch worker for task 2.0 in stage 71.0 (TID 86) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:57.525 Executor task launch worker for task 5.0 in stage 71.0 (TID 89) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.525 Executor task launch worker for task 5.0 in stage 71.0 (TID 89) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:57.526 Executor task launch worker for task 4.0 in stage 71.0 (TID 88) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.526 Executor task launch worker for task 4.0 in stage 71.0 (TID 88) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:57.526 Executor task launch worker for task 0.0 in stage 71.0 (TID 84) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.527 Executor task launch worker for task 3.0 in stage 71.0 (TID 87) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.527 Executor task launch worker for task 0.0 in stage 71.0 (TID 84) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:16:57.527 Executor task launch worker for task 1.0 in stage 71.0 (TID 85) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.527 Executor task launch worker for task 1.0 in stage 71.0 (TID 85) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:16:57.527 Executor task launch worker for task 3.0 in stage 71.0 (TID 87) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:57.541 Executor task launch worker for task 6.0 in stage 71.0 (TID 90) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.542 Executor task launch worker for task 4.0 in stage 71.0 (TID 88) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.542 Executor task launch worker for task 1.0 in stage 71.0 (TID 85) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.548 Executor task launch worker for task 7.0 in stage 71.0 (TID 91) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.560 Executor task launch worker for task 0.0 in stage 71.0 (TID 84) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.561 Executor task launch worker for task 5.0 in stage 71.0 (TID 89) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.576 Executor task launch worker for task 4.0 in stage 71.0 (TID 88) INFO CodeGenerator: Code generated in 12.782 ms
23/10/22 22:16:57.602 Executor task launch worker for task 2.0 in stage 71.0 (TID 86) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.612 Executor task launch worker for task 3.0 in stage 71.0 (TID 87) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:16:57.616 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:16:57.663 Executor task launch worker for task 7.0 in stage 71.0 (TID 91) INFO Executor: Finished task 7.0 in stage 71.0 (TID 91). 6648 bytes result sent to driver
23/10/22 22:16:57.664 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 91) in 176 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:16:57.667 Executor task launch worker for task 6.0 in stage 71.0 (TID 90) INFO Executor: Finished task 6.0 in stage 71.0 (TID 90). 6605 bytes result sent to driver
23/10/22 22:16:57.668 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 90) in 180 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:16:57.672 Executor task launch worker for task 4.0 in stage 71.0 (TID 88) INFO Executor: Finished task 4.0 in stage 71.0 (TID 88). 6648 bytes result sent to driver
23/10/22 22:16:57.673 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 88) in 185 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:16:57.676 Executor task launch worker for task 5.0 in stage 71.0 (TID 89) INFO Executor: Finished task 5.0 in stage 71.0 (TID 89). 6605 bytes result sent to driver
23/10/22 22:16:57.677 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 89) in 189 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:16:57.701 Executor task launch worker for task 0.0 in stage 71.0 (TID 84) INFO Executor: Finished task 0.0 in stage 71.0 (TID 84). 6691 bytes result sent to driver
23/10/22 22:16:57.703 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 84) in 216 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:16:57.711 Executor task launch worker for task 2.0 in stage 71.0 (TID 86) INFO Executor: Finished task 2.0 in stage 71.0 (TID 86). 6648 bytes result sent to driver
23/10/22 22:16:57.718 Executor task launch worker for task 1.0 in stage 71.0 (TID 85) INFO Executor: Finished task 1.0 in stage 71.0 (TID 85). 6648 bytes result sent to driver
23/10/22 22:16:57.718 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 86) in 231 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:16:57.719 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 85) in 232 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:16:57.731 Executor task launch worker for task 3.0 in stage 71.0 (TID 87) INFO Executor: Finished task 3.0 in stage 71.0 (TID 87). 6648 bytes result sent to driver
23/10/22 22:16:57.731 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 87) in 243 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:16:57.731 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
23/10/22 22:16:57.731 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 71 (treeAggregate at Statistics.scala:58) finished in 0.252 s
23/10/22 22:16:57.731 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:16:57.731 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:16:57.731 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 72)
23/10/22 22:16:57.731 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:16:57.733 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[140] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:16:57.737 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 83.6 KiB, free 1036.9 MiB)
23/10/22 22:16:57.739 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1036.9 MiB)
23/10/22 22:16:57.739 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:55185 (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:16:57.740 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:57.740 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (MapPartitionsRDD[140] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:16:57.740 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks resource profile 0
23/10/22 22:16:57.749 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 92) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:16:57.749 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 93) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:16:57.750 Executor task launch worker for task 0.0 in stage 72.0 (TID 92) INFO Executor: Running task 0.0 in stage 72.0 (TID 92)
23/10/22 22:16:57.752 Executor task launch worker for task 1.0 in stage 72.0 (TID 93) INFO Executor: Running task 1.0 in stage 72.0 (TID 93)
23/10/22 22:16:57.760 Executor task launch worker for task 0.0 in stage 72.0 (TID 92) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.760 Executor task launch worker for task 0.0 in stage 72.0 (TID 92) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:16:57.770 Executor task launch worker for task 1.0 in stage 72.0 (TID 93) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:16:57.771 Executor task launch worker for task 1.0 in stage 72.0 (TID 93) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:16:57.773 Executor task launch worker for task 0.0 in stage 72.0 (TID 92) INFO Executor: Finished task 0.0 in stage 72.0 (TID 92). 7630 bytes result sent to driver
23/10/22 22:16:57.774 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 92) in 26 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:16:57.781 Executor task launch worker for task 1.0 in stage 72.0 (TID 93) INFO Executor: Finished task 1.0 in stage 72.0 (TID 93). 7630 bytes result sent to driver
23/10/22 22:16:57.781 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 93) in 32 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:16:57.781 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
23/10/22 22:16:57.782 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 72 (treeAggregate at Statistics.scala:58) finished in 0.048 s
23/10/22 22:16:57.782 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:57.782 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
23/10/22 22:16:57.783 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: treeAggregate at Statistics.scala:58, took 0.304550 s
23/10/22 22:16:57.786 nioEventLoopGroup-2-2 INFO Instrumentation: [fe66e629] training finished
23/10/22 22:16:58.400 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:16:58.401 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:16:58.401 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:26)
23/10/22 22:16:58.401 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:58.401 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:58.401 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[142] at collect at utils.scala:26), which has no missing parents
23/10/22 22:16:58.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 22:16:58.405 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 22:16:58.406 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:58.407 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:58.408 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[142] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:58.408 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
23/10/22 22:16:58.409 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 94) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:16:58.410 Executor task launch worker for task 0.0 in stage 73.0 (TID 94) INFO Executor: Running task 0.0 in stage 73.0 (TID 94)
23/10/22 22:16:58.412 Executor task launch worker for task 0.0 in stage 73.0 (TID 94) INFO Executor: Finished task 0.0 in stage 73.0 (TID 94). 1370 bytes result sent to driver
23/10/22 22:16:58.413 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 94) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:58.413 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
23/10/22 22:16:58.414 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 73 (collect at utils.scala:26) finished in 0.011 s
23/10/22 22:16:58.414 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:58.414 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
23/10/22 22:16:58.415 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collect at utils.scala:26, took 0.014151 s
23/10/22 22:16:58.759 nioEventLoopGroup-2-2 INFO Instrumentation: [c50c5a92] training finished
23/10/22 22:16:58.880 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:16:58.881 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:16:58.881 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:26)
23/10/22 22:16:58.881 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:58.881 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:58.881 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[144] at collect at utils.scala:26), which has no missing parents
23/10/22 22:16:58.883 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 22:16:58.889 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 22:16:58.891 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:58.892 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:58.893 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[144] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:58.893 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
23/10/22 22:16:58.893 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 95) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:16:58.895 Executor task launch worker for task 0.0 in stage 74.0 (TID 95) INFO Executor: Running task 0.0 in stage 74.0 (TID 95)
23/10/22 22:16:58.900 Executor task launch worker for task 0.0 in stage 74.0 (TID 95) INFO Executor: Finished task 0.0 in stage 74.0 (TID 95). 1370 bytes result sent to driver
23/10/22 22:16:58.901 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 95) in 8 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:58.902 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
23/10/22 22:16:58.902 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 74 (collect at utils.scala:26) finished in 0.020 s
23/10/22 22:16:58.902 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:58.902 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
23/10/22 22:16:58.902 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collect at utils.scala:26, took 0.022105 s
23/10/22 22:16:58.911 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.4361 ms
23/10/22 22:16:59.731 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:16:59.731 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:16:59.731 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:26)
23/10/22 22:16:59.731 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:16:59.731 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:16:59.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[146] at collect at utils.scala:26), which has no missing parents
23/10/22 22:16:59.733 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 22:16:59.735 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 22:16:59.737 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:16:59.738 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
23/10/22 22:16:59.738 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[146] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:16:59.738 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
23/10/22 22:16:59.739 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 96) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:16:59.740 Executor task launch worker for task 0.0 in stage 75.0 (TID 96) INFO Executor: Running task 0.0 in stage 75.0 (TID 96)
23/10/22 22:16:59.742 Executor task launch worker for task 0.0 in stage 75.0 (TID 96) INFO Executor: Finished task 0.0 in stage 75.0 (TID 96). 1327 bytes result sent to driver
23/10/22 22:16:59.743 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 96) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:16:59.743 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
23/10/22 22:16:59.743 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 75 (collect at utils.scala:26) finished in 0.012 s
23/10/22 22:16:59.744 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:16:59.744 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
23/10/22 22:16:59.744 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0.013457 s
23/10/22 22:17:00.682 nioEventLoopGroup-2-2 INFO Instrumentation: [33a05baa] training finished
23/10/22 22:17:00.698 nioEventLoopGroup-2-2 INFO Instrumentation: [f0c23224] training finished
23/10/22 22:17:00.710 nioEventLoopGroup-2-2 INFO Instrumentation: [d405dda3] Stage class: LinearRegression
23/10/22 22:17:00.710 nioEventLoopGroup-2-2 INFO Instrumentation: [d405dda3] Stage uid: linear_regression__55d93a20_b973_436b_b9c6_67f4ece3769f
23/10/22 22:17:00.757 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 149 (rdd at Instrumentation.scala:62) as input to shuffle 21
23/10/22 22:17:00.757 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 43 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:17:00.757 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 76 (rdd at Instrumentation.scala:62)
23/10/22 22:17:00.757 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:00.757 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:00.757 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[149] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:00.759 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:00.760 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:00.760 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:00.761 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:00.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[149] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:00.761 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
23/10/22 22:17:01.121 dispatcher-event-loop-7 WARN TaskSetManager: Stage 76 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:01.121 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 97) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:01.121 Executor task launch worker for task 0.0 in stage 76.0 (TID 97) INFO Executor: Running task 0.0 in stage 76.0 (TID 97)
23/10/22 22:17:01.298 Executor task launch worker for task 0.0 in stage 76.0 (TID 97) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:01.681 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:01.686 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:01.692 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:55185 in memory (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:01.695 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:01.954 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:55185 in memory (size: 35.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:02.656 Executor task launch worker for task 0.0 in stage 76.0 (TID 97) INFO Executor: Finished task 0.0 in stage 76.0 (TID 97). 2104 bytes result sent to driver
23/10/22 22:17:02.656 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 97) in 1894 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:02.656 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
23/10/22 22:17:02.657 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 76 (rdd at Instrumentation.scala:62) finished in 1.899 s
23/10/22 22:17:02.657 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:02.657 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:02.657 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:02.657 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:02.662 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:02.667 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 153 (rdd at Instrumentation.scala:62) as input to shuffle 22
23/10/22 22:17:02.668 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 44 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:17:02.668 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 78 (rdd at Instrumentation.scala:62)
23/10/22 22:17:02.668 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
23/10/22 22:17:02.668 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:02.669 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[153] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:02.672 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:02.674 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 22:17:02.674 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:55185 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:02.674 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:02.674 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[153] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:02.674 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 78.0 with 8 tasks resource profile 0
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 98) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 99) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 100) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 101) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 102) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 103) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 104) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.677 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 105) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:02.679 Executor task launch worker for task 2.0 in stage 78.0 (TID 100) INFO Executor: Running task 2.0 in stage 78.0 (TID 100)
23/10/22 22:17:02.679 Executor task launch worker for task 0.0 in stage 78.0 (TID 98) INFO Executor: Running task 0.0 in stage 78.0 (TID 98)
23/10/22 22:17:02.679 Executor task launch worker for task 4.0 in stage 78.0 (TID 102) INFO Executor: Running task 4.0 in stage 78.0 (TID 102)
23/10/22 22:17:02.679 Executor task launch worker for task 5.0 in stage 78.0 (TID 103) INFO Executor: Running task 5.0 in stage 78.0 (TID 103)
23/10/22 22:17:02.679 Executor task launch worker for task 6.0 in stage 78.0 (TID 104) INFO Executor: Running task 6.0 in stage 78.0 (TID 104)
23/10/22 22:17:02.679 Executor task launch worker for task 1.0 in stage 78.0 (TID 99) INFO Executor: Running task 1.0 in stage 78.0 (TID 99)
23/10/22 22:17:02.679 Executor task launch worker for task 3.0 in stage 78.0 (TID 101) INFO Executor: Running task 3.0 in stage 78.0 (TID 101)
23/10/22 22:17:02.679 Executor task launch worker for task 7.0 in stage 78.0 (TID 105) INFO Executor: Running task 7.0 in stage 78.0 (TID 105)
23/10/22 22:17:02.683 Executor task launch worker for task 7.0 in stage 78.0 (TID 105) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.683 Executor task launch worker for task 6.0 in stage 78.0 (TID 104) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.683 Executor task launch worker for task 5.0 in stage 78.0 (TID 103) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.683 Executor task launch worker for task 7.0 in stage 78.0 (TID 105) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.683 Executor task launch worker for task 6.0 in stage 78.0 (TID 104) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.683 Executor task launch worker for task 5.0 in stage 78.0 (TID 103) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.683 Executor task launch worker for task 1.0 in stage 78.0 (TID 99) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.683 Executor task launch worker for task 1.0 in stage 78.0 (TID 99) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.684 Executor task launch worker for task 4.0 in stage 78.0 (TID 102) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.684 Executor task launch worker for task 3.0 in stage 78.0 (TID 101) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.684 Executor task launch worker for task 4.0 in stage 78.0 (TID 102) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.684 Executor task launch worker for task 3.0 in stage 78.0 (TID 101) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.684 Executor task launch worker for task 2.0 in stage 78.0 (TID 100) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.684 Executor task launch worker for task 2.0 in stage 78.0 (TID 100) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.685 Executor task launch worker for task 0.0 in stage 78.0 (TID 98) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:02.685 Executor task launch worker for task 0.0 in stage 78.0 (TID 98) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:02.691 Executor task launch worker for task 7.0 in stage 78.0 (TID 105) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.691 Executor task launch worker for task 1.0 in stage 78.0 (TID 99) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.692 Executor task launch worker for task 5.0 in stage 78.0 (TID 103) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.692 Executor task launch worker for task 6.0 in stage 78.0 (TID 104) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.693 Executor task launch worker for task 2.0 in stage 78.0 (TID 100) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.695 Executor task launch worker for task 4.0 in stage 78.0 (TID 102) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.703 Executor task launch worker for task 3.0 in stage 78.0 (TID 101) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.715 Executor task launch worker for task 7.0 in stage 78.0 (TID 105) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.718 Executor task launch worker for task 0.0 in stage 78.0 (TID 98) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.729 Executor task launch worker for task 6.0 in stage 78.0 (TID 104) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.739 Executor task launch worker for task 2.0 in stage 78.0 (TID 100) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.743 Executor task launch worker for task 3.0 in stage 78.0 (TID 101) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.759 Executor task launch worker for task 5.0 in stage 78.0 (TID 103) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.769 Executor task launch worker for task 0.0 in stage 78.0 (TID 98) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.771 Executor task launch worker for task 1.0 in stage 78.0 (TID 99) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.778 Executor task launch worker for task 4.0 in stage 78.0 (TID 102) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:02.922 Executor task launch worker for task 3.0 in stage 78.0 (TID 101) INFO Executor: Finished task 3.0 in stage 78.0 (TID 101). 4985 bytes result sent to driver
23/10/22 22:17:02.963 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 101) in 286 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:02.963 Executor task launch worker for task 2.0 in stage 78.0 (TID 100) INFO Executor: Finished task 2.0 in stage 78.0 (TID 100). 4942 bytes result sent to driver
23/10/22 22:17:02.966 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 100) in 289 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:03.154 Executor task launch worker for task 0.0 in stage 78.0 (TID 98) INFO Executor: Finished task 0.0 in stage 78.0 (TID 98). 4942 bytes result sent to driver
23/10/22 22:17:03.166 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 98) in 489 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:03.187 Executor task launch worker for task 6.0 in stage 78.0 (TID 104) INFO Executor: Finished task 6.0 in stage 78.0 (TID 104). 4942 bytes result sent to driver
23/10/22 22:17:03.188 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 104) in 511 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:03.192 Executor task launch worker for task 4.0 in stage 78.0 (TID 102) INFO Executor: Finished task 4.0 in stage 78.0 (TID 102). 4985 bytes result sent to driver
23/10/22 22:17:03.194 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 102) in 517 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:03.195 Executor task launch worker for task 7.0 in stage 78.0 (TID 105) INFO Executor: Finished task 7.0 in stage 78.0 (TID 105). 4942 bytes result sent to driver
23/10/22 22:17:03.204 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 105) in 527 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:03.210 Executor task launch worker for task 1.0 in stage 78.0 (TID 99) INFO Executor: Finished task 1.0 in stage 78.0 (TID 99). 4942 bytes result sent to driver
23/10/22 22:17:03.218 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:03.220 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 99) in 543 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:03.268 Executor task launch worker for task 5.0 in stage 78.0 (TID 103) INFO Executor: Finished task 5.0 in stage 78.0 (TID 103). 4942 bytes result sent to driver
23/10/22 22:17:03.271 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 103) in 594 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:03.272 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
23/10/22 22:17:03.274 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 78 (rdd at Instrumentation.scala:62) finished in 0.602 s
23/10/22 22:17:03.274 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:03.274 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:03.274 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:03.274 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:03.287 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:03.314 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.48 ms
23/10/22 22:17:03.333 nioEventLoopGroup-2-2 INFO Instrumentation: [d405dda3] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:17:03.335 nioEventLoopGroup-2-2 INFO Instrumentation: [d405dda3] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:17:03.337 nioEventLoopGroup-2-2 INFO Instrumentation: [d405dda3] {"numFeatures":1}
23/10/22 22:17:03.475 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 162 (rdd at LinearRegression.scala:348) as input to shuffle 23
23/10/22 22:17:03.476 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 45 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:17:03.476 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 79 (rdd at LinearRegression.scala:348)
23/10/22 22:17:03.476 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:03.476 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:03.477 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[162] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:03.480 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 22:17:03.483 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:03.484 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:03.485 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:03.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[162] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:03.486 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
23/10/22 22:17:03.855 dispatcher-event-loop-4 WARN TaskSetManager: Stage 79 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:03.856 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 106) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:03.856 Executor task launch worker for task 0.0 in stage 79.0 (TID 106) INFO Executor: Running task 0.0 in stage 79.0 (TID 106)
23/10/22 22:17:04.011 Executor task launch worker for task 0.0 in stage 79.0 (TID 106) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:04.553 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:55185 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:05.188 Executor task launch worker for task 0.0 in stage 79.0 (TID 106) INFO Executor: Finished task 0.0 in stage 79.0 (TID 106). 2104 bytes result sent to driver
23/10/22 22:17:05.189 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 106) in 1702 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:05.189 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
23/10/22 22:17:05.189 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 79 (rdd at LinearRegression.scala:348) finished in 1.711 s
23/10/22 22:17:05.189 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:05.189 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:05.189 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:05.189 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:05.195 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:05.199 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 166 (rdd at LinearRegression.scala:348) as input to shuffle 24
23/10/22 22:17:05.199 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 46 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:17:05.199 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 81 (rdd at LinearRegression.scala:348)
23/10/22 22:17:05.199 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
23/10/22 22:17:05.199 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:05.199 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[166] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:05.202 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:05.203 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:05.203 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:05.204 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:05.204 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[166] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:05.204 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 81.0 with 8 tasks resource profile 0
23/10/22 22:17:05.205 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 107) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.205 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 108) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.205 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 109) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.206 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 110) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.206 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 111) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.206 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 112) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.206 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 113) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.206 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 114) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.207 Executor task launch worker for task 2.0 in stage 81.0 (TID 109) INFO Executor: Running task 2.0 in stage 81.0 (TID 109)
23/10/22 22:17:05.207 Executor task launch worker for task 6.0 in stage 81.0 (TID 113) INFO Executor: Running task 6.0 in stage 81.0 (TID 113)
23/10/22 22:17:05.207 Executor task launch worker for task 3.0 in stage 81.0 (TID 110) INFO Executor: Running task 3.0 in stage 81.0 (TID 110)
23/10/22 22:17:05.207 Executor task launch worker for task 5.0 in stage 81.0 (TID 112) INFO Executor: Running task 5.0 in stage 81.0 (TID 112)
23/10/22 22:17:05.207 Executor task launch worker for task 1.0 in stage 81.0 (TID 108) INFO Executor: Running task 1.0 in stage 81.0 (TID 108)
23/10/22 22:17:05.207 Executor task launch worker for task 0.0 in stage 81.0 (TID 107) INFO Executor: Running task 0.0 in stage 81.0 (TID 107)
23/10/22 22:17:05.207 Executor task launch worker for task 4.0 in stage 81.0 (TID 111) INFO Executor: Running task 4.0 in stage 81.0 (TID 111)
23/10/22 22:17:05.207 Executor task launch worker for task 7.0 in stage 81.0 (TID 114) INFO Executor: Running task 7.0 in stage 81.0 (TID 114)
23/10/22 22:17:05.211 Executor task launch worker for task 2.0 in stage 81.0 (TID 109) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.211 Executor task launch worker for task 0.0 in stage 81.0 (TID 107) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.211 Executor task launch worker for task 1.0 in stage 81.0 (TID 108) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.211 Executor task launch worker for task 5.0 in stage 81.0 (TID 112) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.211 Executor task launch worker for task 7.0 in stage 81.0 (TID 114) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.211 Executor task launch worker for task 0.0 in stage 81.0 (TID 107) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.211 Executor task launch worker for task 5.0 in stage 81.0 (TID 112) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.211 Executor task launch worker for task 7.0 in stage 81.0 (TID 114) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.211 Executor task launch worker for task 4.0 in stage 81.0 (TID 111) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.211 Executor task launch worker for task 1.0 in stage 81.0 (TID 108) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.211 Executor task launch worker for task 6.0 in stage 81.0 (TID 113) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.212 Executor task launch worker for task 6.0 in stage 81.0 (TID 113) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.211 Executor task launch worker for task 2.0 in stage 81.0 (TID 109) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.211 Executor task launch worker for task 4.0 in stage 81.0 (TID 111) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.212 Executor task launch worker for task 3.0 in stage 81.0 (TID 110) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.213 Executor task launch worker for task 3.0 in stage 81.0 (TID 110) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.220 Executor task launch worker for task 1.0 in stage 81.0 (TID 108) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.221 Executor task launch worker for task 4.0 in stage 81.0 (TID 111) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.221 Executor task launch worker for task 2.0 in stage 81.0 (TID 109) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.221 Executor task launch worker for task 5.0 in stage 81.0 (TID 112) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.227 Executor task launch worker for task 6.0 in stage 81.0 (TID 113) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.227 Executor task launch worker for task 0.0 in stage 81.0 (TID 107) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.227 Executor task launch worker for task 3.0 in stage 81.0 (TID 110) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.236 Executor task launch worker for task 7.0 in stage 81.0 (TID 114) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.244 Executor task launch worker for task 1.0 in stage 81.0 (TID 108) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.251 Executor task launch worker for task 2.0 in stage 81.0 (TID 109) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.253 Executor task launch worker for task 3.0 in stage 81.0 (TID 110) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.254 Executor task launch worker for task 4.0 in stage 81.0 (TID 111) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.261 Executor task launch worker for task 0.0 in stage 81.0 (TID 107) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.263 Executor task launch worker for task 6.0 in stage 81.0 (TID 113) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.324 Executor task launch worker for task 5.0 in stage 81.0 (TID 112) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.326 Executor task launch worker for task 7.0 in stage 81.0 (TID 114) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.380 Executor task launch worker for task 4.0 in stage 81.0 (TID 111) INFO Executor: Finished task 4.0 in stage 81.0 (TID 111). 4985 bytes result sent to driver
23/10/22 22:17:05.382 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 111) in 176 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:05.404 Executor task launch worker for task 2.0 in stage 81.0 (TID 109) INFO Executor: Finished task 2.0 in stage 81.0 (TID 109). 4942 bytes result sent to driver
23/10/22 22:17:05.405 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 109) in 200 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:05.409 Executor task launch worker for task 3.0 in stage 81.0 (TID 110) INFO Executor: Finished task 3.0 in stage 81.0 (TID 110). 4942 bytes result sent to driver
23/10/22 22:17:05.410 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 110) in 205 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:05.420 Executor task launch worker for task 0.0 in stage 81.0 (TID 107) INFO Executor: Finished task 0.0 in stage 81.0 (TID 107). 4942 bytes result sent to driver
23/10/22 22:17:05.422 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 107) in 217 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:05.428 Executor task launch worker for task 1.0 in stage 81.0 (TID 108) INFO Executor: Finished task 1.0 in stage 81.0 (TID 108). 4942 bytes result sent to driver
23/10/22 22:17:05.430 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 108) in 225 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:05.440 Executor task launch worker for task 7.0 in stage 81.0 (TID 114) INFO Executor: Finished task 7.0 in stage 81.0 (TID 114). 4942 bytes result sent to driver
23/10/22 22:17:05.441 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 114) in 235 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:05.448 Executor task launch worker for task 6.0 in stage 81.0 (TID 113) INFO Executor: Finished task 6.0 in stage 81.0 (TID 113). 4942 bytes result sent to driver
23/10/22 22:17:05.449 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 113) in 243 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:05.462 Executor task launch worker for task 5.0 in stage 81.0 (TID 112) INFO Executor: Finished task 5.0 in stage 81.0 (TID 112). 4942 bytes result sent to driver
23/10/22 22:17:05.463 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 112) in 257 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:05.463 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
23/10/22 22:17:05.464 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 81 (rdd at LinearRegression.scala:348) finished in 0.263 s
23/10/22 22:17:05.464 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:05.464 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:05.464 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:05.464 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:05.472 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:05.523 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 37.3591 ms
23/10/22 22:17:05.542 nioEventLoopGroup-2-2 WARN Instrumentation: [d405dda3] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:17:05.592 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:05.593 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:17:05.596 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 175 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 25
23/10/22 22:17:05.596 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:17:05.596 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 85 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:17:05.596 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
23/10/22 22:17:05.597 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
23/10/22 22:17:05.597 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[175] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:05.602 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 92.6 KiB, free 1037.0 MiB)
23/10/22 22:17:05.604 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1037.0 MiB)
23/10/22 22:17:05.611 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:55185 (size: 36.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:05.611 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:05.612 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[175] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:05.612 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 84.0 with 8 tasks resource profile 0
23/10/22 22:17:05.614 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 115) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.614 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 116) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.615 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 117) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.615 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 118) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.615 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 119) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.616 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 84.0 (TID 120) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.616 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 84.0 (TID 121) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.616 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 84.0 (TID 122) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:05.617 Executor task launch worker for task 4.0 in stage 84.0 (TID 119) INFO Executor: Running task 4.0 in stage 84.0 (TID 119)
23/10/22 22:17:05.617 Executor task launch worker for task 6.0 in stage 84.0 (TID 121) INFO Executor: Running task 6.0 in stage 84.0 (TID 121)
23/10/22 22:17:05.617 Executor task launch worker for task 7.0 in stage 84.0 (TID 122) INFO Executor: Running task 7.0 in stage 84.0 (TID 122)
23/10/22 22:17:05.617 Executor task launch worker for task 3.0 in stage 84.0 (TID 118) INFO Executor: Running task 3.0 in stage 84.0 (TID 118)
23/10/22 22:17:05.617 Executor task launch worker for task 5.0 in stage 84.0 (TID 120) INFO Executor: Running task 5.0 in stage 84.0 (TID 120)
23/10/22 22:17:05.626 Executor task launch worker for task 4.0 in stage 84.0 (TID 119) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.627 Executor task launch worker for task 4.0 in stage 84.0 (TID 119) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.630 Executor task launch worker for task 6.0 in stage 84.0 (TID 121) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.630 Executor task launch worker for task 6.0 in stage 84.0 (TID 121) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.631 Executor task launch worker for task 3.0 in stage 84.0 (TID 118) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.631 Executor task launch worker for task 3.0 in stage 84.0 (TID 118) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.632 Executor task launch worker for task 7.0 in stage 84.0 (TID 122) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.632 Executor task launch worker for task 5.0 in stage 84.0 (TID 120) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.632 Executor task launch worker for task 7.0 in stage 84.0 (TID 122) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.632 Executor task launch worker for task 5.0 in stage 84.0 (TID 120) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.638 Executor task launch worker for task 0.0 in stage 84.0 (TID 115) INFO Executor: Running task 0.0 in stage 84.0 (TID 115)
23/10/22 22:17:05.641 Executor task launch worker for task 2.0 in stage 84.0 (TID 117) INFO Executor: Running task 2.0 in stage 84.0 (TID 117)
23/10/22 22:17:05.641 Executor task launch worker for task 1.0 in stage 84.0 (TID 116) INFO Executor: Running task 1.0 in stage 84.0 (TID 116)
23/10/22 22:17:05.661 Executor task launch worker for task 2.0 in stage 84.0 (TID 117) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.661 Executor task launch worker for task 2.0 in stage 84.0 (TID 117) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.661 Executor task launch worker for task 1.0 in stage 84.0 (TID 116) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.661 Executor task launch worker for task 1.0 in stage 84.0 (TID 116) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:05.671 Executor task launch worker for task 0.0 in stage 84.0 (TID 115) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.672 Executor task launch worker for task 0.0 in stage 84.0 (TID 115) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.720 Executor task launch worker for task 2.0 in stage 84.0 (TID 117) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.720 Executor task launch worker for task 1.0 in stage 84.0 (TID 116) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.721 Executor task launch worker for task 5.0 in stage 84.0 (TID 120) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.732 Executor task launch worker for task 4.0 in stage 84.0 (TID 119) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.736 Executor task launch worker for task 3.0 in stage 84.0 (TID 118) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.737 Executor task launch worker for task 0.0 in stage 84.0 (TID 115) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.737 Executor task launch worker for task 7.0 in stage 84.0 (TID 122) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.753 Executor task launch worker for task 6.0 in stage 84.0 (TID 121) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:05.809 Executor task launch worker for task 4.0 in stage 84.0 (TID 119) INFO Executor: Finished task 4.0 in stage 84.0 (TID 119). 6562 bytes result sent to driver
23/10/22 22:17:05.813 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 119) in 197 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:05.818 Executor task launch worker for task 7.0 in stage 84.0 (TID 122) INFO Executor: Finished task 7.0 in stage 84.0 (TID 122). 6562 bytes result sent to driver
23/10/22 22:17:05.819 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 84.0 (TID 122) in 203 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:05.847 Executor task launch worker for task 6.0 in stage 84.0 (TID 121) INFO Executor: Finished task 6.0 in stage 84.0 (TID 121). 6562 bytes result sent to driver
23/10/22 22:17:05.854 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 84.0 (TID 121) in 237 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:05.866 Executor task launch worker for task 3.0 in stage 84.0 (TID 118) INFO Executor: Finished task 3.0 in stage 84.0 (TID 118). 6605 bytes result sent to driver
23/10/22 22:17:05.867 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 118) in 252 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:05.874 Executor task launch worker for task 1.0 in stage 84.0 (TID 116) INFO Executor: Finished task 1.0 in stage 84.0 (TID 116). 6605 bytes result sent to driver
23/10/22 22:17:05.877 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 116) in 262 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:05.918 Executor task launch worker for task 5.0 in stage 84.0 (TID 120) INFO Executor: Finished task 5.0 in stage 84.0 (TID 120). 6605 bytes result sent to driver
23/10/22 22:17:05.919 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 84.0 (TID 120) in 304 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:05.956 Executor task launch worker for task 2.0 in stage 84.0 (TID 117) INFO Executor: Finished task 2.0 in stage 84.0 (TID 117). 6562 bytes result sent to driver
23/10/22 22:17:05.960 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 117) in 346 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:05.964 Executor task launch worker for task 0.0 in stage 84.0 (TID 115) INFO Executor: Finished task 0.0 in stage 84.0 (TID 115). 6605 bytes result sent to driver
23/10/22 22:17:05.965 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 115) in 351 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:05.965 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
23/10/22 22:17:05.966 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 84 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.367 s
23/10/22 22:17:05.966 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:05.966 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:05.966 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 85)
23/10/22 22:17:05.966 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:05.967 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[177] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:05.971 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 93.6 KiB, free 1036.9 MiB)
23/10/22 22:17:05.973 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 1036.8 MiB)
23/10/22 22:17:05.976 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:55185 (size: 37.3 KiB, free: 1037.1 MiB)
23/10/22 22:17:05.977 dag-scheduler-event-loop INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:05.977 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (MapPartitionsRDD[177] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:05.978 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
23/10/22 22:17:05.979 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 123) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:05.980 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 124) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:05.982 Executor task launch worker for task 1.0 in stage 85.0 (TID 124) INFO Executor: Running task 1.0 in stage 85.0 (TID 124)
23/10/22 22:17:05.982 Executor task launch worker for task 0.0 in stage 85.0 (TID 123) INFO Executor: Running task 0.0 in stage 85.0 (TID 123)
23/10/22 22:17:05.992 Executor task launch worker for task 0.0 in stage 85.0 (TID 123) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.992 Executor task launch worker for task 0.0 in stage 85.0 (TID 123) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:05.994 Executor task launch worker for task 1.0 in stage 85.0 (TID 124) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:05.994 Executor task launch worker for task 1.0 in stage 85.0 (TID 124) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:06.003 Executor task launch worker for task 1.0 in stage 85.0 (TID 124) INFO Executor: Finished task 1.0 in stage 85.0 (TID 124). 6742 bytes result sent to driver
23/10/22 22:17:06.003 Executor task launch worker for task 0.0 in stage 85.0 (TID 123) INFO Executor: Finished task 0.0 in stage 85.0 (TID 123). 6742 bytes result sent to driver
23/10/22 22:17:06.003 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 124) in 23 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:06.004 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 123) in 25 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:06.004 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
23/10/22 22:17:06.004 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 85 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.036 s
23/10/22 22:17:06.004 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:06.004 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
23/10/22 22:17:06.005 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.411244 s
23/10/22 22:17:06.005 nioEventLoopGroup-2-2 INFO Instrumentation: [d405dda3] Number of instances: 3785.
23/10/22 22:17:06.114 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 180 (rdd at LinearRegression.scala:921) as input to shuffle 26
23/10/22 22:17:06.114 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 48 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:17:06.115 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 86 (rdd at LinearRegression.scala:921)
23/10/22 22:17:06.115 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:06.115 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:06.115 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[180] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:06.118 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:06.119 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:06.120 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:06.120 dag-scheduler-event-loop INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:06.120 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[180] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:06.120 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
23/10/22 22:17:06.491 dispatcher-event-loop-6 WARN TaskSetManager: Stage 86 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:06.491 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 125) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:06.492 Executor task launch worker for task 0.0 in stage 86.0 (TID 125) INFO Executor: Running task 0.0 in stage 86.0 (TID 125)
23/10/22 22:17:06.659 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:06.662 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:55185 in memory (size: 36.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:06.665 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:55185 in memory (size: 37.3 KiB, free: 1037.1 MiB)
23/10/22 22:17:06.669 Executor task launch worker for task 0.0 in stage 86.0 (TID 125) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.771 Executor task launch worker for task 0.0 in stage 86.0 (TID 125) INFO Executor: Finished task 0.0 in stage 86.0 (TID 125). 2147 bytes result sent to driver
23/10/22 22:17:07.772 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 125) in 1651 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:07.772 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
23/10/22 22:17:07.772 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 86 (rdd at LinearRegression.scala:921) finished in 1.656 s
23/10/22 22:17:07.772 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:07.772 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:07.773 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:07.773 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:07.778 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:07.780 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 184 (rdd at LinearRegression.scala:921) as input to shuffle 27
23/10/22 22:17:07.780 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 49 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:17:07.781 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 88 (rdd at LinearRegression.scala:921)
23/10/22 22:17:07.781 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
23/10/22 22:17:07.781 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:07.781 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[184] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:07.783 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:07.784 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:07.784 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:07.785 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:07.785 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[184] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:07.785 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 88.0 with 8 tasks resource profile 0
23/10/22 22:17:07.787 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 126) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.787 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 127) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.787 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 128) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.788 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 88.0 (TID 129) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.788 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 88.0 (TID 130) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.788 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 88.0 (TID 131) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.788 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 88.0 (TID 132) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.788 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 88.0 (TID 133) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:07.788 Executor task launch worker for task 1.0 in stage 88.0 (TID 127) INFO Executor: Running task 1.0 in stage 88.0 (TID 127)
23/10/22 22:17:07.788 Executor task launch worker for task 2.0 in stage 88.0 (TID 128) INFO Executor: Running task 2.0 in stage 88.0 (TID 128)
23/10/22 22:17:07.789 Executor task launch worker for task 5.0 in stage 88.0 (TID 131) INFO Executor: Running task 5.0 in stage 88.0 (TID 131)
23/10/22 22:17:07.789 Executor task launch worker for task 6.0 in stage 88.0 (TID 132) INFO Executor: Running task 6.0 in stage 88.0 (TID 132)
23/10/22 22:17:07.788 Executor task launch worker for task 0.0 in stage 88.0 (TID 126) INFO Executor: Running task 0.0 in stage 88.0 (TID 126)
23/10/22 22:17:07.789 Executor task launch worker for task 7.0 in stage 88.0 (TID 133) INFO Executor: Running task 7.0 in stage 88.0 (TID 133)
23/10/22 22:17:07.792 Executor task launch worker for task 6.0 in stage 88.0 (TID 132) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.792 Executor task launch worker for task 1.0 in stage 88.0 (TID 127) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.793 Executor task launch worker for task 7.0 in stage 88.0 (TID 133) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.793 Executor task launch worker for task 4.0 in stage 88.0 (TID 130) INFO Executor: Running task 4.0 in stage 88.0 (TID 130)
23/10/22 22:17:07.793 Executor task launch worker for task 7.0 in stage 88.0 (TID 133) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:07.793 Executor task launch worker for task 0.0 in stage 88.0 (TID 126) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.793 Executor task launch worker for task 0.0 in stage 88.0 (TID 126) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:07.793 Executor task launch worker for task 1.0 in stage 88.0 (TID 127) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:07.793 Executor task launch worker for task 6.0 in stage 88.0 (TID 132) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:07.796 Executor task launch worker for task 4.0 in stage 88.0 (TID 130) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.796 Executor task launch worker for task 2.0 in stage 88.0 (TID 128) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.797 Executor task launch worker for task 2.0 in stage 88.0 (TID 128) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:07.797 Executor task launch worker for task 4.0 in stage 88.0 (TID 130) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:07.799 Executor task launch worker for task 3.0 in stage 88.0 (TID 129) INFO Executor: Running task 3.0 in stage 88.0 (TID 129)
23/10/22 22:17:07.805 Executor task launch worker for task 7.0 in stage 88.0 (TID 133) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.805 Executor task launch worker for task 2.0 in stage 88.0 (TID 128) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.806 Executor task launch worker for task 4.0 in stage 88.0 (TID 130) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.806 Executor task launch worker for task 3.0 in stage 88.0 (TID 129) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.806 Executor task launch worker for task 3.0 in stage 88.0 (TID 129) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:07.807 Executor task launch worker for task 5.0 in stage 88.0 (TID 131) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:07.807 Executor task launch worker for task 5.0 in stage 88.0 (TID 131) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:07.818 Executor task launch worker for task 6.0 in stage 88.0 (TID 132) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.825 Executor task launch worker for task 5.0 in stage 88.0 (TID 131) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.828 Executor task launch worker for task 3.0 in stage 88.0 (TID 129) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.829 Executor task launch worker for task 1.0 in stage 88.0 (TID 127) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.830 Executor task launch worker for task 7.0 in stage 88.0 (TID 133) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.847 Executor task launch worker for task 2.0 in stage 88.0 (TID 128) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.848 Executor task launch worker for task 4.0 in stage 88.0 (TID 130) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.848 Executor task launch worker for task 6.0 in stage 88.0 (TID 132) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.853 Executor task launch worker for task 1.0 in stage 88.0 (TID 127) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.891 Executor task launch worker for task 0.0 in stage 88.0 (TID 126) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.906 Executor task launch worker for task 5.0 in stage 88.0 (TID 131) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.978 Executor task launch worker for task 3.0 in stage 88.0 (TID 129) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:07.982 Executor task launch worker for task 0.0 in stage 88.0 (TID 126) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.054 Executor task launch worker for task 4.0 in stage 88.0 (TID 130) INFO Executor: Finished task 4.0 in stage 88.0 (TID 130). 4899 bytes result sent to driver
23/10/22 22:17:08.056 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 88.0 (TID 130) in 268 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:08.081 Executor task launch worker for task 7.0 in stage 88.0 (TID 133) INFO Executor: Finished task 7.0 in stage 88.0 (TID 133). 4899 bytes result sent to driver
23/10/22 22:17:08.089 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 88.0 (TID 133) in 301 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:08.127 Executor task launch worker for task 2.0 in stage 88.0 (TID 128) INFO Executor: Finished task 2.0 in stage 88.0 (TID 128). 4899 bytes result sent to driver
23/10/22 22:17:08.128 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 128) in 341 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:08.134 Executor task launch worker for task 6.0 in stage 88.0 (TID 132) INFO Executor: Finished task 6.0 in stage 88.0 (TID 132). 4899 bytes result sent to driver
23/10/22 22:17:08.136 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 88.0 (TID 132) in 348 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:08.144 Executor task launch worker for task 1.0 in stage 88.0 (TID 127) INFO Executor: Finished task 1.0 in stage 88.0 (TID 127). 4899 bytes result sent to driver
23/10/22 22:17:08.147 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 127) in 360 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:08.155 Executor task launch worker for task 5.0 in stage 88.0 (TID 131) INFO Executor: Finished task 5.0 in stage 88.0 (TID 131). 4942 bytes result sent to driver
23/10/22 22:17:08.157 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 88.0 (TID 131) in 369 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:08.192 Executor task launch worker for task 0.0 in stage 88.0 (TID 126) INFO Executor: Finished task 0.0 in stage 88.0 (TID 126). 4899 bytes result sent to driver
23/10/22 22:17:08.193 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 126) in 406 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:08.214 Executor task launch worker for task 3.0 in stage 88.0 (TID 129) INFO Executor: Finished task 3.0 in stage 88.0 (TID 129). 4899 bytes result sent to driver
23/10/22 22:17:08.215 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 88.0 (TID 129) in 428 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:08.215 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
23/10/22 22:17:08.216 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 88 (rdd at LinearRegression.scala:921) finished in 0.434 s
23/10/22 22:17:08.216 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:08.216 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:08.216 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:08.216 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:08.223 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:08.245 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.6804 ms
23/10/22 22:17:08.286 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:17:08.287 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 194 (treeAggregate at Statistics.scala:58) as input to shuffle 28
23/10/22 22:17:08.288 dag-scheduler-event-loop INFO DAGScheduler: Got job 50 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:17:08.288 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 92 (treeAggregate at Statistics.scala:58)
23/10/22 22:17:08.288 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
23/10/22 22:17:08.288 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
23/10/22 22:17:08.288 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[194] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:08.293 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 83.1 KiB, free 1037.0 MiB)
23/10/22 22:17:08.294 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1036.9 MiB)
23/10/22 22:17:08.295 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:55185 (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 22:17:08.295 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:08.297 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[194] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:08.297 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 91.0 with 8 tasks resource profile 0
23/10/22 22:17:08.298 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 134) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.298 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 135) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.299 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 136) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.299 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 137) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.299 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 138) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.299 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 139) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.299 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 140) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.299 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 141) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:08.301 Executor task launch worker for task 0.0 in stage 91.0 (TID 134) INFO Executor: Running task 0.0 in stage 91.0 (TID 134)
23/10/22 22:17:08.301 Executor task launch worker for task 1.0 in stage 91.0 (TID 135) INFO Executor: Running task 1.0 in stage 91.0 (TID 135)
23/10/22 22:17:08.301 Executor task launch worker for task 3.0 in stage 91.0 (TID 137) INFO Executor: Running task 3.0 in stage 91.0 (TID 137)
23/10/22 22:17:08.301 Executor task launch worker for task 4.0 in stage 91.0 (TID 138) INFO Executor: Running task 4.0 in stage 91.0 (TID 138)
23/10/22 22:17:08.301 Executor task launch worker for task 7.0 in stage 91.0 (TID 141) INFO Executor: Running task 7.0 in stage 91.0 (TID 141)
23/10/22 22:17:08.301 Executor task launch worker for task 2.0 in stage 91.0 (TID 136) INFO Executor: Running task 2.0 in stage 91.0 (TID 136)
23/10/22 22:17:08.301 Executor task launch worker for task 6.0 in stage 91.0 (TID 140) INFO Executor: Running task 6.0 in stage 91.0 (TID 140)
23/10/22 22:17:08.301 Executor task launch worker for task 5.0 in stage 91.0 (TID 139) INFO Executor: Running task 5.0 in stage 91.0 (TID 139)
23/10/22 22:17:08.310 Executor task launch worker for task 7.0 in stage 91.0 (TID 141) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.310 Executor task launch worker for task 7.0 in stage 91.0 (TID 141) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.312 Executor task launch worker for task 2.0 in stage 91.0 (TID 136) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.312 Executor task launch worker for task 2.0 in stage 91.0 (TID 136) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.313 Executor task launch worker for task 5.0 in stage 91.0 (TID 139) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.313 Executor task launch worker for task 5.0 in stage 91.0 (TID 139) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.317 Executor task launch worker for task 3.0 in stage 91.0 (TID 137) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.317 Executor task launch worker for task 3.0 in stage 91.0 (TID 137) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.317 Executor task launch worker for task 6.0 in stage 91.0 (TID 140) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.319 Executor task launch worker for task 6.0 in stage 91.0 (TID 140) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:08.323 Executor task launch worker for task 4.0 in stage 91.0 (TID 138) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.323 Executor task launch worker for task 4.0 in stage 91.0 (TID 138) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.317 Executor task launch worker for task 1.0 in stage 91.0 (TID 135) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.325 Executor task launch worker for task 1.0 in stage 91.0 (TID 135) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
23/10/22 22:17:08.329 Executor task launch worker for task 0.0 in stage 91.0 (TID 134) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.329 Executor task launch worker for task 0.0 in stage 91.0 (TID 134) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.338 Executor task launch worker for task 2.0 in stage 91.0 (TID 136) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.340 Executor task launch worker for task 5.0 in stage 91.0 (TID 139) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.344 Executor task launch worker for task 6.0 in stage 91.0 (TID 140) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.360 Executor task launch worker for task 4.0 in stage 91.0 (TID 138) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.365 Executor task launch worker for task 1.0 in stage 91.0 (TID 135) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.368 Executor task launch worker for task 0.0 in stage 91.0 (TID 134) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.386 Executor task launch worker for task 3.0 in stage 91.0 (TID 137) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.440 Executor task launch worker for task 5.0 in stage 91.0 (TID 139) INFO Executor: Finished task 5.0 in stage 91.0 (TID 139). 6605 bytes result sent to driver
23/10/22 22:17:08.441 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 139) in 142 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:08.466 Executor task launch worker for task 2.0 in stage 91.0 (TID 136) INFO Executor: Finished task 2.0 in stage 91.0 (TID 136). 6562 bytes result sent to driver
23/10/22 22:17:08.468 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 136) in 170 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:08.476 Executor task launch worker for task 6.0 in stage 91.0 (TID 140) INFO Executor: Finished task 6.0 in stage 91.0 (TID 140). 6605 bytes result sent to driver
23/10/22 22:17:08.477 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 140) in 178 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:08.492 Executor task launch worker for task 1.0 in stage 91.0 (TID 135) INFO Executor: Finished task 1.0 in stage 91.0 (TID 135). 6562 bytes result sent to driver
23/10/22 22:17:08.494 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 135) in 196 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:08.506 Executor task launch worker for task 3.0 in stage 91.0 (TID 137) INFO Executor: Finished task 3.0 in stage 91.0 (TID 137). 6605 bytes result sent to driver
23/10/22 22:17:08.507 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 137) in 208 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:08.512 Executor task launch worker for task 0.0 in stage 91.0 (TID 134) INFO Executor: Finished task 0.0 in stage 91.0 (TID 134). 6605 bytes result sent to driver
23/10/22 22:17:08.513 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 134) in 216 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:08.517 Executor task launch worker for task 7.0 in stage 91.0 (TID 141) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:08.539 Executor task launch worker for task 4.0 in stage 91.0 (TID 138) INFO Executor: Finished task 4.0 in stage 91.0 (TID 138). 6605 bytes result sent to driver
23/10/22 22:17:08.540 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 138) in 241 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:08.578 Executor task launch worker for task 7.0 in stage 91.0 (TID 141) INFO Executor: Finished task 7.0 in stage 91.0 (TID 141). 6562 bytes result sent to driver
23/10/22 22:17:08.578 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 141) in 279 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:08.578 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
23/10/22 22:17:08.579 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 91 (treeAggregate at Statistics.scala:58) finished in 0.289 s
23/10/22 22:17:08.579 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:08.579 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:08.579 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 92)
23/10/22 22:17:08.579 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:08.580 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[196] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:08.586 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 84.2 KiB, free 1036.8 MiB)
23/10/22 22:17:08.589 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 1036.8 MiB)
23/10/22 22:17:08.589 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:55185 (size: 35.9 KiB, free: 1037.0 MiB)
23/10/22 22:17:08.590 dag-scheduler-event-loop INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:08.590 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 92 (MapPartitionsRDD[196] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:08.590 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 92.0 with 2 tasks resource profile 0
23/10/22 22:17:08.591 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 142) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:08.592 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 143) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:08.593 Executor task launch worker for task 0.0 in stage 92.0 (TID 142) INFO Executor: Running task 0.0 in stage 92.0 (TID 142)
23/10/22 22:17:08.593 Executor task launch worker for task 1.0 in stage 92.0 (TID 143) INFO Executor: Running task 1.0 in stage 92.0 (TID 143)
23/10/22 22:17:08.601 Executor task launch worker for task 1.0 in stage 92.0 (TID 143) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.601 Executor task launch worker for task 0.0 in stage 92.0 (TID 142) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:08.602 Executor task launch worker for task 0.0 in stage 92.0 (TID 142) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.602 Executor task launch worker for task 1.0 in stage 92.0 (TID 143) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:08.612 Executor task launch worker for task 1.0 in stage 92.0 (TID 143) INFO Executor: Finished task 1.0 in stage 92.0 (TID 143). 7630 bytes result sent to driver
23/10/22 22:17:08.612 Executor task launch worker for task 0.0 in stage 92.0 (TID 142) INFO Executor: Finished task 0.0 in stage 92.0 (TID 142). 7630 bytes result sent to driver
23/10/22 22:17:08.613 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 143) in 21 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:08.614 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 142) in 23 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:08.614 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
23/10/22 22:17:08.615 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 92 (treeAggregate at Statistics.scala:58) finished in 0.034 s
23/10/22 22:17:08.615 dag-scheduler-event-loop INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:08.615 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
23/10/22 22:17:08.616 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 50 finished: treeAggregate at Statistics.scala:58, took 0.329340 s
23/10/22 22:17:08.618 nioEventLoopGroup-2-2 INFO Instrumentation: [a0380339] training finished
23/10/22 22:17:09.343 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:09.344 dag-scheduler-event-loop INFO DAGScheduler: Got job 51 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:09.344 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:26)
23/10/22 22:17:09.344 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:09.344 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:09.345 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[198] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:09.346 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:09.348 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:09.348 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:09.348 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:09.348 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[198] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:09.348 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
23/10/22 22:17:09.349 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 144) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:09.350 Executor task launch worker for task 0.0 in stage 93.0 (TID 144) INFO Executor: Running task 0.0 in stage 93.0 (TID 144)
23/10/22 22:17:09.353 Executor task launch worker for task 0.0 in stage 93.0 (TID 144) INFO Executor: Finished task 0.0 in stage 93.0 (TID 144). 1327 bytes result sent to driver
23/10/22 22:17:09.353 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 144) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:09.354 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
23/10/22 22:17:09.354 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 93 (collect at utils.scala:26) finished in 0.009 s
23/10/22 22:17:09.354 dag-scheduler-event-loop INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:09.354 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
23/10/22 22:17:09.354 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 51 finished: collect at utils.scala:26, took 0.009899 s
23/10/22 22:17:09.596 nioEventLoopGroup-2-2 INFO Instrumentation: [89afdccf] training finished
23/10/22 22:17:09.687 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:09.688 dag-scheduler-event-loop INFO DAGScheduler: Got job 52 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:09.688 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 94 (collect at utils.scala:26)
23/10/22 22:17:09.688 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:09.688 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:09.688 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[200] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:09.689 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:09.690 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:09.690 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:09.691 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:09.691 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[200] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:09.691 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
23/10/22 22:17:09.693 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 145) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:09.693 Executor task launch worker for task 0.0 in stage 94.0 (TID 145) INFO Executor: Running task 0.0 in stage 94.0 (TID 145)
23/10/22 22:17:09.695 Executor task launch worker for task 0.0 in stage 94.0 (TID 145) INFO Executor: Finished task 0.0 in stage 94.0 (TID 145). 1284 bytes result sent to driver
23/10/22 22:17:09.696 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 145) in 5 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:09.696 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
23/10/22 22:17:09.696 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 94 (collect at utils.scala:26) finished in 0.007 s
23/10/22 22:17:09.696 dag-scheduler-event-loop INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:09.696 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
23/10/22 22:17:09.696 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 52 finished: collect at utils.scala:26, took 0.008194 s
23/10/22 22:17:10.133 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:10.133 dag-scheduler-event-loop INFO DAGScheduler: Got job 53 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:10.133 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:26)
23/10/22 22:17:10.133 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:10.133 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:10.134 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[202] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:10.134 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:10.135 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:10.135 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:10.136 dag-scheduler-event-loop INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:10.136 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[202] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:10.136 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0
23/10/22 22:17:10.137 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 146) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:10.137 Executor task launch worker for task 0.0 in stage 95.0 (TID 146) INFO Executor: Running task 0.0 in stage 95.0 (TID 146)
23/10/22 22:17:10.139 Executor task launch worker for task 0.0 in stage 95.0 (TID 146) INFO Executor: Finished task 0.0 in stage 95.0 (TID 146). 1284 bytes result sent to driver
23/10/22 22:17:10.139 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 146) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:10.139 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
23/10/22 22:17:10.140 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 95 (collect at utils.scala:26) finished in 0.005 s
23/10/22 22:17:10.140 dag-scheduler-event-loop INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:10.140 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
23/10/22 22:17:10.140 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 53 finished: collect at utils.scala:26, took 0.006814 s
23/10/22 22:17:10.826 nioEventLoopGroup-2-2 INFO Instrumentation: [4d62a201] training finished
23/10/22 22:17:10.844 nioEventLoopGroup-2-2 INFO Instrumentation: [6a490503] training finished
23/10/22 22:17:10.852 nioEventLoopGroup-2-2 INFO Instrumentation: [ab7b824a] Stage class: LinearRegression
23/10/22 22:17:10.852 nioEventLoopGroup-2-2 INFO Instrumentation: [ab7b824a] Stage uid: linear_regression__541147d5_d65e_42f5_ba3a_f0c5b4ea1169
23/10/22 22:17:10.891 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 205 (rdd at Instrumentation.scala:62) as input to shuffle 29
23/10/22 22:17:10.891 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 54 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:17:10.891 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 96 (rdd at Instrumentation.scala:62)
23/10/22 22:17:10.891 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:10.891 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:10.891 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[205] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:10.893 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 32.7 KiB, free 1036.7 MiB)
23/10/22 22:17:10.893 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 22:17:10.894 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:10.894 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:10.894 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[205] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:10.894 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
23/10/22 22:17:10.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 22:17:10.995 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:10.999 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:11.001 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:55185 in memory (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 22:17:11.003 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:11.005 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:55185 in memory (size: 35.9 KiB, free: 1037.1 MiB)
23/10/22 22:17:11.150 dispatcher-event-loop-7 WARN TaskSetManager: Stage 96 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:11.150 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 147) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:11.150 Executor task launch worker for task 0.0 in stage 96.0 (TID 147) INFO Executor: Running task 0.0 in stage 96.0 (TID 147)
23/10/22 22:17:11.323 Executor task launch worker for task 0.0 in stage 96.0 (TID 147) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:11.442 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:12.368 Executor task launch worker for task 0.0 in stage 96.0 (TID 147) INFO Executor: Finished task 0.0 in stage 96.0 (TID 147). 2104 bytes result sent to driver
23/10/22 22:17:12.369 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 147) in 1474 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:12.369 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
23/10/22 22:17:12.369 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 96 (rdd at Instrumentation.scala:62) finished in 1.477 s
23/10/22 22:17:12.369 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:12.370 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:12.370 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:12.370 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:12.377 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(29), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:12.381 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 209 (rdd at Instrumentation.scala:62) as input to shuffle 30
23/10/22 22:17:12.381 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 55 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:17:12.381 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 98 (rdd at Instrumentation.scala:62)
23/10/22 22:17:12.381 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
23/10/22 22:17:12.381 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:12.381 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[209] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:12.384 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:12.385 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:12.385 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:12.385 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:12.386 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[209] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:12.386 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 98.0 with 8 tasks resource profile 0
23/10/22 22:17:12.387 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 148) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.387 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 149) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.388 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 150) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.388 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 151) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.388 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 98.0 (TID 152) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.388 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 98.0 (TID 153) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.388 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 98.0 (TID 154) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.389 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 98.0 (TID 155) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:12.389 Executor task launch worker for task 0.0 in stage 98.0 (TID 148) INFO Executor: Running task 0.0 in stage 98.0 (TID 148)
23/10/22 22:17:12.389 Executor task launch worker for task 5.0 in stage 98.0 (TID 153) INFO Executor: Running task 5.0 in stage 98.0 (TID 153)
23/10/22 22:17:12.389 Executor task launch worker for task 6.0 in stage 98.0 (TID 154) INFO Executor: Running task 6.0 in stage 98.0 (TID 154)
23/10/22 22:17:12.389 Executor task launch worker for task 1.0 in stage 98.0 (TID 149) INFO Executor: Running task 1.0 in stage 98.0 (TID 149)
23/10/22 22:17:12.389 Executor task launch worker for task 4.0 in stage 98.0 (TID 152) INFO Executor: Running task 4.0 in stage 98.0 (TID 152)
23/10/22 22:17:12.389 Executor task launch worker for task 7.0 in stage 98.0 (TID 155) INFO Executor: Running task 7.0 in stage 98.0 (TID 155)
23/10/22 22:17:12.389 Executor task launch worker for task 3.0 in stage 98.0 (TID 151) INFO Executor: Running task 3.0 in stage 98.0 (TID 151)
23/10/22 22:17:12.389 Executor task launch worker for task 2.0 in stage 98.0 (TID 150) INFO Executor: Running task 2.0 in stage 98.0 (TID 150)
23/10/22 22:17:12.393 Executor task launch worker for task 5.0 in stage 98.0 (TID 153) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.393 Executor task launch worker for task 4.0 in stage 98.0 (TID 152) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.393 Executor task launch worker for task 6.0 in stage 98.0 (TID 154) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.393 Executor task launch worker for task 3.0 in stage 98.0 (TID 151) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.393 Executor task launch worker for task 5.0 in stage 98.0 (TID 153) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.393 Executor task launch worker for task 6.0 in stage 98.0 (TID 154) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.393 Executor task launch worker for task 4.0 in stage 98.0 (TID 152) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.393 Executor task launch worker for task 2.0 in stage 98.0 (TID 150) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.393 Executor task launch worker for task 7.0 in stage 98.0 (TID 155) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.394 Executor task launch worker for task 2.0 in stage 98.0 (TID 150) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.393 Executor task launch worker for task 3.0 in stage 98.0 (TID 151) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.394 Executor task launch worker for task 7.0 in stage 98.0 (TID 155) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.394 Executor task launch worker for task 1.0 in stage 98.0 (TID 149) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.394 Executor task launch worker for task 1.0 in stage 98.0 (TID 149) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.394 Executor task launch worker for task 0.0 in stage 98.0 (TID 148) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:12.395 Executor task launch worker for task 0.0 in stage 98.0 (TID 148) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:12.401 Executor task launch worker for task 5.0 in stage 98.0 (TID 153) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.401 Executor task launch worker for task 6.0 in stage 98.0 (TID 154) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.402 Executor task launch worker for task 1.0 in stage 98.0 (TID 149) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.402 Executor task launch worker for task 3.0 in stage 98.0 (TID 151) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.403 Executor task launch worker for task 4.0 in stage 98.0 (TID 152) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.408 Executor task launch worker for task 2.0 in stage 98.0 (TID 150) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.411 Executor task launch worker for task 7.0 in stage 98.0 (TID 155) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.423 Executor task launch worker for task 6.0 in stage 98.0 (TID 154) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.424 Executor task launch worker for task 5.0 in stage 98.0 (TID 153) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.431 Executor task launch worker for task 1.0 in stage 98.0 (TID 149) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.433 Executor task launch worker for task 7.0 in stage 98.0 (TID 155) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.440 Executor task launch worker for task 4.0 in stage 98.0 (TID 152) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.441 Executor task launch worker for task 0.0 in stage 98.0 (TID 148) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.480 Executor task launch worker for task 2.0 in stage 98.0 (TID 150) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.488 Executor task launch worker for task 3.0 in stage 98.0 (TID 151) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.492 Executor task launch worker for task 0.0 in stage 98.0 (TID 148) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:12.554 Executor task launch worker for task 7.0 in stage 98.0 (TID 155) INFO Executor: Finished task 7.0 in stage 98.0 (TID 155). 4942 bytes result sent to driver
23/10/22 22:17:12.557 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 98.0 (TID 155) in 169 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:12.575 Executor task launch worker for task 4.0 in stage 98.0 (TID 152) INFO Executor: Finished task 4.0 in stage 98.0 (TID 152). 4942 bytes result sent to driver
23/10/22 22:17:12.575 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 98.0 (TID 152) in 187 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:12.582 Executor task launch worker for task 1.0 in stage 98.0 (TID 149) INFO Executor: Finished task 1.0 in stage 98.0 (TID 149). 4942 bytes result sent to driver
23/10/22 22:17:12.582 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 149) in 195 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:12.596 Executor task launch worker for task 2.0 in stage 98.0 (TID 150) INFO Executor: Finished task 2.0 in stage 98.0 (TID 150). 4942 bytes result sent to driver
23/10/22 22:17:12.597 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 150) in 210 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:12.605 Executor task launch worker for task 3.0 in stage 98.0 (TID 151) INFO Executor: Finished task 3.0 in stage 98.0 (TID 151). 4942 bytes result sent to driver
23/10/22 22:17:12.606 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 151) in 218 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:12.609 Executor task launch worker for task 6.0 in stage 98.0 (TID 154) INFO Executor: Finished task 6.0 in stage 98.0 (TID 154). 4942 bytes result sent to driver
23/10/22 22:17:12.610 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 98.0 (TID 154) in 222 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:12.614 Executor task launch worker for task 5.0 in stage 98.0 (TID 153) INFO Executor: Finished task 5.0 in stage 98.0 (TID 153). 4942 bytes result sent to driver
23/10/22 22:17:12.615 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 98.0 (TID 153) in 227 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:12.617 Executor task launch worker for task 0.0 in stage 98.0 (TID 148) INFO Executor: Finished task 0.0 in stage 98.0 (TID 148). 4942 bytes result sent to driver
23/10/22 22:17:12.618 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 148) in 231 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:12.618 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
23/10/22 22:17:12.618 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 98 (rdd at Instrumentation.scala:62) finished in 0.236 s
23/10/22 22:17:12.618 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:12.618 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:12.618 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:12.618 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:12.623 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:12.646 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.6414 ms
23/10/22 22:17:12.657 nioEventLoopGroup-2-2 INFO Instrumentation: [ab7b824a] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:17:12.658 nioEventLoopGroup-2-2 INFO Instrumentation: [ab7b824a] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:17:12.659 nioEventLoopGroup-2-2 INFO Instrumentation: [ab7b824a] {"numFeatures":2}
23/10/22 22:17:12.738 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 218 (rdd at LinearRegression.scala:348) as input to shuffle 31
23/10/22 22:17:12.739 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 56 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:17:12.739 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 99 (rdd at LinearRegression.scala:348)
23/10/22 22:17:12.739 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:12.739 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:12.739 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[218] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:12.741 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:17:12.745 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:12.747 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:12.748 dag-scheduler-event-loop INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:12.748 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[218] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:12.748 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
23/10/22 22:17:12.920 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:12.924 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:13.167 dispatcher-event-loop-0 WARN TaskSetManager: Stage 99 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:13.167 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 156) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:13.168 Executor task launch worker for task 0.0 in stage 99.0 (TID 156) INFO Executor: Running task 0.0 in stage 99.0 (TID 156)
23/10/22 22:17:13.305 Executor task launch worker for task 0.0 in stage 99.0 (TID 156) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.346 Executor task launch worker for task 0.0 in stage 99.0 (TID 156) INFO Executor: Finished task 0.0 in stage 99.0 (TID 156). 2104 bytes result sent to driver
23/10/22 22:17:14.347 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 156) in 1598 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:14.347 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
23/10/22 22:17:14.347 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 99 (rdd at LinearRegression.scala:348) finished in 1.608 s
23/10/22 22:17:14.347 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:14.347 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:14.347 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:14.347 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:14.352 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:14.354 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 222 (rdd at LinearRegression.scala:348) as input to shuffle 32
23/10/22 22:17:14.355 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 57 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:17:14.355 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 101 (rdd at LinearRegression.scala:348)
23/10/22 22:17:14.355 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
23/10/22 22:17:14.355 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:14.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[222] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:14.357 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:14.358 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 22:17:14.358 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:55185 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:14.358 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:14.359 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[222] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:14.359 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 101.0 with 8 tasks resource profile 0
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 157) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 158) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 159) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 160) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 101.0 (TID 161) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 101.0 (TID 162) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 101.0 (TID 163) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.360 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 101.0 (TID 164) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.361 Executor task launch worker for task 3.0 in stage 101.0 (TID 160) INFO Executor: Running task 3.0 in stage 101.0 (TID 160)
23/10/22 22:17:14.361 Executor task launch worker for task 1.0 in stage 101.0 (TID 158) INFO Executor: Running task 1.0 in stage 101.0 (TID 158)
23/10/22 22:17:14.361 Executor task launch worker for task 6.0 in stage 101.0 (TID 163) INFO Executor: Running task 6.0 in stage 101.0 (TID 163)
23/10/22 22:17:14.361 Executor task launch worker for task 4.0 in stage 101.0 (TID 161) INFO Executor: Running task 4.0 in stage 101.0 (TID 161)
23/10/22 22:17:14.361 Executor task launch worker for task 7.0 in stage 101.0 (TID 164) INFO Executor: Running task 7.0 in stage 101.0 (TID 164)
23/10/22 22:17:14.361 Executor task launch worker for task 5.0 in stage 101.0 (TID 162) INFO Executor: Running task 5.0 in stage 101.0 (TID 162)
23/10/22 22:17:14.361 Executor task launch worker for task 0.0 in stage 101.0 (TID 157) INFO Executor: Running task 0.0 in stage 101.0 (TID 157)
23/10/22 22:17:14.361 Executor task launch worker for task 2.0 in stage 101.0 (TID 159) INFO Executor: Running task 2.0 in stage 101.0 (TID 159)
23/10/22 22:17:14.365 Executor task launch worker for task 1.0 in stage 101.0 (TID 158) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.365 Executor task launch worker for task 5.0 in stage 101.0 (TID 162) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.365 Executor task launch worker for task 2.0 in stage 101.0 (TID 159) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.365 Executor task launch worker for task 2.0 in stage 101.0 (TID 159) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.365 Executor task launch worker for task 1.0 in stage 101.0 (TID 158) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.365 Executor task launch worker for task 5.0 in stage 101.0 (TID 162) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.365 Executor task launch worker for task 7.0 in stage 101.0 (TID 164) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.365 Executor task launch worker for task 7.0 in stage 101.0 (TID 164) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.367 Executor task launch worker for task 6.0 in stage 101.0 (TID 163) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.367 Executor task launch worker for task 6.0 in stage 101.0 (TID 163) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.367 Executor task launch worker for task 4.0 in stage 101.0 (TID 161) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.367 Executor task launch worker for task 4.0 in stage 101.0 (TID 161) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.368 Executor task launch worker for task 3.0 in stage 101.0 (TID 160) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.368 Executor task launch worker for task 0.0 in stage 101.0 (TID 157) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.368 Executor task launch worker for task 3.0 in stage 101.0 (TID 160) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.368 Executor task launch worker for task 0.0 in stage 101.0 (TID 157) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.374 Executor task launch worker for task 1.0 in stage 101.0 (TID 158) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.374 Executor task launch worker for task 2.0 in stage 101.0 (TID 159) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.375 Executor task launch worker for task 6.0 in stage 101.0 (TID 163) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.375 Executor task launch worker for task 4.0 in stage 101.0 (TID 161) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.378 Executor task launch worker for task 5.0 in stage 101.0 (TID 162) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.378 Executor task launch worker for task 3.0 in stage 101.0 (TID 160) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.397 Executor task launch worker for task 1.0 in stage 101.0 (TID 158) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.397 Executor task launch worker for task 4.0 in stage 101.0 (TID 161) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.401 Executor task launch worker for task 2.0 in stage 101.0 (TID 159) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.404 Executor task launch worker for task 6.0 in stage 101.0 (TID 163) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.405 Executor task launch worker for task 5.0 in stage 101.0 (TID 162) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.423 Executor task launch worker for task 0.0 in stage 101.0 (TID 157) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.430 Executor task launch worker for task 7.0 in stage 101.0 (TID 164) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.438 Executor task launch worker for task 3.0 in stage 101.0 (TID 160) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.456 Executor task launch worker for task 0.0 in stage 101.0 (TID 157) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.469 Executor task launch worker for task 7.0 in stage 101.0 (TID 164) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.550 Executor task launch worker for task 4.0 in stage 101.0 (TID 161) INFO Executor: Finished task 4.0 in stage 101.0 (TID 161). 4899 bytes result sent to driver
23/10/22 22:17:14.557 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 101.0 (TID 161) in 197 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:14.601 Executor task launch worker for task 1.0 in stage 101.0 (TID 158) INFO Executor: Finished task 1.0 in stage 101.0 (TID 158). 4942 bytes result sent to driver
23/10/22 22:17:14.604 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 158) in 243 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:14.610 Executor task launch worker for task 3.0 in stage 101.0 (TID 160) INFO Executor: Finished task 3.0 in stage 101.0 (TID 160). 4899 bytes result sent to driver
23/10/22 22:17:14.612 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 160) in 251 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:14.615 Executor task launch worker for task 7.0 in stage 101.0 (TID 164) INFO Executor: Finished task 7.0 in stage 101.0 (TID 164). 4942 bytes result sent to driver
23/10/22 22:17:14.616 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 101.0 (TID 164) in 256 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:14.629 Executor task launch worker for task 5.0 in stage 101.0 (TID 162) INFO Executor: Finished task 5.0 in stage 101.0 (TID 162). 4942 bytes result sent to driver
23/10/22 22:17:14.630 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 101.0 (TID 162) in 270 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:14.634 Executor task launch worker for task 2.0 in stage 101.0 (TID 159) INFO Executor: Finished task 2.0 in stage 101.0 (TID 159). 4942 bytes result sent to driver
23/10/22 22:17:14.635 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 159) in 275 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:14.638 Executor task launch worker for task 0.0 in stage 101.0 (TID 157) INFO Executor: Finished task 0.0 in stage 101.0 (TID 157). 4899 bytes result sent to driver
23/10/22 22:17:14.638 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 157) in 279 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:14.642 Executor task launch worker for task 6.0 in stage 101.0 (TID 163) INFO Executor: Finished task 6.0 in stage 101.0 (TID 163). 4899 bytes result sent to driver
23/10/22 22:17:14.642 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 101.0 (TID 163) in 282 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:14.643 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
23/10/22 22:17:14.643 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 101 (rdd at LinearRegression.scala:348) finished in 0.288 s
23/10/22 22:17:14.643 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:14.643 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:14.643 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:14.643 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:14.652 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:14.691 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 29.0466 ms
23/10/22 22:17:14.707 nioEventLoopGroup-2-2 WARN Instrumentation: [ab7b824a] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:17:14.731 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:17:14.732 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 231 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 33
23/10/22 22:17:14.732 dag-scheduler-event-loop INFO DAGScheduler: Got job 58 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:17:14.732 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 105 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:17:14.732 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
23/10/22 22:17:14.732 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
23/10/22 22:17:14.733 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[231] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:14.737 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 93.3 KiB, free 1037.0 MiB)
23/10/22 22:17:14.738 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1036.9 MiB)
23/10/22 22:17:14.738 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:55185 (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:17:14.739 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:14.739 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[231] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:14.739 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 104.0 with 8 tasks resource profile 0
23/10/22 22:17:14.740 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 165) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.740 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 166) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.740 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 167) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.741 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 168) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.741 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 169) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.741 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 170) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.741 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 171) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.741 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 172) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:14.742 Executor task launch worker for task 1.0 in stage 104.0 (TID 166) INFO Executor: Running task 1.0 in stage 104.0 (TID 166)
23/10/22 22:17:14.742 Executor task launch worker for task 5.0 in stage 104.0 (TID 170) INFO Executor: Running task 5.0 in stage 104.0 (TID 170)
23/10/22 22:17:14.742 Executor task launch worker for task 3.0 in stage 104.0 (TID 168) INFO Executor: Running task 3.0 in stage 104.0 (TID 168)
23/10/22 22:17:14.742 Executor task launch worker for task 0.0 in stage 104.0 (TID 165) INFO Executor: Running task 0.0 in stage 104.0 (TID 165)
23/10/22 22:17:14.742 Executor task launch worker for task 2.0 in stage 104.0 (TID 167) INFO Executor: Running task 2.0 in stage 104.0 (TID 167)
23/10/22 22:17:14.742 Executor task launch worker for task 6.0 in stage 104.0 (TID 171) INFO Executor: Running task 6.0 in stage 104.0 (TID 171)
23/10/22 22:17:14.742 Executor task launch worker for task 7.0 in stage 104.0 (TID 172) INFO Executor: Running task 7.0 in stage 104.0 (TID 172)
23/10/22 22:17:14.742 Executor task launch worker for task 4.0 in stage 104.0 (TID 169) INFO Executor: Running task 4.0 in stage 104.0 (TID 169)
23/10/22 22:17:14.751 Executor task launch worker for task 6.0 in stage 104.0 (TID 171) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.752 Executor task launch worker for task 6.0 in stage 104.0 (TID 171) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:14.752 Executor task launch worker for task 3.0 in stage 104.0 (TID 168) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.752 Executor task launch worker for task 2.0 in stage 104.0 (TID 167) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.752 Executor task launch worker for task 3.0 in stage 104.0 (TID 168) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.752 Executor task launch worker for task 2.0 in stage 104.0 (TID 167) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.755 Executor task launch worker for task 4.0 in stage 104.0 (TID 169) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.755 Executor task launch worker for task 4.0 in stage 104.0 (TID 169) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.756 Executor task launch worker for task 1.0 in stage 104.0 (TID 166) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.756 Executor task launch worker for task 1.0 in stage 104.0 (TID 166) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.759 Executor task launch worker for task 5.0 in stage 104.0 (TID 170) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.759 Executor task launch worker for task 5.0 in stage 104.0 (TID 170) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.761 Executor task launch worker for task 7.0 in stage 104.0 (TID 172) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.761 Executor task launch worker for task 7.0 in stage 104.0 (TID 172) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.761 Executor task launch worker for task 0.0 in stage 104.0 (TID 165) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.761 Executor task launch worker for task 0.0 in stage 104.0 (TID 165) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.773 Executor task launch worker for task 6.0 in stage 104.0 (TID 171) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.775 Executor task launch worker for task 2.0 in stage 104.0 (TID 167) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.779 Executor task launch worker for task 3.0 in stage 104.0 (TID 168) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.780 Executor task launch worker for task 4.0 in stage 104.0 (TID 169) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.787 Executor task launch worker for task 1.0 in stage 104.0 (TID 166) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.797 Executor task launch worker for task 5.0 in stage 104.0 (TID 170) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.802 Executor task launch worker for task 0.0 in stage 104.0 (TID 165) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.809 Executor task launch worker for task 7.0 in stage 104.0 (TID 172) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:14.833 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:55185 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:14.885 Executor task launch worker for task 3.0 in stage 104.0 (TID 168) INFO Executor: Finished task 3.0 in stage 104.0 (TID 168). 6648 bytes result sent to driver
23/10/22 22:17:14.899 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 168) in 159 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:14.902 Executor task launch worker for task 2.0 in stage 104.0 (TID 167) INFO Executor: Finished task 2.0 in stage 104.0 (TID 167). 6605 bytes result sent to driver
23/10/22 22:17:14.903 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 167) in 163 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:14.906 Executor task launch worker for task 1.0 in stage 104.0 (TID 166) INFO Executor: Finished task 1.0 in stage 104.0 (TID 166). 6648 bytes result sent to driver
23/10/22 22:17:14.911 Executor task launch worker for task 4.0 in stage 104.0 (TID 169) INFO Executor: Finished task 4.0 in stage 104.0 (TID 169). 6648 bytes result sent to driver
23/10/22 22:17:14.923 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 169) in 182 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:14.927 Executor task launch worker for task 6.0 in stage 104.0 (TID 171) INFO Executor: Finished task 6.0 in stage 104.0 (TID 171). 6605 bytes result sent to driver
23/10/22 22:17:14.932 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 166) in 192 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:14.938 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 171) in 196 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:14.939 Executor task launch worker for task 5.0 in stage 104.0 (TID 170) INFO Executor: Finished task 5.0 in stage 104.0 (TID 170). 6605 bytes result sent to driver
23/10/22 22:17:14.940 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 170) in 199 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:14.947 Executor task launch worker for task 0.0 in stage 104.0 (TID 165) INFO Executor: Finished task 0.0 in stage 104.0 (TID 165). 6605 bytes result sent to driver
23/10/22 22:17:14.947 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 165) in 207 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:14.969 Executor task launch worker for task 7.0 in stage 104.0 (TID 172) INFO Executor: Finished task 7.0 in stage 104.0 (TID 172). 6605 bytes result sent to driver
23/10/22 22:17:14.972 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 172) in 231 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:14.972 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
23/10/22 22:17:14.973 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 104 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.239 s
23/10/22 22:17:14.973 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:14.973 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:14.973 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 105)
23/10/22 22:17:14.973 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:14.974 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[233] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:14.979 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 94.4 KiB, free 1036.9 MiB)
23/10/22 22:17:14.981 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 22:17:14.981 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:55185 (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:14.983 dag-scheduler-event-loop INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:14.983 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 105 (MapPartitionsRDD[233] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:14.983 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 105.0 with 2 tasks resource profile 0
23/10/22 22:17:14.985 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 173) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:14.985 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 174) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:14.986 Executor task launch worker for task 0.0 in stage 105.0 (TID 173) INFO Executor: Running task 0.0 in stage 105.0 (TID 173)
23/10/22 22:17:14.986 Executor task launch worker for task 1.0 in stage 105.0 (TID 174) INFO Executor: Running task 1.0 in stage 105.0 (TID 174)
23/10/22 22:17:14.995 Executor task launch worker for task 1.0 in stage 105.0 (TID 174) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.995 Executor task launch worker for task 0.0 in stage 105.0 (TID 173) INFO ShuffleBlockFetcherIterator: Getting 4 (2.0 KiB) non-empty blocks including 4 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:14.995 Executor task launch worker for task 1.0 in stage 105.0 (TID 174) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:14.995 Executor task launch worker for task 0.0 in stage 105.0 (TID 173) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:15.005 Executor task launch worker for task 1.0 in stage 105.0 (TID 174) INFO Executor: Finished task 1.0 in stage 105.0 (TID 174). 6774 bytes result sent to driver
23/10/22 22:17:15.005 Executor task launch worker for task 0.0 in stage 105.0 (TID 173) INFO Executor: Finished task 0.0 in stage 105.0 (TID 173). 6774 bytes result sent to driver
23/10/22 22:17:15.006 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 174) in 21 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:15.006 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 173) in 21 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:15.006 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
23/10/22 22:17:15.007 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 105 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.032 s
23/10/22 22:17:15.007 dag-scheduler-event-loop INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:15.007 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
23/10/22 22:17:15.007 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 58 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.276186 s
23/10/22 22:17:15.008 nioEventLoopGroup-2-2 INFO Instrumentation: [ab7b824a] Number of instances: 3785.
23/10/22 22:17:15.098 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:15.121 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 236 (rdd at LinearRegression.scala:921) as input to shuffle 34
23/10/22 22:17:15.121 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 59 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:17:15.121 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 106 (rdd at LinearRegression.scala:921)
23/10/22 22:17:15.121 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:15.121 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:15.122 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[236] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:15.124 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 32.7 KiB, free 1036.9 MiB)
23/10/22 22:17:15.125 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:15.126 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:15.126 dag-scheduler-event-loop INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:15.127 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[236] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:15.127 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
23/10/22 22:17:15.440 dispatcher-event-loop-6 WARN TaskSetManager: Stage 106 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:15.440 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 175) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:15.440 Executor task launch worker for task 0.0 in stage 106.0 (TID 175) INFO Executor: Running task 0.0 in stage 106.0 (TID 175)
23/10/22 22:17:15.584 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:55185 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:15.616 Executor task launch worker for task 0.0 in stage 106.0 (TID 175) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.561 Executor task launch worker for task 0.0 in stage 106.0 (TID 175) INFO Executor: Finished task 0.0 in stage 106.0 (TID 175). 2147 bytes result sent to driver
23/10/22 22:17:16.562 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 175) in 1434 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:16.562 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
23/10/22 22:17:16.562 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 106 (rdd at LinearRegression.scala:921) finished in 1.440 s
23/10/22 22:17:16.562 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:16.562 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:16.562 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:16.562 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:16.567 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:16.570 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 240 (rdd at LinearRegression.scala:921) as input to shuffle 35
23/10/22 22:17:16.570 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 60 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:17:16.570 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 108 (rdd at LinearRegression.scala:921)
23/10/22 22:17:16.570 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
23/10/22 22:17:16.570 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:16.571 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[240] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:16.572 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 37.8 KiB, free 1036.9 MiB)
23/10/22 22:17:16.573 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1036.9 MiB)
23/10/22 22:17:16.574 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:16.574 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:16.574 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[240] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:16.574 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 108.0 with 8 tasks resource profile 0
23/10/22 22:17:16.575 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 176) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.575 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 177) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.575 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 178) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.576 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 179) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.576 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 108.0 (TID 180) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.576 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 108.0 (TID 181) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.576 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 108.0 (TID 182) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.576 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 108.0 (TID 183) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.577 Executor task launch worker for task 2.0 in stage 108.0 (TID 178) INFO Executor: Running task 2.0 in stage 108.0 (TID 178)
23/10/22 22:17:16.577 Executor task launch worker for task 4.0 in stage 108.0 (TID 180) INFO Executor: Running task 4.0 in stage 108.0 (TID 180)
23/10/22 22:17:16.577 Executor task launch worker for task 6.0 in stage 108.0 (TID 182) INFO Executor: Running task 6.0 in stage 108.0 (TID 182)
23/10/22 22:17:16.577 Executor task launch worker for task 5.0 in stage 108.0 (TID 181) INFO Executor: Running task 5.0 in stage 108.0 (TID 181)
23/10/22 22:17:16.577 Executor task launch worker for task 7.0 in stage 108.0 (TID 183) INFO Executor: Running task 7.0 in stage 108.0 (TID 183)
23/10/22 22:17:16.577 Executor task launch worker for task 1.0 in stage 108.0 (TID 177) INFO Executor: Running task 1.0 in stage 108.0 (TID 177)
23/10/22 22:17:16.577 Executor task launch worker for task 3.0 in stage 108.0 (TID 179) INFO Executor: Running task 3.0 in stage 108.0 (TID 179)
23/10/22 22:17:16.577 Executor task launch worker for task 0.0 in stage 108.0 (TID 176) INFO Executor: Running task 0.0 in stage 108.0 (TID 176)
23/10/22 22:17:16.581 Executor task launch worker for task 0.0 in stage 108.0 (TID 176) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.581 Executor task launch worker for task 5.0 in stage 108.0 (TID 181) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.581 Executor task launch worker for task 7.0 in stage 108.0 (TID 183) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.581 Executor task launch worker for task 7.0 in stage 108.0 (TID 183) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.581 Executor task launch worker for task 5.0 in stage 108.0 (TID 181) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.581 Executor task launch worker for task 1.0 in stage 108.0 (TID 177) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.582 Executor task launch worker for task 1.0 in stage 108.0 (TID 177) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.581 Executor task launch worker for task 0.0 in stage 108.0 (TID 176) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.581 Executor task launch worker for task 3.0 in stage 108.0 (TID 179) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.582 Executor task launch worker for task 3.0 in stage 108.0 (TID 179) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:16.583 Executor task launch worker for task 4.0 in stage 108.0 (TID 180) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.583 Executor task launch worker for task 6.0 in stage 108.0 (TID 182) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.583 Executor task launch worker for task 4.0 in stage 108.0 (TID 180) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.583 Executor task launch worker for task 6.0 in stage 108.0 (TID 182) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.585 Executor task launch worker for task 2.0 in stage 108.0 (TID 178) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.585 Executor task launch worker for task 2.0 in stage 108.0 (TID 178) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.590 Executor task launch worker for task 5.0 in stage 108.0 (TID 181) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.590 Executor task launch worker for task 3.0 in stage 108.0 (TID 179) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.591 Executor task launch worker for task 6.0 in stage 108.0 (TID 182) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.593 Executor task launch worker for task 2.0 in stage 108.0 (TID 178) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.603 Executor task launch worker for task 1.0 in stage 108.0 (TID 177) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.610 Executor task launch worker for task 5.0 in stage 108.0 (TID 181) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.615 Executor task launch worker for task 3.0 in stage 108.0 (TID 179) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.618 Executor task launch worker for task 2.0 in stage 108.0 (TID 178) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.622 Executor task launch worker for task 4.0 in stage 108.0 (TID 180) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.624 Executor task launch worker for task 7.0 in stage 108.0 (TID 183) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.630 Executor task launch worker for task 1.0 in stage 108.0 (TID 177) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.640 Executor task launch worker for task 0.0 in stage 108.0 (TID 176) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.649 Executor task launch worker for task 6.0 in stage 108.0 (TID 182) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.655 Executor task launch worker for task 7.0 in stage 108.0 (TID 183) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.655 Executor task launch worker for task 4.0 in stage 108.0 (TID 180) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.699 Executor task launch worker for task 0.0 in stage 108.0 (TID 176) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.748 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:55185 in memory (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:17:16.788 Executor task launch worker for task 5.0 in stage 108.0 (TID 181) INFO Executor: Finished task 5.0 in stage 108.0 (TID 181). 4899 bytes result sent to driver
23/10/22 22:17:16.793 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 108.0 (TID 181) in 217 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:16.828 Executor task launch worker for task 3.0 in stage 108.0 (TID 179) INFO Executor: Finished task 3.0 in stage 108.0 (TID 179). 4899 bytes result sent to driver
23/10/22 22:17:16.830 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 179) in 254 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:16.850 Executor task launch worker for task 1.0 in stage 108.0 (TID 177) INFO Executor: Finished task 1.0 in stage 108.0 (TID 177). 4942 bytes result sent to driver
23/10/22 22:17:16.852 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 177) in 277 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:16.858 Executor task launch worker for task 4.0 in stage 108.0 (TID 180) INFO Executor: Finished task 4.0 in stage 108.0 (TID 180). 4899 bytes result sent to driver
23/10/22 22:17:16.858 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 108.0 (TID 180) in 282 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:16.865 Executor task launch worker for task 7.0 in stage 108.0 (TID 183) INFO Executor: Finished task 7.0 in stage 108.0 (TID 183). 4899 bytes result sent to driver
23/10/22 22:17:16.866 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 108.0 (TID 183) in 290 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:16.868 Executor task launch worker for task 2.0 in stage 108.0 (TID 178) INFO Executor: Finished task 2.0 in stage 108.0 (TID 178). 4899 bytes result sent to driver
23/10/22 22:17:16.869 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 178) in 294 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:16.871 Executor task launch worker for task 0.0 in stage 108.0 (TID 176) INFO Executor: Finished task 0.0 in stage 108.0 (TID 176). 4899 bytes result sent to driver
23/10/22 22:17:16.872 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 176) in 297 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:16.874 Executor task launch worker for task 6.0 in stage 108.0 (TID 182) INFO Executor: Finished task 6.0 in stage 108.0 (TID 182). 4942 bytes result sent to driver
23/10/22 22:17:16.875 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 108.0 (TID 182) in 299 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:16.875 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
23/10/22 22:17:16.875 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 108 (rdd at LinearRegression.scala:921) finished in 0.304 s
23/10/22 22:17:16.875 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:16.875 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:16.875 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:16.875 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:16.878 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:16.910 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 23.0328 ms
23/10/22 22:17:16.945 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:17:16.946 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 250 (treeAggregate at Statistics.scala:58) as input to shuffle 36
23/10/22 22:17:16.947 dag-scheduler-event-loop INFO DAGScheduler: Got job 61 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:17:16.947 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 112 (treeAggregate at Statistics.scala:58)
23/10/22 22:17:16.947 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)
23/10/22 22:17:16.947 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 111)
23/10/22 22:17:16.947 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 111 (MapPartitionsRDD[250] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:16.951 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 83.8 KiB, free 1037.0 MiB)
23/10/22 22:17:16.952 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1036.9 MiB)
23/10/22 22:17:16.952 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:55185 (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:16.953 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:16.953 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 111 (MapPartitionsRDD[250] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:16.953 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 111.0 with 8 tasks resource profile 0
23/10/22 22:17:16.954 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 184) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.955 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 185) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.955 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 186) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.955 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 187) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.956 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 111.0 (TID 188) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.956 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 111.0 (TID 189) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.956 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 111.0 (TID 190) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.956 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 111.0 (TID 191) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:16.957 Executor task launch worker for task 2.0 in stage 111.0 (TID 186) INFO Executor: Running task 2.0 in stage 111.0 (TID 186)
23/10/22 22:17:16.957 Executor task launch worker for task 1.0 in stage 111.0 (TID 185) INFO Executor: Running task 1.0 in stage 111.0 (TID 185)
23/10/22 22:17:16.957 Executor task launch worker for task 0.0 in stage 111.0 (TID 184) INFO Executor: Running task 0.0 in stage 111.0 (TID 184)
23/10/22 22:17:16.957 Executor task launch worker for task 3.0 in stage 111.0 (TID 187) INFO Executor: Running task 3.0 in stage 111.0 (TID 187)
23/10/22 22:17:16.958 Executor task launch worker for task 4.0 in stage 111.0 (TID 188) INFO Executor: Running task 4.0 in stage 111.0 (TID 188)
23/10/22 22:17:16.958 Executor task launch worker for task 6.0 in stage 111.0 (TID 190) INFO Executor: Running task 6.0 in stage 111.0 (TID 190)
23/10/22 22:17:16.958 Executor task launch worker for task 7.0 in stage 111.0 (TID 191) INFO Executor: Running task 7.0 in stage 111.0 (TID 191)
23/10/22 22:17:16.958 Executor task launch worker for task 5.0 in stage 111.0 (TID 189) INFO Executor: Running task 5.0 in stage 111.0 (TID 189)
23/10/22 22:17:16.966 Executor task launch worker for task 1.0 in stage 111.0 (TID 185) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.966 Executor task launch worker for task 3.0 in stage 111.0 (TID 187) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.966 Executor task launch worker for task 7.0 in stage 111.0 (TID 191) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.967 Executor task launch worker for task 3.0 in stage 111.0 (TID 187) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.967 Executor task launch worker for task 1.0 in stage 111.0 (TID 185) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.967 Executor task launch worker for task 7.0 in stage 111.0 (TID 191) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.967 Executor task launch worker for task 6.0 in stage 111.0 (TID 190) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.967 Executor task launch worker for task 6.0 in stage 111.0 (TID 190) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.968 Executor task launch worker for task 2.0 in stage 111.0 (TID 186) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.969 Executor task launch worker for task 2.0 in stage 111.0 (TID 186) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.970 Executor task launch worker for task 0.0 in stage 111.0 (TID 184) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.970 Executor task launch worker for task 0.0 in stage 111.0 (TID 184) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.974 Executor task launch worker for task 4.0 in stage 111.0 (TID 188) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.974 Executor task launch worker for task 5.0 in stage 111.0 (TID 189) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:16.974 Executor task launch worker for task 4.0 in stage 111.0 (TID 188) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.975 Executor task launch worker for task 5.0 in stage 111.0 (TID 189) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:16.983 Executor task launch worker for task 7.0 in stage 111.0 (TID 191) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.985 Executor task launch worker for task 0.0 in stage 111.0 (TID 184) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.986 Executor task launch worker for task 3.0 in stage 111.0 (TID 187) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:16.988 Executor task launch worker for task 2.0 in stage 111.0 (TID 186) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:17.004 Executor task launch worker for task 4.0 in stage 111.0 (TID 188) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:17.005 Executor task launch worker for task 5.0 in stage 111.0 (TID 189) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:17.005 Executor task launch worker for task 1.0 in stage 111.0 (TID 185) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:17.005 Executor task launch worker for task 6.0 in stage 111.0 (TID 190) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:17.062 Executor task launch worker for task 3.0 in stage 111.0 (TID 187) INFO Executor: Finished task 3.0 in stage 111.0 (TID 187). 6562 bytes result sent to driver
23/10/22 22:17:17.067 Executor task launch worker for task 7.0 in stage 111.0 (TID 191) INFO Executor: Finished task 7.0 in stage 111.0 (TID 191). 6562 bytes result sent to driver
23/10/22 22:17:17.068 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 187) in 109 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:17.070 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 111.0 (TID 191) in 114 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:17.071 Executor task launch worker for task 4.0 in stage 111.0 (TID 188) INFO Executor: Finished task 4.0 in stage 111.0 (TID 188). 6605 bytes result sent to driver
23/10/22 22:17:17.072 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 111.0 (TID 188) in 117 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:17.078 Executor task launch worker for task 5.0 in stage 111.0 (TID 189) INFO Executor: Finished task 5.0 in stage 111.0 (TID 189). 6605 bytes result sent to driver
23/10/22 22:17:17.081 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 111.0 (TID 189) in 125 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:17.083 Executor task launch worker for task 6.0 in stage 111.0 (TID 190) INFO Executor: Finished task 6.0 in stage 111.0 (TID 190). 6562 bytes result sent to driver
23/10/22 22:17:17.084 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 111.0 (TID 190) in 128 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:17.092 Executor task launch worker for task 2.0 in stage 111.0 (TID 186) INFO Executor: Finished task 2.0 in stage 111.0 (TID 186). 6562 bytes result sent to driver
23/10/22 22:17:17.093 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 186) in 138 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:17.095 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:17.097 Executor task launch worker for task 0.0 in stage 111.0 (TID 184) INFO Executor: Finished task 0.0 in stage 111.0 (TID 184). 6605 bytes result sent to driver
23/10/22 22:17:17.098 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 184) in 144 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:17.114 Executor task launch worker for task 1.0 in stage 111.0 (TID 185) INFO Executor: Finished task 1.0 in stage 111.0 (TID 185). 6605 bytes result sent to driver
23/10/22 22:17:17.115 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 185) in 160 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:17.115 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
23/10/22 22:17:17.116 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 111 (treeAggregate at Statistics.scala:58) finished in 0.167 s
23/10/22 22:17:17.116 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:17.116 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:17.116 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 112)
23/10/22 22:17:17.116 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:17.116 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[252] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:17.120 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 84.9 KiB, free 1036.9 MiB)
23/10/22 22:17:17.122 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 1036.9 MiB)
23/10/22 22:17:17.123 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:55185 (size: 36.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:17.123 dag-scheduler-event-loop INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:17.124 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 112 (MapPartitionsRDD[252] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:17.124 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 112.0 with 2 tasks resource profile 0
23/10/22 22:17:17.125 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 192) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:17.125 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 193) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:17.126 Executor task launch worker for task 1.0 in stage 112.0 (TID 193) INFO Executor: Running task 1.0 in stage 112.0 (TID 193)
23/10/22 22:17:17.126 Executor task launch worker for task 0.0 in stage 112.0 (TID 192) INFO Executor: Running task 0.0 in stage 112.0 (TID 192)
23/10/22 22:17:17.134 Executor task launch worker for task 0.0 in stage 112.0 (TID 192) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:17.134 Executor task launch worker for task 1.0 in stage 112.0 (TID 193) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:17.134 Executor task launch worker for task 1.0 in stage 112.0 (TID 193) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:17.134 Executor task launch worker for task 0.0 in stage 112.0 (TID 192) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:17.141 Executor task launch worker for task 1.0 in stage 112.0 (TID 193) INFO Executor: Finished task 1.0 in stage 112.0 (TID 193). 7630 bytes result sent to driver
23/10/22 22:17:17.141 Executor task launch worker for task 0.0 in stage 112.0 (TID 192) INFO Executor: Finished task 0.0 in stage 112.0 (TID 192). 7630 bytes result sent to driver
23/10/22 22:17:17.142 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 193) in 17 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:17.142 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 192) in 17 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:17.143 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
23/10/22 22:17:17.143 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 112 (treeAggregate at Statistics.scala:58) finished in 0.026 s
23/10/22 22:17:17.143 dag-scheduler-event-loop INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:17.143 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished
23/10/22 22:17:17.143 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 61 finished: treeAggregate at Statistics.scala:58, took 0.197894 s
23/10/22 22:17:17.144 nioEventLoopGroup-2-2 INFO Instrumentation: [3f6762a9] training finished
23/10/22 22:17:17.577 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:17.578 dag-scheduler-event-loop INFO DAGScheduler: Got job 62 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:17.578 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 113 (collect at utils.scala:26)
23/10/22 22:17:17.578 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:17.578 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:17.578 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[254] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:17.580 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 7.4 KiB, free 1036.9 MiB)
23/10/22 22:17:17.582 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:17.582 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:17.583 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:17.583 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[254] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:17.583 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0
23/10/22 22:17:17.584 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 194) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:17.586 Executor task launch worker for task 0.0 in stage 113.0 (TID 194) INFO Executor: Running task 0.0 in stage 113.0 (TID 194)
23/10/22 22:17:17.589 Executor task launch worker for task 0.0 in stage 113.0 (TID 194) INFO Executor: Finished task 0.0 in stage 113.0 (TID 194). 1327 bytes result sent to driver
23/10/22 22:17:17.589 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 194) in 5 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:17.589 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
23/10/22 22:17:17.590 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 113 (collect at utils.scala:26) finished in 0.012 s
23/10/22 22:17:17.590 dag-scheduler-event-loop INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:17.590 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
23/10/22 22:17:17.590 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 62 finished: collect at utils.scala:26, took 0.012528 s
23/10/22 22:17:17.952 nioEventLoopGroup-2-2 INFO Instrumentation: [2598d240] training finished
23/10/22 22:17:18.048 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:18.049 dag-scheduler-event-loop INFO DAGScheduler: Got job 63 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:18.049 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 114 (collect at utils.scala:26)
23/10/22 22:17:18.049 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:18.049 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:18.049 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[256] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:18.050 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:18.051 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:18.051 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:18.052 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:18.052 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[256] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:18.052 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
23/10/22 22:17:18.052 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 195) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:18.053 Executor task launch worker for task 0.0 in stage 114.0 (TID 195) INFO Executor: Running task 0.0 in stage 114.0 (TID 195)
23/10/22 22:17:18.055 Executor task launch worker for task 0.0 in stage 114.0 (TID 195) INFO Executor: Finished task 0.0 in stage 114.0 (TID 195). 1327 bytes result sent to driver
23/10/22 22:17:18.056 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 195) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:18.056 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
23/10/22 22:17:18.056 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 114 (collect at utils.scala:26) finished in 0.006 s
23/10/22 22:17:18.056 dag-scheduler-event-loop INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:18.056 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
23/10/22 22:17:18.056 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 63 finished: collect at utils.scala:26, took 0.007707 s
23/10/22 22:17:18.570 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:18.571 dag-scheduler-event-loop INFO DAGScheduler: Got job 64 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:18.571 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 115 (collect at utils.scala:26)
23/10/22 22:17:18.571 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:18.571 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:18.572 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[258] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:18.572 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:18.574 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:18.574 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:18.575 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:18.575 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[258] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:18.575 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0
23/10/22 22:17:18.576 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 196) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:18.577 Executor task launch worker for task 0.0 in stage 115.0 (TID 196) INFO Executor: Running task 0.0 in stage 115.0 (TID 196)
23/10/22 22:17:18.580 Executor task launch worker for task 0.0 in stage 115.0 (TID 196) INFO Executor: Finished task 0.0 in stage 115.0 (TID 196). 1327 bytes result sent to driver
23/10/22 22:17:18.581 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 196) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:18.581 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
23/10/22 22:17:18.581 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 115 (collect at utils.scala:26) finished in 0.009 s
23/10/22 22:17:18.581 dag-scheduler-event-loop INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:18.581 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished
23/10/22 22:17:18.581 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 64 finished: collect at utils.scala:26, took 0.010792 s
23/10/22 22:17:19.410 nioEventLoopGroup-2-2 INFO Instrumentation: [79b6ed14] training finished
23/10/22 22:17:19.443 nioEventLoopGroup-2-2 INFO Instrumentation: [5383526a] training finished
23/10/22 22:17:19.452 nioEventLoopGroup-2-2 INFO Instrumentation: [ee1298cf] Stage class: LinearRegression
23/10/22 22:17:19.452 nioEventLoopGroup-2-2 INFO Instrumentation: [ee1298cf] Stage uid: linear_regression__ef5dabcf_14d1_4b27_88f9_3221514e1542
23/10/22 22:17:19.480 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 261 (rdd at Instrumentation.scala:62) as input to shuffle 37
23/10/22 22:17:19.480 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 65 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:17:19.480 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 116 (rdd at Instrumentation.scala:62)
23/10/22 22:17:19.480 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:19.480 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:19.480 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[261] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:19.482 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:19.482 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:19.483 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:19.483 dag-scheduler-event-loop INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:19.483 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[261] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:19.483 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0
23/10/22 22:17:19.736 dispatcher-event-loop-4 WARN TaskSetManager: Stage 116 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:19.736 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 197) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:19.736 Executor task launch worker for task 0.0 in stage 116.0 (TID 197) INFO Executor: Running task 0.0 in stage 116.0 (TID 197)
23/10/22 22:17:19.757 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:55185 in memory (size: 36.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:19.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:55185 in memory (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:19.760 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:19.762 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:19.763 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:19.906 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:19.916 Executor task launch worker for task 0.0 in stage 116.0 (TID 197) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.881 Executor task launch worker for task 0.0 in stage 116.0 (TID 197) INFO Executor: Finished task 0.0 in stage 116.0 (TID 197). 2104 bytes result sent to driver
23/10/22 22:17:20.881 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 197) in 1397 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:20.881 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
23/10/22 22:17:20.881 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 116 (rdd at Instrumentation.scala:62) finished in 1.400 s
23/10/22 22:17:20.881 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:20.881 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:20.881 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:20.881 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:20.886 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:20.888 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 265 (rdd at Instrumentation.scala:62) as input to shuffle 38
23/10/22 22:17:20.888 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 66 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:17:20.888 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 118 (rdd at Instrumentation.scala:62)
23/10/22 22:17:20.888 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)
23/10/22 22:17:20.888 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:20.889 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[265] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:20.891 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:20.893 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:20.893 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:20.893 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:20.894 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[265] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:20.894 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 118.0 with 8 tasks resource profile 0
23/10/22 22:17:20.894 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 198) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.895 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 199) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.895 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 200) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.895 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 201) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.895 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 202) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.896 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 203) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.896 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 204) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.896 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 205) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:20.896 Executor task launch worker for task 0.0 in stage 118.0 (TID 198) INFO Executor: Running task 0.0 in stage 118.0 (TID 198)
23/10/22 22:17:20.896 Executor task launch worker for task 4.0 in stage 118.0 (TID 202) INFO Executor: Running task 4.0 in stage 118.0 (TID 202)
23/10/22 22:17:20.896 Executor task launch worker for task 5.0 in stage 118.0 (TID 203) INFO Executor: Running task 5.0 in stage 118.0 (TID 203)
23/10/22 22:17:20.896 Executor task launch worker for task 6.0 in stage 118.0 (TID 204) INFO Executor: Running task 6.0 in stage 118.0 (TID 204)
23/10/22 22:17:20.896 Executor task launch worker for task 2.0 in stage 118.0 (TID 200) INFO Executor: Running task 2.0 in stage 118.0 (TID 200)
23/10/22 22:17:20.897 Executor task launch worker for task 7.0 in stage 118.0 (TID 205) INFO Executor: Running task 7.0 in stage 118.0 (TID 205)
23/10/22 22:17:20.896 Executor task launch worker for task 1.0 in stage 118.0 (TID 199) INFO Executor: Running task 1.0 in stage 118.0 (TID 199)
23/10/22 22:17:20.900 Executor task launch worker for task 7.0 in stage 118.0 (TID 205) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.896 Executor task launch worker for task 3.0 in stage 118.0 (TID 201) INFO Executor: Running task 3.0 in stage 118.0 (TID 201)
23/10/22 22:17:20.900 Executor task launch worker for task 7.0 in stage 118.0 (TID 205) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:20.900 Executor task launch worker for task 2.0 in stage 118.0 (TID 200) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.900 Executor task launch worker for task 2.0 in stage 118.0 (TID 200) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:20.900 Executor task launch worker for task 4.0 in stage 118.0 (TID 202) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.900 Executor task launch worker for task 4.0 in stage 118.0 (TID 202) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:20.900 Executor task launch worker for task 1.0 in stage 118.0 (TID 199) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.902 Executor task launch worker for task 1.0 in stage 118.0 (TID 199) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:20.903 Executor task launch worker for task 0.0 in stage 118.0 (TID 198) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.903 Executor task launch worker for task 0.0 in stage 118.0 (TID 198) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:20.903 Executor task launch worker for task 5.0 in stage 118.0 (TID 203) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.903 Executor task launch worker for task 3.0 in stage 118.0 (TID 201) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.903 Executor task launch worker for task 3.0 in stage 118.0 (TID 201) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:20.903 Executor task launch worker for task 5.0 in stage 118.0 (TID 203) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:20.900 Executor task launch worker for task 6.0 in stage 118.0 (TID 204) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:20.903 Executor task launch worker for task 6.0 in stage 118.0 (TID 204) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 22:17:20.909 Executor task launch worker for task 2.0 in stage 118.0 (TID 200) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.909 Executor task launch worker for task 4.0 in stage 118.0 (TID 202) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.910 Executor task launch worker for task 1.0 in stage 118.0 (TID 199) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.912 Executor task launch worker for task 6.0 in stage 118.0 (TID 204) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.928 Executor task launch worker for task 0.0 in stage 118.0 (TID 198) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.928 Executor task launch worker for task 4.0 in stage 118.0 (TID 202) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.929 Executor task launch worker for task 2.0 in stage 118.0 (TID 200) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.938 Executor task launch worker for task 6.0 in stage 118.0 (TID 204) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.938 Executor task launch worker for task 1.0 in stage 118.0 (TID 199) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.939 Executor task launch worker for task 7.0 in stage 118.0 (TID 205) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.941 Executor task launch worker for task 5.0 in stage 118.0 (TID 203) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.942 Executor task launch worker for task 3.0 in stage 118.0 (TID 201) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.954 Executor task launch worker for task 0.0 in stage 118.0 (TID 198) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.964 Executor task launch worker for task 7.0 in stage 118.0 (TID 205) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.966 Executor task launch worker for task 5.0 in stage 118.0 (TID 203) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:20.968 Executor task launch worker for task 3.0 in stage 118.0 (TID 201) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:21.076 Executor task launch worker for task 4.0 in stage 118.0 (TID 202) INFO Executor: Finished task 4.0 in stage 118.0 (TID 202). 4942 bytes result sent to driver
23/10/22 22:17:21.078 Executor task launch worker for task 2.0 in stage 118.0 (TID 200) INFO Executor: Finished task 2.0 in stage 118.0 (TID 200). 4899 bytes result sent to driver
23/10/22 22:17:21.078 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 202) in 183 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:21.079 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 200) in 184 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:21.098 Executor task launch worker for task 1.0 in stage 118.0 (TID 199) INFO Executor: Finished task 1.0 in stage 118.0 (TID 199). 4899 bytes result sent to driver
23/10/22 22:17:21.100 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 199) in 204 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:21.108 Executor task launch worker for task 6.0 in stage 118.0 (TID 204) INFO Executor: Finished task 6.0 in stage 118.0 (TID 204). 4899 bytes result sent to driver
23/10/22 22:17:21.108 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 204) in 212 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:21.115 Executor task launch worker for task 3.0 in stage 118.0 (TID 201) INFO Executor: Finished task 3.0 in stage 118.0 (TID 201). 4899 bytes result sent to driver
23/10/22 22:17:21.115 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 201) in 220 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:21.121 Executor task launch worker for task 0.0 in stage 118.0 (TID 198) INFO Executor: Finished task 0.0 in stage 118.0 (TID 198). 4899 bytes result sent to driver
23/10/22 22:17:21.122 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 198) in 228 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:21.126 Executor task launch worker for task 5.0 in stage 118.0 (TID 203) INFO Executor: Finished task 5.0 in stage 118.0 (TID 203). 4899 bytes result sent to driver
23/10/22 22:17:21.127 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 203) in 231 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:21.129 Executor task launch worker for task 7.0 in stage 118.0 (TID 205) INFO Executor: Finished task 7.0 in stage 118.0 (TID 205). 4899 bytes result sent to driver
23/10/22 22:17:21.129 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 205) in 233 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:21.129 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
23/10/22 22:17:21.130 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 118 (rdd at Instrumentation.scala:62) finished in 0.240 s
23/10/22 22:17:21.130 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:21.130 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:21.130 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:21.130 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:21.133 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:21.153 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.7288 ms
23/10/22 22:17:21.163 nioEventLoopGroup-2-2 INFO Instrumentation: [ee1298cf] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:17:21.164 nioEventLoopGroup-2-2 INFO Instrumentation: [ee1298cf] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:17:21.164 nioEventLoopGroup-2-2 INFO Instrumentation: [ee1298cf] {"numFeatures":3}
23/10/22 22:17:21.168 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:21.228 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 274 (rdd at LinearRegression.scala:348) as input to shuffle 39
23/10/22 22:17:21.228 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 67 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:17:21.228 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 119 (rdd at LinearRegression.scala:348)
23/10/22 22:17:21.228 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:21.228 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:21.228 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[274] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:21.231 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 22:17:21.232 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:21.232 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:21.233 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:21.233 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[274] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:21.233 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0
23/10/22 22:17:21.482 dispatcher-event-loop-7 WARN TaskSetManager: Stage 119 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:21.482 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 206) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:21.482 Executor task launch worker for task 0.0 in stage 119.0 (TID 206) INFO Executor: Running task 0.0 in stage 119.0 (TID 206)
23/10/22 22:17:21.651 Executor task launch worker for task 0.0 in stage 119.0 (TID 206) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:21.731 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:22.776 Executor task launch worker for task 0.0 in stage 119.0 (TID 206) INFO Executor: Finished task 0.0 in stage 119.0 (TID 206). 2104 bytes result sent to driver
23/10/22 22:17:22.779 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 206) in 1546 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:22.779 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
23/10/22 22:17:22.779 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 119 (rdd at LinearRegression.scala:348) finished in 1.550 s
23/10/22 22:17:22.779 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:22.779 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:22.780 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:22.780 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:22.785 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:22.788 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 278 (rdd at LinearRegression.scala:348) as input to shuffle 40
23/10/22 22:17:22.788 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 68 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:17:22.788 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 121 (rdd at LinearRegression.scala:348)
23/10/22 22:17:22.788 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)
23/10/22 22:17:22.788 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:22.789 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[278] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:22.790 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:22.791 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:22.791 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:22.792 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:22.792 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[278] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:22.792 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 121.0 with 8 tasks resource profile 0
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 207) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 208) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 121.0 (TID 209) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 121.0 (TID 210) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 121.0 (TID 211) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 121.0 (TID 212) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.793 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 121.0 (TID 213) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.794 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 121.0 (TID 214) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:22.794 Executor task launch worker for task 3.0 in stage 121.0 (TID 210) INFO Executor: Running task 3.0 in stage 121.0 (TID 210)
23/10/22 22:17:22.794 Executor task launch worker for task 1.0 in stage 121.0 (TID 208) INFO Executor: Running task 1.0 in stage 121.0 (TID 208)
23/10/22 22:17:22.794 Executor task launch worker for task 5.0 in stage 121.0 (TID 212) INFO Executor: Running task 5.0 in stage 121.0 (TID 212)
23/10/22 22:17:22.794 Executor task launch worker for task 7.0 in stage 121.0 (TID 214) INFO Executor: Running task 7.0 in stage 121.0 (TID 214)
23/10/22 22:17:22.794 Executor task launch worker for task 4.0 in stage 121.0 (TID 211) INFO Executor: Running task 4.0 in stage 121.0 (TID 211)
23/10/22 22:17:22.794 Executor task launch worker for task 0.0 in stage 121.0 (TID 207) INFO Executor: Running task 0.0 in stage 121.0 (TID 207)
23/10/22 22:17:22.794 Executor task launch worker for task 2.0 in stage 121.0 (TID 209) INFO Executor: Running task 2.0 in stage 121.0 (TID 209)
23/10/22 22:17:22.794 Executor task launch worker for task 6.0 in stage 121.0 (TID 213) INFO Executor: Running task 6.0 in stage 121.0 (TID 213)
23/10/22 22:17:22.798 Executor task launch worker for task 4.0 in stage 121.0 (TID 211) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.798 Executor task launch worker for task 3.0 in stage 121.0 (TID 210) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.798 Executor task launch worker for task 3.0 in stage 121.0 (TID 210) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.798 Executor task launch worker for task 1.0 in stage 121.0 (TID 208) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.798 Executor task launch worker for task 7.0 in stage 121.0 (TID 214) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.799 Executor task launch worker for task 1.0 in stage 121.0 (TID 208) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.799 Executor task launch worker for task 7.0 in stage 121.0 (TID 214) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.799 Executor task launch worker for task 5.0 in stage 121.0 (TID 212) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.799 Executor task launch worker for task 5.0 in stage 121.0 (TID 212) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.799 Executor task launch worker for task 4.0 in stage 121.0 (TID 211) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:22.799 Executor task launch worker for task 2.0 in stage 121.0 (TID 209) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.799 Executor task launch worker for task 2.0 in stage 121.0 (TID 209) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.799 Executor task launch worker for task 6.0 in stage 121.0 (TID 213) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.799 Executor task launch worker for task 6.0 in stage 121.0 (TID 213) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.800 Executor task launch worker for task 0.0 in stage 121.0 (TID 207) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:22.800 Executor task launch worker for task 0.0 in stage 121.0 (TID 207) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:22.808 Executor task launch worker for task 3.0 in stage 121.0 (TID 210) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.808 Executor task launch worker for task 2.0 in stage 121.0 (TID 209) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.808 Executor task launch worker for task 4.0 in stage 121.0 (TID 211) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.809 Executor task launch worker for task 5.0 in stage 121.0 (TID 212) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.810 Executor task launch worker for task 7.0 in stage 121.0 (TID 214) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.812 Executor task launch worker for task 6.0 in stage 121.0 (TID 213) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.823 Executor task launch worker for task 1.0 in stage 121.0 (TID 208) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.832 Executor task launch worker for task 0.0 in stage 121.0 (TID 207) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.832 Executor task launch worker for task 5.0 in stage 121.0 (TID 212) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.840 Executor task launch worker for task 6.0 in stage 121.0 (TID 213) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.840 Executor task launch worker for task 4.0 in stage 121.0 (TID 211) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.842 Executor task launch worker for task 3.0 in stage 121.0 (TID 210) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.843 Executor task launch worker for task 7.0 in stage 121.0 (TID 214) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.846 Executor task launch worker for task 1.0 in stage 121.0 (TID 208) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.849 Executor task launch worker for task 2.0 in stage 121.0 (TID 209) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.871 Executor task launch worker for task 0.0 in stage 121.0 (TID 207) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:22.958 Executor task launch worker for task 5.0 in stage 121.0 (TID 212) INFO Executor: Finished task 5.0 in stage 121.0 (TID 212). 4942 bytes result sent to driver
23/10/22 22:17:22.959 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 121.0 (TID 212) in 166 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:22.963 Executor task launch worker for task 7.0 in stage 121.0 (TID 214) INFO Executor: Finished task 7.0 in stage 121.0 (TID 214). 4942 bytes result sent to driver
23/10/22 22:17:22.963 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 121.0 (TID 214) in 170 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:22.967 Executor task launch worker for task 6.0 in stage 121.0 (TID 213) INFO Executor: Finished task 6.0 in stage 121.0 (TID 213). 4942 bytes result sent to driver
23/10/22 22:17:22.968 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 121.0 (TID 213) in 175 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:22.971 Executor task launch worker for task 4.0 in stage 121.0 (TID 211) INFO Executor: Finished task 4.0 in stage 121.0 (TID 211). 4942 bytes result sent to driver
23/10/22 22:17:22.972 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 121.0 (TID 211) in 179 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:22.974 Executor task launch worker for task 0.0 in stage 121.0 (TID 207) INFO Executor: Finished task 0.0 in stage 121.0 (TID 207). 4942 bytes result sent to driver
23/10/22 22:17:22.974 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 207) in 181 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:22.977 Executor task launch worker for task 1.0 in stage 121.0 (TID 208) INFO Executor: Finished task 1.0 in stage 121.0 (TID 208). 4942 bytes result sent to driver
23/10/22 22:17:22.978 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 208) in 185 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:22.980 Executor task launch worker for task 3.0 in stage 121.0 (TID 210) INFO Executor: Finished task 3.0 in stage 121.0 (TID 210). 4942 bytes result sent to driver
23/10/22 22:17:22.981 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 121.0 (TID 210) in 188 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:22.984 Executor task launch worker for task 2.0 in stage 121.0 (TID 209) INFO Executor: Finished task 2.0 in stage 121.0 (TID 209). 4942 bytes result sent to driver
23/10/22 22:17:22.984 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 121.0 (TID 209) in 191 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:22.984 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
23/10/22 22:17:22.985 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 121 (rdd at LinearRegression.scala:348) finished in 0.196 s
23/10/22 22:17:22.985 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:22.985 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:22.985 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:22.985 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:22.988 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:23.018 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.8764 ms
23/10/22 22:17:23.032 nioEventLoopGroup-2-2 WARN Instrumentation: [ee1298cf] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:17:23.057 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:17:23.058 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 287 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 41
23/10/22 22:17:23.058 dag-scheduler-event-loop INFO DAGScheduler: Got job 69 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:17:23.059 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 125 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:17:23.059 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
23/10/22 22:17:23.059 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 124)
23/10/22 22:17:23.059 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[287] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:23.062 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 98.9 KiB, free 1036.9 MiB)
23/10/22 22:17:23.064 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 1036.9 MiB)
23/10/22 22:17:23.065 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:55185 (size: 39.0 KiB, free: 1037.1 MiB)
23/10/22 22:17:23.065 dag-scheduler-event-loop INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:23.066 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[287] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:23.066 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 124.0 with 8 tasks resource profile 0
23/10/22 22:17:23.067 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 215) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.067 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 216) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.067 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 217) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.067 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 218) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.067 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 124.0 (TID 219) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.067 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 124.0 (TID 220) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.068 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 124.0 (TID 221) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.068 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 124.0 (TID 222) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:23.068 Executor task launch worker for task 0.0 in stage 124.0 (TID 215) INFO Executor: Running task 0.0 in stage 124.0 (TID 215)
23/10/22 22:17:23.068 Executor task launch worker for task 2.0 in stage 124.0 (TID 217) INFO Executor: Running task 2.0 in stage 124.0 (TID 217)
23/10/22 22:17:23.068 Executor task launch worker for task 5.0 in stage 124.0 (TID 220) INFO Executor: Running task 5.0 in stage 124.0 (TID 220)
23/10/22 22:17:23.068 Executor task launch worker for task 7.0 in stage 124.0 (TID 222) INFO Executor: Running task 7.0 in stage 124.0 (TID 222)
23/10/22 22:17:23.068 Executor task launch worker for task 3.0 in stage 124.0 (TID 218) INFO Executor: Running task 3.0 in stage 124.0 (TID 218)
23/10/22 22:17:23.068 Executor task launch worker for task 1.0 in stage 124.0 (TID 216) INFO Executor: Running task 1.0 in stage 124.0 (TID 216)
23/10/22 22:17:23.068 Executor task launch worker for task 4.0 in stage 124.0 (TID 219) INFO Executor: Running task 4.0 in stage 124.0 (TID 219)
23/10/22 22:17:23.068 Executor task launch worker for task 6.0 in stage 124.0 (TID 221) INFO Executor: Running task 6.0 in stage 124.0 (TID 221)
23/10/22 22:17:23.084 Executor task launch worker for task 1.0 in stage 124.0 (TID 216) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.084 Executor task launch worker for task 1.0 in stage 124.0 (TID 216) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.086 Executor task launch worker for task 3.0 in stage 124.0 (TID 218) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.086 Executor task launch worker for task 3.0 in stage 124.0 (TID 218) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.086 Executor task launch worker for task 7.0 in stage 124.0 (TID 222) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.086 Executor task launch worker for task 7.0 in stage 124.0 (TID 222) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.086 Executor task launch worker for task 2.0 in stage 124.0 (TID 217) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.087 Executor task launch worker for task 2.0 in stage 124.0 (TID 217) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:23.088 Executor task launch worker for task 0.0 in stage 124.0 (TID 215) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.088 Executor task launch worker for task 0.0 in stage 124.0 (TID 215) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.086 Executor task launch worker for task 5.0 in stage 124.0 (TID 220) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.086 Executor task launch worker for task 4.0 in stage 124.0 (TID 219) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.088 Executor task launch worker for task 5.0 in stage 124.0 (TID 220) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:23.088 Executor task launch worker for task 4.0 in stage 124.0 (TID 219) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:23.088 Executor task launch worker for task 6.0 in stage 124.0 (TID 221) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.089 Executor task launch worker for task 6.0 in stage 124.0 (TID 221) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.101 Executor task launch worker for task 1.0 in stage 124.0 (TID 216) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.102 Executor task launch worker for task 7.0 in stage 124.0 (TID 222) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.102 Executor task launch worker for task 5.0 in stage 124.0 (TID 220) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.107 Executor task launch worker for task 0.0 in stage 124.0 (TID 215) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.121 Executor task launch worker for task 4.0 in stage 124.0 (TID 219) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.123 Executor task launch worker for task 2.0 in stage 124.0 (TID 217) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.127 Executor task launch worker for task 6.0 in stage 124.0 (TID 221) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.127 Executor task launch worker for task 3.0 in stage 124.0 (TID 218) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:23.194 Executor task launch worker for task 1.0 in stage 124.0 (TID 216) INFO Executor: Finished task 1.0 in stage 124.0 (TID 216). 6691 bytes result sent to driver
23/10/22 22:17:23.207 Executor task launch worker for task 2.0 in stage 124.0 (TID 217) INFO Executor: Finished task 2.0 in stage 124.0 (TID 217). 6605 bytes result sent to driver
23/10/22 22:17:23.215 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 216) in 148 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:23.217 Executor task launch worker for task 7.0 in stage 124.0 (TID 222) INFO Executor: Finished task 7.0 in stage 124.0 (TID 222). 6648 bytes result sent to driver
23/10/22 22:17:23.228 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 217) in 161 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:23.229 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 124.0 (TID 222) in 161 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:23.256 Executor task launch worker for task 5.0 in stage 124.0 (TID 220) INFO Executor: Finished task 5.0 in stage 124.0 (TID 220). 6648 bytes result sent to driver
23/10/22 22:17:23.257 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 124.0 (TID 220) in 190 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:23.271 Executor task launch worker for task 0.0 in stage 124.0 (TID 215) INFO Executor: Finished task 0.0 in stage 124.0 (TID 215). 6605 bytes result sent to driver
23/10/22 22:17:23.273 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 215) in 207 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:23.277 Executor task launch worker for task 4.0 in stage 124.0 (TID 219) INFO Executor: Finished task 4.0 in stage 124.0 (TID 219). 6648 bytes result sent to driver
23/10/22 22:17:23.283 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 124.0 (TID 219) in 216 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:23.285 Executor task launch worker for task 3.0 in stage 124.0 (TID 218) INFO Executor: Finished task 3.0 in stage 124.0 (TID 218). 6605 bytes result sent to driver
23/10/22 22:17:23.288 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 218) in 221 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:23.319 Executor task launch worker for task 6.0 in stage 124.0 (TID 221) INFO Executor: Finished task 6.0 in stage 124.0 (TID 221). 6648 bytes result sent to driver
23/10/22 22:17:23.320 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 124.0 (TID 221) in 253 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:23.320 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
23/10/22 22:17:23.321 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 124 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.261 s
23/10/22 22:17:23.321 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:23.321 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:23.321 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 125)
23/10/22 22:17:23.321 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:23.321 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[289] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:23.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 99.9 KiB, free 1036.8 MiB)
23/10/22 22:17:23.328 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 1036.8 MiB)
23/10/22 22:17:23.328 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:55185 (size: 39.5 KiB, free: 1037.0 MiB)
23/10/22 22:17:23.329 dag-scheduler-event-loop INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:23.329 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 125 (MapPartitionsRDD[289] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:23.329 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 125.0 with 2 tasks resource profile 0
23/10/22 22:17:23.333 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 223) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:23.334 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 224) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:23.335 Executor task launch worker for task 1.0 in stage 125.0 (TID 224) INFO Executor: Running task 1.0 in stage 125.0 (TID 224)
23/10/22 22:17:23.335 Executor task launch worker for task 0.0 in stage 125.0 (TID 223) INFO Executor: Running task 0.0 in stage 125.0 (TID 223)
23/10/22 22:17:23.343 Executor task launch worker for task 1.0 in stage 125.0 (TID 224) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.343 Executor task launch worker for task 0.0 in stage 125.0 (TID 223) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:23.344 Executor task launch worker for task 1.0 in stage 125.0 (TID 224) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.344 Executor task launch worker for task 0.0 in stage 125.0 (TID 223) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:23.353 Executor task launch worker for task 1.0 in stage 125.0 (TID 224) INFO Executor: Finished task 1.0 in stage 125.0 (TID 224). 6814 bytes result sent to driver
23/10/22 22:17:23.355 Executor task launch worker for task 0.0 in stage 125.0 (TID 223) INFO Executor: Finished task 0.0 in stage 125.0 (TID 223). 6771 bytes result sent to driver
23/10/22 22:17:23.355 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 224) in 21 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:23.356 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 223) in 23 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:23.356 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
23/10/22 22:17:23.356 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 125 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.034 s
23/10/22 22:17:23.357 dag-scheduler-event-loop INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:23.357 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished
23/10/22 22:17:23.357 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 69 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.299906 s
23/10/22 22:17:23.358 nioEventLoopGroup-2-2 INFO Instrumentation: [ee1298cf] Number of instances: 3785.
23/10/22 22:17:23.385 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:23.390 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:23.500 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 292 (rdd at LinearRegression.scala:921) as input to shuffle 42
23/10/22 22:17:23.500 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 70 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:17:23.500 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 126 (rdd at LinearRegression.scala:921)
23/10/22 22:17:23.500 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:23.500 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:23.501 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[292] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:23.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:23.504 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:23.504 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:23.504 dag-scheduler-event-loop INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:23.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[292] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:23.504 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
23/10/22 22:17:23.867 dispatcher-event-loop-5 WARN TaskSetManager: Stage 126 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:23.867 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 225) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:23.868 Executor task launch worker for task 0.0 in stage 126.0 (TID 225) INFO Executor: Running task 0.0 in stage 126.0 (TID 225)
23/10/22 22:17:24.004 Executor task launch worker for task 0.0 in stage 126.0 (TID 225) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:24.399 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:55185 in memory (size: 39.0 KiB, free: 1037.1 MiB)
23/10/22 22:17:24.402 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:55185 in memory (size: 39.5 KiB, free: 1037.1 MiB)
23/10/22 22:17:24.945 Executor task launch worker for task 0.0 in stage 126.0 (TID 225) INFO Executor: Finished task 0.0 in stage 126.0 (TID 225). 2147 bytes result sent to driver
23/10/22 22:17:24.945 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 225) in 1439 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:24.945 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
23/10/22 22:17:24.946 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 126 (rdd at LinearRegression.scala:921) finished in 1.445 s
23/10/22 22:17:24.946 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:24.946 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:24.946 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:24.946 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:24.952 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(42), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:24.955 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 296 (rdd at LinearRegression.scala:921) as input to shuffle 43
23/10/22 22:17:24.955 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 71 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:17:24.955 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 128 (rdd at LinearRegression.scala:921)
23/10/22 22:17:24.955 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
23/10/22 22:17:24.955 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:24.955 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[296] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:24.958 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:24.959 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:24.960 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:24.961 dag-scheduler-event-loop INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:24.962 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[296] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:24.962 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 128.0 with 8 tasks resource profile 0
23/10/22 22:17:24.963 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 226) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.964 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 227) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.964 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 228) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.964 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 229) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.964 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 128.0 (TID 230) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 128.0 (TID 231) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 128.0 (TID 232) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.965 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 128.0 (TID 233) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:24.966 Executor task launch worker for task 1.0 in stage 128.0 (TID 227) INFO Executor: Running task 1.0 in stage 128.0 (TID 227)
23/10/22 22:17:24.967 Executor task launch worker for task 0.0 in stage 128.0 (TID 226) INFO Executor: Running task 0.0 in stage 128.0 (TID 226)
23/10/22 22:17:24.967 Executor task launch worker for task 2.0 in stage 128.0 (TID 228) INFO Executor: Running task 2.0 in stage 128.0 (TID 228)
23/10/22 22:17:24.968 Executor task launch worker for task 3.0 in stage 128.0 (TID 229) INFO Executor: Running task 3.0 in stage 128.0 (TID 229)
23/10/22 22:17:24.968 Executor task launch worker for task 4.0 in stage 128.0 (TID 230) INFO Executor: Running task 4.0 in stage 128.0 (TID 230)
23/10/22 22:17:24.971 Executor task launch worker for task 1.0 in stage 128.0 (TID 227) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.971 Executor task launch worker for task 1.0 in stage 128.0 (TID 227) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.971 Executor task launch worker for task 5.0 in stage 128.0 (TID 231) INFO Executor: Running task 5.0 in stage 128.0 (TID 231)
23/10/22 22:17:24.971 Executor task launch worker for task 6.0 in stage 128.0 (TID 232) INFO Executor: Running task 6.0 in stage 128.0 (TID 232)
23/10/22 22:17:24.972 Executor task launch worker for task 3.0 in stage 128.0 (TID 229) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.972 Executor task launch worker for task 3.0 in stage 128.0 (TID 229) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.972 Executor task launch worker for task 2.0 in stage 128.0 (TID 228) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.972 Executor task launch worker for task 2.0 in stage 128.0 (TID 228) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.972 Executor task launch worker for task 0.0 in stage 128.0 (TID 226) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.972 Executor task launch worker for task 0.0 in stage 128.0 (TID 226) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:24.972 Executor task launch worker for task 7.0 in stage 128.0 (TID 233) INFO Executor: Running task 7.0 in stage 128.0 (TID 233)
23/10/22 22:17:24.974 Executor task launch worker for task 5.0 in stage 128.0 (TID 231) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.974 Executor task launch worker for task 6.0 in stage 128.0 (TID 232) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.974 Executor task launch worker for task 5.0 in stage 128.0 (TID 231) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.975 Executor task launch worker for task 6.0 in stage 128.0 (TID 232) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.976 Executor task launch worker for task 7.0 in stage 128.0 (TID 233) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.976 Executor task launch worker for task 7.0 in stage 128.0 (TID 233) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.978 Executor task launch worker for task 4.0 in stage 128.0 (TID 230) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:24.978 Executor task launch worker for task 4.0 in stage 128.0 (TID 230) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:24.985 Executor task launch worker for task 1.0 in stage 128.0 (TID 227) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:24.988 Executor task launch worker for task 0.0 in stage 128.0 (TID 226) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:24.989 Executor task launch worker for task 3.0 in stage 128.0 (TID 229) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.008 Executor task launch worker for task 2.0 in stage 128.0 (TID 228) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.014 Executor task launch worker for task 0.0 in stage 128.0 (TID 226) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.022 Executor task launch worker for task 3.0 in stage 128.0 (TID 229) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.023 Executor task launch worker for task 4.0 in stage 128.0 (TID 230) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.029 Executor task launch worker for task 2.0 in stage 128.0 (TID 228) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.033 Executor task launch worker for task 6.0 in stage 128.0 (TID 232) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.058 Executor task launch worker for task 5.0 in stage 128.0 (TID 231) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.061 Executor task launch worker for task 4.0 in stage 128.0 (TID 230) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.088 Executor task launch worker for task 1.0 in stage 128.0 (TID 227) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.172 Executor task launch worker for task 5.0 in stage 128.0 (TID 231) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.176 Executor task launch worker for task 6.0 in stage 128.0 (TID 232) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.181 Executor task launch worker for task 7.0 in stage 128.0 (TID 233) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.227 Executor task launch worker for task 7.0 in stage 128.0 (TID 233) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.227 Executor task launch worker for task 3.0 in stage 128.0 (TID 229) INFO Executor: Finished task 3.0 in stage 128.0 (TID 229). 4899 bytes result sent to driver
23/10/22 22:17:25.229 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 229) in 265 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:25.241 Executor task launch worker for task 4.0 in stage 128.0 (TID 230) INFO Executor: Finished task 4.0 in stage 128.0 (TID 230). 4942 bytes result sent to driver
23/10/22 22:17:25.244 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 128.0 (TID 230) in 280 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:25.263 Executor task launch worker for task 0.0 in stage 128.0 (TID 226) INFO Executor: Finished task 0.0 in stage 128.0 (TID 226). 4899 bytes result sent to driver
23/10/22 22:17:25.265 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 226) in 301 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:25.270 Executor task launch worker for task 2.0 in stage 128.0 (TID 228) INFO Executor: Finished task 2.0 in stage 128.0 (TID 228). 4899 bytes result sent to driver
23/10/22 22:17:25.272 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 228) in 308 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:25.299 Executor task launch worker for task 1.0 in stage 128.0 (TID 227) INFO Executor: Finished task 1.0 in stage 128.0 (TID 227). 4899 bytes result sent to driver
23/10/22 22:17:25.300 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 227) in 337 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:25.309 Executor task launch worker for task 6.0 in stage 128.0 (TID 232) INFO Executor: Finished task 6.0 in stage 128.0 (TID 232). 4942 bytes result sent to driver
23/10/22 22:17:25.310 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 128.0 (TID 232) in 345 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:25.332 Executor task launch worker for task 5.0 in stage 128.0 (TID 231) INFO Executor: Finished task 5.0 in stage 128.0 (TID 231). 4942 bytes result sent to driver
23/10/22 22:17:25.332 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 128.0 (TID 231) in 368 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:25.335 Executor task launch worker for task 7.0 in stage 128.0 (TID 233) INFO Executor: Finished task 7.0 in stage 128.0 (TID 233). 4942 bytes result sent to driver
23/10/22 22:17:25.336 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 128.0 (TID 233) in 371 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:25.336 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
23/10/22 22:17:25.336 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 128 (rdd at LinearRegression.scala:921) finished in 0.380 s
23/10/22 22:17:25.336 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:25.336 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:25.336 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:25.337 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:25.342 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(43), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:25.366 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.2448 ms
23/10/22 22:17:25.406 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:17:25.407 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 306 (treeAggregate at Statistics.scala:58) as input to shuffle 44
23/10/22 22:17:25.407 dag-scheduler-event-loop INFO DAGScheduler: Got job 72 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:17:25.407 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 132 (treeAggregate at Statistics.scala:58)
23/10/22 22:17:25.408 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
23/10/22 22:17:25.408 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 131)
23/10/22 22:17:25.408 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[306] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:25.412 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 89.3 KiB, free 1037.0 MiB)
23/10/22 22:17:25.413 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1036.9 MiB)
23/10/22 22:17:25.414 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:55185 (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:17:25.414 dag-scheduler-event-loop INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:25.415 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[306] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:25.415 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 131.0 with 8 tasks resource profile 0
23/10/22 22:17:25.416 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 234) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.416 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 235) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.416 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 236) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.416 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 237) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.416 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 131.0 (TID 238) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.417 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 131.0 (TID 239) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.417 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 131.0 (TID 240) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.417 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 131.0 (TID 241) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:25.417 Executor task launch worker for task 1.0 in stage 131.0 (TID 235) INFO Executor: Running task 1.0 in stage 131.0 (TID 235)
23/10/22 22:17:25.417 Executor task launch worker for task 2.0 in stage 131.0 (TID 236) INFO Executor: Running task 2.0 in stage 131.0 (TID 236)
23/10/22 22:17:25.417 Executor task launch worker for task 5.0 in stage 131.0 (TID 239) INFO Executor: Running task 5.0 in stage 131.0 (TID 239)
23/10/22 22:17:25.417 Executor task launch worker for task 4.0 in stage 131.0 (TID 238) INFO Executor: Running task 4.0 in stage 131.0 (TID 238)
23/10/22 22:17:25.417 Executor task launch worker for task 0.0 in stage 131.0 (TID 234) INFO Executor: Running task 0.0 in stage 131.0 (TID 234)
23/10/22 22:17:25.417 Executor task launch worker for task 3.0 in stage 131.0 (TID 237) INFO Executor: Running task 3.0 in stage 131.0 (TID 237)
23/10/22 22:17:25.417 Executor task launch worker for task 7.0 in stage 131.0 (TID 241) INFO Executor: Running task 7.0 in stage 131.0 (TID 241)
23/10/22 22:17:25.417 Executor task launch worker for task 6.0 in stage 131.0 (TID 240) INFO Executor: Running task 6.0 in stage 131.0 (TID 240)
23/10/22 22:17:25.426 Executor task launch worker for task 7.0 in stage 131.0 (TID 241) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.427 Executor task launch worker for task 7.0 in stage 131.0 (TID 241) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.429 Executor task launch worker for task 4.0 in stage 131.0 (TID 238) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.429 Executor task launch worker for task 4.0 in stage 131.0 (TID 238) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.430 Executor task launch worker for task 0.0 in stage 131.0 (TID 234) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.430 Executor task launch worker for task 0.0 in stage 131.0 (TID 234) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.431 Executor task launch worker for task 1.0 in stage 131.0 (TID 235) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.431 Executor task launch worker for task 2.0 in stage 131.0 (TID 236) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.431 Executor task launch worker for task 1.0 in stage 131.0 (TID 235) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.431 Executor task launch worker for task 2.0 in stage 131.0 (TID 236) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.431 Executor task launch worker for task 5.0 in stage 131.0 (TID 239) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.431 Executor task launch worker for task 5.0 in stage 131.0 (TID 239) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.433 Executor task launch worker for task 3.0 in stage 131.0 (TID 237) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.433 Executor task launch worker for task 3.0 in stage 131.0 (TID 237) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.435 Executor task launch worker for task 6.0 in stage 131.0 (TID 240) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.435 Executor task launch worker for task 6.0 in stage 131.0 (TID 240) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.446 Executor task launch worker for task 7.0 in stage 131.0 (TID 241) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.447 Executor task launch worker for task 1.0 in stage 131.0 (TID 235) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.447 Executor task launch worker for task 4.0 in stage 131.0 (TID 238) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.451 Executor task launch worker for task 5.0 in stage 131.0 (TID 239) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.452 Executor task launch worker for task 2.0 in stage 131.0 (TID 236) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.453 Executor task launch worker for task 0.0 in stage 131.0 (TID 234) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.457 Executor task launch worker for task 3.0 in stage 131.0 (TID 237) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.480 Executor task launch worker for task 6.0 in stage 131.0 (TID 240) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:25.515 Executor task launch worker for task 2.0 in stage 131.0 (TID 236) INFO Executor: Finished task 2.0 in stage 131.0 (TID 236). 6562 bytes result sent to driver
23/10/22 22:17:25.517 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 236) in 101 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:25.521 Executor task launch worker for task 3.0 in stage 131.0 (TID 237) INFO Executor: Finished task 3.0 in stage 131.0 (TID 237). 6605 bytes result sent to driver
23/10/22 22:17:25.522 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 237) in 106 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:25.526 Executor task launch worker for task 4.0 in stage 131.0 (TID 238) INFO Executor: Finished task 4.0 in stage 131.0 (TID 238). 6605 bytes result sent to driver
23/10/22 22:17:25.527 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 131.0 (TID 238) in 111 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:25.534 Executor task launch worker for task 5.0 in stage 131.0 (TID 239) INFO Executor: Finished task 5.0 in stage 131.0 (TID 239). 6562 bytes result sent to driver
23/10/22 22:17:25.535 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 131.0 (TID 239) in 119 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:25.539 Executor task launch worker for task 7.0 in stage 131.0 (TID 241) INFO Executor: Finished task 7.0 in stage 131.0 (TID 241). 6562 bytes result sent to driver
23/10/22 22:17:25.540 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 131.0 (TID 241) in 123 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:25.543 Executor task launch worker for task 0.0 in stage 131.0 (TID 234) INFO Executor: Finished task 0.0 in stage 131.0 (TID 234). 6605 bytes result sent to driver
23/10/22 22:17:25.545 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 234) in 129 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:25.556 Executor task launch worker for task 6.0 in stage 131.0 (TID 240) INFO Executor: Finished task 6.0 in stage 131.0 (TID 240). 6562 bytes result sent to driver
23/10/22 22:17:25.557 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 131.0 (TID 240) in 140 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:25.561 Executor task launch worker for task 1.0 in stage 131.0 (TID 235) INFO Executor: Finished task 1.0 in stage 131.0 (TID 235). 6562 bytes result sent to driver
23/10/22 22:17:25.562 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 235) in 145 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:25.562 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
23/10/22 22:17:25.562 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 131 (treeAggregate at Statistics.scala:58) finished in 0.153 s
23/10/22 22:17:25.562 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:25.562 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:25.562 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 132)
23/10/22 22:17:25.562 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:25.563 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[308] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:25.570 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 90.4 KiB, free 1036.8 MiB)
23/10/22 22:17:25.573 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 22:17:25.574 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:55185 (size: 37.6 KiB, free: 1037.0 MiB)
23/10/22 22:17:25.575 dag-scheduler-event-loop INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:25.575 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 132 (MapPartitionsRDD[308] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:25.575 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 132.0 with 2 tasks resource profile 0
23/10/22 22:17:25.576 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 242) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:25.576 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 243) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:25.577 Executor task launch worker for task 0.0 in stage 132.0 (TID 242) INFO Executor: Running task 0.0 in stage 132.0 (TID 242)
23/10/22 22:17:25.577 Executor task launch worker for task 1.0 in stage 132.0 (TID 243) INFO Executor: Running task 1.0 in stage 132.0 (TID 243)
23/10/22 22:17:25.585 Executor task launch worker for task 1.0 in stage 132.0 (TID 243) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.585 Executor task launch worker for task 0.0 in stage 132.0 (TID 242) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:25.585 Executor task launch worker for task 1.0 in stage 132.0 (TID 243) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.585 Executor task launch worker for task 0.0 in stage 132.0 (TID 242) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:25.592 Executor task launch worker for task 1.0 in stage 132.0 (TID 243) INFO Executor: Finished task 1.0 in stage 132.0 (TID 243). 7630 bytes result sent to driver
23/10/22 22:17:25.592 Executor task launch worker for task 0.0 in stage 132.0 (TID 242) INFO Executor: Finished task 0.0 in stage 132.0 (TID 242). 7630 bytes result sent to driver
23/10/22 22:17:25.592 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 243) in 16 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:25.592 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 242) in 16 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:25.593 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
23/10/22 22:17:25.593 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 132 (treeAggregate at Statistics.scala:58) finished in 0.030 s
23/10/22 22:17:25.593 dag-scheduler-event-loop INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:25.593 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 132: Stage finished
23/10/22 22:17:25.593 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 72 finished: treeAggregate at Statistics.scala:58, took 0.186823 s
23/10/22 22:17:25.594 nioEventLoopGroup-2-2 INFO Instrumentation: [db728b3f] training finished
23/10/22 22:17:26.196 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:26.197 dag-scheduler-event-loop INFO DAGScheduler: Got job 73 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:26.197 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 133 (collect at utils.scala:26)
23/10/22 22:17:26.197 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:26.197 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:26.197 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[310] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:26.198 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:26.199 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:26.200 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:26.200 dag-scheduler-event-loop INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:26.200 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[310] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:26.200 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
23/10/22 22:17:26.200 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 244) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:26.201 Executor task launch worker for task 0.0 in stage 133.0 (TID 244) INFO Executor: Running task 0.0 in stage 133.0 (TID 244)
23/10/22 22:17:26.202 Executor task launch worker for task 0.0 in stage 133.0 (TID 244) INFO Executor: Finished task 0.0 in stage 133.0 (TID 244). 1284 bytes result sent to driver
23/10/22 22:17:26.203 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 244) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:26.203 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
23/10/22 22:17:26.203 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 133 (collect at utils.scala:26) finished in 0.005 s
23/10/22 22:17:26.203 dag-scheduler-event-loop INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:26.203 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
23/10/22 22:17:26.203 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 73 finished: collect at utils.scala:26, took 0.007213 s
23/10/22 22:17:26.446 nioEventLoopGroup-2-2 INFO Instrumentation: [34cd3844] training finished
23/10/22 22:17:26.533 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:26.534 dag-scheduler-event-loop INFO DAGScheduler: Got job 74 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:26.534 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 134 (collect at utils.scala:26)
23/10/22 22:17:26.534 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:26.535 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:26.535 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[312] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:26.536 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:26.537 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:26.538 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:26.538 dag-scheduler-event-loop INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:26.538 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[312] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:26.538 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0
23/10/22 22:17:26.539 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 245) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:26.539 Executor task launch worker for task 0.0 in stage 134.0 (TID 245) INFO Executor: Running task 0.0 in stage 134.0 (TID 245)
23/10/22 22:17:26.541 Executor task launch worker for task 0.0 in stage 134.0 (TID 245) INFO Executor: Finished task 0.0 in stage 134.0 (TID 245). 1327 bytes result sent to driver
23/10/22 22:17:26.542 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 245) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:26.542 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
23/10/22 22:17:26.542 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 134 (collect at utils.scala:26) finished in 0.007 s
23/10/22 22:17:26.542 dag-scheduler-event-loop INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:26.542 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 134: Stage finished
23/10/22 22:17:26.542 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 74 finished: collect at utils.scala:26, took 0.008898 s
23/10/22 22:17:26.977 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:26.977 dag-scheduler-event-loop INFO DAGScheduler: Got job 75 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:26.978 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 135 (collect at utils.scala:26)
23/10/22 22:17:26.978 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:26.978 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:26.978 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[314] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:26.978 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:26.979 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:26.979 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:26.980 dag-scheduler-event-loop INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:26.980 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[314] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:26.980 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0
23/10/22 22:17:26.981 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 246) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:26.981 Executor task launch worker for task 0.0 in stage 135.0 (TID 246) INFO Executor: Running task 0.0 in stage 135.0 (TID 246)
23/10/22 22:17:26.982 Executor task launch worker for task 0.0 in stage 135.0 (TID 246) INFO Executor: Finished task 0.0 in stage 135.0 (TID 246). 1284 bytes result sent to driver
23/10/22 22:17:26.983 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 246) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:26.983 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
23/10/22 22:17:26.983 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 135 (collect at utils.scala:26) finished in 0.005 s
23/10/22 22:17:26.983 dag-scheduler-event-loop INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:26.983 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished
23/10/22 22:17:26.983 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 75 finished: collect at utils.scala:26, took 0.006370 s
23/10/22 22:17:36.323 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:36.323 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 22:17:36.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:55185 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:36.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:36.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:55185 in memory (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:17:36.327 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:36.333 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:36.334 dag-scheduler-event-loop INFO DAGScheduler: Got job 76 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:36.334 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 136 (collect at utils.scala:26)
23/10/22 22:17:36.334 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:36.334 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:36.334 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[316] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:36.337 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 7.3 KiB, free 1037.1 MiB)
23/10/22 22:17:36.339 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:17:36.339 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:36.339 dag-scheduler-event-loop INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:36.340 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[316] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:36.340 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
23/10/22 22:17:36.340 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 247) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:36.341 Executor task launch worker for task 0.0 in stage 136.0 (TID 247) INFO Executor: Running task 0.0 in stage 136.0 (TID 247)
23/10/22 22:17:36.343 Executor task launch worker for task 0.0 in stage 136.0 (TID 247) INFO Executor: Finished task 0.0 in stage 136.0 (TID 247). 1327 bytes result sent to driver
23/10/22 22:17:36.343 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 247) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:36.343 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
23/10/22 22:17:36.343 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 136 (collect at utils.scala:26) finished in 0.008 s
23/10/22 22:17:36.343 dag-scheduler-event-loop INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:36.343 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
23/10/22 22:17:36.343 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 76 finished: collect at utils.scala:26, took 0.010619 s
23/10/22 22:17:36.484 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:36.485 dag-scheduler-event-loop INFO DAGScheduler: Got job 77 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:36.485 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 137 (collect at utils.scala:26)
23/10/22 22:17:36.485 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:36.486 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:36.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[318] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:36.487 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 7.3 KiB, free 1037.1 MiB)
23/10/22 22:17:36.487 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:17:36.488 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:36.488 dag-scheduler-event-loop INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:36.488 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[318] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:36.488 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0
23/10/22 22:17:36.489 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 248) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:36.489 Executor task launch worker for task 0.0 in stage 137.0 (TID 248) INFO Executor: Running task 0.0 in stage 137.0 (TID 248)
23/10/22 22:17:36.491 Executor task launch worker for task 0.0 in stage 137.0 (TID 248) INFO Executor: Finished task 0.0 in stage 137.0 (TID 248). 1284 bytes result sent to driver
23/10/22 22:17:36.491 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 248) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:36.491 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
23/10/22 22:17:36.491 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 137 (collect at utils.scala:26) finished in 0.005 s
23/10/22 22:17:36.491 dag-scheduler-event-loop INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:36.491 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
23/10/22 22:17:36.492 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 77 finished: collect at utils.scala:26, took 0.006745 s
23/10/22 22:17:37.316 nioEventLoopGroup-2-2 INFO Instrumentation: [6f5a1b04] training finished
23/10/22 22:17:37.366 nioEventLoopGroup-2-2 INFO Instrumentation: [8041d6f1] training finished
23/10/22 22:17:37.372 nioEventLoopGroup-2-2 INFO Instrumentation: [0be1d95c] Stage class: LinearRegression
23/10/22 22:17:37.372 nioEventLoopGroup-2-2 INFO Instrumentation: [0be1d95c] Stage uid: linear_regression__72641e05_3afe_4edc_9f5f_25d899844b50
23/10/22 22:17:37.401 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 321 (rdd at Instrumentation.scala:62) as input to shuffle 45
23/10/22 22:17:37.401 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 78 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:17:37.401 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 138 (rdd at Instrumentation.scala:62)
23/10/22 22:17:37.401 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:37.401 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:37.402 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[321] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:37.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:17:37.405 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:37.405 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:37.405 dag-scheduler-event-loop INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:37.406 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[321] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:37.406 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0
23/10/22 22:17:37.801 dispatcher-event-loop-2 WARN TaskSetManager: Stage 138 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:37.801 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 249) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:37.802 Executor task launch worker for task 0.0 in stage 138.0 (TID 249) INFO Executor: Running task 0.0 in stage 138.0 (TID 249)
23/10/22 22:17:37.923 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:37.925 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:38.081 Executor task launch worker for task 0.0 in stage 138.0 (TID 249) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:38.231 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:39.474 Executor task launch worker for task 0.0 in stage 138.0 (TID 249) INFO Executor: Finished task 0.0 in stage 138.0 (TID 249). 2147 bytes result sent to driver
23/10/22 22:17:39.477 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 249) in 2071 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:39.477 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
23/10/22 22:17:39.478 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 138 (rdd at Instrumentation.scala:62) finished in 2.075 s
23/10/22 22:17:39.478 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:39.478 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:39.479 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:39.479 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:39.486 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(45), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:39.492 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 325 (rdd at Instrumentation.scala:62) as input to shuffle 46
23/10/22 22:17:39.493 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 79 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:17:39.493 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 140 (rdd at Instrumentation.scala:62)
23/10/22 22:17:39.493 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 139)
23/10/22 22:17:39.493 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:39.493 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[325] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:39.498 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:39.500 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:39.502 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:39.504 dag-scheduler-event-loop INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:39.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[325] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:39.505 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 140.0 with 8 tasks resource profile 0
23/10/22 22:17:39.508 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 250) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.508 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 251) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.509 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 140.0 (TID 252) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.509 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 140.0 (TID 253) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.511 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 140.0 (TID 254) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.511 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 140.0 (TID 255) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.511 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 140.0 (TID 256) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.511 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 140.0 (TID 257) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:39.512 Executor task launch worker for task 1.0 in stage 140.0 (TID 251) INFO Executor: Running task 1.0 in stage 140.0 (TID 251)
23/10/22 22:17:39.512 Executor task launch worker for task 2.0 in stage 140.0 (TID 252) INFO Executor: Running task 2.0 in stage 140.0 (TID 252)
23/10/22 22:17:39.512 Executor task launch worker for task 4.0 in stage 140.0 (TID 254) INFO Executor: Running task 4.0 in stage 140.0 (TID 254)
23/10/22 22:17:39.512 Executor task launch worker for task 5.0 in stage 140.0 (TID 255) INFO Executor: Running task 5.0 in stage 140.0 (TID 255)
23/10/22 22:17:39.512 Executor task launch worker for task 7.0 in stage 140.0 (TID 257) INFO Executor: Running task 7.0 in stage 140.0 (TID 257)
23/10/22 22:17:39.512 Executor task launch worker for task 0.0 in stage 140.0 (TID 250) INFO Executor: Running task 0.0 in stage 140.0 (TID 250)
23/10/22 22:17:39.512 Executor task launch worker for task 6.0 in stage 140.0 (TID 256) INFO Executor: Running task 6.0 in stage 140.0 (TID 256)
23/10/22 22:17:39.520 Executor task launch worker for task 5.0 in stage 140.0 (TID 255) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.526 Executor task launch worker for task 5.0 in stage 140.0 (TID 255) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
23/10/22 22:17:39.528 Executor task launch worker for task 2.0 in stage 140.0 (TID 252) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.528 Executor task launch worker for task 2.0 in stage 140.0 (TID 252) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:39.528 Executor task launch worker for task 0.0 in stage 140.0 (TID 250) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.528 Executor task launch worker for task 0.0 in stage 140.0 (TID 250) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
23/10/22 22:17:39.512 Executor task launch worker for task 3.0 in stage 140.0 (TID 253) INFO Executor: Running task 3.0 in stage 140.0 (TID 253)
23/10/22 22:17:39.532 Executor task launch worker for task 1.0 in stage 140.0 (TID 251) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.532 Executor task launch worker for task 1.0 in stage 140.0 (TID 251) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:39.520 Executor task launch worker for task 6.0 in stage 140.0 (TID 256) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.533 Executor task launch worker for task 6.0 in stage 140.0 (TID 256) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
23/10/22 22:17:39.536 Executor task launch worker for task 7.0 in stage 140.0 (TID 257) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.537 Executor task launch worker for task 7.0 in stage 140.0 (TID 257) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:39.540 Executor task launch worker for task 4.0 in stage 140.0 (TID 254) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.540 Executor task launch worker for task 4.0 in stage 140.0 (TID 254) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:39.540 Executor task launch worker for task 3.0 in stage 140.0 (TID 253) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:39.540 Executor task launch worker for task 3.0 in stage 140.0 (TID 253) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:39.553 Executor task launch worker for task 5.0 in stage 140.0 (TID 255) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.554 Executor task launch worker for task 1.0 in stage 140.0 (TID 251) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.554 Executor task launch worker for task 2.0 in stage 140.0 (TID 252) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.557 Executor task launch worker for task 3.0 in stage 140.0 (TID 253) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.558 Executor task launch worker for task 4.0 in stage 140.0 (TID 254) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.585 Executor task launch worker for task 7.0 in stage 140.0 (TID 257) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.585 Executor task launch worker for task 6.0 in stage 140.0 (TID 256) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.599 Executor task launch worker for task 4.0 in stage 140.0 (TID 254) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.603 Executor task launch worker for task 0.0 in stage 140.0 (TID 250) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.607 Executor task launch worker for task 3.0 in stage 140.0 (TID 253) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.608 Executor task launch worker for task 1.0 in stage 140.0 (TID 251) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.633 Executor task launch worker for task 6.0 in stage 140.0 (TID 256) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.643 Executor task launch worker for task 5.0 in stage 140.0 (TID 255) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.694 Executor task launch worker for task 7.0 in stage 140.0 (TID 257) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.696 Executor task launch worker for task 0.0 in stage 140.0 (TID 250) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.713 Executor task launch worker for task 2.0 in stage 140.0 (TID 252) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:39.822 Executor task launch worker for task 4.0 in stage 140.0 (TID 254) INFO Executor: Finished task 4.0 in stage 140.0 (TID 254). 4899 bytes result sent to driver
23/10/22 22:17:39.823 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 140.0 (TID 254) in 314 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:39.832 Executor task launch worker for task 1.0 in stage 140.0 (TID 251) INFO Executor: Finished task 1.0 in stage 140.0 (TID 251). 4899 bytes result sent to driver
23/10/22 22:17:39.834 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 251) in 326 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:39.869 Executor task launch worker for task 3.0 in stage 140.0 (TID 253) INFO Executor: Finished task 3.0 in stage 140.0 (TID 253). 4899 bytes result sent to driver
23/10/22 22:17:39.871 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 140.0 (TID 253) in 362 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:39.908 Executor task launch worker for task 5.0 in stage 140.0 (TID 255) INFO Executor: Finished task 5.0 in stage 140.0 (TID 255). 4899 bytes result sent to driver
23/10/22 22:17:39.908 Executor task launch worker for task 6.0 in stage 140.0 (TID 256) INFO Executor: Finished task 6.0 in stage 140.0 (TID 256). 4899 bytes result sent to driver
23/10/22 22:17:39.909 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 140.0 (TID 255) in 398 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:39.910 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 140.0 (TID 256) in 399 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:39.930 Executor task launch worker for task 7.0 in stage 140.0 (TID 257) INFO Executor: Finished task 7.0 in stage 140.0 (TID 257). 4942 bytes result sent to driver
23/10/22 22:17:39.931 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 140.0 (TID 257) in 420 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:39.937 Executor task launch worker for task 2.0 in stage 140.0 (TID 252) INFO Executor: Finished task 2.0 in stage 140.0 (TID 252). 4899 bytes result sent to driver
23/10/22 22:17:39.939 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 140.0 (TID 252) in 431 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:39.942 Executor task launch worker for task 0.0 in stage 140.0 (TID 250) INFO Executor: Finished task 0.0 in stage 140.0 (TID 250). 4899 bytes result sent to driver
23/10/22 22:17:39.945 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 250) in 437 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:39.945 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
23/10/22 22:17:39.945 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 140 (rdd at Instrumentation.scala:62) finished in 0.450 s
23/10/22 22:17:39.945 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:39.946 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:39.946 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:39.946 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:39.951 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(46), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:39.976 nioEventLoopGroup-2-2 INFO Instrumentation: [0be1d95c] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:17:39.977 nioEventLoopGroup-2-2 INFO Instrumentation: [0be1d95c] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:17:39.979 nioEventLoopGroup-2-2 INFO Instrumentation: [0be1d95c] {"numFeatures":1}
23/10/22 22:17:40.084 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 334 (rdd at LinearRegression.scala:348) as input to shuffle 47
23/10/22 22:17:40.085 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 80 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:17:40.085 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 141 (rdd at LinearRegression.scala:348)
23/10/22 22:17:40.085 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:40.086 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:40.087 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 141 (MapPartitionsRDD[334] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:40.091 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:17:40.093 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:40.093 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:40.094 dag-scheduler-event-loop INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:40.095 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 141 (MapPartitionsRDD[334] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:40.095 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0
23/10/22 22:17:40.874 dispatcher-event-loop-6 WARN TaskSetManager: Stage 141 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:40.874 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 258) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:40.874 Executor task launch worker for task 0.0 in stage 141.0 (TID 258) INFO Executor: Running task 0.0 in stage 141.0 (TID 258)
23/10/22 22:17:41.054 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:41.138 Executor task launch worker for task 0.0 in stage 141.0 (TID 258) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:41.307 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:42.111 Executor task launch worker for task 0.0 in stage 141.0 (TID 258) INFO Executor: Finished task 0.0 in stage 141.0 (TID 258). 2147 bytes result sent to driver
23/10/22 22:17:42.112 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 258) in 2015 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:42.112 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
23/10/22 22:17:42.113 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 141 (rdd at LinearRegression.scala:348) finished in 2.024 s
23/10/22 22:17:42.113 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:42.113 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:42.113 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:42.113 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:42.118 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(47), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:42.121 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 338 (rdd at LinearRegression.scala:348) as input to shuffle 48
23/10/22 22:17:42.121 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 81 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:17:42.121 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 143 (rdd at LinearRegression.scala:348)
23/10/22 22:17:42.121 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)
23/10/22 22:17:42.121 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:42.121 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 143 (MapPartitionsRDD[338] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:42.123 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:42.124 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:42.124 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:42.125 dag-scheduler-event-loop INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:42.125 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 143 (MapPartitionsRDD[338] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:42.125 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 143.0 with 8 tasks resource profile 0
23/10/22 22:17:42.126 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 259) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.126 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 260) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.126 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 143.0 (TID 261) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.126 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 143.0 (TID 262) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.126 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 143.0 (TID 263) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.126 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 143.0 (TID 264) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.127 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 143.0 (TID 265) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.127 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 143.0 (TID 266) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.127 Executor task launch worker for task 1.0 in stage 143.0 (TID 260) INFO Executor: Running task 1.0 in stage 143.0 (TID 260)
23/10/22 22:17:42.127 Executor task launch worker for task 5.0 in stage 143.0 (TID 264) INFO Executor: Running task 5.0 in stage 143.0 (TID 264)
23/10/22 22:17:42.127 Executor task launch worker for task 3.0 in stage 143.0 (TID 262) INFO Executor: Running task 3.0 in stage 143.0 (TID 262)
23/10/22 22:17:42.127 Executor task launch worker for task 6.0 in stage 143.0 (TID 265) INFO Executor: Running task 6.0 in stage 143.0 (TID 265)
23/10/22 22:17:42.127 Executor task launch worker for task 2.0 in stage 143.0 (TID 261) INFO Executor: Running task 2.0 in stage 143.0 (TID 261)
23/10/22 22:17:42.127 Executor task launch worker for task 0.0 in stage 143.0 (TID 259) INFO Executor: Running task 0.0 in stage 143.0 (TID 259)
23/10/22 22:17:42.127 Executor task launch worker for task 7.0 in stage 143.0 (TID 266) INFO Executor: Running task 7.0 in stage 143.0 (TID 266)
23/10/22 22:17:42.127 Executor task launch worker for task 4.0 in stage 143.0 (TID 263) INFO Executor: Running task 4.0 in stage 143.0 (TID 263)
23/10/22 22:17:42.135 Executor task launch worker for task 2.0 in stage 143.0 (TID 261) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.136 Executor task launch worker for task 2.0 in stage 143.0 (TID 261) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:42.139 Executor task launch worker for task 4.0 in stage 143.0 (TID 263) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.140 Executor task launch worker for task 4.0 in stage 143.0 (TID 263) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.141 Executor task launch worker for task 7.0 in stage 143.0 (TID 266) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.141 Executor task launch worker for task 7.0 in stage 143.0 (TID 266) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.135 Executor task launch worker for task 6.0 in stage 143.0 (TID 265) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.141 Executor task launch worker for task 6.0 in stage 143.0 (TID 265) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
23/10/22 22:17:42.139 Executor task launch worker for task 3.0 in stage 143.0 (TID 262) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.139 Executor task launch worker for task 5.0 in stage 143.0 (TID 264) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.149 Executor task launch worker for task 3.0 in stage 143.0 (TID 262) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
23/10/22 22:17:42.144 Executor task launch worker for task 1.0 in stage 143.0 (TID 260) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.149 Executor task launch worker for task 1.0 in stage 143.0 (TID 260) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
23/10/22 22:17:42.149 Executor task launch worker for task 2.0 in stage 143.0 (TID 261) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.142 Executor task launch worker for task 0.0 in stage 143.0 (TID 259) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.150 Executor task launch worker for task 0.0 in stage 143.0 (TID 259) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
23/10/22 22:17:42.151 Executor task launch worker for task 4.0 in stage 143.0 (TID 263) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.149 Executor task launch worker for task 5.0 in stage 143.0 (TID 264) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
23/10/22 22:17:42.156 Executor task launch worker for task 7.0 in stage 143.0 (TID 266) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.164 Executor task launch worker for task 1.0 in stage 143.0 (TID 260) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.172 Executor task launch worker for task 0.0 in stage 143.0 (TID 259) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.173 Executor task launch worker for task 2.0 in stage 143.0 (TID 261) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.178 Executor task launch worker for task 4.0 in stage 143.0 (TID 263) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.181 Executor task launch worker for task 7.0 in stage 143.0 (TID 266) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.190 Executor task launch worker for task 3.0 in stage 143.0 (TID 262) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.192 Executor task launch worker for task 1.0 in stage 143.0 (TID 260) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.201 Executor task launch worker for task 5.0 in stage 143.0 (TID 264) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.207 Executor task launch worker for task 6.0 in stage 143.0 (TID 265) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.210 Executor task launch worker for task 3.0 in stage 143.0 (TID 262) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.247 Executor task launch worker for task 0.0 in stage 143.0 (TID 259) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.256 Executor task launch worker for task 5.0 in stage 143.0 (TID 264) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.266 Executor task launch worker for task 6.0 in stage 143.0 (TID 265) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.353 Executor task launch worker for task 4.0 in stage 143.0 (TID 263) INFO Executor: Finished task 4.0 in stage 143.0 (TID 263). 4899 bytes result sent to driver
23/10/22 22:17:42.353 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 143.0 (TID 263) in 227 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:42.369 Executor task launch worker for task 1.0 in stage 143.0 (TID 260) INFO Executor: Finished task 1.0 in stage 143.0 (TID 260). 4899 bytes result sent to driver
23/10/22 22:17:42.370 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 260) in 244 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:42.375 Executor task launch worker for task 3.0 in stage 143.0 (TID 262) INFO Executor: Finished task 3.0 in stage 143.0 (TID 262). 4899 bytes result sent to driver
23/10/22 22:17:42.376 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 143.0 (TID 262) in 250 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:42.379 Executor task launch worker for task 2.0 in stage 143.0 (TID 261) INFO Executor: Finished task 2.0 in stage 143.0 (TID 261). 4942 bytes result sent to driver
23/10/22 22:17:42.380 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 143.0 (TID 261) in 254 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:42.384 Executor task launch worker for task 6.0 in stage 143.0 (TID 265) INFO Executor: Finished task 6.0 in stage 143.0 (TID 265). 4899 bytes result sent to driver
23/10/22 22:17:42.384 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 143.0 (TID 265) in 257 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:42.396 Executor task launch worker for task 5.0 in stage 143.0 (TID 264) INFO Executor: Finished task 5.0 in stage 143.0 (TID 264). 4899 bytes result sent to driver
23/10/22 22:17:42.396 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 143.0 (TID 264) in 270 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:42.401 Executor task launch worker for task 7.0 in stage 143.0 (TID 266) INFO Executor: Finished task 7.0 in stage 143.0 (TID 266). 4899 bytes result sent to driver
23/10/22 22:17:42.403 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 143.0 (TID 266) in 276 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:42.410 Executor task launch worker for task 0.0 in stage 143.0 (TID 259) INFO Executor: Finished task 0.0 in stage 143.0 (TID 259). 4899 bytes result sent to driver
23/10/22 22:17:42.411 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 259) in 285 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:42.411 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
23/10/22 22:17:42.411 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 143 (rdd at LinearRegression.scala:348) finished in 0.289 s
23/10/22 22:17:42.411 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:42.412 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:42.412 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:42.412 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:42.417 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(48), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:42.433 nioEventLoopGroup-2-2 WARN Instrumentation: [0be1d95c] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:17:42.455 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:17:42.456 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 347 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 49
23/10/22 22:17:42.456 dag-scheduler-event-loop INFO DAGScheduler: Got job 82 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:17:42.456 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 147 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:17:42.456 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
23/10/22 22:17:42.456 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 146)
23/10/22 22:17:42.456 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[347] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:42.460 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 92.1 KiB, free 1037.0 MiB)
23/10/22 22:17:42.461 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 1036.9 MiB)
23/10/22 22:17:42.461 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:55185 (size: 36.5 KiB, free: 1037.1 MiB)
23/10/22 22:17:42.461 dag-scheduler-event-loop INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:42.462 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[347] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:42.462 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 146.0 with 8 tasks resource profile 0
23/10/22 22:17:42.463 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 267) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.463 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 268) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.463 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 146.0 (TID 269) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.464 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 146.0 (TID 270) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.464 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 146.0 (TID 271) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.464 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 146.0 (TID 272) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.464 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 146.0 (TID 273) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.464 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 146.0 (TID 274) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:42.464 Executor task launch worker for task 0.0 in stage 146.0 (TID 267) INFO Executor: Running task 0.0 in stage 146.0 (TID 267)
23/10/22 22:17:42.464 Executor task launch worker for task 2.0 in stage 146.0 (TID 269) INFO Executor: Running task 2.0 in stage 146.0 (TID 269)
23/10/22 22:17:42.464 Executor task launch worker for task 5.0 in stage 146.0 (TID 272) INFO Executor: Running task 5.0 in stage 146.0 (TID 272)
23/10/22 22:17:42.464 Executor task launch worker for task 1.0 in stage 146.0 (TID 268) INFO Executor: Running task 1.0 in stage 146.0 (TID 268)
23/10/22 22:17:42.464 Executor task launch worker for task 3.0 in stage 146.0 (TID 270) INFO Executor: Running task 3.0 in stage 146.0 (TID 270)
23/10/22 22:17:42.464 Executor task launch worker for task 4.0 in stage 146.0 (TID 271) INFO Executor: Running task 4.0 in stage 146.0 (TID 271)
23/10/22 22:17:42.465 Executor task launch worker for task 6.0 in stage 146.0 (TID 273) INFO Executor: Running task 6.0 in stage 146.0 (TID 273)
23/10/22 22:17:42.464 Executor task launch worker for task 7.0 in stage 146.0 (TID 274) INFO Executor: Running task 7.0 in stage 146.0 (TID 274)
23/10/22 22:17:42.473 Executor task launch worker for task 1.0 in stage 146.0 (TID 268) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.473 Executor task launch worker for task 3.0 in stage 146.0 (TID 270) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.473 Executor task launch worker for task 1.0 in stage 146.0 (TID 268) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.473 Executor task launch worker for task 3.0 in stage 146.0 (TID 270) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.473 Executor task launch worker for task 7.0 in stage 146.0 (TID 274) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.473 Executor task launch worker for task 4.0 in stage 146.0 (TID 271) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.473 Executor task launch worker for task 7.0 in stage 146.0 (TID 274) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.473 Executor task launch worker for task 4.0 in stage 146.0 (TID 271) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.473 Executor task launch worker for task 6.0 in stage 146.0 (TID 273) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.473 Executor task launch worker for task 6.0 in stage 146.0 (TID 273) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.474 Executor task launch worker for task 0.0 in stage 146.0 (TID 267) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.474 Executor task launch worker for task 0.0 in stage 146.0 (TID 267) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.479 Executor task launch worker for task 5.0 in stage 146.0 (TID 272) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.479 Executor task launch worker for task 5.0 in stage 146.0 (TID 272) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.479 Executor task launch worker for task 2.0 in stage 146.0 (TID 269) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.480 Executor task launch worker for task 2.0 in stage 146.0 (TID 269) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.488 Executor task launch worker for task 4.0 in stage 146.0 (TID 271) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.488 Executor task launch worker for task 7.0 in stage 146.0 (TID 274) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.488 Executor task launch worker for task 3.0 in stage 146.0 (TID 270) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.488 Executor task launch worker for task 6.0 in stage 146.0 (TID 273) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.503 Executor task launch worker for task 5.0 in stage 146.0 (TID 272) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.504 Executor task launch worker for task 0.0 in stage 146.0 (TID 267) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.509 Executor task launch worker for task 1.0 in stage 146.0 (TID 268) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.512 Executor task launch worker for task 2.0 in stage 146.0 (TID 269) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:42.539 Executor task launch worker for task 4.0 in stage 146.0 (TID 271) INFO Executor: Finished task 4.0 in stage 146.0 (TID 271). 6562 bytes result sent to driver
23/10/22 22:17:42.540 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 146.0 (TID 271) in 76 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:42.543 Executor task launch worker for task 6.0 in stage 146.0 (TID 273) INFO Executor: Finished task 6.0 in stage 146.0 (TID 273). 6562 bytes result sent to driver
23/10/22 22:17:42.544 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 146.0 (TID 273) in 80 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:42.554 Executor task launch worker for task 7.0 in stage 146.0 (TID 274) INFO Executor: Finished task 7.0 in stage 146.0 (TID 274). 6562 bytes result sent to driver
23/10/22 22:17:42.554 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 146.0 (TID 274) in 90 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:42.557 Executor task launch worker for task 3.0 in stage 146.0 (TID 270) INFO Executor: Finished task 3.0 in stage 146.0 (TID 270). 6562 bytes result sent to driver
23/10/22 22:17:42.559 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 146.0 (TID 270) in 95 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:42.565 Executor task launch worker for task 5.0 in stage 146.0 (TID 272) INFO Executor: Finished task 5.0 in stage 146.0 (TID 272). 6605 bytes result sent to driver
23/10/22 22:17:42.566 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 146.0 (TID 272) in 102 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:42.570 Executor task launch worker for task 0.0 in stage 146.0 (TID 267) INFO Executor: Finished task 0.0 in stage 146.0 (TID 267). 6605 bytes result sent to driver
23/10/22 22:17:42.570 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 267) in 107 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:42.574 Executor task launch worker for task 1.0 in stage 146.0 (TID 268) INFO Executor: Finished task 1.0 in stage 146.0 (TID 268). 6562 bytes result sent to driver
23/10/22 22:17:42.575 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 268) in 111 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:42.578 Executor task launch worker for task 2.0 in stage 146.0 (TID 269) INFO Executor: Finished task 2.0 in stage 146.0 (TID 269). 6605 bytes result sent to driver
23/10/22 22:17:42.578 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 146.0 (TID 269) in 115 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:42.578 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
23/10/22 22:17:42.579 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 146 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.121 s
23/10/22 22:17:42.579 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:42.579 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:42.579 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 147)
23/10/22 22:17:42.579 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:42.579 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[349] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:42.582 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 93.2 KiB, free 1036.8 MiB)
23/10/22 22:17:42.583 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 1036.8 MiB)
23/10/22 22:17:42.584 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:55185 (size: 37.2 KiB, free: 1037.0 MiB)
23/10/22 22:17:42.584 dag-scheduler-event-loop INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:42.585 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 147 (MapPartitionsRDD[349] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:42.585 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 147.0 with 2 tasks resource profile 0
23/10/22 22:17:42.586 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 275) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:42.586 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 276) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:42.586 Executor task launch worker for task 0.0 in stage 147.0 (TID 275) INFO Executor: Running task 0.0 in stage 147.0 (TID 275)
23/10/22 22:17:42.586 Executor task launch worker for task 1.0 in stage 147.0 (TID 276) INFO Executor: Running task 1.0 in stage 147.0 (TID 276)
23/10/22 22:17:42.592 Executor task launch worker for task 1.0 in stage 147.0 (TID 276) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.592 Executor task launch worker for task 1.0 in stage 147.0 (TID 276) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.592 Executor task launch worker for task 0.0 in stage 147.0 (TID 275) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:42.592 Executor task launch worker for task 0.0 in stage 147.0 (TID 275) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:42.598 Executor task launch worker for task 1.0 in stage 147.0 (TID 276) INFO Executor: Finished task 1.0 in stage 147.0 (TID 276). 6699 bytes result sent to driver
23/10/22 22:17:42.598 Executor task launch worker for task 0.0 in stage 147.0 (TID 275) INFO Executor: Finished task 0.0 in stage 147.0 (TID 275). 6699 bytes result sent to driver
23/10/22 22:17:42.599 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 276) in 13 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:42.599 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 275) in 14 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:42.599 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
23/10/22 22:17:42.599 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 147 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.019 s
23/10/22 22:17:42.599 dag-scheduler-event-loop INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:42.599 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished
23/10/22 22:17:42.600 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 82 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.144137 s
23/10/22 22:17:42.600 nioEventLoopGroup-2-2 INFO Instrumentation: [0be1d95c] Number of instances: 3785.
23/10/22 22:17:42.672 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 352 (rdd at LinearRegression.scala:921) as input to shuffle 50
23/10/22 22:17:42.673 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 83 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:17:42.673 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 148 (rdd at LinearRegression.scala:921)
23/10/22 22:17:42.673 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:42.673 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:42.673 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 148 (MapPartitionsRDD[352] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:42.674 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:42.675 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 22:17:42.676 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:42.676 dag-scheduler-event-loop INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:42.676 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[352] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:42.676 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0
23/10/22 22:17:42.963 dispatcher-event-loop-1 WARN TaskSetManager: Stage 148 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:42.963 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 277) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:42.964 Executor task launch worker for task 0.0 in stage 148.0 (TID 277) INFO Executor: Running task 0.0 in stage 148.0 (TID 277)
23/10/22 22:17:43.085 Executor task launch worker for task 0.0 in stage 148.0 (TID 277) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:43.135 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 22:17:43.136 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:55185 in memory (size: 36.5 KiB, free: 1037.1 MiB)
23/10/22 22:17:43.137 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:55185 in memory (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:43.979 Executor task launch worker for task 0.0 in stage 148.0 (TID 277) INFO Executor: Finished task 0.0 in stage 148.0 (TID 277). 2147 bytes result sent to driver
23/10/22 22:17:43.980 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 277) in 1303 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:43.980 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
23/10/22 22:17:43.980 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 148 (rdd at LinearRegression.scala:921) finished in 1.307 s
23/10/22 22:17:43.980 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:43.980 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:43.980 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:43.980 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:43.984 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(50), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:43.988 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 356 (rdd at LinearRegression.scala:921) as input to shuffle 51
23/10/22 22:17:43.988 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 84 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:17:43.989 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 150 (rdd at LinearRegression.scala:921)
23/10/22 22:17:43.989 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 149)
23/10/22 22:17:43.989 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:43.989 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[356] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:43.991 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 22:17:43.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:43.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:43.992 dag-scheduler-event-loop INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:43.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[356] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:43.992 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 150.0 with 8 tasks resource profile 0
23/10/22 22:17:43.993 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 278) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.993 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 279) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.993 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 150.0 (TID 280) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.993 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 150.0 (TID 281) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.993 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 150.0 (TID 282) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.994 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 150.0 (TID 283) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.994 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 150.0 (TID 284) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.994 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 150.0 (TID 285) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:43.994 Executor task launch worker for task 2.0 in stage 150.0 (TID 280) INFO Executor: Running task 2.0 in stage 150.0 (TID 280)
23/10/22 22:17:43.994 Executor task launch worker for task 0.0 in stage 150.0 (TID 278) INFO Executor: Running task 0.0 in stage 150.0 (TID 278)
23/10/22 22:17:43.994 Executor task launch worker for task 4.0 in stage 150.0 (TID 282) INFO Executor: Running task 4.0 in stage 150.0 (TID 282)
23/10/22 22:17:43.994 Executor task launch worker for task 5.0 in stage 150.0 (TID 283) INFO Executor: Running task 5.0 in stage 150.0 (TID 283)
23/10/22 22:17:43.994 Executor task launch worker for task 7.0 in stage 150.0 (TID 285) INFO Executor: Running task 7.0 in stage 150.0 (TID 285)
23/10/22 22:17:43.994 Executor task launch worker for task 1.0 in stage 150.0 (TID 279) INFO Executor: Running task 1.0 in stage 150.0 (TID 279)
23/10/22 22:17:43.994 Executor task launch worker for task 6.0 in stage 150.0 (TID 284) INFO Executor: Running task 6.0 in stage 150.0 (TID 284)
23/10/22 22:17:43.994 Executor task launch worker for task 3.0 in stage 150.0 (TID 281) INFO Executor: Running task 3.0 in stage 150.0 (TID 281)
23/10/22 22:17:43.997 Executor task launch worker for task 6.0 in stage 150.0 (TID 284) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:43.997 Executor task launch worker for task 3.0 in stage 150.0 (TID 281) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:43.997 Executor task launch worker for task 6.0 in stage 150.0 (TID 284) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:43.997 Executor task launch worker for task 3.0 in stage 150.0 (TID 281) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:43.997 Executor task launch worker for task 2.0 in stage 150.0 (TID 280) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:43.997 Executor task launch worker for task 2.0 in stage 150.0 (TID 280) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:43.999 Executor task launch worker for task 4.0 in stage 150.0 (TID 282) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:43.999 Executor task launch worker for task 4.0 in stage 150.0 (TID 282) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.001 Executor task launch worker for task 1.0 in stage 150.0 (TID 279) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.001 Executor task launch worker for task 1.0 in stage 150.0 (TID 279) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.001 Executor task launch worker for task 7.0 in stage 150.0 (TID 285) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.001 Executor task launch worker for task 5.0 in stage 150.0 (TID 283) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.001 Executor task launch worker for task 5.0 in stage 150.0 (TID 283) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.001 Executor task launch worker for task 0.0 in stage 150.0 (TID 278) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.001 Executor task launch worker for task 0.0 in stage 150.0 (TID 278) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.001 Executor task launch worker for task 7.0 in stage 150.0 (TID 285) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.007 Executor task launch worker for task 3.0 in stage 150.0 (TID 281) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.007 Executor task launch worker for task 2.0 in stage 150.0 (TID 280) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.008 Executor task launch worker for task 4.0 in stage 150.0 (TID 282) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.009 Executor task launch worker for task 1.0 in stage 150.0 (TID 279) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.012 Executor task launch worker for task 5.0 in stage 150.0 (TID 283) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.020 Executor task launch worker for task 7.0 in stage 150.0 (TID 285) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.025 Executor task launch worker for task 3.0 in stage 150.0 (TID 281) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.029 Executor task launch worker for task 1.0 in stage 150.0 (TID 279) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.029 Executor task launch worker for task 4.0 in stage 150.0 (TID 282) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.031 Executor task launch worker for task 2.0 in stage 150.0 (TID 280) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.033 Executor task launch worker for task 0.0 in stage 150.0 (TID 278) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.055 Executor task launch worker for task 5.0 in stage 150.0 (TID 283) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.058 Executor task launch worker for task 0.0 in stage 150.0 (TID 278) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.060 Executor task launch worker for task 6.0 in stage 150.0 (TID 284) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.060 Executor task launch worker for task 7.0 in stage 150.0 (TID 285) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.082 Executor task launch worker for task 6.0 in stage 150.0 (TID 284) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.159 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:44.160 Executor task launch worker for task 4.0 in stage 150.0 (TID 282) INFO Executor: Finished task 4.0 in stage 150.0 (TID 282). 4899 bytes result sent to driver
23/10/22 22:17:44.162 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 150.0 (TID 282) in 169 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:44.172 Executor task launch worker for task 1.0 in stage 150.0 (TID 279) INFO Executor: Finished task 1.0 in stage 150.0 (TID 279). 4899 bytes result sent to driver
23/10/22 22:17:44.172 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 279) in 179 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:44.211 Executor task launch worker for task 2.0 in stage 150.0 (TID 280) INFO Executor: Finished task 2.0 in stage 150.0 (TID 280). 4899 bytes result sent to driver
23/10/22 22:17:44.212 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 150.0 (TID 280) in 219 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:44.218 Executor task launch worker for task 0.0 in stage 150.0 (TID 278) INFO Executor: Finished task 0.0 in stage 150.0 (TID 278). 4899 bytes result sent to driver
23/10/22 22:17:44.221 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 278) in 227 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:44.233 Executor task launch worker for task 3.0 in stage 150.0 (TID 281) INFO Executor: Finished task 3.0 in stage 150.0 (TID 281). 4899 bytes result sent to driver
23/10/22 22:17:44.234 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 150.0 (TID 281) in 241 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:44.236 Executor task launch worker for task 7.0 in stage 150.0 (TID 285) INFO Executor: Finished task 7.0 in stage 150.0 (TID 285). 4899 bytes result sent to driver
23/10/22 22:17:44.237 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 150.0 (TID 285) in 243 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:44.252 Executor task launch worker for task 6.0 in stage 150.0 (TID 284) INFO Executor: Finished task 6.0 in stage 150.0 (TID 284). 4899 bytes result sent to driver
23/10/22 22:17:44.253 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 150.0 (TID 284) in 259 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:44.265 Executor task launch worker for task 5.0 in stage 150.0 (TID 283) INFO Executor: Finished task 5.0 in stage 150.0 (TID 283). 4899 bytes result sent to driver
23/10/22 22:17:44.265 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 150.0 (TID 283) in 271 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:44.265 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
23/10/22 22:17:44.266 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 150 (rdd at LinearRegression.scala:921) finished in 0.275 s
23/10/22 22:17:44.266 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:44.266 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:44.266 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:44.266 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:44.270 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(51), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:44.316 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:17:44.319 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 366 (treeAggregate at Statistics.scala:58) as input to shuffle 52
23/10/22 22:17:44.320 dag-scheduler-event-loop INFO DAGScheduler: Got job 85 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:17:44.320 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 154 (treeAggregate at Statistics.scala:58)
23/10/22 22:17:44.320 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)
23/10/22 22:17:44.320 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 153)
23/10/22 22:17:44.320 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[366] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:44.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 82.5 KiB, free 1037.0 MiB)
23/10/22 22:17:44.328 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 1036.9 MiB)
23/10/22 22:17:44.328 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:55185 (size: 35.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:44.328 dag-scheduler-event-loop INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:44.329 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[366] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:44.329 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 153.0 with 8 tasks resource profile 0
23/10/22 22:17:44.330 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 286) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.330 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 287) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.331 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 153.0 (TID 288) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.331 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 153.0 (TID 289) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.331 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 153.0 (TID 290) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.332 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 153.0 (TID 291) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.332 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 153.0 (TID 292) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.332 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 153.0 (TID 293) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:44.332 Executor task launch worker for task 0.0 in stage 153.0 (TID 286) INFO Executor: Running task 0.0 in stage 153.0 (TID 286)
23/10/22 22:17:44.332 Executor task launch worker for task 5.0 in stage 153.0 (TID 291) INFO Executor: Running task 5.0 in stage 153.0 (TID 291)
23/10/22 22:17:44.332 Executor task launch worker for task 4.0 in stage 153.0 (TID 290) INFO Executor: Running task 4.0 in stage 153.0 (TID 290)
23/10/22 22:17:44.332 Executor task launch worker for task 6.0 in stage 153.0 (TID 292) INFO Executor: Running task 6.0 in stage 153.0 (TID 292)
23/10/22 22:17:44.333 Executor task launch worker for task 7.0 in stage 153.0 (TID 293) INFO Executor: Running task 7.0 in stage 153.0 (TID 293)
23/10/22 22:17:44.332 Executor task launch worker for task 1.0 in stage 153.0 (TID 287) INFO Executor: Running task 1.0 in stage 153.0 (TID 287)
23/10/22 22:17:44.339 Executor task launch worker for task 3.0 in stage 153.0 (TID 289) INFO Executor: Running task 3.0 in stage 153.0 (TID 289)
23/10/22 22:17:44.332 Executor task launch worker for task 2.0 in stage 153.0 (TID 288) INFO Executor: Running task 2.0 in stage 153.0 (TID 288)
23/10/22 22:17:44.348 Executor task launch worker for task 0.0 in stage 153.0 (TID 286) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.349 Executor task launch worker for task 6.0 in stage 153.0 (TID 292) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.349 Executor task launch worker for task 6.0 in stage 153.0 (TID 292) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.349 Executor task launch worker for task 4.0 in stage 153.0 (TID 290) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.349 Executor task launch worker for task 4.0 in stage 153.0 (TID 290) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.348 Executor task launch worker for task 7.0 in stage 153.0 (TID 293) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.351 Executor task launch worker for task 7.0 in stage 153.0 (TID 293) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:44.349 Executor task launch worker for task 0.0 in stage 153.0 (TID 286) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.355 Executor task launch worker for task 1.0 in stage 153.0 (TID 287) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.355 Executor task launch worker for task 1.0 in stage 153.0 (TID 287) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.355 Executor task launch worker for task 2.0 in stage 153.0 (TID 288) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.355 Executor task launch worker for task 2.0 in stage 153.0 (TID 288) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.356 Executor task launch worker for task 3.0 in stage 153.0 (TID 289) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.356 Executor task launch worker for task 3.0 in stage 153.0 (TID 289) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.357 Executor task launch worker for task 5.0 in stage 153.0 (TID 291) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.357 Executor task launch worker for task 5.0 in stage 153.0 (TID 291) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.369 Executor task launch worker for task 6.0 in stage 153.0 (TID 292) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.371 Executor task launch worker for task 1.0 in stage 153.0 (TID 287) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.371 Executor task launch worker for task 7.0 in stage 153.0 (TID 293) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.371 Executor task launch worker for task 0.0 in stage 153.0 (TID 286) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.372 Executor task launch worker for task 3.0 in stage 153.0 (TID 289) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.374 Executor task launch worker for task 2.0 in stage 153.0 (TID 288) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.383 Executor task launch worker for task 4.0 in stage 153.0 (TID 290) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.398 Executor task launch worker for task 5.0 in stage 153.0 (TID 291) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:44.488 Executor task launch worker for task 3.0 in stage 153.0 (TID 289) INFO Executor: Finished task 3.0 in stage 153.0 (TID 289). 6562 bytes result sent to driver
23/10/22 22:17:44.489 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 153.0 (TID 289) in 158 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:44.497 Executor task launch worker for task 7.0 in stage 153.0 (TID 293) INFO Executor: Finished task 7.0 in stage 153.0 (TID 293). 6605 bytes result sent to driver
23/10/22 22:17:44.498 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 153.0 (TID 293) in 166 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:44.521 Executor task launch worker for task 2.0 in stage 153.0 (TID 288) INFO Executor: Finished task 2.0 in stage 153.0 (TID 288). 6562 bytes result sent to driver
23/10/22 22:17:44.528 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 153.0 (TID 288) in 198 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:44.556 Executor task launch worker for task 6.0 in stage 153.0 (TID 292) INFO Executor: Finished task 6.0 in stage 153.0 (TID 292). 6562 bytes result sent to driver
23/10/22 22:17:44.559 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 153.0 (TID 292) in 227 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:44.567 Executor task launch worker for task 4.0 in stage 153.0 (TID 290) INFO Executor: Finished task 4.0 in stage 153.0 (TID 290). 6562 bytes result sent to driver
23/10/22 22:17:44.570 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 153.0 (TID 290) in 239 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:44.576 Executor task launch worker for task 0.0 in stage 153.0 (TID 286) INFO Executor: Finished task 0.0 in stage 153.0 (TID 286). 6562 bytes result sent to driver
23/10/22 22:17:44.578 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 286) in 248 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:44.584 Executor task launch worker for task 1.0 in stage 153.0 (TID 287) INFO Executor: Finished task 1.0 in stage 153.0 (TID 287). 6605 bytes result sent to driver
23/10/22 22:17:44.586 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 287) in 256 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:44.670 Executor task launch worker for task 5.0 in stage 153.0 (TID 291) INFO Executor: Finished task 5.0 in stage 153.0 (TID 291). 6562 bytes result sent to driver
23/10/22 22:17:44.670 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 153.0 (TID 291) in 338 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:44.672 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
23/10/22 22:17:44.672 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 153 (treeAggregate at Statistics.scala:58) finished in 0.351 s
23/10/22 22:17:44.672 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:44.672 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:44.672 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 154)
23/10/22 22:17:44.673 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:44.673 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[368] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:44.679 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 83.6 KiB, free 1036.8 MiB)
23/10/22 22:17:44.681 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1036.8 MiB)
23/10/22 22:17:44.681 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:55185 (size: 35.6 KiB, free: 1037.0 MiB)
23/10/22 22:17:44.682 dag-scheduler-event-loop INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:44.683 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 154 (MapPartitionsRDD[368] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:44.683 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 154.0 with 2 tasks resource profile 0
23/10/22 22:17:44.685 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 294) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:44.686 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 295) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:44.686 Executor task launch worker for task 0.0 in stage 154.0 (TID 294) INFO Executor: Running task 0.0 in stage 154.0 (TID 294)
23/10/22 22:17:44.686 Executor task launch worker for task 1.0 in stage 154.0 (TID 295) INFO Executor: Running task 1.0 in stage 154.0 (TID 295)
23/10/22 22:17:44.698 Executor task launch worker for task 0.0 in stage 154.0 (TID 294) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.698 Executor task launch worker for task 1.0 in stage 154.0 (TID 295) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:44.698 Executor task launch worker for task 0.0 in stage 154.0 (TID 294) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.698 Executor task launch worker for task 1.0 in stage 154.0 (TID 295) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:44.721 Executor task launch worker for task 1.0 in stage 154.0 (TID 295) INFO Executor: Finished task 1.0 in stage 154.0 (TID 295). 7630 bytes result sent to driver
23/10/22 22:17:44.721 Executor task launch worker for task 0.0 in stage 154.0 (TID 294) INFO Executor: Finished task 0.0 in stage 154.0 (TID 294). 7673 bytes result sent to driver
23/10/22 22:17:44.721 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 295) in 35 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:44.722 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 294) in 37 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:44.722 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
23/10/22 22:17:44.722 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 154 (treeAggregate at Statistics.scala:58) finished in 0.049 s
23/10/22 22:17:44.723 dag-scheduler-event-loop INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:44.723 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 154: Stage finished
23/10/22 22:17:44.723 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 85 finished: treeAggregate at Statistics.scala:58, took 0.406929 s
23/10/22 22:17:44.725 nioEventLoopGroup-2-2 INFO Instrumentation: [0bd3d752] training finished
23/10/22 22:17:45.433 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:45.433 dag-scheduler-event-loop INFO DAGScheduler: Got job 86 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:45.433 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 155 (collect at utils.scala:26)
23/10/22 22:17:45.433 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:45.433 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:45.434 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[370] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:45.435 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:45.436 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:45.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:45.437 dag-scheduler-event-loop INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:45.437 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[370] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:45.437 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks resource profile 0
23/10/22 22:17:45.438 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 296) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:45.439 Executor task launch worker for task 0.0 in stage 155.0 (TID 296) INFO Executor: Running task 0.0 in stage 155.0 (TID 296)
23/10/22 22:17:45.441 Executor task launch worker for task 0.0 in stage 155.0 (TID 296) INFO Executor: Finished task 0.0 in stage 155.0 (TID 296). 1327 bytes result sent to driver
23/10/22 22:17:45.441 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 296) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:45.441 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
23/10/22 22:17:45.441 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 155 (collect at utils.scala:26) finished in 0.007 s
23/10/22 22:17:45.442 dag-scheduler-event-loop INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:45.442 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 155: Stage finished
23/10/22 22:17:45.442 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 86 finished: collect at utils.scala:26, took 0.008826 s
23/10/22 22:17:45.873 nioEventLoopGroup-2-2 INFO Instrumentation: [a93bf2d1] training finished
23/10/22 22:17:46.054 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:46.055 dag-scheduler-event-loop INFO DAGScheduler: Got job 87 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:46.055 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 156 (collect at utils.scala:26)
23/10/22 22:17:46.055 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:46.055 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:46.055 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[372] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:46.057 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:46.058 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:46.058 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:46.058 dag-scheduler-event-loop INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:46.059 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[372] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:46.059 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0
23/10/22 22:17:46.060 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 297) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:46.060 Executor task launch worker for task 0.0 in stage 156.0 (TID 297) INFO Executor: Running task 0.0 in stage 156.0 (TID 297)
23/10/22 22:17:46.062 Executor task launch worker for task 0.0 in stage 156.0 (TID 297) INFO Executor: Finished task 0.0 in stage 156.0 (TID 297). 1327 bytes result sent to driver
23/10/22 22:17:46.062 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 297) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:46.063 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
23/10/22 22:17:46.063 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 156 (collect at utils.scala:26) finished in 0.007 s
23/10/22 22:17:46.064 dag-scheduler-event-loop INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:46.064 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
23/10/22 22:17:46.064 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 87 finished: collect at utils.scala:26, took 0.009460 s
23/10/22 22:17:46.836 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:46.836 dag-scheduler-event-loop INFO DAGScheduler: Got job 88 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:46.836 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 157 (collect at utils.scala:26)
23/10/22 22:17:46.837 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:46.837 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:46.837 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[374] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:46.838 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:17:46.839 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:17:46.839 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:17:46.840 dag-scheduler-event-loop INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:46.840 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[374] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:46.840 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks resource profile 0
23/10/22 22:17:46.841 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 298) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:46.841 Executor task launch worker for task 0.0 in stage 157.0 (TID 298) INFO Executor: Running task 0.0 in stage 157.0 (TID 298)
23/10/22 22:17:46.843 Executor task launch worker for task 0.0 in stage 157.0 (TID 298) INFO Executor: Finished task 0.0 in stage 157.0 (TID 298). 1327 bytes result sent to driver
23/10/22 22:17:46.844 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 298) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:46.844 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
23/10/22 22:17:46.844 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 157 (collect at utils.scala:26) finished in 0.007 s
23/10/22 22:17:46.844 dag-scheduler-event-loop INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:46.844 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished
23/10/22 22:17:46.844 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 88 finished: collect at utils.scala:26, took 0.008625 s
23/10/22 22:17:47.621 nioEventLoopGroup-2-2 INFO Instrumentation: [ee6ce411] training finished
23/10/22 22:17:47.636 nioEventLoopGroup-2-2 INFO Instrumentation: [e3bd5dfb] training finished
23/10/22 22:17:47.642 nioEventLoopGroup-2-2 INFO Instrumentation: [ad2b1a59] Stage class: LinearRegression
23/10/22 22:17:47.642 nioEventLoopGroup-2-2 INFO Instrumentation: [ad2b1a59] Stage uid: linear_regression__58904c11_e8aa_4730_a60e_649aa5340fd1
23/10/22 22:17:47.693 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 377 (rdd at Instrumentation.scala:62) as input to shuffle 53
23/10/22 22:17:47.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.0 MiB)
23/10/22 22:17:47.693 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 89 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:17:47.693 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 158 (rdd at Instrumentation.scala:62)
23/10/22 22:17:47.693 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:47.693 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:47.693 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 158 (MapPartitionsRDD[377] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:47.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:47.695 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:47.695 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:47.696 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:47.696 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:55185 in memory (size: 35.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:47.696 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:47.696 dag-scheduler-event-loop INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:47.696 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 158 (MapPartitionsRDD[377] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:47.696 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks resource profile 0
23/10/22 22:17:47.697 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:55185 in memory (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:17:47.699 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:48.033 dispatcher-event-loop-0 WARN TaskSetManager: Stage 158 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:48.034 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 299) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:48.034 Executor task launch worker for task 0.0 in stage 158.0 (TID 299) INFO Executor: Running task 0.0 in stage 158.0 (TID 299)
23/10/22 22:17:48.211 Executor task launch worker for task 0.0 in stage 158.0 (TID 299) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:48.447 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:49.377 Executor task launch worker for task 0.0 in stage 158.0 (TID 299) INFO Executor: Finished task 0.0 in stage 158.0 (TID 299). 2147 bytes result sent to driver
23/10/22 22:17:49.377 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 299) in 1680 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:49.377 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
23/10/22 22:17:49.378 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 158 (rdd at Instrumentation.scala:62) finished in 1.685 s
23/10/22 22:17:49.378 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:49.378 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:49.378 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:49.378 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:49.383 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:49.387 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 381 (rdd at Instrumentation.scala:62) as input to shuffle 54
23/10/22 22:17:49.387 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 90 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:17:49.387 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 160 (rdd at Instrumentation.scala:62)
23/10/22 22:17:49.387 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 159)
23/10/22 22:17:49.387 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:49.387 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 160 (MapPartitionsRDD[381] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:49.389 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:49.390 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 22:17:49.390 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:55185 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:49.390 dag-scheduler-event-loop INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:49.391 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 160 (MapPartitionsRDD[381] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:49.391 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 160.0 with 8 tasks resource profile 0
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 300) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 160.0 (TID 301) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 160.0 (TID 302) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 160.0 (TID 303) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 160.0 (TID 304) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 160.0 (TID 305) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 160.0 (TID 306) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 160.0 (TID 307) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:49.392 Executor task launch worker for task 0.0 in stage 160.0 (TID 300) INFO Executor: Running task 0.0 in stage 160.0 (TID 300)
23/10/22 22:17:49.392 Executor task launch worker for task 4.0 in stage 160.0 (TID 304) INFO Executor: Running task 4.0 in stage 160.0 (TID 304)
23/10/22 22:17:49.392 Executor task launch worker for task 3.0 in stage 160.0 (TID 303) INFO Executor: Running task 3.0 in stage 160.0 (TID 303)
23/10/22 22:17:49.392 Executor task launch worker for task 2.0 in stage 160.0 (TID 302) INFO Executor: Running task 2.0 in stage 160.0 (TID 302)
23/10/22 22:17:49.392 Executor task launch worker for task 1.0 in stage 160.0 (TID 301) INFO Executor: Running task 1.0 in stage 160.0 (TID 301)
23/10/22 22:17:49.393 Executor task launch worker for task 7.0 in stage 160.0 (TID 307) INFO Executor: Running task 7.0 in stage 160.0 (TID 307)
23/10/22 22:17:49.393 Executor task launch worker for task 6.0 in stage 160.0 (TID 306) INFO Executor: Running task 6.0 in stage 160.0 (TID 306)
23/10/22 22:17:49.393 Executor task launch worker for task 5.0 in stage 160.0 (TID 305) INFO Executor: Running task 5.0 in stage 160.0 (TID 305)
23/10/22 22:17:49.396 Executor task launch worker for task 6.0 in stage 160.0 (TID 306) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.396 Executor task launch worker for task 6.0 in stage 160.0 (TID 306) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.396 Executor task launch worker for task 7.0 in stage 160.0 (TID 307) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.397 Executor task launch worker for task 7.0 in stage 160.0 (TID 307) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.397 Executor task launch worker for task 1.0 in stage 160.0 (TID 301) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.397 Executor task launch worker for task 1.0 in stage 160.0 (TID 301) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.397 Executor task launch worker for task 2.0 in stage 160.0 (TID 302) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.398 Executor task launch worker for task 2.0 in stage 160.0 (TID 302) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.398 Executor task launch worker for task 4.0 in stage 160.0 (TID 304) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.398 Executor task launch worker for task 4.0 in stage 160.0 (TID 304) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.402 Executor task launch worker for task 5.0 in stage 160.0 (TID 305) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.402 Executor task launch worker for task 0.0 in stage 160.0 (TID 300) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.402 Executor task launch worker for task 3.0 in stage 160.0 (TID 303) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:49.402 Executor task launch worker for task 0.0 in stage 160.0 (TID 300) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.402 Executor task launch worker for task 3.0 in stage 160.0 (TID 303) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:49.402 Executor task launch worker for task 5.0 in stage 160.0 (TID 305) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:49.412 Executor task launch worker for task 4.0 in stage 160.0 (TID 304) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.413 Executor task launch worker for task 6.0 in stage 160.0 (TID 306) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.413 Executor task launch worker for task 1.0 in stage 160.0 (TID 301) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.427 Executor task launch worker for task 5.0 in stage 160.0 (TID 305) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.429 Executor task launch worker for task 3.0 in stage 160.0 (TID 303) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.430 Executor task launch worker for task 2.0 in stage 160.0 (TID 302) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.433 Executor task launch worker for task 4.0 in stage 160.0 (TID 304) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.436 Executor task launch worker for task 1.0 in stage 160.0 (TID 301) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.448 Executor task launch worker for task 0.0 in stage 160.0 (TID 300) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.452 Executor task launch worker for task 5.0 in stage 160.0 (TID 305) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.453 Executor task launch worker for task 6.0 in stage 160.0 (TID 306) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.453 Executor task launch worker for task 2.0 in stage 160.0 (TID 302) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.482 Executor task launch worker for task 0.0 in stage 160.0 (TID 300) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.501 Executor task launch worker for task 3.0 in stage 160.0 (TID 303) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.541 Executor task launch worker for task 7.0 in stage 160.0 (TID 307) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.611 Executor task launch worker for task 7.0 in stage 160.0 (TID 307) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:49.643 Executor task launch worker for task 1.0 in stage 160.0 (TID 301) INFO Executor: Finished task 1.0 in stage 160.0 (TID 301). 4942 bytes result sent to driver
23/10/22 22:17:49.645 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 160.0 (TID 301) in 252 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:49.674 Executor task launch worker for task 6.0 in stage 160.0 (TID 306) INFO Executor: Finished task 6.0 in stage 160.0 (TID 306). 4942 bytes result sent to driver
23/10/22 22:17:49.678 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 160.0 (TID 306) in 286 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:49.691 Executor task launch worker for task 2.0 in stage 160.0 (TID 302) INFO Executor: Finished task 2.0 in stage 160.0 (TID 302). 4899 bytes result sent to driver
23/10/22 22:17:49.694 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 160.0 (TID 302) in 302 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:49.698 Executor task launch worker for task 4.0 in stage 160.0 (TID 304) INFO Executor: Finished task 4.0 in stage 160.0 (TID 304). 4942 bytes result sent to driver
23/10/22 22:17:49.700 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 160.0 (TID 304) in 308 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:49.713 Executor task launch worker for task 0.0 in stage 160.0 (TID 300) INFO Executor: Finished task 0.0 in stage 160.0 (TID 300). 4899 bytes result sent to driver
23/10/22 22:17:49.714 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 300) in 323 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:49.718 Executor task launch worker for task 3.0 in stage 160.0 (TID 303) INFO Executor: Finished task 3.0 in stage 160.0 (TID 303). 4899 bytes result sent to driver
23/10/22 22:17:49.719 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 160.0 (TID 303) in 327 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:49.722 Executor task launch worker for task 5.0 in stage 160.0 (TID 305) INFO Executor: Finished task 5.0 in stage 160.0 (TID 305). 4899 bytes result sent to driver
23/10/22 22:17:49.723 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 160.0 (TID 305) in 331 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:49.753 Executor task launch worker for task 7.0 in stage 160.0 (TID 307) INFO Executor: Finished task 7.0 in stage 160.0 (TID 307). 4942 bytes result sent to driver
23/10/22 22:17:49.754 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 160.0 (TID 307) in 362 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:49.754 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
23/10/22 22:17:49.755 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 160 (rdd at Instrumentation.scala:62) finished in 0.366 s
23/10/22 22:17:49.755 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:49.755 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:49.755 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:49.755 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:49.760 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:49.779 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.9208 ms
23/10/22 22:17:49.792 nioEventLoopGroup-2-2 INFO Instrumentation: [ad2b1a59] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:17:49.793 nioEventLoopGroup-2-2 INFO Instrumentation: [ad2b1a59] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:17:49.794 nioEventLoopGroup-2-2 INFO Instrumentation: [ad2b1a59] {"numFeatures":1}
23/10/22 22:17:49.851 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 390 (rdd at LinearRegression.scala:348) as input to shuffle 55
23/10/22 22:17:49.851 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 91 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:17:49.851 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 161 (rdd at LinearRegression.scala:348)
23/10/22 22:17:49.852 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:49.852 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:49.852 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 161 (MapPartitionsRDD[390] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:49.853 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:17:49.854 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:49.854 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:49.855 dag-scheduler-event-loop INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:49.855 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 161 (MapPartitionsRDD[390] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:49.855 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks resource profile 0
23/10/22 22:17:50.272 dispatcher-event-loop-2 WARN TaskSetManager: Stage 161 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:50.272 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 308) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:50.273 Executor task launch worker for task 0.0 in stage 161.0 (TID 308) INFO Executor: Running task 0.0 in stage 161.0 (TID 308)
23/10/22 22:17:50.430 Executor task launch worker for task 0.0 in stage 161.0 (TID 308) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:50.607 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:55185 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:51.543 Executor task launch worker for task 0.0 in stage 161.0 (TID 308) INFO Executor: Finished task 0.0 in stage 161.0 (TID 308). 2147 bytes result sent to driver
23/10/22 22:17:51.544 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 308) in 1688 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:51.544 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
23/10/22 22:17:51.544 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 161 (rdd at LinearRegression.scala:348) finished in 1.692 s
23/10/22 22:17:51.544 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:51.544 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:51.544 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:51.544 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:51.550 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:51.556 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 394 (rdd at LinearRegression.scala:348) as input to shuffle 56
23/10/22 22:17:51.556 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 92 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:17:51.556 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 163 (rdd at LinearRegression.scala:348)
23/10/22 22:17:51.556 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)
23/10/22 22:17:51.556 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:51.556 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 163 (MapPartitionsRDD[394] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:51.559 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 22:17:51.560 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 22:17:51.561 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:55185 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:51.561 dag-scheduler-event-loop INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:51.562 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 163 (MapPartitionsRDD[394] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:51.562 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 163.0 with 8 tasks resource profile 0
23/10/22 22:17:51.563 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 309) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.564 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 163.0 (TID 310) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.564 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 163.0 (TID 311) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.564 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 163.0 (TID 312) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.564 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 163.0 (TID 313) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.564 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 163.0 (TID 314) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.564 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 163.0 (TID 315) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.565 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 163.0 (TID 316) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:51.565 Executor task launch worker for task 1.0 in stage 163.0 (TID 310) INFO Executor: Running task 1.0 in stage 163.0 (TID 310)
23/10/22 22:17:51.565 Executor task launch worker for task 3.0 in stage 163.0 (TID 312) INFO Executor: Running task 3.0 in stage 163.0 (TID 312)
23/10/22 22:17:51.565 Executor task launch worker for task 7.0 in stage 163.0 (TID 316) INFO Executor: Running task 7.0 in stage 163.0 (TID 316)
23/10/22 22:17:51.565 Executor task launch worker for task 0.0 in stage 163.0 (TID 309) INFO Executor: Running task 0.0 in stage 163.0 (TID 309)
23/10/22 22:17:51.565 Executor task launch worker for task 2.0 in stage 163.0 (TID 311) INFO Executor: Running task 2.0 in stage 163.0 (TID 311)
23/10/22 22:17:51.565 Executor task launch worker for task 4.0 in stage 163.0 (TID 313) INFO Executor: Running task 4.0 in stage 163.0 (TID 313)
23/10/22 22:17:51.565 Executor task launch worker for task 5.0 in stage 163.0 (TID 314) INFO Executor: Running task 5.0 in stage 163.0 (TID 314)
23/10/22 22:17:51.566 Executor task launch worker for task 6.0 in stage 163.0 (TID 315) INFO Executor: Running task 6.0 in stage 163.0 (TID 315)
23/10/22 22:17:51.569 Executor task launch worker for task 7.0 in stage 163.0 (TID 316) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.569 Executor task launch worker for task 7.0 in stage 163.0 (TID 316) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.569 Executor task launch worker for task 5.0 in stage 163.0 (TID 314) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.570 Executor task launch worker for task 5.0 in stage 163.0 (TID 314) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.570 Executor task launch worker for task 6.0 in stage 163.0 (TID 315) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.570 Executor task launch worker for task 6.0 in stage 163.0 (TID 315) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.571 Executor task launch worker for task 3.0 in stage 163.0 (TID 312) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.571 Executor task launch worker for task 3.0 in stage 163.0 (TID 312) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.571 Executor task launch worker for task 1.0 in stage 163.0 (TID 310) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.572 Executor task launch worker for task 1.0 in stage 163.0 (TID 310) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.572 Executor task launch worker for task 2.0 in stage 163.0 (TID 311) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.572 Executor task launch worker for task 2.0 in stage 163.0 (TID 311) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.572 Executor task launch worker for task 0.0 in stage 163.0 (TID 309) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.572 Executor task launch worker for task 4.0 in stage 163.0 (TID 313) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:51.572 Executor task launch worker for task 0.0 in stage 163.0 (TID 309) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.572 Executor task launch worker for task 4.0 in stage 163.0 (TID 313) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:51.579 Executor task launch worker for task 1.0 in stage 163.0 (TID 310) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.579 Executor task launch worker for task 7.0 in stage 163.0 (TID 316) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.579 Executor task launch worker for task 0.0 in stage 163.0 (TID 309) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.585 Executor task launch worker for task 6.0 in stage 163.0 (TID 315) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.598 Executor task launch worker for task 3.0 in stage 163.0 (TID 312) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.601 Executor task launch worker for task 7.0 in stage 163.0 (TID 316) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.607 Executor task launch worker for task 2.0 in stage 163.0 (TID 311) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.609 Executor task launch worker for task 1.0 in stage 163.0 (TID 310) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.618 Executor task launch worker for task 3.0 in stage 163.0 (TID 312) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.622 Executor task launch worker for task 0.0 in stage 163.0 (TID 309) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.634 Executor task launch worker for task 2.0 in stage 163.0 (TID 311) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.644 Executor task launch worker for task 4.0 in stage 163.0 (TID 313) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.671 Executor task launch worker for task 6.0 in stage 163.0 (TID 315) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.683 Executor task launch worker for task 5.0 in stage 163.0 (TID 314) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.672 Executor task launch worker for task 4.0 in stage 163.0 (TID 313) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.732 Executor task launch worker for task 5.0 in stage 163.0 (TID 314) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:51.753 Executor task launch worker for task 1.0 in stage 163.0 (TID 310) INFO Executor: Finished task 1.0 in stage 163.0 (TID 310). 4899 bytes result sent to driver
23/10/22 22:17:51.757 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 163.0 (TID 310) in 193 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:51.758 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:51.792 Executor task launch worker for task 0.0 in stage 163.0 (TID 309) INFO Executor: Finished task 0.0 in stage 163.0 (TID 309). 4899 bytes result sent to driver
23/10/22 22:17:51.794 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 309) in 231 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:51.858 Executor task launch worker for task 2.0 in stage 163.0 (TID 311) INFO Executor: Finished task 2.0 in stage 163.0 (TID 311). 4942 bytes result sent to driver
23/10/22 22:17:51.865 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 163.0 (TID 311) in 300 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:51.874 Executor task launch worker for task 4.0 in stage 163.0 (TID 313) INFO Executor: Finished task 4.0 in stage 163.0 (TID 313). 4899 bytes result sent to driver
23/10/22 22:17:51.875 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 163.0 (TID 313) in 311 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:51.879 Executor task launch worker for task 3.0 in stage 163.0 (TID 312) INFO Executor: Finished task 3.0 in stage 163.0 (TID 312). 4899 bytes result sent to driver
23/10/22 22:17:51.884 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 163.0 (TID 312) in 320 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:51.886 Executor task launch worker for task 7.0 in stage 163.0 (TID 316) INFO Executor: Finished task 7.0 in stage 163.0 (TID 316). 4942 bytes result sent to driver
23/10/22 22:17:51.888 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 163.0 (TID 316) in 324 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:51.892 Executor task launch worker for task 5.0 in stage 163.0 (TID 314) INFO Executor: Finished task 5.0 in stage 163.0 (TID 314). 4942 bytes result sent to driver
23/10/22 22:17:51.892 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 163.0 (TID 314) in 328 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:51.897 Executor task launch worker for task 6.0 in stage 163.0 (TID 315) INFO Executor: Finished task 6.0 in stage 163.0 (TID 315). 4899 bytes result sent to driver
23/10/22 22:17:51.898 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 163.0 (TID 315) in 334 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:51.898 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
23/10/22 22:17:51.898 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 163 (rdd at LinearRegression.scala:348) finished in 0.341 s
23/10/22 22:17:51.898 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:51.898 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:51.898 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:51.898 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:51.906 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(56), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:51.957 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 37.3114 ms
23/10/22 22:17:51.969 nioEventLoopGroup-2-2 WARN Instrumentation: [ad2b1a59] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:17:51.992 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:17:51.993 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 403 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 57
23/10/22 22:17:51.993 dag-scheduler-event-loop INFO DAGScheduler: Got job 93 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:17:51.993 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 167 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:17:51.993 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 166)
23/10/22 22:17:51.993 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 166)
23/10/22 22:17:51.993 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 166 (MapPartitionsRDD[403] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:51.998 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 92.6 KiB, free 1037.0 MiB)
23/10/22 22:17:51.999 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 36.7 KiB, free 1036.9 MiB)
23/10/22 22:17:51.999 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:55185 (size: 36.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:52.000 dag-scheduler-event-loop INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:52.000 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[403] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:52.000 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 166.0 with 8 tasks resource profile 0
23/10/22 22:17:52.001 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 317) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 166.0 (TID 318) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 166.0 (TID 319) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 166.0 (TID 320) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 166.0 (TID 321) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 166.0 (TID 322) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.003 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 166.0 (TID 323) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.003 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 166.0 (TID 324) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:52.003 Executor task launch worker for task 2.0 in stage 166.0 (TID 319) INFO Executor: Running task 2.0 in stage 166.0 (TID 319)
23/10/22 22:17:52.003 Executor task launch worker for task 3.0 in stage 166.0 (TID 320) INFO Executor: Running task 3.0 in stage 166.0 (TID 320)
23/10/22 22:17:52.003 Executor task launch worker for task 4.0 in stage 166.0 (TID 321) INFO Executor: Running task 4.0 in stage 166.0 (TID 321)
23/10/22 22:17:52.003 Executor task launch worker for task 0.0 in stage 166.0 (TID 317) INFO Executor: Running task 0.0 in stage 166.0 (TID 317)
23/10/22 22:17:52.003 Executor task launch worker for task 7.0 in stage 166.0 (TID 324) INFO Executor: Running task 7.0 in stage 166.0 (TID 324)
23/10/22 22:17:52.003 Executor task launch worker for task 1.0 in stage 166.0 (TID 318) INFO Executor: Running task 1.0 in stage 166.0 (TID 318)
23/10/22 22:17:52.003 Executor task launch worker for task 6.0 in stage 166.0 (TID 323) INFO Executor: Running task 6.0 in stage 166.0 (TID 323)
23/10/22 22:17:52.003 Executor task launch worker for task 5.0 in stage 166.0 (TID 322) INFO Executor: Running task 5.0 in stage 166.0 (TID 322)
23/10/22 22:17:52.011 Executor task launch worker for task 3.0 in stage 166.0 (TID 320) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.012 Executor task launch worker for task 3.0 in stage 166.0 (TID 320) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.012 Executor task launch worker for task 1.0 in stage 166.0 (TID 318) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.012 Executor task launch worker for task 1.0 in stage 166.0 (TID 318) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.011 Executor task launch worker for task 6.0 in stage 166.0 (TID 323) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.012 Executor task launch worker for task 6.0 in stage 166.0 (TID 323) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.019 Executor task launch worker for task 2.0 in stage 166.0 (TID 319) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.020 Executor task launch worker for task 2.0 in stage 166.0 (TID 319) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:52.022 Executor task launch worker for task 5.0 in stage 166.0 (TID 322) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.022 Executor task launch worker for task 5.0 in stage 166.0 (TID 322) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.022 Executor task launch worker for task 4.0 in stage 166.0 (TID 321) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.028 Executor task launch worker for task 4.0 in stage 166.0 (TID 321) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
23/10/22 22:17:52.030 Executor task launch worker for task 0.0 in stage 166.0 (TID 317) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.030 Executor task launch worker for task 7.0 in stage 166.0 (TID 324) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.030 Executor task launch worker for task 7.0 in stage 166.0 (TID 324) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.030 Executor task launch worker for task 0.0 in stage 166.0 (TID 317) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.044 Executor task launch worker for task 3.0 in stage 166.0 (TID 320) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.048 Executor task launch worker for task 1.0 in stage 166.0 (TID 318) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.051 Executor task launch worker for task 2.0 in stage 166.0 (TID 319) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.054 Executor task launch worker for task 0.0 in stage 166.0 (TID 317) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.056 Executor task launch worker for task 5.0 in stage 166.0 (TID 322) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.058 Executor task launch worker for task 4.0 in stage 166.0 (TID 321) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.082 Executor task launch worker for task 6.0 in stage 166.0 (TID 323) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.083 Executor task launch worker for task 7.0 in stage 166.0 (TID 324) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:52.123 Executor task launch worker for task 1.0 in stage 166.0 (TID 318) INFO Executor: Finished task 1.0 in stage 166.0 (TID 318). 6562 bytes result sent to driver
23/10/22 22:17:52.124 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 166.0 (TID 318) in 123 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:52.126 Executor task launch worker for task 3.0 in stage 166.0 (TID 320) INFO Executor: Finished task 3.0 in stage 166.0 (TID 320). 6605 bytes result sent to driver
23/10/22 22:17:52.128 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 166.0 (TID 320) in 125 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:52.133 Executor task launch worker for task 5.0 in stage 166.0 (TID 322) INFO Executor: Finished task 5.0 in stage 166.0 (TID 322). 6562 bytes result sent to driver
23/10/22 22:17:52.134 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 166.0 (TID 322) in 132 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:52.141 Executor task launch worker for task 0.0 in stage 166.0 (TID 317) INFO Executor: Finished task 0.0 in stage 166.0 (TID 317). 6562 bytes result sent to driver
23/10/22 22:17:52.142 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 317) in 140 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:52.154 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:55185 in memory (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:17:52.158 Executor task launch worker for task 2.0 in stage 166.0 (TID 319) INFO Executor: Finished task 2.0 in stage 166.0 (TID 319). 6605 bytes result sent to driver
23/10/22 22:17:52.158 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 166.0 (TID 319) in 156 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:52.161 Executor task launch worker for task 6.0 in stage 166.0 (TID 323) INFO Executor: Finished task 6.0 in stage 166.0 (TID 323). 6605 bytes result sent to driver
23/10/22 22:17:52.163 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 166.0 (TID 323) in 161 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:52.170 Executor task launch worker for task 4.0 in stage 166.0 (TID 321) INFO Executor: Finished task 4.0 in stage 166.0 (TID 321). 6605 bytes result sent to driver
23/10/22 22:17:52.171 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 166.0 (TID 321) in 169 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:52.176 Executor task launch worker for task 7.0 in stage 166.0 (TID 324) INFO Executor: Finished task 7.0 in stage 166.0 (TID 324). 6605 bytes result sent to driver
23/10/22 22:17:52.176 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 166.0 (TID 324) in 173 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:52.177 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
23/10/22 22:17:52.177 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 166 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.183 s
23/10/22 22:17:52.177 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:52.177 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:52.177 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 167)
23/10/22 22:17:52.177 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:52.178 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[405] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:17:52.182 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 93.6 KiB, free 1036.9 MiB)
23/10/22 22:17:52.183 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 1036.8 MiB)
23/10/22 22:17:52.183 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:55185 (size: 37.4 KiB, free: 1037.1 MiB)
23/10/22 22:17:52.183 dag-scheduler-event-loop INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:52.184 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 167 (MapPartitionsRDD[405] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:52.184 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 167.0 with 2 tasks resource profile 0
23/10/22 22:17:52.185 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 325) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:52.185 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 326) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:52.186 Executor task launch worker for task 0.0 in stage 167.0 (TID 325) INFO Executor: Running task 0.0 in stage 167.0 (TID 325)
23/10/22 22:17:52.186 Executor task launch worker for task 1.0 in stage 167.0 (TID 326) INFO Executor: Running task 1.0 in stage 167.0 (TID 326)
23/10/22 22:17:52.193 Executor task launch worker for task 0.0 in stage 167.0 (TID 325) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.193 Executor task launch worker for task 0.0 in stage 167.0 (TID 325) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.193 Executor task launch worker for task 1.0 in stage 167.0 (TID 326) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:52.193 Executor task launch worker for task 1.0 in stage 167.0 (TID 326) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:52.200 Executor task launch worker for task 1.0 in stage 167.0 (TID 326) INFO Executor: Finished task 1.0 in stage 167.0 (TID 326). 6742 bytes result sent to driver
23/10/22 22:17:52.200 Executor task launch worker for task 0.0 in stage 167.0 (TID 325) INFO Executor: Finished task 0.0 in stage 167.0 (TID 325). 6742 bytes result sent to driver
23/10/22 22:17:52.201 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 325) in 16 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:52.201 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 326) in 16 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:52.201 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
23/10/22 22:17:52.201 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 167 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.022 s
23/10/22 22:17:52.202 dag-scheduler-event-loop INFO DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:52.202 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished
23/10/22 22:17:52.202 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 93 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.210079 s
23/10/22 22:17:52.202 nioEventLoopGroup-2-2 INFO Instrumentation: [ad2b1a59] Number of instances: 3785.
23/10/22 22:17:52.307 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 408 (rdd at LinearRegression.scala:921) as input to shuffle 58
23/10/22 22:17:52.307 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 94 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:17:52.307 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 168 (rdd at LinearRegression.scala:921)
23/10/22 22:17:52.307 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:52.307 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:52.307 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[408] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:52.309 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:17:52.310 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:17:52.310 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:17:52.311 dag-scheduler-event-loop INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:52.311 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[408] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:52.311 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks resource profile 0
23/10/22 22:17:52.752 dispatcher-event-loop-4 WARN TaskSetManager: Stage 168 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:52.752 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 327) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:52.753 Executor task launch worker for task 0.0 in stage 168.0 (TID 327) INFO Executor: Running task 0.0 in stage 168.0 (TID 327)
23/10/22 22:17:52.848 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:55185 in memory (size: 37.4 KiB, free: 1037.1 MiB)
23/10/22 22:17:52.850 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:55185 in memory (size: 36.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:53.011 Executor task launch worker for task 0.0 in stage 168.0 (TID 327) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:53.159 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:54.445 Executor task launch worker for task 0.0 in stage 168.0 (TID 327) INFO Executor: Finished task 0.0 in stage 168.0 (TID 327). 2147 bytes result sent to driver
23/10/22 22:17:54.446 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 327) in 2135 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:54.447 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
23/10/22 22:17:54.447 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 168 (rdd at LinearRegression.scala:921) finished in 2.140 s
23/10/22 22:17:54.448 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:54.448 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:54.448 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:54.448 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:54.452 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(58), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:54.454 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 412 (rdd at LinearRegression.scala:921) as input to shuffle 59
23/10/22 22:17:54.454 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 95 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:17:54.454 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 170 (rdd at LinearRegression.scala:921)
23/10/22 22:17:54.454 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 169)
23/10/22 22:17:54.454 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:54.455 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 170 (MapPartitionsRDD[412] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:17:54.458 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:54.459 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:54.459 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:54.459 dag-scheduler-event-loop INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:54.460 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 170 (MapPartitionsRDD[412] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:54.460 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 170.0 with 8 tasks resource profile 0
23/10/22 22:17:54.460 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 328) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 170.0 (TID 329) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 170.0 (TID 330) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 170.0 (TID 331) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 170.0 (TID 332) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 170.0 (TID 333) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.461 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 170.0 (TID 334) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.463 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 170.0 (TID 335) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.463 Executor task launch worker for task 1.0 in stage 170.0 (TID 329) INFO Executor: Running task 1.0 in stage 170.0 (TID 329)
23/10/22 22:17:54.463 Executor task launch worker for task 3.0 in stage 170.0 (TID 331) INFO Executor: Running task 3.0 in stage 170.0 (TID 331)
23/10/22 22:17:54.463 Executor task launch worker for task 7.0 in stage 170.0 (TID 335) INFO Executor: Running task 7.0 in stage 170.0 (TID 335)
23/10/22 22:17:54.463 Executor task launch worker for task 2.0 in stage 170.0 (TID 330) INFO Executor: Running task 2.0 in stage 170.0 (TID 330)
23/10/22 22:17:54.463 Executor task launch worker for task 0.0 in stage 170.0 (TID 328) INFO Executor: Running task 0.0 in stage 170.0 (TID 328)
23/10/22 22:17:54.463 Executor task launch worker for task 6.0 in stage 170.0 (TID 334) INFO Executor: Running task 6.0 in stage 170.0 (TID 334)
23/10/22 22:17:54.463 Executor task launch worker for task 5.0 in stage 170.0 (TID 333) INFO Executor: Running task 5.0 in stage 170.0 (TID 333)
23/10/22 22:17:54.463 Executor task launch worker for task 4.0 in stage 170.0 (TID 332) INFO Executor: Running task 4.0 in stage 170.0 (TID 332)
23/10/22 22:17:54.468 Executor task launch worker for task 2.0 in stage 170.0 (TID 330) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.468 Executor task launch worker for task 2.0 in stage 170.0 (TID 330) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.469 Executor task launch worker for task 6.0 in stage 170.0 (TID 334) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.469 Executor task launch worker for task 6.0 in stage 170.0 (TID 334) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.469 Executor task launch worker for task 7.0 in stage 170.0 (TID 335) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.468 Executor task launch worker for task 3.0 in stage 170.0 (TID 331) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.469 Executor task launch worker for task 3.0 in stage 170.0 (TID 331) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:17:54.469 Executor task launch worker for task 7.0 in stage 170.0 (TID 335) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.471 Executor task launch worker for task 5.0 in stage 170.0 (TID 333) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.471 Executor task launch worker for task 5.0 in stage 170.0 (TID 333) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.471 Executor task launch worker for task 0.0 in stage 170.0 (TID 328) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.472 Executor task launch worker for task 0.0 in stage 170.0 (TID 328) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.472 Executor task launch worker for task 4.0 in stage 170.0 (TID 332) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.472 Executor task launch worker for task 4.0 in stage 170.0 (TID 332) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.473 Executor task launch worker for task 1.0 in stage 170.0 (TID 329) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.473 Executor task launch worker for task 1.0 in stage 170.0 (TID 329) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.477 Executor task launch worker for task 2.0 in stage 170.0 (TID 330) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.480 Executor task launch worker for task 7.0 in stage 170.0 (TID 335) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.483 Executor task launch worker for task 4.0 in stage 170.0 (TID 332) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.483 Executor task launch worker for task 5.0 in stage 170.0 (TID 333) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.495 Executor task launch worker for task 1.0 in stage 170.0 (TID 329) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.502 Executor task launch worker for task 2.0 in stage 170.0 (TID 330) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.507 Executor task launch worker for task 0.0 in stage 170.0 (TID 328) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.519 Executor task launch worker for task 7.0 in stage 170.0 (TID 335) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.520 Executor task launch worker for task 4.0 in stage 170.0 (TID 332) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.521 Executor task launch worker for task 6.0 in stage 170.0 (TID 334) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.523 Executor task launch worker for task 5.0 in stage 170.0 (TID 333) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.535 Executor task launch worker for task 3.0 in stage 170.0 (TID 331) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.537 Executor task launch worker for task 1.0 in stage 170.0 (TID 329) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.571 Executor task launch worker for task 6.0 in stage 170.0 (TID 334) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.614 Executor task launch worker for task 3.0 in stage 170.0 (TID 331) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.630 Executor task launch worker for task 0.0 in stage 170.0 (TID 328) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.672 Executor task launch worker for task 4.0 in stage 170.0 (TID 332) INFO Executor: Finished task 4.0 in stage 170.0 (TID 332). 4899 bytes result sent to driver
23/10/22 22:17:54.676 Executor task launch worker for task 5.0 in stage 170.0 (TID 333) INFO Executor: Finished task 5.0 in stage 170.0 (TID 333). 4899 bytes result sent to driver
23/10/22 22:17:54.676 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 170.0 (TID 332) in 215 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:54.679 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 170.0 (TID 333) in 218 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:54.707 Executor task launch worker for task 1.0 in stage 170.0 (TID 329) INFO Executor: Finished task 1.0 in stage 170.0 (TID 329). 4942 bytes result sent to driver
23/10/22 22:17:54.708 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 170.0 (TID 329) in 247 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:54.760 Executor task launch worker for task 2.0 in stage 170.0 (TID 330) INFO Executor: Finished task 2.0 in stage 170.0 (TID 330). 4899 bytes result sent to driver
23/10/22 22:17:54.761 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 170.0 (TID 330) in 300 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:54.771 Executor task launch worker for task 7.0 in stage 170.0 (TID 335) INFO Executor: Finished task 7.0 in stage 170.0 (TID 335). 4899 bytes result sent to driver
23/10/22 22:17:54.772 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 170.0 (TID 335) in 309 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:54.799 Executor task launch worker for task 6.0 in stage 170.0 (TID 334) INFO Executor: Finished task 6.0 in stage 170.0 (TID 334). 4899 bytes result sent to driver
23/10/22 22:17:54.799 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 170.0 (TID 334) in 338 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:54.802 Executor task launch worker for task 3.0 in stage 170.0 (TID 331) INFO Executor: Finished task 3.0 in stage 170.0 (TID 331). 4899 bytes result sent to driver
23/10/22 22:17:54.803 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 170.0 (TID 331) in 341 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:54.805 Executor task launch worker for task 0.0 in stage 170.0 (TID 328) INFO Executor: Finished task 0.0 in stage 170.0 (TID 328). 4899 bytes result sent to driver
23/10/22 22:17:54.806 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 328) in 346 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:54.806 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
23/10/22 22:17:54.806 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 170 (rdd at LinearRegression.scala:921) finished in 0.350 s
23/10/22 22:17:54.806 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:54.806 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:54.807 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:54.807 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:54.812 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(59), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:54.836 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.6635 ms
23/10/22 22:17:54.881 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:17:54.882 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 422 (treeAggregate at Statistics.scala:58) as input to shuffle 60
23/10/22 22:17:54.882 dag-scheduler-event-loop INFO DAGScheduler: Got job 96 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:17:54.882 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 174 (treeAggregate at Statistics.scala:58)
23/10/22 22:17:54.883 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 173)
23/10/22 22:17:54.883 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 173)
23/10/22 22:17:54.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 173 (MapPartitionsRDD[422] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:54.889 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 83.1 KiB, free 1037.0 MiB)
23/10/22 22:17:54.891 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1036.9 MiB)
23/10/22 22:17:54.892 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:55185 (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 22:17:54.892 dag-scheduler-event-loop INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:54.893 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 173 (MapPartitionsRDD[422] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:54.893 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 173.0 with 8 tasks resource profile 0
23/10/22 22:17:54.894 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 336) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.895 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 173.0 (TID 337) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.895 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 173.0 (TID 338) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.895 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 173.0 (TID 339) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.895 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 173.0 (TID 340) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.896 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 173.0 (TID 341) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.896 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 173.0 (TID 342) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.896 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 173.0 (TID 343) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:54.896 Executor task launch worker for task 2.0 in stage 173.0 (TID 338) INFO Executor: Running task 2.0 in stage 173.0 (TID 338)
23/10/22 22:17:54.896 Executor task launch worker for task 6.0 in stage 173.0 (TID 342) INFO Executor: Running task 6.0 in stage 173.0 (TID 342)
23/10/22 22:17:54.896 Executor task launch worker for task 7.0 in stage 173.0 (TID 343) INFO Executor: Running task 7.0 in stage 173.0 (TID 343)
23/10/22 22:17:54.896 Executor task launch worker for task 0.0 in stage 173.0 (TID 336) INFO Executor: Running task 0.0 in stage 173.0 (TID 336)
23/10/22 22:17:54.896 Executor task launch worker for task 5.0 in stage 173.0 (TID 341) INFO Executor: Running task 5.0 in stage 173.0 (TID 341)
23/10/22 22:17:54.896 Executor task launch worker for task 1.0 in stage 173.0 (TID 337) INFO Executor: Running task 1.0 in stage 173.0 (TID 337)
23/10/22 22:17:54.896 Executor task launch worker for task 3.0 in stage 173.0 (TID 339) INFO Executor: Running task 3.0 in stage 173.0 (TID 339)
23/10/22 22:17:54.896 Executor task launch worker for task 4.0 in stage 173.0 (TID 340) INFO Executor: Running task 4.0 in stage 173.0 (TID 340)
23/10/22 22:17:54.905 Executor task launch worker for task 3.0 in stage 173.0 (TID 339) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.906 Executor task launch worker for task 3.0 in stage 173.0 (TID 339) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.906 Executor task launch worker for task 2.0 in stage 173.0 (TID 338) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.906 Executor task launch worker for task 2.0 in stage 173.0 (TID 338) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.907 Executor task launch worker for task 4.0 in stage 173.0 (TID 340) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.907 Executor task launch worker for task 4.0 in stage 173.0 (TID 340) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.907 Executor task launch worker for task 0.0 in stage 173.0 (TID 336) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.907 Executor task launch worker for task 0.0 in stage 173.0 (TID 336) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.908 Executor task launch worker for task 6.0 in stage 173.0 (TID 342) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.908 Executor task launch worker for task 6.0 in stage 173.0 (TID 342) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.908 Executor task launch worker for task 5.0 in stage 173.0 (TID 341) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.908 Executor task launch worker for task 5.0 in stage 173.0 (TID 341) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.910 Executor task launch worker for task 7.0 in stage 173.0 (TID 343) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.910 Executor task launch worker for task 7.0 in stage 173.0 (TID 343) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.911 Executor task launch worker for task 1.0 in stage 173.0 (TID 337) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:54.912 Executor task launch worker for task 1.0 in stage 173.0 (TID 337) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:54.928 Executor task launch worker for task 4.0 in stage 173.0 (TID 340) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.928 Executor task launch worker for task 5.0 in stage 173.0 (TID 341) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.928 Executor task launch worker for task 3.0 in stage 173.0 (TID 339) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.930 Executor task launch worker for task 6.0 in stage 173.0 (TID 342) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.950 Executor task launch worker for task 1.0 in stage 173.0 (TID 337) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.950 Executor task launch worker for task 0.0 in stage 173.0 (TID 336) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.956 Executor task launch worker for task 7.0 in stage 173.0 (TID 343) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:54.972 Executor task launch worker for task 2.0 in stage 173.0 (TID 338) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:55.001 Executor task launch worker for task 5.0 in stage 173.0 (TID 341) INFO Executor: Finished task 5.0 in stage 173.0 (TID 341). 6562 bytes result sent to driver
23/10/22 22:17:55.002 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 173.0 (TID 341) in 107 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:55.006 Executor task launch worker for task 6.0 in stage 173.0 (TID 342) INFO Executor: Finished task 6.0 in stage 173.0 (TID 342). 6562 bytes result sent to driver
23/10/22 22:17:55.006 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 173.0 (TID 342) in 110 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:55.016 Executor task launch worker for task 4.0 in stage 173.0 (TID 340) INFO Executor: Finished task 4.0 in stage 173.0 (TID 340). 6562 bytes result sent to driver
23/10/22 22:17:55.018 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 173.0 (TID 340) in 123 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:55.024 Executor task launch worker for task 3.0 in stage 173.0 (TID 339) INFO Executor: Finished task 3.0 in stage 173.0 (TID 339). 6562 bytes result sent to driver
23/10/22 22:17:55.025 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 173.0 (TID 339) in 130 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:55.028 Executor task launch worker for task 0.0 in stage 173.0 (TID 336) INFO Executor: Finished task 0.0 in stage 173.0 (TID 336). 6562 bytes result sent to driver
23/10/22 22:17:55.030 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 336) in 136 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:55.050 Executor task launch worker for task 1.0 in stage 173.0 (TID 337) INFO Executor: Finished task 1.0 in stage 173.0 (TID 337). 6605 bytes result sent to driver
23/10/22 22:17:55.051 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 173.0 (TID 337) in 157 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:55.058 Executor task launch worker for task 7.0 in stage 173.0 (TID 343) INFO Executor: Finished task 7.0 in stage 173.0 (TID 343). 6562 bytes result sent to driver
23/10/22 22:17:55.058 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 173.0 (TID 343) in 162 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:55.061 Executor task launch worker for task 2.0 in stage 173.0 (TID 338) INFO Executor: Finished task 2.0 in stage 173.0 (TID 338). 6562 bytes result sent to driver
23/10/22 22:17:55.061 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 173.0 (TID 338) in 166 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:55.062 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
23/10/22 22:17:55.062 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 173 (treeAggregate at Statistics.scala:58) finished in 0.178 s
23/10/22 22:17:55.062 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:55.062 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:55.062 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 174)
23/10/22 22:17:55.062 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:55.062 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 174 (MapPartitionsRDD[424] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:17:55.067 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 84.2 KiB, free 1036.8 MiB)
23/10/22 22:17:55.068 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 1036.8 MiB)
23/10/22 22:17:55.068 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:55185 (size: 35.9 KiB, free: 1037.0 MiB)
23/10/22 22:17:55.069 dag-scheduler-event-loop INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:55.069 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 174 (MapPartitionsRDD[424] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:17:55.069 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 174.0 with 2 tasks resource profile 0
23/10/22 22:17:55.070 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 344) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:55.070 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 174.0 (TID 345) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:17:55.070 Executor task launch worker for task 0.0 in stage 174.0 (TID 344) INFO Executor: Running task 0.0 in stage 174.0 (TID 344)
23/10/22 22:17:55.070 Executor task launch worker for task 1.0 in stage 174.0 (TID 345) INFO Executor: Running task 1.0 in stage 174.0 (TID 345)
23/10/22 22:17:55.076 Executor task launch worker for task 0.0 in stage 174.0 (TID 344) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:55.076 Executor task launch worker for task 1.0 in stage 174.0 (TID 345) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:55.076 Executor task launch worker for task 0.0 in stage 174.0 (TID 344) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:55.076 Executor task launch worker for task 1.0 in stage 174.0 (TID 345) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:55.082 Executor task launch worker for task 1.0 in stage 174.0 (TID 345) INFO Executor: Finished task 1.0 in stage 174.0 (TID 345). 7587 bytes result sent to driver
23/10/22 22:17:55.082 Executor task launch worker for task 0.0 in stage 174.0 (TID 344) INFO Executor: Finished task 0.0 in stage 174.0 (TID 344). 7587 bytes result sent to driver
23/10/22 22:17:55.082 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 174.0 (TID 345) in 12 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:17:55.083 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 344) in 14 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:17:55.083 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
23/10/22 22:17:55.083 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 174 (treeAggregate at Statistics.scala:58) finished in 0.020 s
23/10/22 22:17:55.083 dag-scheduler-event-loop INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:55.083 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 174: Stage finished
23/10/22 22:17:55.083 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 96 finished: treeAggregate at Statistics.scala:58, took 0.202299 s
23/10/22 22:17:55.084 nioEventLoopGroup-2-2 INFO Instrumentation: [96aa6860] training finished
23/10/22 22:17:55.472 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:55.472 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:55.473 dag-scheduler-event-loop INFO DAGScheduler: Got job 97 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:55.473 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 175 (collect at utils.scala:26)
23/10/22 22:17:55.473 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:55.473 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:55.473 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[426] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:55.474 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:55185 in memory (size: 35.9 KiB, free: 1037.1 MiB)
23/10/22 22:17:55.475 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 7.4 KiB, free 1037.0 MiB)
23/10/22 22:17:55.475 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:55185 in memory (size: 35.4 KiB, free: 1037.1 MiB)
23/10/22 22:17:55.476 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:17:55.476 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:55.476 dag-scheduler-event-loop INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:55.477 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[426] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:55.477 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0
23/10/22 22:17:55.478 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 346) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:55.478 Executor task launch worker for task 0.0 in stage 175.0 (TID 346) INFO Executor: Running task 0.0 in stage 175.0 (TID 346)
23/10/22 22:17:55.480 Executor task launch worker for task 0.0 in stage 175.0 (TID 346) INFO Executor: Finished task 0.0 in stage 175.0 (TID 346). 1284 bytes result sent to driver
23/10/22 22:17:55.480 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 346) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:55.480 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
23/10/22 22:17:55.481 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 175 (collect at utils.scala:26) finished in 0.008 s
23/10/22 22:17:55.481 dag-scheduler-event-loop INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:55.481 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished
23/10/22 22:17:55.481 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 97 finished: collect at utils.scala:26, took 0.008354 s
23/10/22 22:17:55.789 nioEventLoopGroup-2-2 INFO Instrumentation: [d319a65d] training finished
23/10/22 22:17:55.902 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:55.902 dag-scheduler-event-loop INFO DAGScheduler: Got job 98 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:55.902 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 176 (collect at utils.scala:26)
23/10/22 22:17:55.902 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:55.902 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:55.903 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[428] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:55.903 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 22:17:55.904 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:17:55.904 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:55.905 dag-scheduler-event-loop INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:55.905 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[428] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:55.905 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0
23/10/22 22:17:55.905 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 347) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:55.906 Executor task launch worker for task 0.0 in stage 176.0 (TID 347) INFO Executor: Running task 0.0 in stage 176.0 (TID 347)
23/10/22 22:17:55.908 Executor task launch worker for task 0.0 in stage 176.0 (TID 347) INFO Executor: Finished task 0.0 in stage 176.0 (TID 347). 1327 bytes result sent to driver
23/10/22 22:17:55.908 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 347) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:55.909 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
23/10/22 22:17:55.909 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 176 (collect at utils.scala:26) finished in 0.006 s
23/10/22 22:17:55.909 dag-scheduler-event-loop INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:55.909 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 176: Stage finished
23/10/22 22:17:55.909 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 98 finished: collect at utils.scala:26, took 0.006999 s
23/10/22 22:17:56.355 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:17:56.355 dag-scheduler-event-loop INFO DAGScheduler: Got job 99 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:17:56.355 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 177 (collect at utils.scala:26)
23/10/22 22:17:56.355 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:56.355 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:56.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[430] at collect at utils.scala:26), which has no missing parents
23/10/22 22:17:56.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 22:17:56.357 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:17:56.357 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:56.357 dag-scheduler-event-loop INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:56.357 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[430] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:56.357 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 177.0 with 1 tasks resource profile 0
23/10/22 22:17:56.358 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 348) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:17:56.358 Executor task launch worker for task 0.0 in stage 177.0 (TID 348) INFO Executor: Running task 0.0 in stage 177.0 (TID 348)
23/10/22 22:17:56.360 Executor task launch worker for task 0.0 in stage 177.0 (TID 348) INFO Executor: Finished task 0.0 in stage 177.0 (TID 348). 1284 bytes result sent to driver
23/10/22 22:17:56.360 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 348) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:56.360 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
23/10/22 22:17:56.360 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 177 (collect at utils.scala:26) finished in 0.004 s
23/10/22 22:17:56.361 dag-scheduler-event-loop INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:17:56.361 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
23/10/22 22:17:56.361 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 99 finished: collect at utils.scala:26, took 0.005877 s
23/10/22 22:17:57.054 nioEventLoopGroup-2-2 INFO Instrumentation: [3c7a736c] training finished
23/10/22 22:17:57.066 nioEventLoopGroup-2-2 INFO Instrumentation: [e37552c3] training finished
23/10/22 22:17:57.072 nioEventLoopGroup-2-2 INFO Instrumentation: [c9cfee14] Stage class: LinearRegression
23/10/22 22:17:57.072 nioEventLoopGroup-2-2 INFO Instrumentation: [c9cfee14] Stage uid: linear_regression__e4b890de_82d2_43a9_84d6_dd31bb1b0117
23/10/22 22:17:57.103 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 433 (rdd at Instrumentation.scala:62) as input to shuffle 61
23/10/22 22:17:57.103 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 100 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:17:57.103 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 178 (rdd at Instrumentation.scala:62)
23/10/22 22:17:57.103 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:57.103 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:57.103 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 178 (MapPartitionsRDD[433] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:57.105 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:17:57.105 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:57.106 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:57.106 dag-scheduler-event-loop INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:57.106 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 178 (MapPartitionsRDD[433] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:57.106 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0
23/10/22 22:17:57.447 dispatcher-event-loop-5 WARN TaskSetManager: Stage 178 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:57.448 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 349) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:57.449 Executor task launch worker for task 0.0 in stage 178.0 (TID 349) INFO Executor: Running task 0.0 in stage 178.0 (TID 349)
23/10/22 22:17:57.526 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:57.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:57.531 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:17:57.641 Executor task launch worker for task 0.0 in stage 178.0 (TID 349) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:57.763 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:58.721 Executor task launch worker for task 0.0 in stage 178.0 (TID 349) INFO Executor: Finished task 0.0 in stage 178.0 (TID 349). 2147 bytes result sent to driver
23/10/22 22:17:58.722 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 349) in 1614 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:17:58.722 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
23/10/22 22:17:58.722 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 178 (rdd at Instrumentation.scala:62) finished in 1.618 s
23/10/22 22:17:58.722 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:58.722 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:58.722 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:58.722 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:58.727 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(61), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:17:58.730 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 437 (rdd at Instrumentation.scala:62) as input to shuffle 62
23/10/22 22:17:58.730 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 101 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:17:58.730 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 180 (rdd at Instrumentation.scala:62)
23/10/22 22:17:58.730 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 179)
23/10/22 22:17:58.730 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:58.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[437] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:17:58.734 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:17:58.735 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:17:58.735 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:17:58.735 dag-scheduler-event-loop INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:58.736 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[437] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:17:58.736 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 180.0 with 8 tasks resource profile 0
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 350) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 351) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 180.0 (TID 352) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 180.0 (TID 353) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 180.0 (TID 354) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 180.0 (TID 355) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.737 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 180.0 (TID 356) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.738 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 180.0 (TID 357) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:17:58.738 Executor task launch worker for task 1.0 in stage 180.0 (TID 351) INFO Executor: Running task 1.0 in stage 180.0 (TID 351)
23/10/22 22:17:58.738 Executor task launch worker for task 7.0 in stage 180.0 (TID 357) INFO Executor: Running task 7.0 in stage 180.0 (TID 357)
23/10/22 22:17:58.738 Executor task launch worker for task 6.0 in stage 180.0 (TID 356) INFO Executor: Running task 6.0 in stage 180.0 (TID 356)
23/10/22 22:17:58.738 Executor task launch worker for task 2.0 in stage 180.0 (TID 352) INFO Executor: Running task 2.0 in stage 180.0 (TID 352)
23/10/22 22:17:58.738 Executor task launch worker for task 0.0 in stage 180.0 (TID 350) INFO Executor: Running task 0.0 in stage 180.0 (TID 350)
23/10/22 22:17:58.738 Executor task launch worker for task 5.0 in stage 180.0 (TID 355) INFO Executor: Running task 5.0 in stage 180.0 (TID 355)
23/10/22 22:17:58.738 Executor task launch worker for task 4.0 in stage 180.0 (TID 354) INFO Executor: Running task 4.0 in stage 180.0 (TID 354)
23/10/22 22:17:58.738 Executor task launch worker for task 3.0 in stage 180.0 (TID 353) INFO Executor: Running task 3.0 in stage 180.0 (TID 353)
23/10/22 22:17:58.741 Executor task launch worker for task 0.0 in stage 180.0 (TID 350) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.742 Executor task launch worker for task 0.0 in stage 180.0 (TID 350) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.742 Executor task launch worker for task 5.0 in stage 180.0 (TID 355) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.742 Executor task launch worker for task 5.0 in stage 180.0 (TID 355) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.743 Executor task launch worker for task 6.0 in stage 180.0 (TID 356) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.743 Executor task launch worker for task 6.0 in stage 180.0 (TID 356) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.743 Executor task launch worker for task 4.0 in stage 180.0 (TID 354) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.743 Executor task launch worker for task 4.0 in stage 180.0 (TID 354) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.743 Executor task launch worker for task 3.0 in stage 180.0 (TID 353) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.743 Executor task launch worker for task 3.0 in stage 180.0 (TID 353) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.741 Executor task launch worker for task 1.0 in stage 180.0 (TID 351) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.743 Executor task launch worker for task 1.0 in stage 180.0 (TID 351) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
23/10/22 22:17:58.743 Executor task launch worker for task 7.0 in stage 180.0 (TID 357) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.743 Executor task launch worker for task 7.0 in stage 180.0 (TID 357) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.744 Executor task launch worker for task 2.0 in stage 180.0 (TID 352) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:17:58.744 Executor task launch worker for task 2.0 in stage 180.0 (TID 352) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:17:58.753 Executor task launch worker for task 2.0 in stage 180.0 (TID 352) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.754 Executor task launch worker for task 1.0 in stage 180.0 (TID 351) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.754 Executor task launch worker for task 4.0 in stage 180.0 (TID 354) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.756 Executor task launch worker for task 6.0 in stage 180.0 (TID 356) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.763 Executor task launch worker for task 5.0 in stage 180.0 (TID 355) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.775 Executor task launch worker for task 7.0 in stage 180.0 (TID 357) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.779 Executor task launch worker for task 4.0 in stage 180.0 (TID 354) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.782 Executor task launch worker for task 3.0 in stage 180.0 (TID 353) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.783 Executor task launch worker for task 1.0 in stage 180.0 (TID 351) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.790 Executor task launch worker for task 2.0 in stage 180.0 (TID 352) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.799 Executor task launch worker for task 5.0 in stage 180.0 (TID 355) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.807 Executor task launch worker for task 3.0 in stage 180.0 (TID 353) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.809 Executor task launch worker for task 7.0 in stage 180.0 (TID 357) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.842 Executor task launch worker for task 6.0 in stage 180.0 (TID 356) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.854 Executor task launch worker for task 0.0 in stage 180.0 (TID 350) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:58.927 Executor task launch worker for task 0.0 in stage 180.0 (TID 350) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:59.034 Executor task launch worker for task 2.0 in stage 180.0 (TID 352) INFO Executor: Finished task 2.0 in stage 180.0 (TID 352). 4899 bytes result sent to driver
23/10/22 22:17:59.039 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 180.0 (TID 352) in 302 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:17:59.053 Executor task launch worker for task 5.0 in stage 180.0 (TID 355) INFO Executor: Finished task 5.0 in stage 180.0 (TID 355). 4899 bytes result sent to driver
23/10/22 22:17:59.054 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 180.0 (TID 355) in 317 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:17:59.058 Executor task launch worker for task 4.0 in stage 180.0 (TID 354) INFO Executor: Finished task 4.0 in stage 180.0 (TID 354). 4899 bytes result sent to driver
23/10/22 22:17:59.059 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 180.0 (TID 354) in 322 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:17:59.064 Executor task launch worker for task 3.0 in stage 180.0 (TID 353) INFO Executor: Finished task 3.0 in stage 180.0 (TID 353). 4899 bytes result sent to driver
23/10/22 22:17:59.065 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 180.0 (TID 353) in 328 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:17:59.070 Executor task launch worker for task 1.0 in stage 180.0 (TID 351) INFO Executor: Finished task 1.0 in stage 180.0 (TID 351). 4942 bytes result sent to driver
23/10/22 22:17:59.072 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 351) in 335 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:17:59.075 Executor task launch worker for task 7.0 in stage 180.0 (TID 357) INFO Executor: Finished task 7.0 in stage 180.0 (TID 357). 4942 bytes result sent to driver
23/10/22 22:17:59.076 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 180.0 (TID 357) in 339 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:17:59.080 Executor task launch worker for task 6.0 in stage 180.0 (TID 356) INFO Executor: Finished task 6.0 in stage 180.0 (TID 356). 4899 bytes result sent to driver
23/10/22 22:17:59.080 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 180.0 (TID 356) in 343 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:17:59.083 Executor task launch worker for task 0.0 in stage 180.0 (TID 350) INFO Executor: Finished task 0.0 in stage 180.0 (TID 350). 4899 bytes result sent to driver
23/10/22 22:17:59.084 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 350) in 347 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:17:59.084 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
23/10/22 22:17:59.086 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 180 (rdd at Instrumentation.scala:62) finished in 0.354 s
23/10/22 22:17:59.086 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:17:59.086 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:17:59.086 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:17:59.086 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:17:59.097 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(62), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:17:59.120 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.0568 ms
23/10/22 22:17:59.132 nioEventLoopGroup-2-2 INFO Instrumentation: [c9cfee14] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:17:59.133 nioEventLoopGroup-2-2 INFO Instrumentation: [c9cfee14] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:17:59.134 nioEventLoopGroup-2-2 INFO Instrumentation: [c9cfee14] {"numFeatures":2}
23/10/22 22:17:59.199 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 446 (rdd at LinearRegression.scala:348) as input to shuffle 63
23/10/22 22:17:59.199 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 102 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:17:59.199 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 181 (rdd at LinearRegression.scala:348)
23/10/22 22:17:59.199 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:17:59.199 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:17:59.199 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 181 (MapPartitionsRDD[446] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:17:59.201 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:17:59.202 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:17:59.203 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:17:59.203 dag-scheduler-event-loop INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1535
23/10/22 22:17:59.203 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 181 (MapPartitionsRDD[446] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:17:59.203 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks resource profile 0
23/10/22 22:17:59.567 dispatcher-event-loop-4 WARN TaskSetManager: Stage 181 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:17:59.568 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 358) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:17:59.569 Executor task launch worker for task 0.0 in stage 181.0 (TID 358) INFO Executor: Running task 0.0 in stage 181.0 (TID 358)
23/10/22 22:17:59.733 Executor task launch worker for task 0.0 in stage 181.0 (TID 358) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:17:59.794 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:00.067 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:00.827 Executor task launch worker for task 0.0 in stage 181.0 (TID 358) INFO Executor: Finished task 0.0 in stage 181.0 (TID 358). 2104 bytes result sent to driver
23/10/22 22:18:00.828 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 358) in 1624 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:00.828 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
23/10/22 22:18:00.828 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 181 (rdd at LinearRegression.scala:348) finished in 1.628 s
23/10/22 22:18:00.828 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:00.828 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:00.828 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:00.828 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:00.834 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:00.835 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 450 (rdd at LinearRegression.scala:348) as input to shuffle 64
23/10/22 22:18:00.836 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 103 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:18:00.836 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 183 (rdd at LinearRegression.scala:348)
23/10/22 22:18:00.836 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 182)
23/10/22 22:18:00.836 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:00.836 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 183 (MapPartitionsRDD[450] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:18:00.838 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:18:00.838 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:18:00.839 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:00.839 dag-scheduler-event-loop INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:00.839 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 183 (MapPartitionsRDD[450] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:00.839 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 183.0 with 8 tasks resource profile 0
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 359) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 183.0 (TID 360) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 183.0 (TID 361) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 183.0 (TID 362) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 183.0 (TID 363) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 5.0 in stage 183.0 (TID 364) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 6.0 in stage 183.0 (TID 365) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.840 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 7.0 in stage 183.0 (TID 366) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:00.841 Executor task launch worker for task 0.0 in stage 183.0 (TID 359) INFO Executor: Running task 0.0 in stage 183.0 (TID 359)
23/10/22 22:18:00.841 Executor task launch worker for task 4.0 in stage 183.0 (TID 363) INFO Executor: Running task 4.0 in stage 183.0 (TID 363)
23/10/22 22:18:00.841 Executor task launch worker for task 1.0 in stage 183.0 (TID 360) INFO Executor: Running task 1.0 in stage 183.0 (TID 360)
23/10/22 22:18:00.841 Executor task launch worker for task 3.0 in stage 183.0 (TID 362) INFO Executor: Running task 3.0 in stage 183.0 (TID 362)
23/10/22 22:18:00.841 Executor task launch worker for task 2.0 in stage 183.0 (TID 361) INFO Executor: Running task 2.0 in stage 183.0 (TID 361)
23/10/22 22:18:00.841 Executor task launch worker for task 6.0 in stage 183.0 (TID 365) INFO Executor: Running task 6.0 in stage 183.0 (TID 365)
23/10/22 22:18:00.841 Executor task launch worker for task 7.0 in stage 183.0 (TID 366) INFO Executor: Running task 7.0 in stage 183.0 (TID 366)
23/10/22 22:18:00.841 Executor task launch worker for task 5.0 in stage 183.0 (TID 364) INFO Executor: Running task 5.0 in stage 183.0 (TID 364)
23/10/22 22:18:00.848 Executor task launch worker for task 1.0 in stage 183.0 (TID 360) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.848 Executor task launch worker for task 1.0 in stage 183.0 (TID 360) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.848 Executor task launch worker for task 5.0 in stage 183.0 (TID 364) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.848 Executor task launch worker for task 6.0 in stage 183.0 (TID 365) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.848 Executor task launch worker for task 5.0 in stage 183.0 (TID 364) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.848 Executor task launch worker for task 6.0 in stage 183.0 (TID 365) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.848 Executor task launch worker for task 0.0 in stage 183.0 (TID 359) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.848 Executor task launch worker for task 0.0 in stage 183.0 (TID 359) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.848 Executor task launch worker for task 4.0 in stage 183.0 (TID 363) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.849 Executor task launch worker for task 4.0 in stage 183.0 (TID 363) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.849 Executor task launch worker for task 7.0 in stage 183.0 (TID 366) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.850 Executor task launch worker for task 7.0 in stage 183.0 (TID 366) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.850 Executor task launch worker for task 3.0 in stage 183.0 (TID 362) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.850 Executor task launch worker for task 3.0 in stage 183.0 (TID 362) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.850 Executor task launch worker for task 2.0 in stage 183.0 (TID 361) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:00.850 Executor task launch worker for task 2.0 in stage 183.0 (TID 361) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:00.855 Executor task launch worker for task 1.0 in stage 183.0 (TID 360) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.856 Executor task launch worker for task 6.0 in stage 183.0 (TID 365) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.856 Executor task launch worker for task 0.0 in stage 183.0 (TID 359) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.856 Executor task launch worker for task 7.0 in stage 183.0 (TID 366) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.856 Executor task launch worker for task 4.0 in stage 183.0 (TID 363) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.857 Executor task launch worker for task 3.0 in stage 183.0 (TID 362) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.857 Executor task launch worker for task 5.0 in stage 183.0 (TID 364) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.874 Executor task launch worker for task 2.0 in stage 183.0 (TID 361) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.878 Executor task launch worker for task 6.0 in stage 183.0 (TID 365) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.881 Executor task launch worker for task 3.0 in stage 183.0 (TID 362) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.882 Executor task launch worker for task 7.0 in stage 183.0 (TID 366) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.882 Executor task launch worker for task 5.0 in stage 183.0 (TID 364) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.886 Executor task launch worker for task 4.0 in stage 183.0 (TID 363) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.887 Executor task launch worker for task 1.0 in stage 183.0 (TID 360) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.901 Executor task launch worker for task 2.0 in stage 183.0 (TID 361) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:00.911 Executor task launch worker for task 0.0 in stage 183.0 (TID 359) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.006 Executor task launch worker for task 1.0 in stage 183.0 (TID 360) INFO Executor: Finished task 1.0 in stage 183.0 (TID 360). 4985 bytes result sent to driver
23/10/22 22:18:01.010 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 183.0 (TID 360) in 169 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:01.045 Executor task launch worker for task 7.0 in stage 183.0 (TID 366) INFO Executor: Finished task 7.0 in stage 183.0 (TID 366). 4985 bytes result sent to driver
23/10/22 22:18:01.047 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 183.0 (TID 366) in 207 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:01.053 Executor task launch worker for task 2.0 in stage 183.0 (TID 361) INFO Executor: Finished task 2.0 in stage 183.0 (TID 361). 4942 bytes result sent to driver
23/10/22 22:18:01.054 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 183.0 (TID 361) in 214 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:01.058 Executor task launch worker for task 3.0 in stage 183.0 (TID 362) INFO Executor: Finished task 3.0 in stage 183.0 (TID 362). 4942 bytes result sent to driver
23/10/22 22:18:01.059 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 183.0 (TID 362) in 219 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:01.063 Executor task launch worker for task 5.0 in stage 183.0 (TID 364) INFO Executor: Finished task 5.0 in stage 183.0 (TID 364). 4985 bytes result sent to driver
23/10/22 22:18:01.063 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 183.0 (TID 364) in 223 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:01.070 Executor task launch worker for task 4.0 in stage 183.0 (TID 363) INFO Executor: Finished task 4.0 in stage 183.0 (TID 363). 4985 bytes result sent to driver
23/10/22 22:18:01.070 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 183.0 (TID 363) in 230 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:01.081 Executor task launch worker for task 6.0 in stage 183.0 (TID 365) INFO Executor: Finished task 6.0 in stage 183.0 (TID 365). 4942 bytes result sent to driver
23/10/22 22:18:01.082 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 183.0 (TID 365) in 242 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:01.090 Executor task launch worker for task 0.0 in stage 183.0 (TID 359) INFO Executor: Finished task 0.0 in stage 183.0 (TID 359). 4942 bytes result sent to driver
23/10/22 22:18:01.091 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 359) in 251 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:01.091 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
23/10/22 22:18:01.091 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 183 (rdd at LinearRegression.scala:348) finished in 0.255 s
23/10/22 22:18:01.091 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:01.091 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:01.091 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:01.091 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:01.096 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(64), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:01.146 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 35.3826 ms
23/10/22 22:18:01.162 nioEventLoopGroup-2-2 WARN Instrumentation: [c9cfee14] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:18:01.199 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:18:01.200 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 459 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 65
23/10/22 22:18:01.200 dag-scheduler-event-loop INFO DAGScheduler: Got job 104 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:18:01.200 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 187 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:18:01.200 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 186)
23/10/22 22:18:01.200 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 186)
23/10/22 22:18:01.201 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 186 (MapPartitionsRDD[459] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:18:01.206 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 93.3 KiB, free 1037.0 MiB)
23/10/22 22:18:01.208 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1036.9 MiB)
23/10/22 22:18:01.226 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:55185 (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:18:01.227 dag-scheduler-event-loop INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:01.227 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 186 (MapPartitionsRDD[459] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:01.228 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 186.0 with 8 tasks resource profile 0
23/10/22 22:18:01.229 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 367) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.229 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 186.0 (TID 368) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.229 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 186.0 (TID 369) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.229 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 186.0 (TID 370) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.230 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 186.0 (TID 371) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.230 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 186.0 (TID 372) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.230 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 186.0 (TID 373) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.231 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 186.0 (TID 374) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:01.232 Executor task launch worker for task 4.0 in stage 186.0 (TID 371) INFO Executor: Running task 4.0 in stage 186.0 (TID 371)
23/10/22 22:18:01.232 Executor task launch worker for task 5.0 in stage 186.0 (TID 372) INFO Executor: Running task 5.0 in stage 186.0 (TID 372)
23/10/22 22:18:01.233 Executor task launch worker for task 7.0 in stage 186.0 (TID 374) INFO Executor: Running task 7.0 in stage 186.0 (TID 374)
23/10/22 22:18:01.233 Executor task launch worker for task 0.0 in stage 186.0 (TID 367) INFO Executor: Running task 0.0 in stage 186.0 (TID 367)
23/10/22 22:18:01.234 Executor task launch worker for task 1.0 in stage 186.0 (TID 368) INFO Executor: Running task 1.0 in stage 186.0 (TID 368)
23/10/22 22:18:01.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:01.237 Executor task launch worker for task 2.0 in stage 186.0 (TID 369) INFO Executor: Running task 2.0 in stage 186.0 (TID 369)
23/10/22 22:18:01.242 Executor task launch worker for task 1.0 in stage 186.0 (TID 368) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.242 Executor task launch worker for task 1.0 in stage 186.0 (TID 368) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.243 Executor task launch worker for task 2.0 in stage 186.0 (TID 369) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.243 Executor task launch worker for task 2.0 in stage 186.0 (TID 369) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.243 Executor task launch worker for task 3.0 in stage 186.0 (TID 370) INFO Executor: Running task 3.0 in stage 186.0 (TID 370)
23/10/22 22:18:01.247 Executor task launch worker for task 0.0 in stage 186.0 (TID 367) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.247 Executor task launch worker for task 0.0 in stage 186.0 (TID 367) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.247 Executor task launch worker for task 6.0 in stage 186.0 (TID 373) INFO Executor: Running task 6.0 in stage 186.0 (TID 373)
23/10/22 22:18:01.248 Executor task launch worker for task 5.0 in stage 186.0 (TID 372) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.248 Executor task launch worker for task 5.0 in stage 186.0 (TID 372) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.243 Executor task launch worker for task 4.0 in stage 186.0 (TID 371) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.250 Executor task launch worker for task 4.0 in stage 186.0 (TID 371) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
23/10/22 22:18:01.258 Executor task launch worker for task 3.0 in stage 186.0 (TID 370) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.258 Executor task launch worker for task 3.0 in stage 186.0 (TID 370) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.263 Executor task launch worker for task 6.0 in stage 186.0 (TID 373) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.263 Executor task launch worker for task 6.0 in stage 186.0 (TID 373) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:01.266 Executor task launch worker for task 7.0 in stage 186.0 (TID 374) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.266 Executor task launch worker for task 7.0 in stage 186.0 (TID 374) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.293 Executor task launch worker for task 1.0 in stage 186.0 (TID 368) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.299 Executor task launch worker for task 3.0 in stage 186.0 (TID 370) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.302 Executor task launch worker for task 7.0 in stage 186.0 (TID 374) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.308 Executor task launch worker for task 2.0 in stage 186.0 (TID 369) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.330 Executor task launch worker for task 4.0 in stage 186.0 (TID 371) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.330 Executor task launch worker for task 6.0 in stage 186.0 (TID 373) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.338 Executor task launch worker for task 0.0 in stage 186.0 (TID 367) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.356 Executor task launch worker for task 5.0 in stage 186.0 (TID 372) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:01.415 Executor task launch worker for task 3.0 in stage 186.0 (TID 370) INFO Executor: Finished task 3.0 in stage 186.0 (TID 370). 6562 bytes result sent to driver
23/10/22 22:18:01.417 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 186.0 (TID 370) in 187 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:01.421 Executor task launch worker for task 2.0 in stage 186.0 (TID 369) INFO Executor: Finished task 2.0 in stage 186.0 (TID 369). 6605 bytes result sent to driver
23/10/22 22:18:01.421 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 186.0 (TID 369) in 192 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:01.426 Executor task launch worker for task 7.0 in stage 186.0 (TID 374) INFO Executor: Finished task 7.0 in stage 186.0 (TID 374). 6562 bytes result sent to driver
23/10/22 22:18:01.427 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 186.0 (TID 374) in 196 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:01.459 Executor task launch worker for task 0.0 in stage 186.0 (TID 367) INFO Executor: Finished task 0.0 in stage 186.0 (TID 367). 6562 bytes result sent to driver
23/10/22 22:18:01.460 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 367) in 231 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:01.474 Executor task launch worker for task 6.0 in stage 186.0 (TID 373) INFO Executor: Finished task 6.0 in stage 186.0 (TID 373). 6605 bytes result sent to driver
23/10/22 22:18:01.475 task-result-getter-0 INFO TaskSetManager: Finished task 6.0 in stage 186.0 (TID 373) in 245 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:01.492 Executor task launch worker for task 4.0 in stage 186.0 (TID 371) INFO Executor: Finished task 4.0 in stage 186.0 (TID 371). 6562 bytes result sent to driver
23/10/22 22:18:01.492 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 186.0 (TID 371) in 263 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:01.500 Executor task launch worker for task 1.0 in stage 186.0 (TID 368) INFO Executor: Finished task 1.0 in stage 186.0 (TID 368). 6605 bytes result sent to driver
23/10/22 22:18:01.500 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 186.0 (TID 368) in 271 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:01.505 Executor task launch worker for task 5.0 in stage 186.0 (TID 372) INFO Executor: Finished task 5.0 in stage 186.0 (TID 372). 6562 bytes result sent to driver
23/10/22 22:18:01.506 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 186.0 (TID 372) in 276 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:01.506 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
23/10/22 22:18:01.506 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 186 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.304 s
23/10/22 22:18:01.506 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:01.506 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:01.506 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 187)
23/10/22 22:18:01.506 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:01.507 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 187 (MapPartitionsRDD[461] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:18:01.511 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 94.4 KiB, free 1036.9 MiB)
23/10/22 22:18:01.512 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 22:18:01.513 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:55185 (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 22:18:01.513 dag-scheduler-event-loop INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:01.514 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 187 (MapPartitionsRDD[461] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:18:01.514 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 187.0 with 2 tasks resource profile 0
23/10/22 22:18:01.516 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 375) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:01.517 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 187.0 (TID 376) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:01.517 Executor task launch worker for task 0.0 in stage 187.0 (TID 375) INFO Executor: Running task 0.0 in stage 187.0 (TID 375)
23/10/22 22:18:01.517 Executor task launch worker for task 1.0 in stage 187.0 (TID 376) INFO Executor: Running task 1.0 in stage 187.0 (TID 376)
23/10/22 22:18:01.524 Executor task launch worker for task 1.0 in stage 187.0 (TID 376) INFO ShuffleBlockFetcherIterator: Getting 4 (1960.0 B) non-empty blocks including 4 (1960.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.525 Executor task launch worker for task 1.0 in stage 187.0 (TID 376) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.526 Executor task launch worker for task 0.0 in stage 187.0 (TID 375) INFO ShuffleBlockFetcherIterator: Getting 4 (2.0 KiB) non-empty blocks including 4 (2.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:01.526 Executor task launch worker for task 0.0 in stage 187.0 (TID 375) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:01.533 Executor task launch worker for task 0.0 in stage 187.0 (TID 375) INFO Executor: Finished task 0.0 in stage 187.0 (TID 375). 6774 bytes result sent to driver
23/10/22 22:18:01.533 Executor task launch worker for task 1.0 in stage 187.0 (TID 376) INFO Executor: Finished task 1.0 in stage 187.0 (TID 376). 6774 bytes result sent to driver
23/10/22 22:18:01.534 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 375) in 19 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:18:01.534 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 187.0 (TID 376) in 17 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:18:01.535 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool 
23/10/22 22:18:01.535 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 187 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.028 s
23/10/22 22:18:01.536 dag-scheduler-event-loop INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:01.536 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 187: Stage finished
23/10/22 22:18:01.536 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 104 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.336982 s
23/10/22 22:18:01.536 nioEventLoopGroup-2-2 INFO Instrumentation: [c9cfee14] Number of instances: 3785.
23/10/22 22:18:01.623 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 464 (rdd at LinearRegression.scala:921) as input to shuffle 66
23/10/22 22:18:01.623 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 105 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:18:01.623 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 188 (rdd at LinearRegression.scala:921)
23/10/22 22:18:01.623 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:01.623 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:01.623 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 188 (MapPartitionsRDD[464] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:18:01.626 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:18:01.627 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:18:01.627 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:18:01.627 dag-scheduler-event-loop INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:01.627 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 188 (MapPartitionsRDD[464] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:01.629 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0
23/10/22 22:18:01.953 dispatcher-event-loop-0 WARN TaskSetManager: Stage 188 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:18:01.953 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 377) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:18:01.953 Executor task launch worker for task 0.0 in stage 188.0 (TID 377) INFO Executor: Running task 0.0 in stage 188.0 (TID 377)
23/10/22 22:18:02.116 Executor task launch worker for task 0.0 in stage 188.0 (TID 377) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:02.531 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:55185 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 22:18:02.535 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:55185 in memory (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:18:02.536 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:03.100 Executor task launch worker for task 0.0 in stage 188.0 (TID 377) INFO Executor: Finished task 0.0 in stage 188.0 (TID 377). 2147 bytes result sent to driver
23/10/22 22:18:03.100 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 377) in 1471 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:03.100 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
23/10/22 22:18:03.101 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 188 (rdd at LinearRegression.scala:921) finished in 1.476 s
23/10/22 22:18:03.101 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:03.101 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:03.101 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:03.101 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:03.105 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(66), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:03.108 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 468 (rdd at LinearRegression.scala:921) as input to shuffle 67
23/10/22 22:18:03.108 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 106 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:18:03.108 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 190 (rdd at LinearRegression.scala:921)
23/10/22 22:18:03.108 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 189)
23/10/22 22:18:03.108 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:03.108 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 190 (MapPartitionsRDD[468] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:18:03.110 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:18:03.111 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:18:03.111 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:03.111 dag-scheduler-event-loop INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:03.111 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 190 (MapPartitionsRDD[468] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:03.112 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 190.0 with 8 tasks resource profile 0
23/10/22 22:18:03.112 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 378) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 190.0 (TID 379) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 190.0 (TID 380) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 190.0 (TID 381) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 190.0 (TID 382) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 190.0 (TID 383) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 190.0 (TID 384) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.113 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 190.0 (TID 385) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.114 Executor task launch worker for task 5.0 in stage 190.0 (TID 383) INFO Executor: Running task 5.0 in stage 190.0 (TID 383)
23/10/22 22:18:03.114 Executor task launch worker for task 4.0 in stage 190.0 (TID 382) INFO Executor: Running task 4.0 in stage 190.0 (TID 382)
23/10/22 22:18:03.114 Executor task launch worker for task 2.0 in stage 190.0 (TID 380) INFO Executor: Running task 2.0 in stage 190.0 (TID 380)
23/10/22 22:18:03.114 Executor task launch worker for task 1.0 in stage 190.0 (TID 379) INFO Executor: Running task 1.0 in stage 190.0 (TID 379)
23/10/22 22:18:03.114 Executor task launch worker for task 0.0 in stage 190.0 (TID 378) INFO Executor: Running task 0.0 in stage 190.0 (TID 378)
23/10/22 22:18:03.114 Executor task launch worker for task 7.0 in stage 190.0 (TID 385) INFO Executor: Running task 7.0 in stage 190.0 (TID 385)
23/10/22 22:18:03.114 Executor task launch worker for task 3.0 in stage 190.0 (TID 381) INFO Executor: Running task 3.0 in stage 190.0 (TID 381)
23/10/22 22:18:03.114 Executor task launch worker for task 6.0 in stage 190.0 (TID 384) INFO Executor: Running task 6.0 in stage 190.0 (TID 384)
23/10/22 22:18:03.121 Executor task launch worker for task 0.0 in stage 190.0 (TID 378) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.122 Executor task launch worker for task 0.0 in stage 190.0 (TID 378) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.124 Executor task launch worker for task 5.0 in stage 190.0 (TID 383) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.124 Executor task launch worker for task 5.0 in stage 190.0 (TID 383) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.124 Executor task launch worker for task 7.0 in stage 190.0 (TID 385) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.125 Executor task launch worker for task 7.0 in stage 190.0 (TID 385) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.125 Executor task launch worker for task 1.0 in stage 190.0 (TID 379) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.126 Executor task launch worker for task 1.0 in stage 190.0 (TID 379) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.121 Executor task launch worker for task 3.0 in stage 190.0 (TID 381) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.126 Executor task launch worker for task 3.0 in stage 190.0 (TID 381) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
23/10/22 22:18:03.124 Executor task launch worker for task 2.0 in stage 190.0 (TID 380) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.126 Executor task launch worker for task 2.0 in stage 190.0 (TID 380) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:03.126 Executor task launch worker for task 6.0 in stage 190.0 (TID 384) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.126 Executor task launch worker for task 4.0 in stage 190.0 (TID 382) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.126 Executor task launch worker for task 6.0 in stage 190.0 (TID 384) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.126 Executor task launch worker for task 4.0 in stage 190.0 (TID 382) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.133 Executor task launch worker for task 4.0 in stage 190.0 (TID 382) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.133 Executor task launch worker for task 5.0 in stage 190.0 (TID 383) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.134 Executor task launch worker for task 1.0 in stage 190.0 (TID 379) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.138 Executor task launch worker for task 3.0 in stage 190.0 (TID 381) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.139 Executor task launch worker for task 2.0 in stage 190.0 (TID 380) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.133 Executor task launch worker for task 7.0 in stage 190.0 (TID 385) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.133 Executor task launch worker for task 0.0 in stage 190.0 (TID 378) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.155 Executor task launch worker for task 6.0 in stage 190.0 (TID 384) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.156 Executor task launch worker for task 1.0 in stage 190.0 (TID 379) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.162 Executor task launch worker for task 2.0 in stage 190.0 (TID 380) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.171 Executor task launch worker for task 3.0 in stage 190.0 (TID 381) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.173 Executor task launch worker for task 5.0 in stage 190.0 (TID 383) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.173 Executor task launch worker for task 0.0 in stage 190.0 (TID 378) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.182 Executor task launch worker for task 4.0 in stage 190.0 (TID 382) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.192 Executor task launch worker for task 7.0 in stage 190.0 (TID 385) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.196 Executor task launch worker for task 6.0 in stage 190.0 (TID 384) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.262 Executor task launch worker for task 2.0 in stage 190.0 (TID 380) INFO Executor: Finished task 2.0 in stage 190.0 (TID 380). 4899 bytes result sent to driver
23/10/22 22:18:03.263 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 190.0 (TID 380) in 150 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:03.275 Executor task launch worker for task 1.0 in stage 190.0 (TID 379) INFO Executor: Finished task 1.0 in stage 190.0 (TID 379). 4899 bytes result sent to driver
23/10/22 22:18:03.277 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 190.0 (TID 379) in 165 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:03.339 Executor task launch worker for task 5.0 in stage 190.0 (TID 383) INFO Executor: Finished task 5.0 in stage 190.0 (TID 383). 4899 bytes result sent to driver
23/10/22 22:18:03.340 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 190.0 (TID 383) in 227 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:03.376 Executor task launch worker for task 3.0 in stage 190.0 (TID 381) INFO Executor: Finished task 3.0 in stage 190.0 (TID 381). 4899 bytes result sent to driver
23/10/22 22:18:03.376 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 190.0 (TID 381) in 263 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:03.383 Executor task launch worker for task 0.0 in stage 190.0 (TID 378) INFO Executor: Finished task 0.0 in stage 190.0 (TID 378). 4899 bytes result sent to driver
23/10/22 22:18:03.383 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 378) in 271 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:03.386 Executor task launch worker for task 4.0 in stage 190.0 (TID 382) INFO Executor: Finished task 4.0 in stage 190.0 (TID 382). 4899 bytes result sent to driver
23/10/22 22:18:03.388 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 190.0 (TID 382) in 275 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:03.391 Executor task launch worker for task 6.0 in stage 190.0 (TID 384) INFO Executor: Finished task 6.0 in stage 190.0 (TID 384). 4899 bytes result sent to driver
23/10/22 22:18:03.391 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 190.0 (TID 384) in 278 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:03.395 Executor task launch worker for task 7.0 in stage 190.0 (TID 385) INFO Executor: Finished task 7.0 in stage 190.0 (TID 385). 4899 bytes result sent to driver
23/10/22 22:18:03.396 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 190.0 (TID 385) in 283 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:03.397 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
23/10/22 22:18:03.397 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 190 (rdd at LinearRegression.scala:921) finished in 0.288 s
23/10/22 22:18:03.397 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:03.397 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:03.397 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:03.397 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:03.402 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(67), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:03.430 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.5815 ms
23/10/22 22:18:03.469 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:18:03.470 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 478 (treeAggregate at Statistics.scala:58) as input to shuffle 68
23/10/22 22:18:03.470 dag-scheduler-event-loop INFO DAGScheduler: Got job 107 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:18:03.470 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 194 (treeAggregate at Statistics.scala:58)
23/10/22 22:18:03.470 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 193)
23/10/22 22:18:03.470 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 193)
23/10/22 22:18:03.470 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 193 (MapPartitionsRDD[478] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:03.473 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 83.8 KiB, free 1037.0 MiB)
23/10/22 22:18:03.475 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 35.6 KiB, free 1036.9 MiB)
23/10/22 22:18:03.475 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:55185 (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:18:03.476 dag-scheduler-event-loop INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:03.476 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 193 (MapPartitionsRDD[478] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:03.476 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 193.0 with 8 tasks resource profile 0
23/10/22 22:18:03.477 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 386) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.477 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 193.0 (TID 387) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.477 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 193.0 (TID 388) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.478 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 193.0 (TID 389) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.478 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 193.0 (TID 390) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.478 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 193.0 (TID 391) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.478 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 193.0 (TID 392) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.478 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 193.0 (TID 393) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:03.478 Executor task launch worker for task 4.0 in stage 193.0 (TID 390) INFO Executor: Running task 4.0 in stage 193.0 (TID 390)
23/10/22 22:18:03.478 Executor task launch worker for task 0.0 in stage 193.0 (TID 386) INFO Executor: Running task 0.0 in stage 193.0 (TID 386)
23/10/22 22:18:03.478 Executor task launch worker for task 6.0 in stage 193.0 (TID 392) INFO Executor: Running task 6.0 in stage 193.0 (TID 392)
23/10/22 22:18:03.478 Executor task launch worker for task 2.0 in stage 193.0 (TID 388) INFO Executor: Running task 2.0 in stage 193.0 (TID 388)
23/10/22 22:18:03.478 Executor task launch worker for task 1.0 in stage 193.0 (TID 387) INFO Executor: Running task 1.0 in stage 193.0 (TID 387)
23/10/22 22:18:03.478 Executor task launch worker for task 3.0 in stage 193.0 (TID 389) INFO Executor: Running task 3.0 in stage 193.0 (TID 389)
23/10/22 22:18:03.478 Executor task launch worker for task 5.0 in stage 193.0 (TID 391) INFO Executor: Running task 5.0 in stage 193.0 (TID 391)
23/10/22 22:18:03.479 Executor task launch worker for task 7.0 in stage 193.0 (TID 393) INFO Executor: Running task 7.0 in stage 193.0 (TID 393)
23/10/22 22:18:03.486 Executor task launch worker for task 4.0 in stage 193.0 (TID 390) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.486 Executor task launch worker for task 0.0 in stage 193.0 (TID 386) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.486 Executor task launch worker for task 4.0 in stage 193.0 (TID 390) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.486 Executor task launch worker for task 0.0 in stage 193.0 (TID 386) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.486 Executor task launch worker for task 2.0 in stage 193.0 (TID 388) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.486 Executor task launch worker for task 2.0 in stage 193.0 (TID 388) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.487 Executor task launch worker for task 6.0 in stage 193.0 (TID 392) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.487 Executor task launch worker for task 6.0 in stage 193.0 (TID 392) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.487 Executor task launch worker for task 5.0 in stage 193.0 (TID 391) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.487 Executor task launch worker for task 5.0 in stage 193.0 (TID 391) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.489 Executor task launch worker for task 7.0 in stage 193.0 (TID 393) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.489 Executor task launch worker for task 7.0 in stage 193.0 (TID 393) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.493 Executor task launch worker for task 1.0 in stage 193.0 (TID 387) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.493 Executor task launch worker for task 1.0 in stage 193.0 (TID 387) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.494 Executor task launch worker for task 3.0 in stage 193.0 (TID 389) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.494 Executor task launch worker for task 3.0 in stage 193.0 (TID 389) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.504 Executor task launch worker for task 4.0 in stage 193.0 (TID 390) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.505 Executor task launch worker for task 2.0 in stage 193.0 (TID 388) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.506 Executor task launch worker for task 6.0 in stage 193.0 (TID 392) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.509 Executor task launch worker for task 5.0 in stage 193.0 (TID 391) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.526 Executor task launch worker for task 1.0 in stage 193.0 (TID 387) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.527 Executor task launch worker for task 3.0 in stage 193.0 (TID 389) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.534 Executor task launch worker for task 7.0 in stage 193.0 (TID 393) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.559 Executor task launch worker for task 2.0 in stage 193.0 (TID 388) INFO Executor: Finished task 2.0 in stage 193.0 (TID 388). 6562 bytes result sent to driver
23/10/22 22:18:03.560 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 193.0 (TID 388) in 83 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:03.576 Executor task launch worker for task 5.0 in stage 193.0 (TID 391) INFO Executor: Finished task 5.0 in stage 193.0 (TID 391). 6562 bytes result sent to driver
23/10/22 22:18:03.583 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 193.0 (TID 391) in 105 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:03.598 Executor task launch worker for task 6.0 in stage 193.0 (TID 392) INFO Executor: Finished task 6.0 in stage 193.0 (TID 392). 6562 bytes result sent to driver
23/10/22 22:18:03.598 Executor task launch worker for task 1.0 in stage 193.0 (TID 387) INFO Executor: Finished task 1.0 in stage 193.0 (TID 387). 6605 bytes result sent to driver
23/10/22 22:18:03.599 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 193.0 (TID 392) in 121 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:03.599 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 193.0 (TID 387) in 122 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:03.604 Executor task launch worker for task 0.0 in stage 193.0 (TID 386) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:03.605 Executor task launch worker for task 4.0 in stage 193.0 (TID 390) INFO Executor: Finished task 4.0 in stage 193.0 (TID 390). 6562 bytes result sent to driver
23/10/22 22:18:03.606 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 193.0 (TID 390) in 128 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:03.624 Executor task launch worker for task 3.0 in stage 193.0 (TID 389) INFO Executor: Finished task 3.0 in stage 193.0 (TID 389). 6605 bytes result sent to driver
23/10/22 22:18:03.625 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 193.0 (TID 389) in 148 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:03.656 Executor task launch worker for task 7.0 in stage 193.0 (TID 393) INFO Executor: Finished task 7.0 in stage 193.0 (TID 393). 6605 bytes result sent to driver
23/10/22 22:18:03.656 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 193.0 (TID 393) in 178 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:03.660 Executor task launch worker for task 0.0 in stage 193.0 (TID 386) INFO Executor: Finished task 0.0 in stage 193.0 (TID 386). 6562 bytes result sent to driver
23/10/22 22:18:03.660 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 386) in 183 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:03.661 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
23/10/22 22:18:03.661 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 193 (treeAggregate at Statistics.scala:58) finished in 0.190 s
23/10/22 22:18:03.661 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:03.661 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:03.661 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 194)
23/10/22 22:18:03.661 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:03.661 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 194 (MapPartitionsRDD[480] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:03.664 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 84.9 KiB, free 1036.8 MiB)
23/10/22 22:18:03.665 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 36.2 KiB, free 1036.8 MiB)
23/10/22 22:18:03.666 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:55185 (size: 36.2 KiB, free: 1037.0 MiB)
23/10/22 22:18:03.666 dag-scheduler-event-loop INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:03.666 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 194 (MapPartitionsRDD[480] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:18:03.666 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 194.0 with 2 tasks resource profile 0
23/10/22 22:18:03.668 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 394) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:03.668 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 194.0 (TID 395) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:03.668 Executor task launch worker for task 0.0 in stage 194.0 (TID 394) INFO Executor: Running task 0.0 in stage 194.0 (TID 394)
23/10/22 22:18:03.668 Executor task launch worker for task 1.0 in stage 194.0 (TID 395) INFO Executor: Running task 1.0 in stage 194.0 (TID 395)
23/10/22 22:18:03.674 Executor task launch worker for task 0.0 in stage 194.0 (TID 394) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.674 Executor task launch worker for task 1.0 in stage 194.0 (TID 395) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:03.674 Executor task launch worker for task 0.0 in stage 194.0 (TID 394) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.674 Executor task launch worker for task 1.0 in stage 194.0 (TID 395) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:03.683 Executor task launch worker for task 0.0 in stage 194.0 (TID 394) INFO Executor: Finished task 0.0 in stage 194.0 (TID 394). 7630 bytes result sent to driver
23/10/22 22:18:03.685 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 394) in 17 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:18:03.686 Executor task launch worker for task 1.0 in stage 194.0 (TID 395) INFO Executor: Finished task 1.0 in stage 194.0 (TID 395). 7587 bytes result sent to driver
23/10/22 22:18:03.686 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 194.0 (TID 395) in 18 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:18:03.686 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
23/10/22 22:18:03.687 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 194 (treeAggregate at Statistics.scala:58) finished in 0.025 s
23/10/22 22:18:03.687 dag-scheduler-event-loop INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:03.687 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 194: Stage finished
23/10/22 22:18:03.687 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 107 finished: treeAggregate at Statistics.scala:58, took 0.218879 s
23/10/22 22:18:03.689 nioEventLoopGroup-2-2 INFO Instrumentation: [895ca653] training finished
23/10/22 22:18:04.100 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:04.101 dag-scheduler-event-loop INFO DAGScheduler: Got job 108 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:04.101 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 195 (collect at utils.scala:26)
23/10/22 22:18:04.101 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:04.101 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:04.101 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[482] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:04.103 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:18:04.103 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:18:04.104 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:18:04.104 dag-scheduler-event-loop INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:04.105 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[482] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:04.105 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 195.0 with 1 tasks resource profile 0
23/10/22 22:18:04.105 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 396) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:04.106 Executor task launch worker for task 0.0 in stage 195.0 (TID 396) INFO Executor: Running task 0.0 in stage 195.0 (TID 396)
23/10/22 22:18:04.108 Executor task launch worker for task 0.0 in stage 195.0 (TID 396) INFO Executor: Finished task 0.0 in stage 195.0 (TID 396). 1327 bytes result sent to driver
23/10/22 22:18:04.109 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 396) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:04.109 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
23/10/22 22:18:04.109 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 195 (collect at utils.scala:26) finished in 0.007 s
23/10/22 22:18:04.109 dag-scheduler-event-loop INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:04.109 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished
23/10/22 22:18:04.109 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 108 finished: collect at utils.scala:26, took 0.008717 s
23/10/22 22:18:04.357 nioEventLoopGroup-2-2 INFO Instrumentation: [f1ab60ec] training finished
23/10/22 22:18:04.445 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:04.446 dag-scheduler-event-loop INFO DAGScheduler: Got job 109 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:04.446 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 196 (collect at utils.scala:26)
23/10/22 22:18:04.446 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:04.446 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:04.446 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[484] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:04.448 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:18:04.448 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:18:04.448 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:18:04.449 dag-scheduler-event-loop INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:04.449 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[484] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:04.449 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 196.0 with 1 tasks resource profile 0
23/10/22 22:18:04.449 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 397) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:04.450 Executor task launch worker for task 0.0 in stage 196.0 (TID 397) INFO Executor: Running task 0.0 in stage 196.0 (TID 397)
23/10/22 22:18:04.451 Executor task launch worker for task 0.0 in stage 196.0 (TID 397) INFO Executor: Finished task 0.0 in stage 196.0 (TID 397). 1284 bytes result sent to driver
23/10/22 22:18:04.452 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 397) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:04.452 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
23/10/22 22:18:04.452 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 196 (collect at utils.scala:26) finished in 0.006 s
23/10/22 22:18:04.452 dag-scheduler-event-loop INFO DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:04.452 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished
23/10/22 22:18:04.452 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 109 finished: collect at utils.scala:26, took 0.006829 s
23/10/22 22:18:04.911 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:04.911 dag-scheduler-event-loop INFO DAGScheduler: Got job 110 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:04.911 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 197 (collect at utils.scala:26)
23/10/22 22:18:04.911 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:04.911 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:04.911 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[486] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:04.912 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:18:04.913 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:18:04.913 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:18:04.913 dag-scheduler-event-loop INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:04.914 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[486] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:04.914 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 197.0 with 1 tasks resource profile 0
23/10/22 22:18:04.916 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 398) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:04.917 Executor task launch worker for task 0.0 in stage 197.0 (TID 398) INFO Executor: Running task 0.0 in stage 197.0 (TID 398)
23/10/22 22:18:04.921 Executor task launch worker for task 0.0 in stage 197.0 (TID 398) INFO Executor: Finished task 0.0 in stage 197.0 (TID 398). 1327 bytes result sent to driver
23/10/22 22:18:04.921 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 398) in 6 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:04.921 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
23/10/22 22:18:04.922 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 197 (collect at utils.scala:26) finished in 0.009 s
23/10/22 22:18:04.922 dag-scheduler-event-loop INFO DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:04.922 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished
23/10/22 22:18:04.922 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 110 finished: collect at utils.scala:26, took 0.011367 s
23/10/22 22:18:05.518 nioEventLoopGroup-2-2 INFO Instrumentation: [3e070323] training finished
23/10/22 22:18:05.543 nioEventLoopGroup-2-2 INFO Instrumentation: [369edb05] training finished
23/10/22 22:18:05.552 nioEventLoopGroup-2-2 INFO Instrumentation: [8d46ce62] Stage class: LinearRegression
23/10/22 22:18:05.552 nioEventLoopGroup-2-2 INFO Instrumentation: [8d46ce62] Stage uid: linear_regression__4d02c369_bb79_48ac_9124_641c273e00be
23/10/22 22:18:05.593 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 489 (rdd at Instrumentation.scala:62) as input to shuffle 69
23/10/22 22:18:05.593 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 111 (rdd at Instrumentation.scala:62) with 1 output partitions
23/10/22 22:18:05.593 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 198 (rdd at Instrumentation.scala:62)
23/10/22 22:18:05.593 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:05.593 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:05.594 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 198 (MapPartitionsRDD[489] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:18:05.596 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 32.7 KiB, free 1036.7 MiB)
23/10/22 22:18:05.597 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 22:18:05.597 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:18:05.597 dag-scheduler-event-loop INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:05.597 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 198 (MapPartitionsRDD[489] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:05.598 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0
23/10/22 22:18:05.939 dispatcher-event-loop-1 WARN TaskSetManager: Stage 198 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:18:05.939 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 399) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:18:05.940 Executor task launch worker for task 0.0 in stage 198.0 (TID 399) INFO Executor: Running task 0.0 in stage 198.0 (TID 399)
23/10/22 22:18:06.050 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:55185 in memory (size: 36.2 KiB, free: 1037.1 MiB)
23/10/22 22:18:06.052 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:06.053 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:06.054 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:06.055 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:06.056 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:55185 in memory (size: 35.6 KiB, free: 1037.1 MiB)
23/10/22 22:18:06.124 Executor task launch worker for task 0.0 in stage 198.0 (TID 399) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:06.308 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:07.175 Executor task launch worker for task 0.0 in stage 198.0 (TID 399) INFO Executor: Finished task 0.0 in stage 198.0 (TID 399). 2147 bytes result sent to driver
23/10/22 22:18:07.176 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 399) in 1578 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:07.176 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
23/10/22 22:18:07.176 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 198 (rdd at Instrumentation.scala:62) finished in 1.582 s
23/10/22 22:18:07.176 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:07.176 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:07.177 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:07.177 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:07.180 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(69), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:07.183 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 493 (rdd at Instrumentation.scala:62) as input to shuffle 70
23/10/22 22:18:07.183 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 112 (rdd at Instrumentation.scala:62) with 8 output partitions
23/10/22 22:18:07.183 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 200 (rdd at Instrumentation.scala:62)
23/10/22 22:18:07.183 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 199)
23/10/22 22:18:07.183 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:07.183 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 200 (MapPartitionsRDD[493] at rdd at Instrumentation.scala:62), which has no missing parents
23/10/22 22:18:07.186 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:18:07.187 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:18:07.187 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:07.187 dag-scheduler-event-loop INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:07.188 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 200 (MapPartitionsRDD[493] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:07.188 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 200.0 with 8 tasks resource profile 0
23/10/22 22:18:07.189 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 400) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.189 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 401) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.189 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 402) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.189 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 403) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.189 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 404) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.189 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 405) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.190 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 406) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.190 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 407) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:07.191 Executor task launch worker for task 0.0 in stage 200.0 (TID 400) INFO Executor: Running task 0.0 in stage 200.0 (TID 400)
23/10/22 22:18:07.191 Executor task launch worker for task 2.0 in stage 200.0 (TID 402) INFO Executor: Running task 2.0 in stage 200.0 (TID 402)
23/10/22 22:18:07.191 Executor task launch worker for task 5.0 in stage 200.0 (TID 405) INFO Executor: Running task 5.0 in stage 200.0 (TID 405)
23/10/22 22:18:07.191 Executor task launch worker for task 3.0 in stage 200.0 (TID 403) INFO Executor: Running task 3.0 in stage 200.0 (TID 403)
23/10/22 22:18:07.191 Executor task launch worker for task 4.0 in stage 200.0 (TID 404) INFO Executor: Running task 4.0 in stage 200.0 (TID 404)
23/10/22 22:18:07.191 Executor task launch worker for task 7.0 in stage 200.0 (TID 407) INFO Executor: Running task 7.0 in stage 200.0 (TID 407)
23/10/22 22:18:07.191 Executor task launch worker for task 1.0 in stage 200.0 (TID 401) INFO Executor: Running task 1.0 in stage 200.0 (TID 401)
23/10/22 22:18:07.192 Executor task launch worker for task 6.0 in stage 200.0 (TID 406) INFO Executor: Running task 6.0 in stage 200.0 (TID 406)
23/10/22 22:18:07.194 Executor task launch worker for task 7.0 in stage 200.0 (TID 407) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.194 Executor task launch worker for task 7.0 in stage 200.0 (TID 407) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.194 Executor task launch worker for task 6.0 in stage 200.0 (TID 406) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.198 Executor task launch worker for task 6.0 in stage 200.0 (TID 406) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
23/10/22 22:18:07.198 Executor task launch worker for task 2.0 in stage 200.0 (TID 402) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.198 Executor task launch worker for task 2.0 in stage 200.0 (TID 402) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.199 Executor task launch worker for task 0.0 in stage 200.0 (TID 400) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.199 Executor task launch worker for task 3.0 in stage 200.0 (TID 403) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.199 Executor task launch worker for task 0.0 in stage 200.0 (TID 400) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.199 Executor task launch worker for task 3.0 in stage 200.0 (TID 403) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.199 Executor task launch worker for task 5.0 in stage 200.0 (TID 405) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.199 Executor task launch worker for task 5.0 in stage 200.0 (TID 405) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.201 Executor task launch worker for task 4.0 in stage 200.0 (TID 404) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.202 Executor task launch worker for task 4.0 in stage 200.0 (TID 404) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.202 Executor task launch worker for task 1.0 in stage 200.0 (TID 401) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:07.202 Executor task launch worker for task 1.0 in stage 200.0 (TID 401) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:07.207 Executor task launch worker for task 2.0 in stage 200.0 (TID 402) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.208 Executor task launch worker for task 7.0 in stage 200.0 (TID 407) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.209 Executor task launch worker for task 4.0 in stage 200.0 (TID 404) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.208 Executor task launch worker for task 5.0 in stage 200.0 (TID 405) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.215 Executor task launch worker for task 6.0 in stage 200.0 (TID 406) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.216 Executor task launch worker for task 1.0 in stage 200.0 (TID 401) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.240 Executor task launch worker for task 5.0 in stage 200.0 (TID 405) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.245 Executor task launch worker for task 4.0 in stage 200.0 (TID 404) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.248 Executor task launch worker for task 6.0 in stage 200.0 (TID 406) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.252 Executor task launch worker for task 2.0 in stage 200.0 (TID 402) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.264 Executor task launch worker for task 3.0 in stage 200.0 (TID 403) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.265 Executor task launch worker for task 0.0 in stage 200.0 (TID 400) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.272 Executor task launch worker for task 1.0 in stage 200.0 (TID 401) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.301 Executor task launch worker for task 7.0 in stage 200.0 (TID 407) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.319 Executor task launch worker for task 3.0 in stage 200.0 (TID 403) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.320 Executor task launch worker for task 0.0 in stage 200.0 (TID 400) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:07.424 Executor task launch worker for task 5.0 in stage 200.0 (TID 405) INFO Executor: Finished task 5.0 in stage 200.0 (TID 405). 4899 bytes result sent to driver
23/10/22 22:18:07.428 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 405) in 239 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:07.461 Executor task launch worker for task 6.0 in stage 200.0 (TID 406) INFO Executor: Finished task 6.0 in stage 200.0 (TID 406). 4899 bytes result sent to driver
23/10/22 22:18:07.464 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 406) in 275 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:07.509 Executor task launch worker for task 0.0 in stage 200.0 (TID 400) INFO Executor: Finished task 0.0 in stage 200.0 (TID 400). 4899 bytes result sent to driver
23/10/22 22:18:07.510 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 400) in 321 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:07.516 Executor task launch worker for task 3.0 in stage 200.0 (TID 403) INFO Executor: Finished task 3.0 in stage 200.0 (TID 403). 4899 bytes result sent to driver
23/10/22 22:18:07.517 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 403) in 328 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:07.525 Executor task launch worker for task 4.0 in stage 200.0 (TID 404) INFO Executor: Finished task 4.0 in stage 200.0 (TID 404). 4899 bytes result sent to driver
23/10/22 22:18:07.526 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 404) in 337 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:07.531 Executor task launch worker for task 7.0 in stage 200.0 (TID 407) INFO Executor: Finished task 7.0 in stage 200.0 (TID 407). 4899 bytes result sent to driver
23/10/22 22:18:07.532 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 407) in 342 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:07.538 Executor task launch worker for task 2.0 in stage 200.0 (TID 402) INFO Executor: Finished task 2.0 in stage 200.0 (TID 402). 4899 bytes result sent to driver
23/10/22 22:18:07.538 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 402) in 349 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:07.541 Executor task launch worker for task 1.0 in stage 200.0 (TID 401) INFO Executor: Finished task 1.0 in stage 200.0 (TID 401). 4899 bytes result sent to driver
23/10/22 22:18:07.541 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 401) in 352 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:07.541 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
23/10/22 22:18:07.541 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 200 (rdd at Instrumentation.scala:62) finished in 0.357 s
23/10/22 22:18:07.541 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:07.542 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:07.542 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:07.542 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:07.547 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(70), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:07.578 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.4738 ms
23/10/22 22:18:07.589 nioEventLoopGroup-2-2 INFO Instrumentation: [8d46ce62] training: numPartitions=8 storageLevel=StorageLevel(1 replicas)
23/10/22 22:18:07.589 nioEventLoopGroup-2-2 INFO Instrumentation: [8d46ce62] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
23/10/22 22:18:07.590 nioEventLoopGroup-2-2 INFO Instrumentation: [8d46ce62] {"numFeatures":3}
23/10/22 22:18:07.657 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 502 (rdd at LinearRegression.scala:348) as input to shuffle 71
23/10/22 22:18:07.658 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 113 (rdd at LinearRegression.scala:348) with 1 output partitions
23/10/22 22:18:07.658 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 201 (rdd at LinearRegression.scala:348)
23/10/22 22:18:07.658 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:07.659 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:07.660 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 201 (MapPartitionsRDD[502] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:18:07.663 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:18:07.664 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:18:07.666 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:07.666 dag-scheduler-event-loop INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:07.667 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 201 (MapPartitionsRDD[502] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:07.667 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 201.0 with 1 tasks resource profile 0
23/10/22 22:18:08.103 dispatcher-event-loop-0 WARN TaskSetManager: Stage 201 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:18:08.103 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 408) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:18:08.103 Executor task launch worker for task 0.0 in stage 201.0 (TID 408) INFO Executor: Running task 0.0 in stage 201.0 (TID 408)
23/10/22 22:18:08.270 Executor task launch worker for task 0.0 in stage 201.0 (TID 408) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:08.541 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:09.219 Executor task launch worker for task 0.0 in stage 201.0 (TID 408) INFO Executor: Finished task 0.0 in stage 201.0 (TID 408). 2147 bytes result sent to driver
23/10/22 22:18:09.220 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 408) in 1552 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:09.220 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
23/10/22 22:18:09.220 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 201 (rdd at LinearRegression.scala:348) finished in 1.560 s
23/10/22 22:18:09.220 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:09.220 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:09.220 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:09.220 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:09.225 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(71), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:09.228 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 506 (rdd at LinearRegression.scala:348) as input to shuffle 72
23/10/22 22:18:09.228 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 114 (rdd at LinearRegression.scala:348) with 8 output partitions
23/10/22 22:18:09.228 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 203 (rdd at LinearRegression.scala:348)
23/10/22 22:18:09.228 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 202)
23/10/22 22:18:09.228 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:09.228 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 203 (MapPartitionsRDD[506] at rdd at LinearRegression.scala:348), which has no missing parents
23/10/22 22:18:09.232 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 37.8 KiB, free 1037.0 MiB)
23/10/22 22:18:09.233 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:18:09.233 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:09.233 dag-scheduler-event-loop INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:09.234 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 203 (MapPartitionsRDD[506] at rdd at LinearRegression.scala:348) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:09.234 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 203.0 with 8 tasks resource profile 0
23/10/22 22:18:09.234 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 409) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.234 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 203.0 (TID 410) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 203.0 (TID 411) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 203.0 (TID 412) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 203.0 (TID 413) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 203.0 (TID 414) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 203.0 (TID 415) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 203.0 (TID 416) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.236 Executor task launch worker for task 2.0 in stage 203.0 (TID 411) INFO Executor: Running task 2.0 in stage 203.0 (TID 411)
23/10/22 22:18:09.236 Executor task launch worker for task 5.0 in stage 203.0 (TID 414) INFO Executor: Running task 5.0 in stage 203.0 (TID 414)
23/10/22 22:18:09.236 Executor task launch worker for task 0.0 in stage 203.0 (TID 409) INFO Executor: Running task 0.0 in stage 203.0 (TID 409)
23/10/22 22:18:09.236 Executor task launch worker for task 1.0 in stage 203.0 (TID 410) INFO Executor: Running task 1.0 in stage 203.0 (TID 410)
23/10/22 22:18:09.236 Executor task launch worker for task 3.0 in stage 203.0 (TID 412) INFO Executor: Running task 3.0 in stage 203.0 (TID 412)
23/10/22 22:18:09.236 Executor task launch worker for task 6.0 in stage 203.0 (TID 415) INFO Executor: Running task 6.0 in stage 203.0 (TID 415)
23/10/22 22:18:09.236 Executor task launch worker for task 7.0 in stage 203.0 (TID 416) INFO Executor: Running task 7.0 in stage 203.0 (TID 416)
23/10/22 22:18:09.236 Executor task launch worker for task 4.0 in stage 203.0 (TID 413) INFO Executor: Running task 4.0 in stage 203.0 (TID 413)
23/10/22 22:18:09.240 Executor task launch worker for task 7.0 in stage 203.0 (TID 416) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.240 Executor task launch worker for task 7.0 in stage 203.0 (TID 416) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.240 Executor task launch worker for task 1.0 in stage 203.0 (TID 410) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.240 Executor task launch worker for task 1.0 in stage 203.0 (TID 410) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.240 Executor task launch worker for task 3.0 in stage 203.0 (TID 412) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.240 Executor task launch worker for task 0.0 in stage 203.0 (TID 409) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.241 Executor task launch worker for task 0.0 in stage 203.0 (TID 409) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.240 Executor task launch worker for task 3.0 in stage 203.0 (TID 412) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.241 Executor task launch worker for task 2.0 in stage 203.0 (TID 411) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.241 Executor task launch worker for task 2.0 in stage 203.0 (TID 411) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.242 Executor task launch worker for task 4.0 in stage 203.0 (TID 413) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.242 Executor task launch worker for task 4.0 in stage 203.0 (TID 413) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.242 Executor task launch worker for task 6.0 in stage 203.0 (TID 415) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.242 Executor task launch worker for task 6.0 in stage 203.0 (TID 415) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.243 Executor task launch worker for task 5.0 in stage 203.0 (TID 414) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.243 Executor task launch worker for task 5.0 in stage 203.0 (TID 414) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.248 Executor task launch worker for task 3.0 in stage 203.0 (TID 412) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.248 Executor task launch worker for task 2.0 in stage 203.0 (TID 411) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.251 Executor task launch worker for task 6.0 in stage 203.0 (TID 415) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.254 Executor task launch worker for task 0.0 in stage 203.0 (TID 409) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.248 Executor task launch worker for task 7.0 in stage 203.0 (TID 416) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.257 Executor task launch worker for task 1.0 in stage 203.0 (TID 410) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.270 Executor task launch worker for task 2.0 in stage 203.0 (TID 411) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.276 Executor task launch worker for task 5.0 in stage 203.0 (TID 414) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.276 Executor task launch worker for task 3.0 in stage 203.0 (TID 412) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.279 Executor task launch worker for task 1.0 in stage 203.0 (TID 410) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.291 Executor task launch worker for task 7.0 in stage 203.0 (TID 416) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.299 Executor task launch worker for task 0.0 in stage 203.0 (TID 409) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.300 Executor task launch worker for task 4.0 in stage 203.0 (TID 413) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.309 Executor task launch worker for task 5.0 in stage 203.0 (TID 414) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.336 Executor task launch worker for task 6.0 in stage 203.0 (TID 415) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.346 Executor task launch worker for task 4.0 in stage 203.0 (TID 413) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.395 Executor task launch worker for task 1.0 in stage 203.0 (TID 410) INFO Executor: Finished task 1.0 in stage 203.0 (TID 410). 4942 bytes result sent to driver
23/10/22 22:18:09.396 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 203.0 (TID 410) in 162 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:09.449 Executor task launch worker for task 2.0 in stage 203.0 (TID 411) INFO Executor: Finished task 2.0 in stage 203.0 (TID 411). 4899 bytes result sent to driver
23/10/22 22:18:09.452 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 203.0 (TID 411) in 216 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:09.460 Executor task launch worker for task 7.0 in stage 203.0 (TID 416) INFO Executor: Finished task 7.0 in stage 203.0 (TID 416). 4942 bytes result sent to driver
23/10/22 22:18:09.461 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 203.0 (TID 416) in 225 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:09.469 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:09.471 Executor task launch worker for task 5.0 in stage 203.0 (TID 414) INFO Executor: Finished task 5.0 in stage 203.0 (TID 414). 4899 bytes result sent to driver
23/10/22 22:18:09.472 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 203.0 (TID 414) in 236 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:09.498 Executor task launch worker for task 3.0 in stage 203.0 (TID 412) INFO Executor: Finished task 3.0 in stage 203.0 (TID 412). 4942 bytes result sent to driver
23/10/22 22:18:09.500 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 203.0 (TID 412) in 264 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:09.504 Executor task launch worker for task 0.0 in stage 203.0 (TID 409) INFO Executor: Finished task 0.0 in stage 203.0 (TID 409). 4942 bytes result sent to driver
23/10/22 22:18:09.506 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 409) in 272 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:09.520 Executor task launch worker for task 4.0 in stage 203.0 (TID 413) INFO Executor: Finished task 4.0 in stage 203.0 (TID 413). 4899 bytes result sent to driver
23/10/22 22:18:09.521 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 203.0 (TID 413) in 285 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:09.524 Executor task launch worker for task 6.0 in stage 203.0 (TID 415) INFO Executor: Finished task 6.0 in stage 203.0 (TID 415). 4899 bytes result sent to driver
23/10/22 22:18:09.524 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 203.0 (TID 415) in 288 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:09.525 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
23/10/22 22:18:09.525 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 203 (rdd at LinearRegression.scala:348) finished in 0.295 s
23/10/22 22:18:09.525 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:09.526 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:09.526 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:09.526 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:09.536 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(72), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:09.568 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.4671 ms
23/10/22 22:18:09.580 nioEventLoopGroup-2-2 WARN Instrumentation: [8d46ce62] regParam is zero, which might cause numerical instability and overfitting.
23/10/22 22:18:09.600 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
23/10/22 22:18:09.601 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 515 (treeAggregate at WeightedLeastSquares.scala:107) as input to shuffle 73
23/10/22 22:18:09.601 dag-scheduler-event-loop INFO DAGScheduler: Got job 115 (treeAggregate at WeightedLeastSquares.scala:107) with 2 output partitions
23/10/22 22:18:09.601 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 207 (treeAggregate at WeightedLeastSquares.scala:107)
23/10/22 22:18:09.601 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 206)
23/10/22 22:18:09.602 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 206)
23/10/22 22:18:09.602 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 206 (MapPartitionsRDD[515] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:18:09.606 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 98.9 KiB, free 1036.9 MiB)
23/10/22 22:18:09.607 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 1036.9 MiB)
23/10/22 22:18:09.608 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:55185 (size: 38.9 KiB, free: 1037.1 MiB)
23/10/22 22:18:09.609 dag-scheduler-event-loop INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:09.610 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 206 (MapPartitionsRDD[515] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:09.610 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 206.0 with 8 tasks resource profile 0
23/10/22 22:18:09.611 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 417) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.611 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 418) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.611 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 206.0 (TID 419) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.611 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 206.0 (TID 420) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.611 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 206.0 (TID 421) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.612 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 206.0 (TID 422) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.612 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 206.0 (TID 423) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.613 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 206.0 (TID 424) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:09.613 Executor task launch worker for task 1.0 in stage 206.0 (TID 418) INFO Executor: Running task 1.0 in stage 206.0 (TID 418)
23/10/22 22:18:09.613 Executor task launch worker for task 4.0 in stage 206.0 (TID 421) INFO Executor: Running task 4.0 in stage 206.0 (TID 421)
23/10/22 22:18:09.613 Executor task launch worker for task 5.0 in stage 206.0 (TID 422) INFO Executor: Running task 5.0 in stage 206.0 (TID 422)
23/10/22 22:18:09.613 Executor task launch worker for task 2.0 in stage 206.0 (TID 419) INFO Executor: Running task 2.0 in stage 206.0 (TID 419)
23/10/22 22:18:09.613 Executor task launch worker for task 3.0 in stage 206.0 (TID 420) INFO Executor: Running task 3.0 in stage 206.0 (TID 420)
23/10/22 22:18:09.614 Executor task launch worker for task 6.0 in stage 206.0 (TID 423) INFO Executor: Running task 6.0 in stage 206.0 (TID 423)
23/10/22 22:18:09.614 Executor task launch worker for task 7.0 in stage 206.0 (TID 424) INFO Executor: Running task 7.0 in stage 206.0 (TID 424)
23/10/22 22:18:09.613 Executor task launch worker for task 0.0 in stage 206.0 (TID 417) INFO Executor: Running task 0.0 in stage 206.0 (TID 417)
23/10/22 22:18:09.620 Executor task launch worker for task 7.0 in stage 206.0 (TID 424) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.621 Executor task launch worker for task 7.0 in stage 206.0 (TID 424) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.621 Executor task launch worker for task 5.0 in stage 206.0 (TID 422) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.621 Executor task launch worker for task 5.0 in stage 206.0 (TID 422) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.620 Executor task launch worker for task 6.0 in stage 206.0 (TID 423) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.622 Executor task launch worker for task 6.0 in stage 206.0 (TID 423) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:09.622 Executor task launch worker for task 3.0 in stage 206.0 (TID 420) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.622 Executor task launch worker for task 3.0 in stage 206.0 (TID 420) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.623 Executor task launch worker for task 1.0 in stage 206.0 (TID 418) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.623 Executor task launch worker for task 1.0 in stage 206.0 (TID 418) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.624 Executor task launch worker for task 4.0 in stage 206.0 (TID 421) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.624 Executor task launch worker for task 4.0 in stage 206.0 (TID 421) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.628 Executor task launch worker for task 2.0 in stage 206.0 (TID 419) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.628 Executor task launch worker for task 2.0 in stage 206.0 (TID 419) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.628 Executor task launch worker for task 0.0 in stage 206.0 (TID 417) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.628 Executor task launch worker for task 0.0 in stage 206.0 (TID 417) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.638 Executor task launch worker for task 6.0 in stage 206.0 (TID 423) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.638 Executor task launch worker for task 1.0 in stage 206.0 (TID 418) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.638 Executor task launch worker for task 4.0 in stage 206.0 (TID 421) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.638 Executor task launch worker for task 7.0 in stage 206.0 (TID 424) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.641 Executor task launch worker for task 0.0 in stage 206.0 (TID 417) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.641 Executor task launch worker for task 2.0 in stage 206.0 (TID 419) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.649 Executor task launch worker for task 5.0 in stage 206.0 (TID 422) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.675 Executor task launch worker for task 3.0 in stage 206.0 (TID 420) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:09.708 Executor task launch worker for task 0.0 in stage 206.0 (TID 417) INFO Executor: Finished task 0.0 in stage 206.0 (TID 417). 6562 bytes result sent to driver
23/10/22 22:18:09.709 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 417) in 98 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:09.713 Executor task launch worker for task 6.0 in stage 206.0 (TID 423) INFO Executor: Finished task 6.0 in stage 206.0 (TID 423). 6562 bytes result sent to driver
23/10/22 22:18:09.721 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 206.0 (TID 423) in 109 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:09.733 Executor task launch worker for task 7.0 in stage 206.0 (TID 424) INFO Executor: Finished task 7.0 in stage 206.0 (TID 424). 6562 bytes result sent to driver
23/10/22 22:18:09.734 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 206.0 (TID 424) in 122 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:09.737 Executor task launch worker for task 1.0 in stage 206.0 (TID 418) INFO Executor: Finished task 1.0 in stage 206.0 (TID 418). 6605 bytes result sent to driver
23/10/22 22:18:09.739 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 418) in 128 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:09.742 Executor task launch worker for task 2.0 in stage 206.0 (TID 419) INFO Executor: Finished task 2.0 in stage 206.0 (TID 419). 6562 bytes result sent to driver
23/10/22 22:18:09.743 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 206.0 (TID 419) in 132 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:09.753 Executor task launch worker for task 4.0 in stage 206.0 (TID 421) INFO Executor: Finished task 4.0 in stage 206.0 (TID 421). 6605 bytes result sent to driver
23/10/22 22:18:09.754 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 206.0 (TID 421) in 143 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:09.761 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:09.776 Executor task launch worker for task 5.0 in stage 206.0 (TID 422) INFO Executor: Finished task 5.0 in stage 206.0 (TID 422). 6605 bytes result sent to driver
23/10/22 22:18:09.777 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 206.0 (TID 422) in 165 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:09.788 Executor task launch worker for task 3.0 in stage 206.0 (TID 420) INFO Executor: Finished task 3.0 in stage 206.0 (TID 420). 6648 bytes result sent to driver
23/10/22 22:18:09.789 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 206.0 (TID 420) in 178 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:09.789 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool 
23/10/22 22:18:09.789 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 206 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.186 s
23/10/22 22:18:09.789 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:09.789 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:09.789 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 207)
23/10/22 22:18:09.789 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:09.789 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[517] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
23/10/22 22:18:09.793 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 99.9 KiB, free 1036.9 MiB)
23/10/22 22:18:09.794 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 1036.8 MiB)
23/10/22 22:18:09.795 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:55185 (size: 39.5 KiB, free: 1037.1 MiB)
23/10/22 22:18:09.795 dag-scheduler-event-loop INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:09.796 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 207 (MapPartitionsRDD[517] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:18:09.796 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 207.0 with 2 tasks resource profile 0
23/10/22 22:18:09.796 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 425) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:09.797 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 426) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:09.798 Executor task launch worker for task 0.0 in stage 207.0 (TID 425) INFO Executor: Running task 0.0 in stage 207.0 (TID 425)
23/10/22 22:18:09.798 Executor task launch worker for task 1.0 in stage 207.0 (TID 426) INFO Executor: Running task 1.0 in stage 207.0 (TID 426)
23/10/22 22:18:09.809 Executor task launch worker for task 1.0 in stage 207.0 (TID 426) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.809 Executor task launch worker for task 0.0 in stage 207.0 (TID 425) INFO ShuffleBlockFetcherIterator: Getting 4 (2.1 KiB) non-empty blocks including 4 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:09.809 Executor task launch worker for task 1.0 in stage 207.0 (TID 426) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.809 Executor task launch worker for task 0.0 in stage 207.0 (TID 425) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:09.814 Executor task launch worker for task 1.0 in stage 207.0 (TID 426) INFO Executor: Finished task 1.0 in stage 207.0 (TID 426). 6814 bytes result sent to driver
23/10/22 22:18:09.814 Executor task launch worker for task 0.0 in stage 207.0 (TID 425) INFO Executor: Finished task 0.0 in stage 207.0 (TID 425). 6814 bytes result sent to driver
23/10/22 22:18:09.815 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 426) in 18 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:18:09.815 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 425) in 19 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:18:09.815 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
23/10/22 22:18:09.815 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 207 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.025 s
23/10/22 22:18:09.816 dag-scheduler-event-loop INFO DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:09.816 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished
23/10/22 22:18:09.816 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 115 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.214858 s
23/10/22 22:18:09.816 nioEventLoopGroup-2-2 INFO Instrumentation: [8d46ce62] Number of instances: 3785.
23/10/22 22:18:09.903 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 520 (rdd at LinearRegression.scala:921) as input to shuffle 74
23/10/22 22:18:09.904 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 116 (rdd at LinearRegression.scala:921) with 1 output partitions
23/10/22 22:18:09.904 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 208 (rdd at LinearRegression.scala:921)
23/10/22 22:18:09.904 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:09.904 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:09.904 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 208 (MapPartitionsRDD[520] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:18:09.906 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:18:09.907 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.8 MiB)
23/10/22 22:18:09.907 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:18:09.907 dag-scheduler-event-loop INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:09.908 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 208 (MapPartitionsRDD[520] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:09.908 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 208.0 with 1 tasks resource profile 0
23/10/22 22:18:10.238 dispatcher-event-loop-5 WARN TaskSetManager: Stage 208 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:18:10.238 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 427) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:18:10.238 Executor task launch worker for task 0.0 in stage 208.0 (TID 427) INFO Executor: Running task 0.0 in stage 208.0 (TID 427)
23/10/22 22:18:10.324 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:55185 in memory (size: 39.5 KiB, free: 1037.1 MiB)
23/10/22 22:18:10.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:55185 in memory (size: 38.9 KiB, free: 1037.1 MiB)
23/10/22 22:18:10.425 Executor task launch worker for task 0.0 in stage 208.0 (TID 427) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:10.563 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:11.655 Executor task launch worker for task 0.0 in stage 208.0 (TID 427) INFO Executor: Finished task 0.0 in stage 208.0 (TID 427). 2147 bytes result sent to driver
23/10/22 22:18:11.655 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 427) in 1747 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:11.656 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
23/10/22 22:18:11.656 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 208 (rdd at LinearRegression.scala:921) finished in 1.752 s
23/10/22 22:18:11.656 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:11.656 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:11.656 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:11.656 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:11.661 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(74), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:11.664 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 524 (rdd at LinearRegression.scala:921) as input to shuffle 75
23/10/22 22:18:11.664 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 117 (rdd at LinearRegression.scala:921) with 8 output partitions
23/10/22 22:18:11.664 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 210 (rdd at LinearRegression.scala:921)
23/10/22 22:18:11.664 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 209)
23/10/22 22:18:11.664 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:11.666 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 210 (MapPartitionsRDD[524] at rdd at LinearRegression.scala:921), which has no missing parents
23/10/22 22:18:11.671 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:18:11.672 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:18:11.672 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:11.672 dag-scheduler-event-loop INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:11.673 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 210 (MapPartitionsRDD[524] at rdd at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:11.673 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 210.0 with 8 tasks resource profile 0
23/10/22 22:18:11.674 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 428) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.675 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 210.0 (TID 429) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.675 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 210.0 (TID 430) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.675 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 210.0 (TID 431) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.675 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 210.0 (TID 432) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.675 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 210.0 (TID 433) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.676 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 210.0 (TID 434) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.676 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 210.0 (TID 435) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:11.676 Executor task launch worker for task 0.0 in stage 210.0 (TID 428) INFO Executor: Running task 0.0 in stage 210.0 (TID 428)
23/10/22 22:18:11.676 Executor task launch worker for task 6.0 in stage 210.0 (TID 434) INFO Executor: Running task 6.0 in stage 210.0 (TID 434)
23/10/22 22:18:11.676 Executor task launch worker for task 4.0 in stage 210.0 (TID 432) INFO Executor: Running task 4.0 in stage 210.0 (TID 432)
23/10/22 22:18:11.676 Executor task launch worker for task 7.0 in stage 210.0 (TID 435) INFO Executor: Running task 7.0 in stage 210.0 (TID 435)
23/10/22 22:18:11.676 Executor task launch worker for task 3.0 in stage 210.0 (TID 431) INFO Executor: Running task 3.0 in stage 210.0 (TID 431)
23/10/22 22:18:11.676 Executor task launch worker for task 2.0 in stage 210.0 (TID 430) INFO Executor: Running task 2.0 in stage 210.0 (TID 430)
23/10/22 22:18:11.680 Executor task launch worker for task 4.0 in stage 210.0 (TID 432) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.680 Executor task launch worker for task 0.0 in stage 210.0 (TID 428) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.680 Executor task launch worker for task 0.0 in stage 210.0 (TID 428) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.680 Executor task launch worker for task 6.0 in stage 210.0 (TID 434) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.680 Executor task launch worker for task 6.0 in stage 210.0 (TID 434) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.676 Executor task launch worker for task 1.0 in stage 210.0 (TID 429) INFO Executor: Running task 1.0 in stage 210.0 (TID 429)
23/10/22 22:18:11.676 Executor task launch worker for task 5.0 in stage 210.0 (TID 433) INFO Executor: Running task 5.0 in stage 210.0 (TID 433)
23/10/22 22:18:11.680 Executor task launch worker for task 2.0 in stage 210.0 (TID 430) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.680 Executor task launch worker for task 2.0 in stage 210.0 (TID 430) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.680 Executor task launch worker for task 4.0 in stage 210.0 (TID 432) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.680 Executor task launch worker for task 3.0 in stage 210.0 (TID 431) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.681 Executor task launch worker for task 3.0 in stage 210.0 (TID 431) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:11.684 Executor task launch worker for task 7.0 in stage 210.0 (TID 435) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.684 Executor task launch worker for task 7.0 in stage 210.0 (TID 435) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.684 Executor task launch worker for task 1.0 in stage 210.0 (TID 429) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.684 Executor task launch worker for task 1.0 in stage 210.0 (TID 429) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.684 Executor task launch worker for task 5.0 in stage 210.0 (TID 433) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:11.684 Executor task launch worker for task 5.0 in stage 210.0 (TID 433) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:11.688 Executor task launch worker for task 0.0 in stage 210.0 (TID 428) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.689 Executor task launch worker for task 2.0 in stage 210.0 (TID 430) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.692 Executor task launch worker for task 1.0 in stage 210.0 (TID 429) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.692 Executor task launch worker for task 6.0 in stage 210.0 (TID 434) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.703 Executor task launch worker for task 4.0 in stage 210.0 (TID 432) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.708 Executor task launch worker for task 0.0 in stage 210.0 (TID 428) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.709 Executor task launch worker for task 5.0 in stage 210.0 (TID 433) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.715 Executor task launch worker for task 2.0 in stage 210.0 (TID 430) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.720 Executor task launch worker for task 1.0 in stage 210.0 (TID 429) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.724 Executor task launch worker for task 3.0 in stage 210.0 (TID 431) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.726 Executor task launch worker for task 4.0 in stage 210.0 (TID 432) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.737 Executor task launch worker for task 7.0 in stage 210.0 (TID 435) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.745 Executor task launch worker for task 6.0 in stage 210.0 (TID 434) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.748 Executor task launch worker for task 5.0 in stage 210.0 (TID 433) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.788 Executor task launch worker for task 3.0 in stage 210.0 (TID 431) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.813 Executor task launch worker for task 7.0 in stage 210.0 (TID 435) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:11.920 Executor task launch worker for task 2.0 in stage 210.0 (TID 430) INFO Executor: Finished task 2.0 in stage 210.0 (TID 430). 4899 bytes result sent to driver
23/10/22 22:18:11.921 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 210.0 (TID 430) in 246 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:11.974 Executor task launch worker for task 0.0 in stage 210.0 (TID 428) INFO Executor: Finished task 0.0 in stage 210.0 (TID 428). 4942 bytes result sent to driver
23/10/22 22:18:11.975 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 428) in 301 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:11.976 Executor task launch worker for task 5.0 in stage 210.0 (TID 433) INFO Executor: Finished task 5.0 in stage 210.0 (TID 433). 4942 bytes result sent to driver
23/10/22 22:18:11.978 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 210.0 (TID 433) in 303 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:11.983 Executor task launch worker for task 4.0 in stage 210.0 (TID 432) INFO Executor: Finished task 4.0 in stage 210.0 (TID 432). 4899 bytes result sent to driver
23/10/22 22:18:11.986 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 210.0 (TID 432) in 311 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:12.001 Executor task launch worker for task 6.0 in stage 210.0 (TID 434) INFO Executor: Finished task 6.0 in stage 210.0 (TID 434). 4899 bytes result sent to driver
23/10/22 22:18:12.004 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 210.0 (TID 434) in 329 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:12.011 Executor task launch worker for task 1.0 in stage 210.0 (TID 429) INFO Executor: Finished task 1.0 in stage 210.0 (TID 429). 4899 bytes result sent to driver
23/10/22 22:18:12.012 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 210.0 (TID 429) in 337 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:12.021 Executor task launch worker for task 3.0 in stage 210.0 (TID 431) INFO Executor: Finished task 3.0 in stage 210.0 (TID 431). 4899 bytes result sent to driver
23/10/22 22:18:12.022 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 210.0 (TID 431) in 347 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:12.036 Executor task launch worker for task 7.0 in stage 210.0 (TID 435) INFO Executor: Finished task 7.0 in stage 210.0 (TID 435). 4899 bytes result sent to driver
23/10/22 22:18:12.036 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 210.0 (TID 435) in 360 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:12.037 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
23/10/22 22:18:12.037 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 210 (rdd at LinearRegression.scala:921) finished in 0.369 s
23/10/22 22:18:12.037 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:12.037 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:12.037 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:12.037 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:12.042 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(75), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:12.073 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.1091 ms
23/10/22 22:18:12.124 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:18:12.125 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 534 (treeAggregate at Statistics.scala:58) as input to shuffle 76
23/10/22 22:18:12.125 dag-scheduler-event-loop INFO DAGScheduler: Got job 118 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:18:12.125 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 214 (treeAggregate at Statistics.scala:58)
23/10/22 22:18:12.125 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 213)
23/10/22 22:18:12.125 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 213)
23/10/22 22:18:12.126 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 213 (MapPartitionsRDD[534] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:12.131 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 89.3 KiB, free 1037.0 MiB)
23/10/22 22:18:12.134 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 1036.9 MiB)
23/10/22 22:18:12.135 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:55185 (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:18:12.135 dag-scheduler-event-loop INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:12.136 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 213 (MapPartitionsRDD[534] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:12.136 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 213.0 with 8 tasks resource profile 0
23/10/22 22:18:12.137 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 436) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.138 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 213.0 (TID 437) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.138 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 213.0 (TID 438) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.138 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 213.0 (TID 439) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.138 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 213.0 (TID 440) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.139 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 213.0 (TID 441) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.139 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 213.0 (TID 442) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.139 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 213.0 (TID 443) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:12.139 Executor task launch worker for task 0.0 in stage 213.0 (TID 436) INFO Executor: Running task 0.0 in stage 213.0 (TID 436)
23/10/22 22:18:12.139 Executor task launch worker for task 7.0 in stage 213.0 (TID 443) INFO Executor: Running task 7.0 in stage 213.0 (TID 443)
23/10/22 22:18:12.139 Executor task launch worker for task 1.0 in stage 213.0 (TID 437) INFO Executor: Running task 1.0 in stage 213.0 (TID 437)
23/10/22 22:18:12.139 Executor task launch worker for task 6.0 in stage 213.0 (TID 442) INFO Executor: Running task 6.0 in stage 213.0 (TID 442)
23/10/22 22:18:12.139 Executor task launch worker for task 3.0 in stage 213.0 (TID 439) INFO Executor: Running task 3.0 in stage 213.0 (TID 439)
23/10/22 22:18:12.139 Executor task launch worker for task 2.0 in stage 213.0 (TID 438) INFO Executor: Running task 2.0 in stage 213.0 (TID 438)
23/10/22 22:18:12.139 Executor task launch worker for task 4.0 in stage 213.0 (TID 440) INFO Executor: Running task 4.0 in stage 213.0 (TID 440)
23/10/22 22:18:12.139 Executor task launch worker for task 5.0 in stage 213.0 (TID 441) INFO Executor: Running task 5.0 in stage 213.0 (TID 441)
23/10/22 22:18:12.151 Executor task launch worker for task 6.0 in stage 213.0 (TID 442) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.151 Executor task launch worker for task 6.0 in stage 213.0 (TID 442) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:12.152 Executor task launch worker for task 3.0 in stage 213.0 (TID 439) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.152 Executor task launch worker for task 3.0 in stage 213.0 (TID 439) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:12.152 Executor task launch worker for task 5.0 in stage 213.0 (TID 441) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.153 Executor task launch worker for task 5.0 in stage 213.0 (TID 441) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:12.153 Executor task launch worker for task 1.0 in stage 213.0 (TID 437) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.153 Executor task launch worker for task 1.0 in stage 213.0 (TID 437) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:12.154 Executor task launch worker for task 4.0 in stage 213.0 (TID 440) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.154 Executor task launch worker for task 2.0 in stage 213.0 (TID 438) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.155 Executor task launch worker for task 4.0 in stage 213.0 (TID 440) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:12.155 Executor task launch worker for task 2.0 in stage 213.0 (TID 438) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:12.155 Executor task launch worker for task 0.0 in stage 213.0 (TID 436) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.155 Executor task launch worker for task 0.0 in stage 213.0 (TID 436) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:12.157 Executor task launch worker for task 7.0 in stage 213.0 (TID 443) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.158 Executor task launch worker for task 7.0 in stage 213.0 (TID 443) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:12.171 Executor task launch worker for task 4.0 in stage 213.0 (TID 440) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.171 Executor task launch worker for task 5.0 in stage 213.0 (TID 441) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.173 Executor task launch worker for task 0.0 in stage 213.0 (TID 436) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.174 Executor task launch worker for task 3.0 in stage 213.0 (TID 439) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.174 Executor task launch worker for task 6.0 in stage 213.0 (TID 442) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.187 Executor task launch worker for task 2.0 in stage 213.0 (TID 438) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.218 Executor task launch worker for task 7.0 in stage 213.0 (TID 443) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.218 Executor task launch worker for task 1.0 in stage 213.0 (TID 437) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:12.243 Executor task launch worker for task 5.0 in stage 213.0 (TID 441) INFO Executor: Finished task 5.0 in stage 213.0 (TID 441). 6605 bytes result sent to driver
23/10/22 22:18:12.244 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 213.0 (TID 441) in 105 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:12.264 Executor task launch worker for task 0.0 in stage 213.0 (TID 436) INFO Executor: Finished task 0.0 in stage 213.0 (TID 436). 6605 bytes result sent to driver
23/10/22 22:18:12.265 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 436) in 128 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:12.276 Executor task launch worker for task 6.0 in stage 213.0 (TID 442) INFO Executor: Finished task 6.0 in stage 213.0 (TID 442). 6605 bytes result sent to driver
23/10/22 22:18:12.277 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 213.0 (TID 442) in 138 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:12.308 Executor task launch worker for task 4.0 in stage 213.0 (TID 440) INFO Executor: Finished task 4.0 in stage 213.0 (TID 440). 6605 bytes result sent to driver
23/10/22 22:18:12.308 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 213.0 (TID 440) in 170 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:12.313 Executor task launch worker for task 3.0 in stage 213.0 (TID 439) INFO Executor: Finished task 3.0 in stage 213.0 (TID 439). 6605 bytes result sent to driver
23/10/22 22:18:12.313 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 213.0 (TID 439) in 175 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:12.320 Executor task launch worker for task 2.0 in stage 213.0 (TID 438) INFO Executor: Finished task 2.0 in stage 213.0 (TID 438). 6605 bytes result sent to driver
23/10/22 22:18:12.321 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 213.0 (TID 438) in 183 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:12.326 Executor task launch worker for task 1.0 in stage 213.0 (TID 437) INFO Executor: Finished task 1.0 in stage 213.0 (TID 437). 6562 bytes result sent to driver
23/10/22 22:18:12.326 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 213.0 (TID 437) in 188 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:12.343 Executor task launch worker for task 7.0 in stage 213.0 (TID 443) INFO Executor: Finished task 7.0 in stage 213.0 (TID 443). 6605 bytes result sent to driver
23/10/22 22:18:12.344 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 213.0 (TID 443) in 205 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:12.344 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
23/10/22 22:18:12.345 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 213 (treeAggregate at Statistics.scala:58) finished in 0.217 s
23/10/22 22:18:12.345 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:12.345 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:12.345 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 214)
23/10/22 22:18:12.345 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:12.345 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[536] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:12.351 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 90.4 KiB, free 1036.8 MiB)
23/10/22 22:18:12.353 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 37.6 KiB, free 1036.8 MiB)
23/10/22 22:18:12.354 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:55185 (size: 37.6 KiB, free: 1037.0 MiB)
23/10/22 22:18:12.355 dag-scheduler-event-loop INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:12.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 214 (MapPartitionsRDD[536] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:18:12.355 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 214.0 with 2 tasks resource profile 0
23/10/22 22:18:12.356 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 444) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:12.357 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 214.0 (TID 445) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:12.357 Executor task launch worker for task 0.0 in stage 214.0 (TID 444) INFO Executor: Running task 0.0 in stage 214.0 (TID 444)
23/10/22 22:18:12.357 Executor task launch worker for task 1.0 in stage 214.0 (TID 445) INFO Executor: Running task 1.0 in stage 214.0 (TID 445)
23/10/22 22:18:12.366 Executor task launch worker for task 0.0 in stage 214.0 (TID 444) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.366 Executor task launch worker for task 1.0 in stage 214.0 (TID 445) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:12.367 Executor task launch worker for task 0.0 in stage 214.0 (TID 444) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:12.367 Executor task launch worker for task 1.0 in stage 214.0 (TID 445) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:18:12.374 Executor task launch worker for task 1.0 in stage 214.0 (TID 445) INFO Executor: Finished task 1.0 in stage 214.0 (TID 445). 7630 bytes result sent to driver
23/10/22 22:18:12.374 Executor task launch worker for task 0.0 in stage 214.0 (TID 444) INFO Executor: Finished task 0.0 in stage 214.0 (TID 444). 7630 bytes result sent to driver
23/10/22 22:18:12.375 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 214.0 (TID 445) in 19 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:18:12.375 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 444) in 19 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:18:12.375 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
23/10/22 22:18:12.375 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 214 (treeAggregate at Statistics.scala:58) finished in 0.029 s
23/10/22 22:18:12.375 dag-scheduler-event-loop INFO DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:12.376 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 214: Stage finished
23/10/22 22:18:12.376 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 118 finished: treeAggregate at Statistics.scala:58, took 0.251801 s
23/10/22 22:18:12.377 nioEventLoopGroup-2-2 INFO Instrumentation: [667a6876] training finished
23/10/22 22:18:12.821 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:12.822 dag-scheduler-event-loop INFO DAGScheduler: Got job 119 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:12.822 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 215 (collect at utils.scala:26)
23/10/22 22:18:12.822 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:12.822 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:12.822 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 215 (MapPartitionsRDD[538] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:12.823 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:18:12.824 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:18:12.825 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:18:12.825 dag-scheduler-event-loop INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:12.825 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 215 (MapPartitionsRDD[538] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:12.825 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 215.0 with 1 tasks resource profile 0
23/10/22 22:18:12.826 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 446) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:12.826 Executor task launch worker for task 0.0 in stage 215.0 (TID 446) INFO Executor: Running task 0.0 in stage 215.0 (TID 446)
23/10/22 22:18:12.828 Executor task launch worker for task 0.0 in stage 215.0 (TID 446) INFO Executor: Finished task 0.0 in stage 215.0 (TID 446). 1327 bytes result sent to driver
23/10/22 22:18:12.830 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 446) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:12.830 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
23/10/22 22:18:12.830 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 215 (collect at utils.scala:26) finished in 0.008 s
23/10/22 22:18:12.830 dag-scheduler-event-loop INFO DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:12.830 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 215: Stage finished
23/10/22 22:18:12.830 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 119 finished: collect at utils.scala:26, took 0.008385 s
23/10/22 22:18:13.401 nioEventLoopGroup-2-2 INFO Instrumentation: [9d3ff4b9] training finished
23/10/22 22:18:13.524 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:13.524 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:18:13.525 dag-scheduler-event-loop INFO DAGScheduler: Got job 120 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:13.525 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 216 (collect at utils.scala:26)
23/10/22 22:18:13.525 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:13.526 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:13.526 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[540] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:13.527 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:18:13.527 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:55185 in memory (size: 37.0 KiB, free: 1037.1 MiB)
23/10/22 22:18:13.528 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.9 MiB)
23/10/22 22:18:13.529 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:13.530 dag-scheduler-event-loop INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:13.531 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[540] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:13.531 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 216.0 with 1 tasks resource profile 0
23/10/22 22:18:13.531 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:55185 in memory (size: 37.6 KiB, free: 1037.1 MiB)
23/10/22 22:18:13.533 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 447) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:13.533 Executor task launch worker for task 0.0 in stage 216.0 (TID 447) INFO Executor: Running task 0.0 in stage 216.0 (TID 447)
23/10/22 22:18:13.534 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:13.536 Executor task launch worker for task 0.0 in stage 216.0 (TID 447) INFO Executor: Finished task 0.0 in stage 216.0 (TID 447). 1327 bytes result sent to driver
23/10/22 22:18:13.536 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 447) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:13.536 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
23/10/22 22:18:13.536 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 216 (collect at utils.scala:26) finished in 0.010 s
23/10/22 22:18:13.536 dag-scheduler-event-loop INFO DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:13.536 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 216: Stage finished
23/10/22 22:18:13.536 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 120 finished: collect at utils.scala:26, took 0.011788 s
23/10/22 22:18:14.055 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:14.056 dag-scheduler-event-loop INFO DAGScheduler: Got job 121 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:14.056 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 217 (collect at utils.scala:26)
23/10/22 22:18:14.056 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:14.056 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:14.056 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[542] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:14.057 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 22:18:14.057 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:18:14.058 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:14.058 dag-scheduler-event-loop INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:14.058 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 217 (MapPartitionsRDD[542] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:14.058 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 217.0 with 1 tasks resource profile 0
23/10/22 22:18:14.059 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 448) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:14.059 Executor task launch worker for task 0.0 in stage 217.0 (TID 448) INFO Executor: Running task 0.0 in stage 217.0 (TID 448)
23/10/22 22:18:14.061 Executor task launch worker for task 0.0 in stage 217.0 (TID 448) INFO Executor: Finished task 0.0 in stage 217.0 (TID 448). 1284 bytes result sent to driver
23/10/22 22:18:14.061 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 448) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:14.062 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
23/10/22 22:18:14.062 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 217 (collect at utils.scala:26) finished in 0.006 s
23/10/22 22:18:14.062 dag-scheduler-event-loop INFO DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:14.062 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 217: Stage finished
23/10/22 22:18:14.062 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 121 finished: collect at utils.scala:26, took 0.006935 s
23/10/22 22:18:35.623 nioEventLoopGroup-2-2 INFO Instrumentation: [13ec5a6c] training finished
23/10/22 22:18:35.631 nioEventLoopGroup-2-2 INFO Instrumentation: [2f5218cb] training finished
23/10/22 22:18:35.709 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:35.709 dag-scheduler-event-loop INFO DAGScheduler: Got job 122 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:35.709 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 218 (collect at utils.scala:26)
23/10/22 22:18:35.709 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:35.709 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:35.709 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 218 (MapPartitionsRDD[544] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:35.710 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 7.4 KiB, free 1037.1 MiB)
23/10/22 22:18:35.711 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1037.1 MiB)
23/10/22 22:18:35.711 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:35.711 dag-scheduler-event-loop INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:35.712 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 218 (MapPartitionsRDD[544] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:35.712 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 218.0 with 1 tasks resource profile 0
23/10/22 22:18:35.712 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 449) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:35.712 Executor task launch worker for task 0.0 in stage 218.0 (TID 449) INFO Executor: Running task 0.0 in stage 218.0 (TID 449)
23/10/22 22:18:35.714 Executor task launch worker for task 0.0 in stage 218.0 (TID 449) INFO Executor: Finished task 0.0 in stage 218.0 (TID 449). 1284 bytes result sent to driver
23/10/22 22:18:35.716 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 449) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:35.716 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
23/10/22 22:18:35.717 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 218 (collect at utils.scala:26) finished in 0.006 s
23/10/22 22:18:35.717 dag-scheduler-event-loop INFO DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:35.717 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 218: Stage finished
23/10/22 22:18:35.717 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 122 finished: collect at utils.scala:26, took 0.007912 s
23/10/22 22:18:36.043 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 547 (rdd at RegressionEvaluator.scala:125) as input to shuffle 77
23/10/22 22:18:36.043 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 123 (rdd at RegressionEvaluator.scala:125) with 1 output partitions
23/10/22 22:18:36.043 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 219 (rdd at RegressionEvaluator.scala:125)
23/10/22 22:18:36.043 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:36.043 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:36.043 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 219 (MapPartitionsRDD[547] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 22:18:36.044 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 32.7 KiB, free 1037.0 MiB)
23/10/22 22:18:36.045 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.0 MiB)
23/10/22 22:18:36.045 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:36.045 dag-scheduler-event-loop INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:36.046 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 219 (MapPartitionsRDD[547] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:36.046 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 219.0 with 1 tasks resource profile 0
23/10/22 22:18:36.256 dispatcher-event-loop-5 WARN TaskSetManager: Stage 219 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:18:36.256 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 219.0 (TID 450) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:18:36.256 Executor task launch worker for task 0.0 in stage 219.0 (TID 450) INFO Executor: Running task 0.0 in stage 219.0 (TID 450)
23/10/22 22:18:36.322 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:36.324 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:36.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:36.418 Executor task launch worker for task 0.0 in stage 219.0 (TID 450) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:36.517 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:37.244 Executor task launch worker for task 0.0 in stage 219.0 (TID 450) INFO Executor: Finished task 0.0 in stage 219.0 (TID 450). 2147 bytes result sent to driver
23/10/22 22:18:37.245 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 219.0 (TID 450) in 1199 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:37.245 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool 
23/10/22 22:18:37.245 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 219 (rdd at RegressionEvaluator.scala:125) finished in 1.202 s
23/10/22 22:18:37.245 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:37.245 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:37.245 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:37.245 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:37.250 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(77), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:37.252 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 551 (rdd at RegressionEvaluator.scala:125) as input to shuffle 78
23/10/22 22:18:37.252 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 124 (rdd at RegressionEvaluator.scala:125) with 8 output partitions
23/10/22 22:18:37.252 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 221 (rdd at RegressionEvaluator.scala:125)
23/10/22 22:18:37.252 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 220)
23/10/22 22:18:37.252 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:37.252 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 221 (MapPartitionsRDD[551] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 22:18:37.253 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:18:37.254 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1037.0 MiB)
23/10/22 22:18:37.254 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:55185 (size: 17.2 KiB, free: 1037.1 MiB)
23/10/22 22:18:37.254 dag-scheduler-event-loop INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:37.255 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 221 (MapPartitionsRDD[551] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:37.255 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 221.0 with 8 tasks resource profile 0
23/10/22 22:18:37.255 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 451) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.255 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 452) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.255 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 221.0 (TID 453) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.255 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 221.0 (TID 454) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.256 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 221.0 (TID 455) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.256 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 221.0 (TID 456) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.256 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 221.0 (TID 457) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.256 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 221.0 (TID 458) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.256 Executor task launch worker for task 0.0 in stage 221.0 (TID 451) INFO Executor: Running task 0.0 in stage 221.0 (TID 451)
23/10/22 22:18:37.256 Executor task launch worker for task 1.0 in stage 221.0 (TID 452) INFO Executor: Running task 1.0 in stage 221.0 (TID 452)
23/10/22 22:18:37.256 Executor task launch worker for task 4.0 in stage 221.0 (TID 455) INFO Executor: Running task 4.0 in stage 221.0 (TID 455)
23/10/22 22:18:37.256 Executor task launch worker for task 3.0 in stage 221.0 (TID 454) INFO Executor: Running task 3.0 in stage 221.0 (TID 454)
23/10/22 22:18:37.256 Executor task launch worker for task 2.0 in stage 221.0 (TID 453) INFO Executor: Running task 2.0 in stage 221.0 (TID 453)
23/10/22 22:18:37.256 Executor task launch worker for task 5.0 in stage 221.0 (TID 456) INFO Executor: Running task 5.0 in stage 221.0 (TID 456)
23/10/22 22:18:37.256 Executor task launch worker for task 7.0 in stage 221.0 (TID 458) INFO Executor: Running task 7.0 in stage 221.0 (TID 458)
23/10/22 22:18:37.256 Executor task launch worker for task 6.0 in stage 221.0 (TID 457) INFO Executor: Running task 6.0 in stage 221.0 (TID 457)
23/10/22 22:18:37.259 Executor task launch worker for task 0.0 in stage 221.0 (TID 451) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.259 Executor task launch worker for task 1.0 in stage 221.0 (TID 452) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.259 Executor task launch worker for task 0.0 in stage 221.0 (TID 451) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.259 Executor task launch worker for task 1.0 in stage 221.0 (TID 452) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.259 Executor task launch worker for task 4.0 in stage 221.0 (TID 455) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.259 Executor task launch worker for task 4.0 in stage 221.0 (TID 455) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.259 Executor task launch worker for task 3.0 in stage 221.0 (TID 454) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.259 Executor task launch worker for task 3.0 in stage 221.0 (TID 454) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.260 Executor task launch worker for task 6.0 in stage 221.0 (TID 457) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.260 Executor task launch worker for task 6.0 in stage 221.0 (TID 457) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.260 Executor task launch worker for task 7.0 in stage 221.0 (TID 458) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.260 Executor task launch worker for task 2.0 in stage 221.0 (TID 453) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.260 Executor task launch worker for task 7.0 in stage 221.0 (TID 458) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.260 Executor task launch worker for task 2.0 in stage 221.0 (TID 453) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.260 Executor task launch worker for task 5.0 in stage 221.0 (TID 456) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.260 Executor task launch worker for task 5.0 in stage 221.0 (TID 456) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.267 Executor task launch worker for task 6.0 in stage 221.0 (TID 457) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.267 Executor task launch worker for task 2.0 in stage 221.0 (TID 453) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.267 Executor task launch worker for task 3.0 in stage 221.0 (TID 454) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.267 Executor task launch worker for task 1.0 in stage 221.0 (TID 452) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.272 Executor task launch worker for task 7.0 in stage 221.0 (TID 458) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.277 Executor task launch worker for task 5.0 in stage 221.0 (TID 456) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.287 Executor task launch worker for task 3.0 in stage 221.0 (TID 454) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.288 Executor task launch worker for task 0.0 in stage 221.0 (TID 451) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.290 Executor task launch worker for task 2.0 in stage 221.0 (TID 453) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.294 Executor task launch worker for task 7.0 in stage 221.0 (TID 458) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.297 Executor task launch worker for task 1.0 in stage 221.0 (TID 452) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.300 Executor task launch worker for task 4.0 in stage 221.0 (TID 455) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.302 Executor task launch worker for task 6.0 in stage 221.0 (TID 457) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.308 Executor task launch worker for task 5.0 in stage 221.0 (TID 456) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.320 Executor task launch worker for task 4.0 in stage 221.0 (TID 455) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.322 Executor task launch worker for task 0.0 in stage 221.0 (TID 451) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.418 Executor task launch worker for task 2.0 in stage 221.0 (TID 453) INFO Executor: Finished task 2.0 in stage 221.0 (TID 453). 4899 bytes result sent to driver
23/10/22 22:18:37.419 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 221.0 (TID 453) in 164 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:37.422 Executor task launch worker for task 6.0 in stage 221.0 (TID 457) INFO Executor: Finished task 6.0 in stage 221.0 (TID 457). 4899 bytes result sent to driver
23/10/22 22:18:37.423 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 221.0 (TID 457) in 167 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:37.445 Executor task launch worker for task 3.0 in stage 221.0 (TID 454) INFO Executor: Finished task 3.0 in stage 221.0 (TID 454). 4899 bytes result sent to driver
23/10/22 22:18:37.446 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 221.0 (TID 454) in 191 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:37.453 Executor task launch worker for task 0.0 in stage 221.0 (TID 451) INFO Executor: Finished task 0.0 in stage 221.0 (TID 451). 4899 bytes result sent to driver
23/10/22 22:18:37.453 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 451) in 198 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:37.457 Executor task launch worker for task 7.0 in stage 221.0 (TID 458) INFO Executor: Finished task 7.0 in stage 221.0 (TID 458). 4899 bytes result sent to driver
23/10/22 22:18:37.458 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 221.0 (TID 458) in 202 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:37.461 Executor task launch worker for task 1.0 in stage 221.0 (TID 452) INFO Executor: Finished task 1.0 in stage 221.0 (TID 452). 4899 bytes result sent to driver
23/10/22 22:18:37.461 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 452) in 206 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:37.466 Executor task launch worker for task 4.0 in stage 221.0 (TID 455) INFO Executor: Finished task 4.0 in stage 221.0 (TID 455). 4899 bytes result sent to driver
23/10/22 22:18:37.466 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 221.0 (TID 455) in 211 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:37.469 Executor task launch worker for task 5.0 in stage 221.0 (TID 456) INFO Executor: Finished task 5.0 in stage 221.0 (TID 456). 4899 bytes result sent to driver
23/10/22 22:18:37.469 task-result-getter-1 INFO TaskSetManager: Finished task 5.0 in stage 221.0 (TID 456) in 213 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:37.469 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
23/10/22 22:18:37.470 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 221 (rdd at RegressionEvaluator.scala:125) finished in 0.218 s
23/10/22 22:18:37.470 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:37.470 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:37.470 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:37.470 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:37.473 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(78), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:37.495 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.2466 ms
23/10/22 22:18:37.534 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:18:37.535 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 561 (treeAggregate at Statistics.scala:58) as input to shuffle 79
23/10/22 22:18:37.535 dag-scheduler-event-loop INFO DAGScheduler: Got job 125 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:18:37.535 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 225 (treeAggregate at Statistics.scala:58)
23/10/22 22:18:37.535 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 224)
23/10/22 22:18:37.535 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
23/10/22 22:18:37.535 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 224 (MapPartitionsRDD[561] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:37.538 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 84.2 KiB, free 1037.0 MiB)
23/10/22 22:18:37.539 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 35.8 KiB, free 1036.9 MiB)
23/10/22 22:18:37.539 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:55185 (size: 35.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:37.539 dag-scheduler-event-loop INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:37.540 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 224 (MapPartitionsRDD[561] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:37.540 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 224.0 with 8 tasks resource profile 0
23/10/22 22:18:37.540 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 459) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.540 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 460) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.540 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 461) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.540 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 462) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.541 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 463) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.541 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 464) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.541 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 465) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.541 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 466) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:37.541 Executor task launch worker for task 4.0 in stage 224.0 (TID 463) INFO Executor: Running task 4.0 in stage 224.0 (TID 463)
23/10/22 22:18:37.541 Executor task launch worker for task 6.0 in stage 224.0 (TID 465) INFO Executor: Running task 6.0 in stage 224.0 (TID 465)
23/10/22 22:18:37.541 Executor task launch worker for task 7.0 in stage 224.0 (TID 466) INFO Executor: Running task 7.0 in stage 224.0 (TID 466)
23/10/22 22:18:37.541 Executor task launch worker for task 5.0 in stage 224.0 (TID 464) INFO Executor: Running task 5.0 in stage 224.0 (TID 464)
23/10/22 22:18:37.541 Executor task launch worker for task 0.0 in stage 224.0 (TID 459) INFO Executor: Running task 0.0 in stage 224.0 (TID 459)
23/10/22 22:18:37.541 Executor task launch worker for task 2.0 in stage 224.0 (TID 461) INFO Executor: Running task 2.0 in stage 224.0 (TID 461)
23/10/22 22:18:37.541 Executor task launch worker for task 3.0 in stage 224.0 (TID 462) INFO Executor: Running task 3.0 in stage 224.0 (TID 462)
23/10/22 22:18:37.541 Executor task launch worker for task 1.0 in stage 224.0 (TID 460) INFO Executor: Running task 1.0 in stage 224.0 (TID 460)
23/10/22 22:18:37.551 Executor task launch worker for task 3.0 in stage 224.0 (TID 462) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 0.0 in stage 224.0 (TID 459) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 6.0 in stage 224.0 (TID 465) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 3.0 in stage 224.0 (TID 462) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 6.0 in stage 224.0 (TID 465) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 1.0 in stage 224.0 (TID 460) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 5.0 in stage 224.0 (TID 464) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 7.0 in stage 224.0 (TID 466) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 4.0 in stage 224.0 (TID 463) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 0.0 in stage 224.0 (TID 459) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 4.0 in stage 224.0 (TID 463) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 2.0 in stage 224.0 (TID 461) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.551 Executor task launch worker for task 5.0 in stage 224.0 (TID 464) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 2.0 in stage 224.0 (TID 461) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 1.0 in stage 224.0 (TID 460) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.551 Executor task launch worker for task 7.0 in stage 224.0 (TID 466) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.560 Executor task launch worker for task 0.0 in stage 224.0 (TID 459) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.560 Executor task launch worker for task 3.0 in stage 224.0 (TID 462) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.560 Executor task launch worker for task 1.0 in stage 224.0 (TID 460) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.562 Executor task launch worker for task 7.0 in stage 224.0 (TID 466) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.563 Executor task launch worker for task 4.0 in stage 224.0 (TID 463) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.560 Executor task launch worker for task 2.0 in stage 224.0 (TID 461) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.566 Executor task launch worker for task 5.0 in stage 224.0 (TID 464) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.591 Executor task launch worker for task 6.0 in stage 224.0 (TID 465) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:37.608 Executor task launch worker for task 3.0 in stage 224.0 (TID 462) INFO Executor: Finished task 3.0 in stage 224.0 (TID 462). 6562 bytes result sent to driver
23/10/22 22:18:37.608 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 462) in 68 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:37.611 Executor task launch worker for task 0.0 in stage 224.0 (TID 459) INFO Executor: Finished task 0.0 in stage 224.0 (TID 459). 6562 bytes result sent to driver
23/10/22 22:18:37.612 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 459) in 72 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:37.616 Executor task launch worker for task 1.0 in stage 224.0 (TID 460) INFO Executor: Finished task 1.0 in stage 224.0 (TID 460). 6562 bytes result sent to driver
23/10/22 22:18:37.617 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 460) in 77 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:37.624 Executor task launch worker for task 7.0 in stage 224.0 (TID 466) INFO Executor: Finished task 7.0 in stage 224.0 (TID 466). 6562 bytes result sent to driver
23/10/22 22:18:37.626 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 466) in 85 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:37.631 Executor task launch worker for task 4.0 in stage 224.0 (TID 463) INFO Executor: Finished task 4.0 in stage 224.0 (TID 463). 6562 bytes result sent to driver
23/10/22 22:18:37.635 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 463) in 95 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:37.637 Executor task launch worker for task 2.0 in stage 224.0 (TID 461) INFO Executor: Finished task 2.0 in stage 224.0 (TID 461). 6562 bytes result sent to driver
23/10/22 22:18:37.638 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 461) in 98 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:37.640 Executor task launch worker for task 5.0 in stage 224.0 (TID 464) INFO Executor: Finished task 5.0 in stage 224.0 (TID 464). 6562 bytes result sent to driver
23/10/22 22:18:37.641 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 464) in 100 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:37.658 Executor task launch worker for task 6.0 in stage 224.0 (TID 465) INFO Executor: Finished task 6.0 in stage 224.0 (TID 465). 6562 bytes result sent to driver
23/10/22 22:18:37.658 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 465) in 117 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:37.658 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
23/10/22 22:18:37.659 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 224 (treeAggregate at Statistics.scala:58) finished in 0.123 s
23/10/22 22:18:37.659 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:37.659 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:37.659 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 225)
23/10/22 22:18:37.659 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:37.659 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[563] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:37.661 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 85.3 KiB, free 1036.8 MiB)
23/10/22 22:18:37.662 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 1036.8 MiB)
23/10/22 22:18:37.663 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:55185 (size: 36.4 KiB, free: 1037.0 MiB)
23/10/22 22:18:37.663 dag-scheduler-event-loop INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:37.663 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 225 (MapPartitionsRDD[563] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:18:37.663 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 225.0 with 2 tasks resource profile 0
23/10/22 22:18:37.664 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 467) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:37.664 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 468) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:37.664 Executor task launch worker for task 1.0 in stage 225.0 (TID 468) INFO Executor: Running task 1.0 in stage 225.0 (TID 468)
23/10/22 22:18:37.664 Executor task launch worker for task 0.0 in stage 225.0 (TID 467) INFO Executor: Running task 0.0 in stage 225.0 (TID 467)
23/10/22 22:18:37.668 Executor task launch worker for task 1.0 in stage 225.0 (TID 468) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.668 Executor task launch worker for task 0.0 in stage 225.0 (TID 467) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:37.668 Executor task launch worker for task 0.0 in stage 225.0 (TID 467) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.669 Executor task launch worker for task 1.0 in stage 225.0 (TID 468) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:37.672 Executor task launch worker for task 0.0 in stage 225.0 (TID 467) INFO Executor: Finished task 0.0 in stage 225.0 (TID 467). 7587 bytes result sent to driver
23/10/22 22:18:37.672 Executor task launch worker for task 1.0 in stage 225.0 (TID 468) INFO Executor: Finished task 1.0 in stage 225.0 (TID 468). 7587 bytes result sent to driver
23/10/22 22:18:37.673 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 467) in 8 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:18:37.673 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 468) in 9 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:18:37.673 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool 
23/10/22 22:18:37.673 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 225 (treeAggregate at Statistics.scala:58) finished in 0.014 s
23/10/22 22:18:37.673 dag-scheduler-event-loop INFO DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:37.673 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
23/10/22 22:18:37.673 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 125 finished: treeAggregate at Statistics.scala:58, took 0.138940 s
23/10/22 22:18:37.770 nioEventLoopGroup-2-2 INFO Instrumentation: [1b32171b] training finished
23/10/22 22:18:37.786 nioEventLoopGroup-2-2 INFO Instrumentation: [a9f84b3f] training finished
23/10/22 22:18:37.869 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:18:37.870 dag-scheduler-event-loop INFO DAGScheduler: Got job 126 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:18:37.870 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 226 (collect at utils.scala:26)
23/10/22 22:18:37.870 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:37.870 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:37.870 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 226 (MapPartitionsRDD[565] at collect at utils.scala:26), which has no missing parents
23/10/22 22:18:37.871 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 7.4 KiB, free 1036.8 MiB)
23/10/22 22:18:37.871 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 1036.8 MiB)
23/10/22 22:18:37.871 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:55185 (size: 3.7 KiB, free: 1037.0 MiB)
23/10/22 22:18:37.871 dag-scheduler-event-loop INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:37.871 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (MapPartitionsRDD[565] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:37.871 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks resource profile 0
23/10/22 22:18:37.873 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 469) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
23/10/22 22:18:37.873 Executor task launch worker for task 0.0 in stage 226.0 (TID 469) INFO Executor: Running task 0.0 in stage 226.0 (TID 469)
23/10/22 22:18:37.874 Executor task launch worker for task 0.0 in stage 226.0 (TID 469) INFO Executor: Finished task 0.0 in stage 226.0 (TID 469). 1284 bytes result sent to driver
23/10/22 22:18:37.875 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 469) in 2 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:37.875 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool 
23/10/22 22:18:37.875 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 226 (collect at utils.scala:26) finished in 0.005 s
23/10/22 22:18:37.875 dag-scheduler-event-loop INFO DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:37.875 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 226: Stage finished
23/10/22 22:18:37.875 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 126 finished: collect at utils.scala:26, took 0.004799 s
23/10/22 22:18:38.194 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 568 (rdd at RegressionEvaluator.scala:125) as input to shuffle 80
23/10/22 22:18:38.194 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 127 (rdd at RegressionEvaluator.scala:125) with 1 output partitions
23/10/22 22:18:38.194 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 227 (rdd at RegressionEvaluator.scala:125)
23/10/22 22:18:38.194 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:18:38.194 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:38.194 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 227 (MapPartitionsRDD[568] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 22:18:38.195 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:18:38.196 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 22:18:38.196 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:18:38.196 dag-scheduler-event-loop INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:38.196 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 227 (MapPartitionsRDD[568] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0))
23/10/22 22:18:38.197 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 227.0 with 1 tasks resource profile 0
23/10/22 22:18:38.449 dispatcher-event-loop-3 WARN TaskSetManager: Stage 227 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:18:38.449 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 470) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:18:38.450 Executor task launch worker for task 0.0 in stage 227.0 (TID 470) INFO Executor: Running task 0.0 in stage 227.0 (TID 470)
23/10/22 22:18:38.476 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:55185 in memory (size: 17.2 KiB, free: 1037.0 MiB)
23/10/22 22:18:38.478 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:55185 in memory (size: 36.4 KiB, free: 1037.1 MiB)
23/10/22 22:18:38.480 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:55185 in memory (size: 3.7 KiB, free: 1037.1 MiB)
23/10/22 22:18:38.481 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:55185 in memory (size: 35.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:38.601 Executor task launch worker for task 0.0 in stage 227.0 (TID 470) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:38.768 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:18:39.420 Executor task launch worker for task 0.0 in stage 227.0 (TID 470) INFO Executor: Finished task 0.0 in stage 227.0 (TID 470). 2147 bytes result sent to driver
23/10/22 22:18:39.421 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 470) in 1224 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:18:39.421 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool 
23/10/22 22:18:39.421 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 227 (rdd at RegressionEvaluator.scala:125) finished in 1.227 s
23/10/22 22:18:39.421 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:39.421 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:39.421 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:39.421 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:39.424 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(80), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:18:39.426 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 572 (rdd at RegressionEvaluator.scala:125) as input to shuffle 81
23/10/22 22:18:39.427 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 128 (rdd at RegressionEvaluator.scala:125) with 8 output partitions
23/10/22 22:18:39.427 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 229 (rdd at RegressionEvaluator.scala:125)
23/10/22 22:18:39.427 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 228)
23/10/22 22:18:39.427 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:18:39.427 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 229 (MapPartitionsRDD[572] at rdd at RegressionEvaluator.scala:125), which has no missing parents
23/10/22 22:18:39.429 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:18:39.431 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:18:39.432 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:18:39.432 dag-scheduler-event-loop INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:39.432 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 229 (MapPartitionsRDD[572] at rdd at RegressionEvaluator.scala:125) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:39.432 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 229.0 with 8 tasks resource profile 0
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 471) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 229.0 (TID 472) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 229.0 (TID 473) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 229.0 (TID 474) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 229.0 (TID 475) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 229.0 (TID 476) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 229.0 (TID 477) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 229.0 (TID 478) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.433 Executor task launch worker for task 0.0 in stage 229.0 (TID 471) INFO Executor: Running task 0.0 in stage 229.0 (TID 471)
23/10/22 22:18:39.433 Executor task launch worker for task 1.0 in stage 229.0 (TID 472) INFO Executor: Running task 1.0 in stage 229.0 (TID 472)
23/10/22 22:18:39.433 Executor task launch worker for task 2.0 in stage 229.0 (TID 473) INFO Executor: Running task 2.0 in stage 229.0 (TID 473)
23/10/22 22:18:39.433 Executor task launch worker for task 5.0 in stage 229.0 (TID 476) INFO Executor: Running task 5.0 in stage 229.0 (TID 476)
23/10/22 22:18:39.433 Executor task launch worker for task 3.0 in stage 229.0 (TID 474) INFO Executor: Running task 3.0 in stage 229.0 (TID 474)
23/10/22 22:18:39.434 Executor task launch worker for task 7.0 in stage 229.0 (TID 478) INFO Executor: Running task 7.0 in stage 229.0 (TID 478)
23/10/22 22:18:39.433 Executor task launch worker for task 4.0 in stage 229.0 (TID 475) INFO Executor: Running task 4.0 in stage 229.0 (TID 475)
23/10/22 22:18:39.434 Executor task launch worker for task 6.0 in stage 229.0 (TID 477) INFO Executor: Running task 6.0 in stage 229.0 (TID 477)
23/10/22 22:18:39.436 Executor task launch worker for task 3.0 in stage 229.0 (TID 474) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.436 Executor task launch worker for task 3.0 in stage 229.0 (TID 474) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.437 Executor task launch worker for task 0.0 in stage 229.0 (TID 471) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.437 Executor task launch worker for task 0.0 in stage 229.0 (TID 471) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.438 Executor task launch worker for task 6.0 in stage 229.0 (TID 477) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.438 Executor task launch worker for task 6.0 in stage 229.0 (TID 477) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.438 Executor task launch worker for task 2.0 in stage 229.0 (TID 473) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.438 Executor task launch worker for task 2.0 in stage 229.0 (TID 473) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.438 Executor task launch worker for task 4.0 in stage 229.0 (TID 475) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.438 Executor task launch worker for task 4.0 in stage 229.0 (TID 475) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.438 Executor task launch worker for task 7.0 in stage 229.0 (TID 478) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.438 Executor task launch worker for task 7.0 in stage 229.0 (TID 478) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.439 Executor task launch worker for task 1.0 in stage 229.0 (TID 472) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.439 Executor task launch worker for task 1.0 in stage 229.0 (TID 472) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.441 Executor task launch worker for task 5.0 in stage 229.0 (TID 476) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.441 Executor task launch worker for task 5.0 in stage 229.0 (TID 476) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.445 Executor task launch worker for task 3.0 in stage 229.0 (TID 474) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.451 Executor task launch worker for task 6.0 in stage 229.0 (TID 477) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.453 Executor task launch worker for task 5.0 in stage 229.0 (TID 476) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.453 Executor task launch worker for task 4.0 in stage 229.0 (TID 475) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.458 Executor task launch worker for task 1.0 in stage 229.0 (TID 472) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.478 Executor task launch worker for task 5.0 in stage 229.0 (TID 476) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.489 Executor task launch worker for task 7.0 in stage 229.0 (TID 478) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.486 Executor task launch worker for task 3.0 in stage 229.0 (TID 474) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.486 Executor task launch worker for task 1.0 in stage 229.0 (TID 472) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.485 Executor task launch worker for task 4.0 in stage 229.0 (TID 475) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.484 Executor task launch worker for task 2.0 in stage 229.0 (TID 473) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.502 Executor task launch worker for task 6.0 in stage 229.0 (TID 477) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.510 Executor task launch worker for task 0.0 in stage 229.0 (TID 471) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.519 Executor task launch worker for task 2.0 in stage 229.0 (TID 473) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.529 Executor task launch worker for task 7.0 in stage 229.0 (TID 478) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.588 Executor task launch worker for task 0.0 in stage 229.0 (TID 471) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.655 Executor task launch worker for task 1.0 in stage 229.0 (TID 472) INFO Executor: Finished task 1.0 in stage 229.0 (TID 472). 4899 bytes result sent to driver
23/10/22 22:18:39.656 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 229.0 (TID 472) in 223 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:39.659 Executor task launch worker for task 5.0 in stage 229.0 (TID 476) INFO Executor: Finished task 5.0 in stage 229.0 (TID 476). 4899 bytes result sent to driver
23/10/22 22:18:39.660 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 229.0 (TID 476) in 227 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:39.664 Executor task launch worker for task 3.0 in stage 229.0 (TID 474) INFO Executor: Finished task 3.0 in stage 229.0 (TID 474). 4899 bytes result sent to driver
23/10/22 22:18:39.665 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 229.0 (TID 474) in 232 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:39.672 Executor task launch worker for task 4.0 in stage 229.0 (TID 475) INFO Executor: Finished task 4.0 in stage 229.0 (TID 475). 4899 bytes result sent to driver
23/10/22 22:18:39.672 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 229.0 (TID 475) in 239 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:39.675 Executor task launch worker for task 7.0 in stage 229.0 (TID 478) INFO Executor: Finished task 7.0 in stage 229.0 (TID 478). 4899 bytes result sent to driver
23/10/22 22:18:39.676 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 229.0 (TID 478) in 243 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:39.699 Executor task launch worker for task 2.0 in stage 229.0 (TID 473) INFO Executor: Finished task 2.0 in stage 229.0 (TID 473). 4899 bytes result sent to driver
23/10/22 22:18:39.700 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 229.0 (TID 473) in 267 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:39.702 Executor task launch worker for task 6.0 in stage 229.0 (TID 477) INFO Executor: Finished task 6.0 in stage 229.0 (TID 477). 4899 bytes result sent to driver
23/10/22 22:18:39.703 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 229.0 (TID 477) in 270 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:39.713 Executor task launch worker for task 0.0 in stage 229.0 (TID 471) INFO Executor: Finished task 0.0 in stage 229.0 (TID 471). 4899 bytes result sent to driver
23/10/22 22:18:39.716 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 471) in 283 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:39.716 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool 
23/10/22 22:18:39.717 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 229 (rdd at RegressionEvaluator.scala:125) finished in 0.288 s
23/10/22 22:18:39.717 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:39.717 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:39.717 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:18:39.717 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:39.723 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(81), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:18:39.738 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.9597 ms
23/10/22 22:18:39.760 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
23/10/22 22:18:39.761 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 582 (treeAggregate at Statistics.scala:58) as input to shuffle 82
23/10/22 22:18:39.761 dag-scheduler-event-loop INFO DAGScheduler: Got job 129 (treeAggregate at Statistics.scala:58) with 2 output partitions
23/10/22 22:18:39.761 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 233 (treeAggregate at Statistics.scala:58)
23/10/22 22:18:39.761 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 232)
23/10/22 22:18:39.761 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 232)
23/10/22 22:18:39.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 232 (MapPartitionsRDD[582] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:39.765 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 89.8 KiB, free 1037.0 MiB)
23/10/22 22:18:39.768 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 1036.9 MiB)
23/10/22 22:18:39.769 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:55185 (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 22:18:39.769 dag-scheduler-event-loop INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:39.770 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 232 (MapPartitionsRDD[582] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:18:39.770 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 232.0 with 8 tasks resource profile 0
23/10/22 22:18:39.771 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 479) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.771 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 232.0 (TID 480) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 232.0 (TID 481) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 232.0 (TID 482) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 232.0 (TID 483) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 232.0 (TID 484) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 232.0 (TID 485) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 232.0 (TID 486) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:18:39.772 Executor task launch worker for task 3.0 in stage 232.0 (TID 482) INFO Executor: Running task 3.0 in stage 232.0 (TID 482)
23/10/22 22:18:39.772 Executor task launch worker for task 7.0 in stage 232.0 (TID 486) INFO Executor: Running task 7.0 in stage 232.0 (TID 486)
23/10/22 22:18:39.772 Executor task launch worker for task 0.0 in stage 232.0 (TID 479) INFO Executor: Running task 0.0 in stage 232.0 (TID 479)
23/10/22 22:18:39.772 Executor task launch worker for task 5.0 in stage 232.0 (TID 484) INFO Executor: Running task 5.0 in stage 232.0 (TID 484)
23/10/22 22:18:39.772 Executor task launch worker for task 4.0 in stage 232.0 (TID 483) INFO Executor: Running task 4.0 in stage 232.0 (TID 483)
23/10/22 22:18:39.772 Executor task launch worker for task 2.0 in stage 232.0 (TID 481) INFO Executor: Running task 2.0 in stage 232.0 (TID 481)
23/10/22 22:18:39.772 Executor task launch worker for task 1.0 in stage 232.0 (TID 480) INFO Executor: Running task 1.0 in stage 232.0 (TID 480)
23/10/22 22:18:39.772 Executor task launch worker for task 6.0 in stage 232.0 (TID 485) INFO Executor: Running task 6.0 in stage 232.0 (TID 485)
23/10/22 22:18:39.778 Executor task launch worker for task 3.0 in stage 232.0 (TID 482) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 7.0 in stage 232.0 (TID 486) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 6.0 in stage 232.0 (TID 485) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 4.0 in stage 232.0 (TID 483) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 4.0 in stage 232.0 (TID 483) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 5.0 in stage 232.0 (TID 484) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 2.0 in stage 232.0 (TID 481) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 1.0 in stage 232.0 (TID 480) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 2.0 in stage 232.0 (TID 481) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 5.0 in stage 232.0 (TID 484) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 7.0 in stage 232.0 (TID 486) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 0.0 in stage 232.0 (TID 479) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.778 Executor task launch worker for task 6.0 in stage 232.0 (TID 485) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 3.0 in stage 232.0 (TID 482) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 0.0 in stage 232.0 (TID 479) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.778 Executor task launch worker for task 1.0 in stage 232.0 (TID 480) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.788 Executor task launch worker for task 2.0 in stage 232.0 (TID 481) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.788 Executor task launch worker for task 0.0 in stage 232.0 (TID 479) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.788 Executor task launch worker for task 3.0 in stage 232.0 (TID 482) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.788 Executor task launch worker for task 4.0 in stage 232.0 (TID 483) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.788 Executor task launch worker for task 7.0 in stage 232.0 (TID 486) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.789 Executor task launch worker for task 6.0 in stage 232.0 (TID 485) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.803 Executor task launch worker for task 5.0 in stage 232.0 (TID 484) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.807 Executor task launch worker for task 1.0 in stage 232.0 (TID 480) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:18:39.835 Executor task launch worker for task 2.0 in stage 232.0 (TID 481) INFO Executor: Finished task 2.0 in stage 232.0 (TID 481). 6562 bytes result sent to driver
23/10/22 22:18:39.837 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 232.0 (TID 481) in 65 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:18:39.842 Executor task launch worker for task 3.0 in stage 232.0 (TID 482) INFO Executor: Finished task 3.0 in stage 232.0 (TID 482). 6562 bytes result sent to driver
23/10/22 22:18:39.842 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 232.0 (TID 482) in 70 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:18:39.844 Executor task launch worker for task 4.0 in stage 232.0 (TID 483) INFO Executor: Finished task 4.0 in stage 232.0 (TID 483). 6562 bytes result sent to driver
23/10/22 22:18:39.845 task-result-getter-2 INFO TaskSetManager: Finished task 4.0 in stage 232.0 (TID 483) in 73 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:18:39.849 Executor task launch worker for task 0.0 in stage 232.0 (TID 479) INFO Executor: Finished task 0.0 in stage 232.0 (TID 479). 6562 bytes result sent to driver
23/10/22 22:18:39.849 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 479) in 78 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:18:39.858 Executor task launch worker for task 7.0 in stage 232.0 (TID 486) INFO Executor: Finished task 7.0 in stage 232.0 (TID 486). 6562 bytes result sent to driver
23/10/22 22:18:39.860 task-result-getter-0 INFO TaskSetManager: Finished task 7.0 in stage 232.0 (TID 486) in 87 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:18:39.872 Executor task launch worker for task 5.0 in stage 232.0 (TID 484) INFO Executor: Finished task 5.0 in stage 232.0 (TID 484). 6562 bytes result sent to driver
23/10/22 22:18:39.872 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 232.0 (TID 484) in 100 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:18:39.874 Executor task launch worker for task 1.0 in stage 232.0 (TID 480) INFO Executor: Finished task 1.0 in stage 232.0 (TID 480). 6562 bytes result sent to driver
23/10/22 22:18:39.875 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 232.0 (TID 480) in 104 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:18:39.876 Executor task launch worker for task 6.0 in stage 232.0 (TID 485) INFO Executor: Finished task 6.0 in stage 232.0 (TID 485). 6562 bytes result sent to driver
23/10/22 22:18:39.877 task-result-getter-1 INFO TaskSetManager: Finished task 6.0 in stage 232.0 (TID 485) in 104 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:18:39.877 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
23/10/22 22:18:39.877 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 232 (treeAggregate at Statistics.scala:58) finished in 0.115 s
23/10/22 22:18:39.877 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:18:39.877 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:18:39.877 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 233)
23/10/22 22:18:39.877 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:18:39.878 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[584] at treeAggregate at Statistics.scala:58), which has no missing parents
23/10/22 22:18:39.880 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 90.9 KiB, free 1036.8 MiB)
23/10/22 22:18:39.884 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 37.9 KiB, free 1036.8 MiB)
23/10/22 22:18:39.884 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:55185 (size: 37.9 KiB, free: 1037.0 MiB)
23/10/22 22:18:39.885 dag-scheduler-event-loop INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1535
23/10/22 22:18:39.885 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 233 (MapPartitionsRDD[584] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0, 1))
23/10/22 22:18:39.885 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 233.0 with 2 tasks resource profile 0
23/10/22 22:18:39.888 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 487) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:39.888 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 233.0 (TID 488) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
23/10/22 22:18:39.888 Executor task launch worker for task 0.0 in stage 233.0 (TID 487) INFO Executor: Running task 0.0 in stage 233.0 (TID 487)
23/10/22 22:18:39.888 Executor task launch worker for task 1.0 in stage 233.0 (TID 488) INFO Executor: Running task 1.0 in stage 233.0 (TID 488)
23/10/22 22:18:39.897 Executor task launch worker for task 0.0 in stage 233.0 (TID 487) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.897 Executor task launch worker for task 0.0 in stage 233.0 (TID 487) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.897 Executor task launch worker for task 1.0 in stage 233.0 (TID 488) INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:18:39.898 Executor task launch worker for task 1.0 in stage 233.0 (TID 488) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:18:39.912 Executor task launch worker for task 0.0 in stage 233.0 (TID 487) INFO Executor: Finished task 0.0 in stage 233.0 (TID 487). 7673 bytes result sent to driver
23/10/22 22:18:39.912 Executor task launch worker for task 1.0 in stage 233.0 (TID 488) INFO Executor: Finished task 1.0 in stage 233.0 (TID 488). 7673 bytes result sent to driver
23/10/22 22:18:39.913 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 487) in 25 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:18:39.913 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 233.0 (TID 488) in 25 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:18:39.913 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool 
23/10/22 22:18:39.913 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 233 (treeAggregate at Statistics.scala:58) finished in 0.035 s
23/10/22 22:18:39.914 dag-scheduler-event-loop INFO DAGScheduler: Job 129 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:18:39.914 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 233: Stage finished
23/10/22 22:18:39.914 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 129 finished: treeAggregate at Statistics.scala:58, took 0.153230 s
23/10/22 22:20:59.400 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 587 (collect at utils.scala:26) as input to shuffle 83
23/10/22 22:20:59.400 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 130 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:20:59.400 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 234 (collect at utils.scala:26)
23/10/22 22:20:59.400 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:20:59.400 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:20:59.400 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 234 (MapPartitionsRDD[587] at collect at utils.scala:26), which has no missing parents
23/10/22 22:20:59.401 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 32.7 KiB, free 1036.8 MiB)
23/10/22 22:20:59.403 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1036.7 MiB)
23/10/22 22:20:59.403 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.0 MiB)
23/10/22 22:20:59.403 dag-scheduler-event-loop INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1535
23/10/22 22:20:59.403 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 234 (MapPartitionsRDD[587] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:20:59.403 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks resource profile 0
23/10/22 22:20:59.733 dispatcher-event-loop-0 WARN TaskSetManager: Stage 234 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:20:59.733 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 489) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:20:59.734 Executor task launch worker for task 0.0 in stage 234.0 (TID 489) INFO Executor: Running task 0.0 in stage 234.0 (TID 489)
23/10/22 22:20:59.864 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:55185 in memory (size: 37.2 KiB, free: 1037.1 MiB)
23/10/22 22:20:59.871 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:20:59.876 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:55185 in memory (size: 37.9 KiB, free: 1037.1 MiB)
23/10/22 22:20:59.932 Executor task launch worker for task 0.0 in stage 234.0 (TID 489) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.095 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:21:00.766 Executor task launch worker for task 0.0 in stage 234.0 (TID 489) INFO Executor: Finished task 0.0 in stage 234.0 (TID 489). 2104 bytes result sent to driver
23/10/22 22:21:00.766 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 489) in 1362 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:21:00.766 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool 
23/10/22 22:21:00.766 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 234 (collect at utils.scala:26) finished in 1.366 s
23/10/22 22:21:00.766 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:21:00.766 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:21:00.766 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:21:00.766 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:21:00.768 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(83), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:21:00.771 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 591 (collect at utils.scala:26) as input to shuffle 84
23/10/22 22:21:00.771 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 131 (collect at utils.scala:26) with 8 output partitions
23/10/22 22:21:00.771 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 236 (collect at utils.scala:26)
23/10/22 22:21:00.771 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 235)
23/10/22 22:21:00.771 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:21:00.771 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 236 (MapPartitionsRDD[591] at collect at utils.scala:26), which has no missing parents
23/10/22 22:21:00.772 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:21:00.774 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:21:00.774 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:21:00.775 dag-scheduler-event-loop INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1535
23/10/22 22:21:00.775 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 236 (MapPartitionsRDD[591] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:21:00.775 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 236.0 with 8 tasks resource profile 0
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 490) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 236.0 (TID 491) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 236.0 (TID 492) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 236.0 (TID 493) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 236.0 (TID 494) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 236.0 (TID 495) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 6.0 in stage 236.0 (TID 496) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 7.0 in stage 236.0 (TID 497) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:21:00.778 Executor task launch worker for task 0.0 in stage 236.0 (TID 490) INFO Executor: Running task 0.0 in stage 236.0 (TID 490)
23/10/22 22:21:00.779 Executor task launch worker for task 1.0 in stage 236.0 (TID 491) INFO Executor: Running task 1.0 in stage 236.0 (TID 491)
23/10/22 22:21:00.779 Executor task launch worker for task 2.0 in stage 236.0 (TID 492) INFO Executor: Running task 2.0 in stage 236.0 (TID 492)
23/10/22 22:21:00.779 Executor task launch worker for task 3.0 in stage 236.0 (TID 493) INFO Executor: Running task 3.0 in stage 236.0 (TID 493)
23/10/22 22:21:00.779 Executor task launch worker for task 4.0 in stage 236.0 (TID 494) INFO Executor: Running task 4.0 in stage 236.0 (TID 494)
23/10/22 22:21:00.779 Executor task launch worker for task 5.0 in stage 236.0 (TID 495) INFO Executor: Running task 5.0 in stage 236.0 (TID 495)
23/10/22 22:21:00.780 Executor task launch worker for task 6.0 in stage 236.0 (TID 496) INFO Executor: Running task 6.0 in stage 236.0 (TID 496)
23/10/22 22:21:00.781 Executor task launch worker for task 7.0 in stage 236.0 (TID 497) INFO Executor: Running task 7.0 in stage 236.0 (TID 497)
23/10/22 22:21:00.781 Executor task launch worker for task 4.0 in stage 236.0 (TID 494) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 1.0 in stage 236.0 (TID 491) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 6.0 in stage 236.0 (TID 496) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 5.0 in stage 236.0 (TID 495) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 4.0 in stage 236.0 (TID 494) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.781 Executor task launch worker for task 3.0 in stage 236.0 (TID 493) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 2.0 in stage 236.0 (TID 492) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 1.0 in stage 236.0 (TID 491) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.782 Executor task launch worker for task 0.0 in stage 236.0 (TID 490) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.781 Executor task launch worker for task 6.0 in stage 236.0 (TID 496) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.782 Executor task launch worker for task 0.0 in stage 236.0 (TID 490) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.782 Executor task launch worker for task 2.0 in stage 236.0 (TID 492) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.782 Executor task launch worker for task 3.0 in stage 236.0 (TID 493) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.782 Executor task launch worker for task 5.0 in stage 236.0 (TID 495) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:00.787 Executor task launch worker for task 7.0 in stage 236.0 (TID 497) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:00.787 Executor task launch worker for task 7.0 in stage 236.0 (TID 497) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/10/22 22:21:00.788 Executor task launch worker for task 1.0 in stage 236.0 (TID 491) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.788 Executor task launch worker for task 4.0 in stage 236.0 (TID 494) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.788 Executor task launch worker for task 0.0 in stage 236.0 (TID 490) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.798 Executor task launch worker for task 2.0 in stage 236.0 (TID 492) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.800 Executor task launch worker for task 3.0 in stage 236.0 (TID 493) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.802 Executor task launch worker for task 5.0 in stage 236.0 (TID 495) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.807 Executor task launch worker for task 1.0 in stage 236.0 (TID 491) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.816 Executor task launch worker for task 4.0 in stage 236.0 (TID 494) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.830 Executor task launch worker for task 7.0 in stage 236.0 (TID 497) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.831 Executor task launch worker for task 0.0 in stage 236.0 (TID 490) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.846 Executor task launch worker for task 2.0 in stage 236.0 (TID 492) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.847 Executor task launch worker for task 5.0 in stage 236.0 (TID 495) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.848 Executor task launch worker for task 3.0 in stage 236.0 (TID 493) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.848 Executor task launch worker for task 6.0 in stage 236.0 (TID 496) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.868 Executor task launch worker for task 6.0 in stage 236.0 (TID 496) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.881 Executor task launch worker for task 7.0 in stage 236.0 (TID 497) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:00.961 Executor task launch worker for task 1.0 in stage 236.0 (TID 491) INFO Executor: Finished task 1.0 in stage 236.0 (TID 491). 4942 bytes result sent to driver
23/10/22 22:21:00.963 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 236.0 (TID 491) in 184 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:21:00.989 Executor task launch worker for task 0.0 in stage 236.0 (TID 490) INFO Executor: Finished task 0.0 in stage 236.0 (TID 490). 4942 bytes result sent to driver
23/10/22 22:21:00.991 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 490) in 214 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:21:01.003 Executor task launch worker for task 5.0 in stage 236.0 (TID 495) INFO Executor: Finished task 5.0 in stage 236.0 (TID 495). 4942 bytes result sent to driver
23/10/22 22:21:01.004 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 236.0 (TID 495) in 226 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:21:01.006 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:21:01.007 Executor task launch worker for task 6.0 in stage 236.0 (TID 496) INFO Executor: Finished task 6.0 in stage 236.0 (TID 496). 4942 bytes result sent to driver
23/10/22 22:21:01.008 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 236.0 (TID 496) in 230 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:21:01.012 Executor task launch worker for task 2.0 in stage 236.0 (TID 492) INFO Executor: Finished task 2.0 in stage 236.0 (TID 492). 4942 bytes result sent to driver
23/10/22 22:21:01.012 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 236.0 (TID 492) in 234 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:21:01.016 Executor task launch worker for task 3.0 in stage 236.0 (TID 493) INFO Executor: Finished task 3.0 in stage 236.0 (TID 493). 4942 bytes result sent to driver
23/10/22 22:21:01.017 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 236.0 (TID 493) in 239 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:21:01.024 Executor task launch worker for task 4.0 in stage 236.0 (TID 494) INFO Executor: Finished task 4.0 in stage 236.0 (TID 494). 4942 bytes result sent to driver
23/10/22 22:21:01.025 task-result-getter-3 INFO TaskSetManager: Finished task 4.0 in stage 236.0 (TID 494) in 247 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:21:01.030 Executor task launch worker for task 7.0 in stage 236.0 (TID 497) INFO Executor: Finished task 7.0 in stage 236.0 (TID 497). 4942 bytes result sent to driver
23/10/22 22:21:01.031 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 236.0 (TID 497) in 253 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:21:01.031 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool 
23/10/22 22:21:01.031 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 236 (collect at utils.scala:26) finished in 0.260 s
23/10/22 22:21:01.031 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:21:01.031 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:21:01.031 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:21:01.031 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:21:01.033 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(84), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:21:01.046 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:21:01.047 dag-scheduler-event-loop INFO DAGScheduler: Got job 132 (collect at utils.scala:26) with 8 output partitions
23/10/22 22:21:01.047 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 239 (collect at utils.scala:26)
23/10/22 22:21:01.047 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 238)
23/10/22 22:21:01.047 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:21:01.048 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[594] at collect at utils.scala:26), which has no missing parents
23/10/22 22:21:01.051 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 44.0 KiB, free 1037.0 MiB)
23/10/22 22:21:01.051 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1037.0 MiB)
23/10/22 22:21:01.051 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:55185 (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 22:21:01.052 dag-scheduler-event-loop INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1535
23/10/22 22:21:01.052 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 239 (MapPartitionsRDD[594] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:21:01.052 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 239.0 with 8 tasks resource profile 0
23/10/22 22:21:01.052 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 239.0 (TID 498) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 239.0 (TID 499) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 239.0 (TID 500) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 239.0 (TID 501) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 239.0 (TID 502) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 239.0 (TID 503) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 239.0 (TID 504) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 239.0 (TID 505) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7363 bytes) 
23/10/22 22:21:01.053 Executor task launch worker for task 1.0 in stage 239.0 (TID 499) INFO Executor: Running task 1.0 in stage 239.0 (TID 499)
23/10/22 22:21:01.053 Executor task launch worker for task 0.0 in stage 239.0 (TID 498) INFO Executor: Running task 0.0 in stage 239.0 (TID 498)
23/10/22 22:21:01.053 Executor task launch worker for task 2.0 in stage 239.0 (TID 500) INFO Executor: Running task 2.0 in stage 239.0 (TID 500)
23/10/22 22:21:01.054 Executor task launch worker for task 4.0 in stage 239.0 (TID 502) INFO Executor: Running task 4.0 in stage 239.0 (TID 502)
23/10/22 22:21:01.054 Executor task launch worker for task 7.0 in stage 239.0 (TID 505) INFO Executor: Running task 7.0 in stage 239.0 (TID 505)
23/10/22 22:21:01.053 Executor task launch worker for task 3.0 in stage 239.0 (TID 501) INFO Executor: Running task 3.0 in stage 239.0 (TID 501)
23/10/22 22:21:01.053 Executor task launch worker for task 6.0 in stage 239.0 (TID 504) INFO Executor: Running task 6.0 in stage 239.0 (TID 504)
23/10/22 22:21:01.054 Executor task launch worker for task 5.0 in stage 239.0 (TID 503) INFO Executor: Running task 5.0 in stage 239.0 (TID 503)
23/10/22 22:21:01.057 Executor task launch worker for task 2.0 in stage 239.0 (TID 500) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.057 Executor task launch worker for task 6.0 in stage 239.0 (TID 504) INFO ShuffleBlockFetcherIterator: Getting 8 (1351.9 KiB) non-empty blocks including 8 (1351.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.057 Executor task launch worker for task 1.0 in stage 239.0 (TID 499) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.057 Executor task launch worker for task 0.0 in stage 239.0 (TID 498) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.058 Executor task launch worker for task 1.0 in stage 239.0 (TID 499) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.058 Executor task launch worker for task 0.0 in stage 239.0 (TID 498) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.058 Executor task launch worker for task 2.0 in stage 239.0 (TID 500) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.057 Executor task launch worker for task 7.0 in stage 239.0 (TID 505) INFO ShuffleBlockFetcherIterator: Getting 8 (1797.3 KiB) non-empty blocks including 8 (1797.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.058 Executor task launch worker for task 7.0 in stage 239.0 (TID 505) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.057 Executor task launch worker for task 3.0 in stage 239.0 (TID 501) INFO ShuffleBlockFetcherIterator: Getting 8 (1371.3 KiB) non-empty blocks including 8 (1371.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.058 Executor task launch worker for task 6.0 in stage 239.0 (TID 504) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.058 Executor task launch worker for task 3.0 in stage 239.0 (TID 501) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.060 Executor task launch worker for task 5.0 in stage 239.0 (TID 503) INFO ShuffleBlockFetcherIterator: Getting 8 (1102.7 KiB) non-empty blocks including 8 (1102.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.060 Executor task launch worker for task 4.0 in stage 239.0 (TID 502) INFO ShuffleBlockFetcherIterator: Getting 8 (1458.8 KiB) non-empty blocks including 8 (1458.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:21:01.060 Executor task launch worker for task 5.0 in stage 239.0 (TID 503) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.060 Executor task launch worker for task 4.0 in stage 239.0 (TID 502) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:21:01.067 Executor task launch worker for task 6.0 in stage 239.0 (TID 504) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.067 Executor task launch worker for task 0.0 in stage 239.0 (TID 498) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.068 Executor task launch worker for task 1.0 in stage 239.0 (TID 499) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.069 Executor task launch worker for task 4.0 in stage 239.0 (TID 502) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.069 Executor task launch worker for task 5.0 in stage 239.0 (TID 503) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.069 Executor task launch worker for task 3.0 in stage 239.0 (TID 501) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.073 Executor task launch worker for task 7.0 in stage 239.0 (TID 505) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.081 Executor task launch worker for task 2.0 in stage 239.0 (TID 500) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:21:01.100 Executor task launch worker for task 0.0 in stage 239.0 (TID 498) INFO Executor: Finished task 0.0 in stage 239.0 (TID 498). 778717 bytes result sent to driver
23/10/22 22:21:01.102 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 239.0 (TID 498) in 50 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:21:01.102 Executor task launch worker for task 5.0 in stage 239.0 (TID 503) INFO Executor: Finished task 5.0 in stage 239.0 (TID 503). 649348 bytes result sent to driver
23/10/22 22:21:01.102 Executor task launch worker for task 6.0 in stage 239.0 (TID 504) INFO Executor: Finished task 6.0 in stage 239.0 (TID 504). 815967 bytes result sent to driver
23/10/22 22:21:01.103 Executor task launch worker for task 3.0 in stage 239.0 (TID 501) INFO Executor: Finished task 3.0 in stage 239.0 (TID 501). 819171 bytes result sent to driver
23/10/22 22:21:01.103 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 239.0 (TID 503) in 50 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:21:01.105 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 239.0 (TID 504) in 52 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:21:01.105 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 239.0 (TID 501) in 52 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:21:01.105 Executor task launch worker for task 4.0 in stage 239.0 (TID 502) INFO Executor: Finished task 4.0 in stage 239.0 (TID 502). 873673 bytes result sent to driver
23/10/22 22:21:01.107 task-result-getter-1 INFO TaskSetManager: Finished task 4.0 in stage 239.0 (TID 502) in 54 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:21:01.108 Executor task launch worker for task 1.0 in stage 239.0 (TID 499) INFO Executor: Finished task 1.0 in stage 239.0 (TID 499). 747484 bytes result sent to driver
23/10/22 22:21:01.110 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 239.0 (TID 499) in 57 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:21:01.129 Executor task launch worker for task 2.0 in stage 239.0 (TID 500) INFO Executor: Finished task 2.0 in stage 239.0 (TID 500). 745936 bytes result sent to driver
23/10/22 22:21:01.130 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 239.0 (TID 500) in 77 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:21:01.133 Executor task launch worker for task 7.0 in stage 239.0 (TID 505) INFO MemoryStore: Block taskresult_505 stored as bytes in memory (estimated size 1052.4 KiB, free 1036.0 MiB)
23/10/22 22:21:01.133 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added taskresult_505 in memory on 127.0.0.1:55185 (size: 1052.4 KiB, free: 1036.1 MiB)
23/10/22 22:21:01.134 Executor task launch worker for task 7.0 in stage 239.0 (TID 505) INFO Executor: Finished task 7.0 in stage 239.0 (TID 505). 1077694 bytes result sent via BlockManager)
23/10/22 22:21:01.153 task-result-getter-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:55185 after 2 ms (0 ms spent in bootstraps)
23/10/22 22:21:01.193 task-result-getter-2 INFO TaskSetManager: Finished task 7.0 in stage 239.0 (TID 505) in 140 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:21:01.193 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool 
23/10/22 22:21:01.194 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 239 (collect at utils.scala:26) finished in 0.144 s
23/10/22 22:21:01.194 dag-scheduler-event-loop INFO DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:21:01.194 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 239: Stage finished
23/10/22 22:21:01.194 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 132 finished: collect at utils.scala:26, took 0.147250 s
23/10/22 22:21:01.194 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed taskresult_505 on 127.0.0.1:55185 in memory (size: 1052.4 KiB, free: 1037.1 MiB)
23/10/22 22:33:34.793 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:33:34.800 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:55185 in memory (size: 18.8 KiB, free: 1037.1 MiB)
23/10/22 22:33:34.939 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 597 (collect at utils.scala:26) as input to shuffle 85
23/10/22 22:33:34.939 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 133 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:33:34.939 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 240 (collect at utils.scala:26)
23/10/22 22:33:34.939 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/10/22 22:33:34.939 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:33:34.940 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 240 (MapPartitionsRDD[597] at collect at utils.scala:26), which has no missing parents
23/10/22 22:33:34.941 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 32.7 KiB, free 1037.1 MiB)
23/10/22 22:33:34.944 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1037.1 MiB)
23/10/22 22:33:34.945 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:55185 (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:33:34.945 dag-scheduler-event-loop INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1535
23/10/22 22:33:34.945 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 240 (MapPartitionsRDD[597] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:33:34.945 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks resource profile 0
23/10/22 22:33:35.366 dispatcher-event-loop-3 WARN TaskSetManager: Stage 240 contains a task of very large size (78040 KiB). The maximum recommended task size is 1000 KiB.
23/10/22 22:33:35.366 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 506) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 79913670 bytes) 
23/10/22 22:33:35.367 Executor task launch worker for task 0.0 in stage 240.0 (TID 506) INFO Executor: Running task 0.0 in stage 240.0 (TID 506)
23/10/22 22:33:35.520 Executor task launch worker for task 0.0 in stage 240.0 (TID 506) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.508 Executor task launch worker for task 0.0 in stage 240.0 (TID 506) INFO Executor: Finished task 0.0 in stage 240.0 (TID 506). 2104 bytes result sent to driver
23/10/22 22:33:36.508 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 506) in 1562 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:33:36.508 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool 
23/10/22 22:33:36.509 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 240 (collect at utils.scala:26) finished in 1.569 s
23/10/22 22:33:36.509 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:33:36.509 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:33:36.509 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:33:36.509 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:33:36.513 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(85), advisory target size: 67108864, actual target size 1489036, minimum partition size: 1048576
23/10/22 22:33:36.517 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 601 (collect at utils.scala:26) as input to shuffle 86
23/10/22 22:33:36.518 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 134 (collect at utils.scala:26) with 8 output partitions
23/10/22 22:33:36.518 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 242 (collect at utils.scala:26)
23/10/22 22:33:36.518 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 241)
23/10/22 22:33:36.518 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:33:36.518 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 242 (MapPartitionsRDD[601] at collect at utils.scala:26), which has no missing parents
23/10/22 22:33:36.519 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 37.8 KiB, free 1037.1 MiB)
23/10/22 22:33:36.520 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1037.0 MiB)
23/10/22 22:33:36.520 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:55185 (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:33:36.520 dag-scheduler-event-loop INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1535
23/10/22 22:33:36.520 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 242 (MapPartitionsRDD[601] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/10/22 22:33:36.520 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 242.0 with 8 tasks resource profile 0
23/10/22 22:33:36.521 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 507) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.521 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 242.0 (TID 508) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.521 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 242.0 (TID 509) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.521 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 242.0 (TID 510) (127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.521 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 4.0 in stage 242.0 (TID 511) (127.0.0.1, executor driver, partition 4, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.521 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 5.0 in stage 242.0 (TID 512) (127.0.0.1, executor driver, partition 5, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.522 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 6.0 in stage 242.0 (TID 513) (127.0.0.1, executor driver, partition 6, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.522 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 242.0 (TID 514) (127.0.0.1, executor driver, partition 7, NODE_LOCAL, 7352 bytes) 
23/10/22 22:33:36.522 Executor task launch worker for task 0.0 in stage 242.0 (TID 507) INFO Executor: Running task 0.0 in stage 242.0 (TID 507)
23/10/22 22:33:36.522 Executor task launch worker for task 1.0 in stage 242.0 (TID 508) INFO Executor: Running task 1.0 in stage 242.0 (TID 508)
23/10/22 22:33:36.522 Executor task launch worker for task 2.0 in stage 242.0 (TID 509) INFO Executor: Running task 2.0 in stage 242.0 (TID 509)
23/10/22 22:33:36.522 Executor task launch worker for task 3.0 in stage 242.0 (TID 510) INFO Executor: Running task 3.0 in stage 242.0 (TID 510)
23/10/22 22:33:36.522 Executor task launch worker for task 4.0 in stage 242.0 (TID 511) INFO Executor: Running task 4.0 in stage 242.0 (TID 511)
23/10/22 22:33:36.523 Executor task launch worker for task 5.0 in stage 242.0 (TID 512) INFO Executor: Running task 5.0 in stage 242.0 (TID 512)
23/10/22 22:33:36.523 Executor task launch worker for task 6.0 in stage 242.0 (TID 513) INFO Executor: Running task 6.0 in stage 242.0 (TID 513)
23/10/22 22:33:36.525 Executor task launch worker for task 0.0 in stage 242.0 (TID 507) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.525 Executor task launch worker for task 7.0 in stage 242.0 (TID 514) INFO Executor: Running task 7.0 in stage 242.0 (TID 514)
23/10/22 22:33:36.525 Executor task launch worker for task 0.0 in stage 242.0 (TID 507) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.525 Executor task launch worker for task 6.0 in stage 242.0 (TID 513) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.525 Executor task launch worker for task 6.0 in stage 242.0 (TID 513) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.525 Executor task launch worker for task 3.0 in stage 242.0 (TID 510) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.525 Executor task launch worker for task 3.0 in stage 242.0 (TID 510) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.525 Executor task launch worker for task 5.0 in stage 242.0 (TID 512) INFO ShuffleBlockFetcherIterator: Getting 1 (1579.8 KiB) non-empty blocks including 1 (1579.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.525 Executor task launch worker for task 5.0 in stage 242.0 (TID 512) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.525 Executor task launch worker for task 4.0 in stage 242.0 (TID 511) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.526 Executor task launch worker for task 4.0 in stage 242.0 (TID 511) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.526 Executor task launch worker for task 1.0 in stage 242.0 (TID 508) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.526 Executor task launch worker for task 2.0 in stage 242.0 (TID 509) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.526 Executor task launch worker for task 1.0 in stage 242.0 (TID 508) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.526 Executor task launch worker for task 2.0 in stage 242.0 (TID 509) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.527 Executor task launch worker for task 7.0 in stage 242.0 (TID 514) INFO ShuffleBlockFetcherIterator: Getting 1 (1436.2 KiB) non-empty blocks including 1 (1436.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.527 Executor task launch worker for task 7.0 in stage 242.0 (TID 514) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.531 Executor task launch worker for task 1.0 in stage 242.0 (TID 508) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.531 Executor task launch worker for task 0.0 in stage 242.0 (TID 507) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.532 Executor task launch worker for task 4.0 in stage 242.0 (TID 511) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.534 Executor task launch worker for task 2.0 in stage 242.0 (TID 509) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.535 Executor task launch worker for task 7.0 in stage 242.0 (TID 514) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.536 Executor task launch worker for task 3.0 in stage 242.0 (TID 510) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.540 Executor task launch worker for task 5.0 in stage 242.0 (TID 512) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.544 Executor task launch worker for task 6.0 in stage 242.0 (TID 513) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.547 Executor task launch worker for task 1.0 in stage 242.0 (TID 508) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.554 Executor task launch worker for task 4.0 in stage 242.0 (TID 511) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.563 Executor task launch worker for task 5.0 in stage 242.0 (TID 512) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.572 Executor task launch worker for task 7.0 in stage 242.0 (TID 514) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.578 Executor task launch worker for task 2.0 in stage 242.0 (TID 509) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.600 Executor task launch worker for task 3.0 in stage 242.0 (TID 510) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.601 Executor task launch worker for task 6.0 in stage 242.0 (TID 513) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.605 Executor task launch worker for task 0.0 in stage 242.0 (TID 507) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.685 Executor task launch worker for task 4.0 in stage 242.0 (TID 511) INFO Executor: Finished task 4.0 in stage 242.0 (TID 511). 4942 bytes result sent to driver
23/10/22 22:33:36.688 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 242.0 (TID 511) in 167 ms on 127.0.0.1 (executor driver) (1/8)
23/10/22 22:33:36.689 Executor task launch worker for task 1.0 in stage 242.0 (TID 508) INFO Executor: Finished task 1.0 in stage 242.0 (TID 508). 4942 bytes result sent to driver
23/10/22 22:33:36.690 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 242.0 (TID 508) in 169 ms on 127.0.0.1 (executor driver) (2/8)
23/10/22 22:33:36.761 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:55185 in memory (size: 14.8 KiB, free: 1037.1 MiB)
23/10/22 22:33:36.774 Executor task launch worker for task 5.0 in stage 242.0 (TID 512) INFO Executor: Finished task 5.0 in stage 242.0 (TID 512). 4942 bytes result sent to driver
23/10/22 22:33:36.776 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 242.0 (TID 512) in 255 ms on 127.0.0.1 (executor driver) (3/8)
23/10/22 22:33:36.802 Executor task launch worker for task 0.0 in stage 242.0 (TID 507) INFO Executor: Finished task 0.0 in stage 242.0 (TID 507). 4942 bytes result sent to driver
23/10/22 22:33:36.803 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 507) in 282 ms on 127.0.0.1 (executor driver) (4/8)
23/10/22 22:33:36.808 Executor task launch worker for task 2.0 in stage 242.0 (TID 509) INFO Executor: Finished task 2.0 in stage 242.0 (TID 509). 4942 bytes result sent to driver
23/10/22 22:33:36.809 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 242.0 (TID 509) in 288 ms on 127.0.0.1 (executor driver) (5/8)
23/10/22 22:33:36.812 Executor task launch worker for task 7.0 in stage 242.0 (TID 514) INFO Executor: Finished task 7.0 in stage 242.0 (TID 514). 4942 bytes result sent to driver
23/10/22 22:33:36.814 task-result-getter-3 INFO TaskSetManager: Finished task 7.0 in stage 242.0 (TID 514) in 292 ms on 127.0.0.1 (executor driver) (6/8)
23/10/22 22:33:36.822 Executor task launch worker for task 6.0 in stage 242.0 (TID 513) INFO Executor: Finished task 6.0 in stage 242.0 (TID 513). 4942 bytes result sent to driver
23/10/22 22:33:36.822 task-result-getter-2 INFO TaskSetManager: Finished task 6.0 in stage 242.0 (TID 513) in 301 ms on 127.0.0.1 (executor driver) (7/8)
23/10/22 22:33:36.825 Executor task launch worker for task 3.0 in stage 242.0 (TID 510) INFO Executor: Finished task 3.0 in stage 242.0 (TID 510). 4942 bytes result sent to driver
23/10/22 22:33:36.827 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 242.0 (TID 510) in 306 ms on 127.0.0.1 (executor driver) (8/8)
23/10/22 22:33:36.827 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
23/10/22 22:33:36.827 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 242 (collect at utils.scala:26) finished in 0.309 s
23/10/22 22:33:36.827 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
23/10/22 22:33:36.827 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
23/10/22 22:33:36.827 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
23/10/22 22:33:36.827 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
23/10/22 22:33:36.829 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(86), advisory target size: 67108864, actual target size 1388758, minimum partition size: 1048576
23/10/22 22:33:36.846 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.1869 ms
23/10/22 22:33:36.856 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:33:36.857 dag-scheduler-event-loop INFO DAGScheduler: Got job 135 (collect at utils.scala:26) with 1 output partitions
23/10/22 22:33:36.857 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 245 (collect at utils.scala:26)
23/10/22 22:33:36.857 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 244)
23/10/22 22:33:36.857 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:33:36.857 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 245 (MapPartitionsRDD[605] at collect at utils.scala:26), which has no missing parents
23/10/22 22:33:36.859 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 50.7 KiB, free 1037.0 MiB)
23/10/22 22:33:36.860 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 1037.0 MiB)
23/10/22 22:33:36.861 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:55185 (size: 21.6 KiB, free: 1037.1 MiB)
23/10/22 22:33:36.861 dag-scheduler-event-loop INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1535
23/10/22 22:33:36.862 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 245 (MapPartitionsRDD[605] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/10/22 22:33:36.862 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 245.0 with 1 tasks resource profile 0
23/10/22 22:33:36.863 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 245.0 (TID 515) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
23/10/22 22:33:36.863 Executor task launch worker for task 0.0 in stage 245.0 (TID 515) INFO Executor: Running task 0.0 in stage 245.0 (TID 515)
23/10/22 22:33:36.867 Executor task launch worker for task 0.0 in stage 245.0 (TID 515) INFO ShuffleBlockFetcherIterator: Getting 8 (1272.9 KiB) non-empty blocks including 8 (1272.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.867 Executor task launch worker for task 0.0 in stage 245.0 (TID 515) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.878 Executor task launch worker for task 0.0 in stage 245.0 (TID 515) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.908 Executor task launch worker for task 0.0 in stage 245.0 (TID 515) INFO Executor: Finished task 0.0 in stage 245.0 (TID 515). 624717 bytes result sent to driver
23/10/22 22:33:36.910 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 245.0 (TID 515) in 47 ms on 127.0.0.1 (executor driver) (1/1)
23/10/22 22:33:36.910 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool 
23/10/22 22:33:36.911 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 245 (collect at utils.scala:26) finished in 0.054 s
23/10/22 22:33:36.911 dag-scheduler-event-loop INFO DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:33:36.911 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 245: Stage finished
23/10/22 22:33:36.911 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 135 finished: collect at utils.scala:26, took 0.054258 s
23/10/22 22:33:36.918 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/10/22 22:33:36.918 dag-scheduler-event-loop INFO DAGScheduler: Got job 136 (collect at utils.scala:26) with 2 output partitions
23/10/22 22:33:36.918 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 248 (collect at utils.scala:26)
23/10/22 22:33:36.918 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 247)
23/10/22 22:33:36.918 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/10/22 22:33:36.918 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 248 (MapPartitionsRDD[605] at collect at utils.scala:26), which has no missing parents
23/10/22 22:33:36.920 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 50.7 KiB, free 1037.0 MiB)
23/10/22 22:33:36.921 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 1036.9 MiB)
23/10/22 22:33:36.921 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:55185 (size: 21.6 KiB, free: 1037.1 MiB)
23/10/22 22:33:36.921 dag-scheduler-event-loop INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1535
23/10/22 22:33:36.921 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 248 (MapPartitionsRDD[605] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(1, 2))
23/10/22 22:33:36.921 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 248.0 with 2 tasks resource profile 0
23/10/22 22:33:36.922 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 516) (127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7363 bytes) 
23/10/22 22:33:36.922 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 248.0 (TID 517) (127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7363 bytes) 
23/10/22 22:33:36.922 Executor task launch worker for task 0.0 in stage 248.0 (TID 516) INFO Executor: Running task 0.0 in stage 248.0 (TID 516)
23/10/22 22:33:36.922 Executor task launch worker for task 1.0 in stage 248.0 (TID 517) INFO Executor: Running task 1.0 in stage 248.0 (TID 517)
23/10/22 22:33:36.926 Executor task launch worker for task 0.0 in stage 248.0 (TID 516) INFO ShuffleBlockFetcherIterator: Getting 8 (1261.3 KiB) non-empty blocks including 8 (1261.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.926 Executor task launch worker for task 1.0 in stage 248.0 (TID 517) INFO ShuffleBlockFetcherIterator: Getting 8 (1233.4 KiB) non-empty blocks including 8 (1233.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/10/22 22:33:36.926 Executor task launch worker for task 0.0 in stage 248.0 (TID 516) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.926 Executor task launch worker for task 1.0 in stage 248.0 (TID 517) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/10/22 22:33:36.936 Executor task launch worker for task 1.0 in stage 248.0 (TID 517) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.936 Executor task launch worker for task 0.0 in stage 248.0 (TID 516) INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
23/10/22 22:33:36.970 Executor task launch worker for task 0.0 in stage 248.0 (TID 516) INFO Executor: Finished task 0.0 in stage 248.0 (TID 516). 609618 bytes result sent to driver
23/10/22 22:33:36.970 Executor task launch worker for task 1.0 in stage 248.0 (TID 517) INFO Executor: Finished task 1.0 in stage 248.0 (TID 517). 576686 bytes result sent to driver
23/10/22 22:33:36.971 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:55185 in memory (size: 17.1 KiB, free: 1037.1 MiB)
23/10/22 22:33:36.972 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 516) in 49 ms on 127.0.0.1 (executor driver) (1/2)
23/10/22 22:33:36.972 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 248.0 (TID 517) in 50 ms on 127.0.0.1 (executor driver) (2/2)
23/10/22 22:33:36.972 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool 
23/10/22 22:33:36.973 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 248 (collect at utils.scala:26) finished in 0.054 s
23/10/22 22:33:36.973 dag-scheduler-event-loop INFO DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job
23/10/22 22:33:36.973 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 248: Stage finished
23/10/22 22:33:36.973 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 136 finished: collect at utils.scala:26, took 0.056242 s
23/10/22 22:33:36.977 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:55185 in memory (size: 21.6 KiB, free: 1037.1 MiB)
